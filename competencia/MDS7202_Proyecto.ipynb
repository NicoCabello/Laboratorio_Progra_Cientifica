{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Proyecto: El Desafío de Don Rene\n",
        "\n",
        "**MDS7202: Laboratorio de Programación Científica para Ciencia de Datos**\n",
        "\n",
        "### Cuerpo Docente:\n",
        "\n",
        "- Profesores: Matías Rojas - Mauricio Araneda\n",
        "- Auxiliar: Ignacio Meza D.\n",
        "- Ayudante: Rodrigo Guerra\n",
        "\n",
        "*Por favor, lean detalladamente las instrucciones de la tarea antes de empezar a escribir.*\n"
      ],
      "metadata": {
        "cell_id": "00000-f53914fc-294a-4bd9-ab99-c7f9f7e072d9",
        "deepnote_cell_type": "markdown",
        "id": "yNkIyWMw3pvz"
      },
      "id": "yNkIyWMw3pvz"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# Proyecto\n",
        "\n",
        "### Equipo:\n",
        "\n",
        "- Nicolás Cabello\n",
        "- Esteban Muñoz\n",
        "\n",
        "- Usuario CodaLab: NicoCabello\n",
        "\n",
        "- Equipo CodaLab: Never Gonna Give You Up\n",
        "\n",
        "### Link de repositorio de GitHub: `https://github.com/NicoCabello/Laboratorio_Progra_Cientifica`\n",
        "\n"
      ],
      "metadata": {
        "cell_id": "00005-7921fb53-59e9-49a1-a5a5-dec92da88299",
        "deepnote_cell_type": "markdown",
        "id": "f8v2to7-3pv1"
      },
      "id": "f8v2to7-3pv1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 1. Introducción\n",
        "\n",
        "El objetivo de este proyecto consiste en generar dos modelos de predicción aplicados a datos de videojuegos.\n",
        "El primer modelo es aplicado a un problema de clasificación del *rating* (evaluación) de un juego, con las posibilidades de ser `('Negative', 'Mixed', 'Mostly Positive', 'Positive', 'Very Positive')`. El segundo modelo se aplica a un problemas de regresión de la cantidad de *ventas* que alcance un juego.\n",
        "\n",
        "Las métricas a utilizar para evaluar la calidad de los modelos son `f1_weighted` para la clasificación y `r_2` para la regresión.\n",
        "La métrica `f1` es una media armónica entre las métricas `precision` y `recall`, reduciendo el desempeño si los valores de ambas métricas son muy diferentes, pero además considera un peso promedio por cada clase mejorando el problema del desbalance en las clases.\n",
        "Es muy útil para el problema de clasificación ya que considera el desbalance que puede haber en las clases, además de combinar de manera armónica dos métricas comunmente utilizadas.\n",
        "\n",
        "En cuanto a la métrica `r_2`, representa la proporción de varianza de los valores predichos por el modelo con respecto a la los target reales.\n",
        "Es útil para regresiones indicando cuanto se acercan los valores predichos de los valores reales, por lo que es una métrica acorde para el problema de regresión en la ventas.\n",
        "\n",
        "\n",
        "Los datos que proveen es un dataset con 7881 ejemplos que describen una observación de la información de videojuegos, tales como su nombre, los developers y publishers, la descripción de \n",
        "Son 16 atributos y la variables objetivos son de la categoría a la que pertenece, además de la edad mínima, plataformas para la que está disponible, entre otros datos.\n",
        "Las variables de interés son del tipo numérico para el caso de *ventas* y *ordinal* para el caso del *rating* (datos categóricos con orden)."
      ],
      "metadata": {
        "cell_id": "00006-200f2a79-7517-4226-8a5b-438553fa1b13",
        "deepnote_cell_type": "markdown",
        "id": "dHT7oe6E3pv1"
      },
      "id": "dHT7oe6E3pv1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 2. Análisis Exploratorio de Datos"
      ],
      "metadata": {
        "cell_id": "00007-d1ce17da-f6e0-4c12-bbe8-a40a46e7371b",
        "deepnote_cell_type": "markdown",
        "id": "wZR-D01W3pv2"
      },
      "id": "wZR-D01W3pv2"
    },
    {
      "cell_type": "code",
      "source": [
        "def mount_drive(path):\n",
        "    try:\n",
        "        from google.colab import drive\n",
        "\n",
        "        drive.mount(\"/content/drive\")\n",
        "        %cd {path}\n",
        "    except: \n",
        "        print('Ignorando conexión drive-colab')"
      ],
      "metadata": {
        "id": "aAVbTc3Wf170"
      },
      "id": "aAVbTc3Wf170",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mount_drive(\"/content/drive/My Drive/MDS7202/Proyecto\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RA4WIdbDf80E",
        "outputId": "36c96cfc-296c-4dd3-ce1a-040ee128bcf8"
      },
      "id": "RA4WIdbDf80E",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/MDS7202/Proyecto\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.model_selection import train_test_split \n",
        "\n",
        "# Pre-procesamiento\n",
        "from sklearn.feature_selection import SelectPercentile, f_classif\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Clasificación\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "#Regresión\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Metricas de evaluación\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, median_absolute_error\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Librería para plotear\n",
        "!pip install --upgrade plotly\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# Librería para NLP\n",
        "!pip install nltk\n",
        "import nltk\n",
        "from nltk import word_tokenize  \n",
        "from nltk.stem import PorterStemmer\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Grilla\n",
        "from sklearn.experimental import enable_halving_search_cv\n",
        "from sklearn.model_selection import HalvingGridSearchCV\n",
        "\n",
        "# Descarga de figuras\n",
        "!pip install -U kaleido\n",
        "\n",
        "from collections import Counter\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCdjuQ4YhJMb",
        "outputId": "432a1f8a-1abd-4010-bb99-c2b6c73b82c2"
      },
      "id": "MCdjuQ4YhJMb",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.8/dist-packages (5.5.0)\n",
            "Collecting plotly\n",
            "  Downloading plotly-5.11.0-py2.py3-none-any.whl (15.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.3 MB 14.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from plotly) (8.1.0)\n",
            "Installing collected packages: plotly\n",
            "  Attempting uninstall: plotly\n",
            "    Found existing installation: plotly 5.5.0\n",
            "    Uninstalling plotly-5.5.0:\n",
            "      Successfully uninstalled plotly-5.5.0\n",
            "Successfully installed plotly-5.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "00008-aae529ec-fdde-46f4-8c4c-f57d7f0f0a11",
        "deepnote_cell_type": "code",
        "id": "AyTVALPj3pv2"
      },
      "source": [
        "df_train = pd.read_pickle(\"train.pickle\")\n",
        "df_test = pd.read_pickle(\"test.pickle\")"
      ],
      "execution_count": 336,
      "outputs": [],
      "id": "AyTVALPj3pv2"
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "MBlYLZskdwzM",
        "outputId": "3170f6f1-180b-4bf4-8654-07c82a4187b6"
      },
      "id": "MBlYLZskdwzM",
      "execution_count": 337,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                name release_date  english                     developer  \\\n",
              "0      An Aspie Life   2018-03-29        1  Bradley Hennessey;Joe Watson   \n",
              "1  GhostControl Inc.   2014-06-06        1                     bumblebee   \n",
              "2            Deponia   2012-08-06        1        Daedalic Entertainment   \n",
              "3      Atlas Reactor   2016-10-04        1                  Trion Worlds   \n",
              "4            CHUCHEL   2018-03-07        1                Amanita Design   \n",
              "\n",
              "                        publisher          platforms  required_age  \\\n",
              "0               EnderLost Studios            windows             0   \n",
              "1  Application Systems Heidelberg  windows;mac;linux             0   \n",
              "2          Daedalic Entertainment  windows;mac;linux             0   \n",
              "3                    Trion Worlds            windows             0   \n",
              "4                  Amanita Design        windows;mac             0   \n",
              "\n",
              "                                          categories  \\\n",
              "0                   Single-player;Steam Achievements   \n",
              "1  Single-player;Steam Achievements;Steam Trading...   \n",
              "2  Single-player;Steam Achievements;Steam Trading...   \n",
              "3  Multi-player;Online Multi-Player;Steam Achieve...   \n",
              "4  Single-player;Steam Achievements;Steam Trading...   \n",
              "\n",
              "                                           genres  \\\n",
              "0  Adventure;Casual;Free to Play;Indie;Simulation   \n",
              "1                Casual;Indie;Simulation;Strategy   \n",
              "2                                 Adventure;Indie   \n",
              "3                           Free to Play;Strategy   \n",
              "4                          Adventure;Casual;Indie   \n",
              "\n",
              "                                tags  achievements  average_playtime  price  \\\n",
              "0       Free to Play;Adventure;Indie            23                 0   0.00   \n",
              "1        Turn-Based;Indie;Simulation            53                65  10.99   \n",
              "2     Adventure;Point & Click;Comedy            19               217   6.99   \n",
              "3  Free to Play;Multiplayer;Strategy           121              1240   0.00   \n",
              "4             Adventure;Indie;Casual             7               245   7.99   \n",
              "\n",
              "                                   short_description  estimated_sells  \\\n",
              "0  One day your roommate Leaves for no reason. Yo...             3914   \n",
              "1  Manage a team of ghosthunters and free London ...            10728   \n",
              "2  In Deponia, the world has degenerated into a v...           635792   \n",
              "3  SEASON 6 NOW LIVE! The battle for Atlas contin...           253864   \n",
              "4  CHUCHEL is a comedy adventure game from the cr...            49818   \n",
              "\n",
              "            rating  \n",
              "0            Mixed  \n",
              "1            Mixed  \n",
              "2         Positive  \n",
              "3         Positive  \n",
              "4  Mostly Positive  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cdf0508b-c0c2-4eca-94e2-c50ef6b4bf78\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>release_date</th>\n",
              "      <th>english</th>\n",
              "      <th>developer</th>\n",
              "      <th>publisher</th>\n",
              "      <th>platforms</th>\n",
              "      <th>required_age</th>\n",
              "      <th>categories</th>\n",
              "      <th>genres</th>\n",
              "      <th>tags</th>\n",
              "      <th>achievements</th>\n",
              "      <th>average_playtime</th>\n",
              "      <th>price</th>\n",
              "      <th>short_description</th>\n",
              "      <th>estimated_sells</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>An Aspie Life</td>\n",
              "      <td>2018-03-29</td>\n",
              "      <td>1</td>\n",
              "      <td>Bradley Hennessey;Joe Watson</td>\n",
              "      <td>EnderLost Studios</td>\n",
              "      <td>windows</td>\n",
              "      <td>0</td>\n",
              "      <td>Single-player;Steam Achievements</td>\n",
              "      <td>Adventure;Casual;Free to Play;Indie;Simulation</td>\n",
              "      <td>Free to Play;Adventure;Indie</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>One day your roommate Leaves for no reason. Yo...</td>\n",
              "      <td>3914</td>\n",
              "      <td>Mixed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>GhostControl Inc.</td>\n",
              "      <td>2014-06-06</td>\n",
              "      <td>1</td>\n",
              "      <td>bumblebee</td>\n",
              "      <td>Application Systems Heidelberg</td>\n",
              "      <td>windows;mac;linux</td>\n",
              "      <td>0</td>\n",
              "      <td>Single-player;Steam Achievements;Steam Trading...</td>\n",
              "      <td>Casual;Indie;Simulation;Strategy</td>\n",
              "      <td>Turn-Based;Indie;Simulation</td>\n",
              "      <td>53</td>\n",
              "      <td>65</td>\n",
              "      <td>10.99</td>\n",
              "      <td>Manage a team of ghosthunters and free London ...</td>\n",
              "      <td>10728</td>\n",
              "      <td>Mixed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Deponia</td>\n",
              "      <td>2012-08-06</td>\n",
              "      <td>1</td>\n",
              "      <td>Daedalic Entertainment</td>\n",
              "      <td>Daedalic Entertainment</td>\n",
              "      <td>windows;mac;linux</td>\n",
              "      <td>0</td>\n",
              "      <td>Single-player;Steam Achievements;Steam Trading...</td>\n",
              "      <td>Adventure;Indie</td>\n",
              "      <td>Adventure;Point &amp; Click;Comedy</td>\n",
              "      <td>19</td>\n",
              "      <td>217</td>\n",
              "      <td>6.99</td>\n",
              "      <td>In Deponia, the world has degenerated into a v...</td>\n",
              "      <td>635792</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Atlas Reactor</td>\n",
              "      <td>2016-10-04</td>\n",
              "      <td>1</td>\n",
              "      <td>Trion Worlds</td>\n",
              "      <td>Trion Worlds</td>\n",
              "      <td>windows</td>\n",
              "      <td>0</td>\n",
              "      <td>Multi-player;Online Multi-Player;Steam Achieve...</td>\n",
              "      <td>Free to Play;Strategy</td>\n",
              "      <td>Free to Play;Multiplayer;Strategy</td>\n",
              "      <td>121</td>\n",
              "      <td>1240</td>\n",
              "      <td>0.00</td>\n",
              "      <td>SEASON 6 NOW LIVE! The battle for Atlas contin...</td>\n",
              "      <td>253864</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CHUCHEL</td>\n",
              "      <td>2018-03-07</td>\n",
              "      <td>1</td>\n",
              "      <td>Amanita Design</td>\n",
              "      <td>Amanita Design</td>\n",
              "      <td>windows;mac</td>\n",
              "      <td>0</td>\n",
              "      <td>Single-player;Steam Achievements;Steam Trading...</td>\n",
              "      <td>Adventure;Casual;Indie</td>\n",
              "      <td>Adventure;Indie;Casual</td>\n",
              "      <td>7</td>\n",
              "      <td>245</td>\n",
              "      <td>7.99</td>\n",
              "      <td>CHUCHEL is a comedy adventure game from the cr...</td>\n",
              "      <td>49818</td>\n",
              "      <td>Mostly Positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cdf0508b-c0c2-4eca-94e2-c50ef6b4bf78')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cdf0508b-c0c2-4eca-94e2-c50ef6b4bf78 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cdf0508b-c0c2-4eca-94e2-c50ef6b4bf78');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 337
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Al visualizar los datos de cada columna, es fácil percatarse que algunas variables de texto cuentan con el caracter \";\". La siguiente celda muestra algunos ejemplos de ello."
      ],
      "metadata": {
        "id": "fdoTSzcgtmnP"
      },
      "id": "fdoTSzcgtmnP"
    },
    {
      "cell_type": "code",
      "source": [
        "df_train[[\"developer\", \"platforms\", \"genres\", \"tags\"]].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "IT-nppXgTzdB",
        "outputId": "7f931d29-b0fe-40d6-e4de-c5111e49f993"
      },
      "id": "IT-nppXgTzdB",
      "execution_count": 338,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      developer          platforms  \\\n",
              "0  Bradley Hennessey;Joe Watson            windows   \n",
              "1                     bumblebee  windows;mac;linux   \n",
              "2        Daedalic Entertainment  windows;mac;linux   \n",
              "3                  Trion Worlds            windows   \n",
              "4                Amanita Design        windows;mac   \n",
              "\n",
              "                                           genres  \\\n",
              "0  Adventure;Casual;Free to Play;Indie;Simulation   \n",
              "1                Casual;Indie;Simulation;Strategy   \n",
              "2                                 Adventure;Indie   \n",
              "3                           Free to Play;Strategy   \n",
              "4                          Adventure;Casual;Indie   \n",
              "\n",
              "                                tags  \n",
              "0       Free to Play;Adventure;Indie  \n",
              "1        Turn-Based;Indie;Simulation  \n",
              "2     Adventure;Point & Click;Comedy  \n",
              "3  Free to Play;Multiplayer;Strategy  \n",
              "4             Adventure;Indie;Casual  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-874b014f-e0e2-4068-9873-18e9dad54a54\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>developer</th>\n",
              "      <th>platforms</th>\n",
              "      <th>genres</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bradley Hennessey;Joe Watson</td>\n",
              "      <td>windows</td>\n",
              "      <td>Adventure;Casual;Free to Play;Indie;Simulation</td>\n",
              "      <td>Free to Play;Adventure;Indie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>bumblebee</td>\n",
              "      <td>windows;mac;linux</td>\n",
              "      <td>Casual;Indie;Simulation;Strategy</td>\n",
              "      <td>Turn-Based;Indie;Simulation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Daedalic Entertainment</td>\n",
              "      <td>windows;mac;linux</td>\n",
              "      <td>Adventure;Indie</td>\n",
              "      <td>Adventure;Point &amp; Click;Comedy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Trion Worlds</td>\n",
              "      <td>windows</td>\n",
              "      <td>Free to Play;Strategy</td>\n",
              "      <td>Free to Play;Multiplayer;Strategy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Amanita Design</td>\n",
              "      <td>windows;mac</td>\n",
              "      <td>Adventure;Casual;Indie</td>\n",
              "      <td>Adventure;Indie;Casual</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-874b014f-e0e2-4068-9873-18e9dad54a54')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-874b014f-e0e2-4068-9873-18e9dad54a54 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-874b014f-e0e2-4068-9873-18e9dad54a54');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 338
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Las variables que cuentan con este formato son variables categóricas, de modo que se permite que cada juego posea más de una categoría por cada una de estas columnas. Esto quiere decir que no se puede simplemente utilizar un encoding para estas variables y se debe realizar un procesamiento anterior, o utilizar alguna técnica de NLP que se encargue de recoger la mayor cantidad de información de estas categorías."
      ],
      "metadata": {
        "id": "zqNBPffGvfnn"
      },
      "id": "zqNBPffGvfnn"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Existencia de juegos duplicados en el dataset:\", df_train.duplicated(subset=[\"name\"]).any())\n",
        "print(\"Dimensiones del dataset: \", df_train.shape, end=\"\\n\\n\")\n",
        "\n",
        "missing = df_train.isna().sum()\n",
        "unique = df_train.nunique()\n",
        "dtype = df_train.dtypes\n",
        "\n",
        "pd.DataFrame({\"Missing\": missing, \"Unique\": unique, \"Dtype\": dtype})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 603
        },
        "id": "xPr3PMd1e2SC",
        "outputId": "52e43dba-5034-41ea-bfa1-5e8ae8a40b22"
      },
      "id": "xPr3PMd1e2SC",
      "execution_count": 339,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Existencia de juegos duplicados en el dataset: False\n",
            "Dimensiones del dataset:  (7881, 16)\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   Missing  Unique     Dtype\n",
              "name                     0    7881    object\n",
              "release_date             0    2251    object\n",
              "english                  0       2     int64\n",
              "developer                0    5365    object\n",
              "publisher                0    3992    object\n",
              "platforms                0       5    object\n",
              "required_age             0       6     int64\n",
              "categories               0    1933    object\n",
              "genres                   0     844    object\n",
              "tags                     0    3981    object\n",
              "achievements             0     280     int64\n",
              "average_playtime         0    1257     int64\n",
              "price                    0     162   float64\n",
              "short_description        0    7848    object\n",
              "estimated_sells          0    4879     int64\n",
              "rating                   0       5  category"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c66e3cd4-8f87-496e-a53a-c03acd6fab1f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Missing</th>\n",
              "      <th>Unique</th>\n",
              "      <th>Dtype</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>name</th>\n",
              "      <td>0</td>\n",
              "      <td>7881</td>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>release_date</th>\n",
              "      <td>0</td>\n",
              "      <td>2251</td>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>english</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>developer</th>\n",
              "      <td>0</td>\n",
              "      <td>5365</td>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>publisher</th>\n",
              "      <td>0</td>\n",
              "      <td>3992</td>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>platforms</th>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>required_age</th>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>categories</th>\n",
              "      <td>0</td>\n",
              "      <td>1933</td>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>genres</th>\n",
              "      <td>0</td>\n",
              "      <td>844</td>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tags</th>\n",
              "      <td>0</td>\n",
              "      <td>3981</td>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>achievements</th>\n",
              "      <td>0</td>\n",
              "      <td>280</td>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>average_playtime</th>\n",
              "      <td>0</td>\n",
              "      <td>1257</td>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>price</th>\n",
              "      <td>0</td>\n",
              "      <td>162</td>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>short_description</th>\n",
              "      <td>0</td>\n",
              "      <td>7848</td>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>estimated_sells</th>\n",
              "      <td>0</td>\n",
              "      <td>4879</td>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rating</th>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>category</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c66e3cd4-8f87-496e-a53a-c03acd6fab1f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c66e3cd4-8f87-496e-a53a-c03acd6fab1f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c66e3cd4-8f87-496e-a53a-c03acd6fab1f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 339
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "No existen datos duplicados ni tampoco hay valores faltantes en el dataset. También se puede notar que, como es de esperar, la mayoría de las variables de tipo texto poseen una alta cardinalidad. Aún así, existen algunas columnas de tipo texto con baja cardinalidad, por lo que es factible utilizar algún tipo de encoding sobre estas variables."
      ],
      "metadata": {
        "id": "dxxOaqQifWpK"
      },
      "id": "dxxOaqQifWpK"
    },
    {
      "cell_type": "markdown",
      "source": [
        "El dataset proporcionado para el entrenamiento contiene 7881 muestras y 16 columnas. De acuerdo a la información proporcionada 9 de estas columnas poseen datos de tipo string, 5 columnas contienen datos enteros, 1 columna consiste en datos de tipo float y una columna guarda datos categóricos.\n",
        "\n",
        "La columna *release_date* contiene en realidad datos de tipo Date, mientras que la columa *english* posee datos binarios nominales. Además, se debe pensar en estrategias para el encoding de variables tipo texto como *categories* o *genres*, pues los valores de estas variables corresponden a colecciones de datos categóricos. Por otra parte, los valores de la columna *rating* contienen un orden natural, por lo que estricatemente hablando se tratan de datos ordinales.\n",
        "\n",
        "- **Columnas de tipo texto**: name, developer, publisher, platforms, categories, genres, tags, short_description.\n",
        "- **Columnas de tipo entero**: required_age, achievements, average_playtime, estimated_sells\n",
        "- **Columnas de tipo Date**: release_date.\n",
        "- **Columnas de tipo nominal**: english.\n",
        "- **Columnas de tipo float**: price.\n",
        "- **Columnas de tipo ordinal**: rating.\n",
        "\n",
        "Sabiendo lo anterior, se procede a transformar las variables english y release_date a sus respectivos tipos de datos."
      ],
      "metadata": {
        "id": "_3AGibKIbpXx"
      },
      "id": "_3AGibKIbpXx"
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = df_train.astype({\n",
        "    \"release_date\": \"datetime64\",\n",
        "    \"english\": \"category\"\n",
        "    })\n",
        "\n",
        "df_test = df_test.astype({\n",
        "    \"release_date\": \"datetime64\",\n",
        "    \"english\": \"category\"\n",
        "    })"
      ],
      "metadata": {
        "id": "_3YiSyT4gSlZ"
      },
      "id": "_3YiSyT4gSlZ",
      "execution_count": 340,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uno de los valores importantes a considerar corresponde a la correlación. Por lo mismo, se procede a calcular la matriz de correlación entre las variables numéricas del dataset."
      ],
      "metadata": {
        "id": "eVJ9DWbLzKM8"
      },
      "id": "eVJ9DWbLzKM8"
    },
    {
      "cell_type": "code",
      "source": [
        "df_corr = df_train.corr()\n",
        "fig = px.imshow(\n",
        "    df_corr,\n",
        "    text_auto=\".2f\",\n",
        "    title=\"Matriz de correlación\",\n",
        "    color_continuous_scale=px.colors.sequential.Blues\n",
        ")\n",
        "fig.show()\n",
        "\n",
        "# fig.write_image(\"corr_matrix.png\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "x__eeIuTajN2",
        "outputId": "085f8d01-ca76-4c7e-b672-944bec9ab7ec"
      },
      "id": "x__eeIuTajN2",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.16.1.min.js\"></script>                <div id=\"d29c8992-da91-43a6-b30d-cf88783d1953\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"d29c8992-da91-43a6-b30d-cf88783d1953\")) {                    Plotly.newPlot(                        \"d29c8992-da91-43a6-b30d-cf88783d1953\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"texttemplate\":\"%{z:.2f}\",\"x\":[\"english\",\"required_age\",\"achievements\",\"average_playtime\",\"price\",\"estimated_sells\"],\"y\":[\"english\",\"required_age\",\"achievements\",\"average_playtime\",\"price\",\"estimated_sells\"],\"z\":[[1.0,0.01579933318307353,0.009747742100637028,-0.007677909616743479,0.018056017517140654,0.014291561504459673],[0.01579933318307353,1.0,-0.0014996069619834067,0.026692372266700837,0.15787539434718853,0.11078867710630126],[0.009747742100637028,-0.0014996069619834067,1.0,0.0008246881147955551,-0.026374473629372633,0.022180136269359416],[-0.007677909616743479,0.026692372266700837,0.0008246881147955551,1.0,0.04565079690236962,0.161612492447891],[0.018056017517140654,0.15787539434718853,-0.026374473629372633,0.04565079690236962,1.0,0.06293450872971137],[0.014291561504459673,0.11078867710630126,0.022180136269359416,0.161612492447891,0.06293450872971137,1.0]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"x: %{x}<br>y: %{y}<br>color: %{z}<extra></extra>\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"scaleanchor\":\"y\",\"constrain\":\"domain\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\"},\"coloraxis\":{\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]]},\"title\":{\"text\":\"Matriz de correlaci\\u00f3n\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('d29c8992-da91-43a6-b30d-cf88783d1953');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se observa que las variables numéricas no presentan correlaciones significativas entre sí. Por un lado, es bueno considerando que no se tiene el problema de sesgar el modelo hacia una característica en particular al querer incluir 2 o más features, por lo que no se requiere de la utilización de herramientas como PCA. Por otra parte, la variable *estimated_sells* es una de las variables que se quiere predecir, por lo que sería ideal que alguna de las variables numéricas tenga alguna correlación con esta variable, sin embargo esto no ocurre.\n",
        "\n",
        "Para conocer un poco mejor la distribución de las variables numéricas, se procede a obtener algunas de sus estadísticas."
      ],
      "metadata": {
        "id": "6R1EQb0vJxkZ"
      },
      "id": "6R1EQb0vJxkZ"
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "kJ3TcTrBjq4V",
        "outputId": "a07e3a57-248d-4769-85ef-a6c042d112b5"
      },
      "id": "kJ3TcTrBjq4V",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       required_age  achievements  average_playtime        price  \\\n",
              "count    7881.00000   7881.000000       7881.000000  7881.000000   \n",
              "mean        0.78924     43.170156        439.296790     8.431342   \n",
              "std         3.55538    265.399206       3303.162083     8.755668   \n",
              "min         0.00000      0.000000          0.000000     0.000000   \n",
              "25%         0.00000      0.000000          0.000000     1.990000   \n",
              "50%         0.00000     15.000000         27.000000     6.990000   \n",
              "75%         0.00000     35.000000        251.000000    11.390000   \n",
              "max        18.00000   9821.000000     190625.000000    78.990000   \n",
              "\n",
              "       estimated_sells  \n",
              "count     7.881000e+03  \n",
              "mean      2.105767e+05  \n",
              "std       1.513926e+06  \n",
              "min       3.600000e+03  \n",
              "25%       9.724000e+03  \n",
              "50%       2.150800e+04  \n",
              "75%       7.357300e+04  \n",
              "max       7.944129e+07  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-41dd1045-43ef-4b96-8afa-b4157f550431\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>required_age</th>\n",
              "      <th>achievements</th>\n",
              "      <th>average_playtime</th>\n",
              "      <th>price</th>\n",
              "      <th>estimated_sells</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>7881.00000</td>\n",
              "      <td>7881.000000</td>\n",
              "      <td>7881.000000</td>\n",
              "      <td>7881.000000</td>\n",
              "      <td>7.881000e+03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.78924</td>\n",
              "      <td>43.170156</td>\n",
              "      <td>439.296790</td>\n",
              "      <td>8.431342</td>\n",
              "      <td>2.105767e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3.55538</td>\n",
              "      <td>265.399206</td>\n",
              "      <td>3303.162083</td>\n",
              "      <td>8.755668</td>\n",
              "      <td>1.513926e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.600000e+03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.990000</td>\n",
              "      <td>9.724000e+03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.00000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>6.990000</td>\n",
              "      <td>2.150800e+04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.00000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>251.000000</td>\n",
              "      <td>11.390000</td>\n",
              "      <td>7.357300e+04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>18.00000</td>\n",
              "      <td>9821.000000</td>\n",
              "      <td>190625.000000</td>\n",
              "      <td>78.990000</td>\n",
              "      <td>7.944129e+07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-41dd1045-43ef-4b96-8afa-b4157f550431')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-41dd1045-43ef-4b96-8afa-b4157f550431 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-41dd1045-43ef-4b96-8afa-b4157f550431');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "De la información desplegada en la celda anterior, se puede extraer que la variable *required_age* comprende valores entre 0 y 18. Es natural pensar que se trata entonces de una variable ordinal, en donde existan una acotada cantidad de valores dependiendo de la clasificación del videojuego. La variable *achievements* se concentra en valores menores a 35, siendo al menos un 25% de las muestras del dataset juegos sin logros; en cuánto al máximo, se puede notar que existe un outlier que se escapa de la distribución, por lo que al momento de revisar esta vafiable se debe chequear si este dato consiste efectivamente en un outlier o en un dato mal inputado.\n",
        "\n",
        "La variable *average_playtime* cuenta con un valo mínimo igual a 0, por lo que se infiere que esta variable se encuentra en horas. La mitad de los juegos cuenta con un playtime promedio de 27 horas o menos, aunque hay un 25% de ellos que superan las 251 horas de juego. El valor máximo se escapa completamente del resto de los valores, pero en este caso no hay como verificar si el dato es correcto o no.\n",
        "\n",
        "El precio de los juegos cuenta con una gran cantidad de videojuegos a bajo costo. La mitad de ellos son gratuitos o cuestan menos de 7 dólares, indicando una gran concentración de valores en un intervalo pequeño. El tercel cuartil se encuentra en 11.39 dólares mientras que el máximo precio es de 79 dólares, aunque por conocimiento previo se sabe que es totalmente factible que hayan juegos por ese precio.\n",
        "\n",
        "Finalmente, la variable a predecir *estimated_sells* oscila entre valores del orden de $10^3$ y $10^7$, indicando que existe una gran diferencia entre los juegos éxito de ventas de los que no lo son, lo que supone un problema difícil al momento de entrenar un regresor."
      ],
      "metadata": {
        "id": "gtnAcpKvXc7W"
      },
      "id": "gtnAcpKvXc7W"
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.loc[df_train[\"achievements\"] == df_train.achievements.max()]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "id": "t-Zx6Hzu0Skl",
        "outputId": "104a5697-5d25-4938-c7af-1afcf06b6dce"
      },
      "id": "t-Zx6Hzu0Skl",
      "execution_count": 352,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            name release_date english developer publisher platforms  \\\n",
              "3503  LOGistICAL   2017-02-15       1    Sacada    Sacada   windows   \n",
              "\n",
              "      required_age                                         categories  \\\n",
              "3503             0  Single-player;Steam Achievements;Steam Trading...   \n",
              "\n",
              "                     genres                   tags  achievements  \\\n",
              "3503  Casual;Indie;Strategy  Casual;Strategy;Indie          9821   \n",
              "\n",
              "      average_playtime  price  \\\n",
              "3503                 0   6.99   \n",
              "\n",
              "                                      short_description  estimated_sells  \\\n",
              "3503  LOGistICAL is a strategy puzzle game where you...             6880   \n",
              "\n",
              "               rating  release_month  \n",
              "3503  Mostly Positive              2  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1ac3322b-3c5d-4f67-be82-a3ce8072707e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>release_date</th>\n",
              "      <th>english</th>\n",
              "      <th>developer</th>\n",
              "      <th>publisher</th>\n",
              "      <th>platforms</th>\n",
              "      <th>required_age</th>\n",
              "      <th>categories</th>\n",
              "      <th>genres</th>\n",
              "      <th>tags</th>\n",
              "      <th>achievements</th>\n",
              "      <th>average_playtime</th>\n",
              "      <th>price</th>\n",
              "      <th>short_description</th>\n",
              "      <th>estimated_sells</th>\n",
              "      <th>rating</th>\n",
              "      <th>release_month</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3503</th>\n",
              "      <td>LOGistICAL</td>\n",
              "      <td>2017-02-15</td>\n",
              "      <td>1</td>\n",
              "      <td>Sacada</td>\n",
              "      <td>Sacada</td>\n",
              "      <td>windows</td>\n",
              "      <td>0</td>\n",
              "      <td>Single-player;Steam Achievements;Steam Trading...</td>\n",
              "      <td>Casual;Indie;Strategy</td>\n",
              "      <td>Casual;Strategy;Indie</td>\n",
              "      <td>9821</td>\n",
              "      <td>0</td>\n",
              "      <td>6.99</td>\n",
              "      <td>LOGistICAL is a strategy puzzle game where you...</td>\n",
              "      <td>6880</td>\n",
              "      <td>Mostly Positive</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1ac3322b-3c5d-4f67-be82-a3ce8072707e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1ac3322b-3c5d-4f67-be82-a3ce8072707e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1ac3322b-3c5d-4f67-be82-a3ce8072707e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 352
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El juego que cuenta con la mayor cantidad de logros se llama LOGistICAL. Al revisar este juego el sitio de Steam, se pudo comprobar que efectivamente el juego cuenta con esa cantidad de logros, por lo que no se trata de un dato mal inputado. Esto quiere decir entonces que es totalmente factible que algunos juegos cuenten con cantidades superiores a 1000 logros. "
      ],
      "metadata": {
        "id": "x8qRM4Dv0q6x"
      },
      "id": "x8qRM4Dv0q6x"
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.describe(include=[\"O\", \"category\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "kR0KQGYJrC95",
        "outputId": "e590aaaa-1213-4383-ed07-1f16999f61bf"
      },
      "id": "kR0KQGYJrC95",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 name  english                   developer publisher  \\\n",
              "count            7881     7881                        7881      7881   \n",
              "unique           7881        2                        5365      3992   \n",
              "top     An Aspie Life        1  KOEI TECMO GAMES CO., LTD.   Ubisoft   \n",
              "freq                1     7769                          32        94   \n",
              "\n",
              "       platforms     categories        genres                    tags  \\\n",
              "count       7881           7881          7881                    7881   \n",
              "unique         5           1933           844                    3981   \n",
              "top      windows  Single-player  Action;Indie  Action;Adventure;Indie   \n",
              "freq        4589            756           505                      68   \n",
              "\n",
              "                              short_description    rating  \n",
              "count                                      7881      7881  \n",
              "unique                                     7848         5  \n",
              "top     Minimal physical puzzle with explosions  Positive  \n",
              "freq                                         11      2031  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7d190cf4-d2eb-47cb-be74-62e74b4b7e23\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>english</th>\n",
              "      <th>developer</th>\n",
              "      <th>publisher</th>\n",
              "      <th>platforms</th>\n",
              "      <th>categories</th>\n",
              "      <th>genres</th>\n",
              "      <th>tags</th>\n",
              "      <th>short_description</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>7881</td>\n",
              "      <td>7881</td>\n",
              "      <td>7881</td>\n",
              "      <td>7881</td>\n",
              "      <td>7881</td>\n",
              "      <td>7881</td>\n",
              "      <td>7881</td>\n",
              "      <td>7881</td>\n",
              "      <td>7881</td>\n",
              "      <td>7881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>7881</td>\n",
              "      <td>2</td>\n",
              "      <td>5365</td>\n",
              "      <td>3992</td>\n",
              "      <td>5</td>\n",
              "      <td>1933</td>\n",
              "      <td>844</td>\n",
              "      <td>3981</td>\n",
              "      <td>7848</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>An Aspie Life</td>\n",
              "      <td>1</td>\n",
              "      <td>KOEI TECMO GAMES CO., LTD.</td>\n",
              "      <td>Ubisoft</td>\n",
              "      <td>windows</td>\n",
              "      <td>Single-player</td>\n",
              "      <td>Action;Indie</td>\n",
              "      <td>Action;Adventure;Indie</td>\n",
              "      <td>Minimal physical puzzle with explosions</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1</td>\n",
              "      <td>7769</td>\n",
              "      <td>32</td>\n",
              "      <td>94</td>\n",
              "      <td>4589</td>\n",
              "      <td>756</td>\n",
              "      <td>505</td>\n",
              "      <td>68</td>\n",
              "      <td>11</td>\n",
              "      <td>2031</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7d190cf4-d2eb-47cb-be74-62e74b4b7e23')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7d190cf4-d2eb-47cb-be74-62e74b4b7e23 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7d190cf4-d2eb-47cb-be74-62e74b4b7e23');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La variables de tipo texto y/o categóricas presentan en genral una alta cardinalidad. Esto es de esperar, pues como se comentó previamente existen columnas con variables categóricas que admiten una o más categorias. En el caso de la variable *english*, se observa que la mayoría de los videojuegos están disponibles en inglés y muy pocos no lo están.\n",
        "\n",
        "Las plataformas consisten únicamente en los 3 principales sistemas operativos de computadores, por lo que la cardinalida de esta variable es baja y permite un encoding más fácil."
      ],
      "metadata": {
        "id": "21lQ7wtc4dmG"
      },
      "id": "21lQ7wtc4dmG"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para el análisis posterior de algunas variables de tipo texto, se ha implementado una función que permite codificar sus valores en columnas tipo One Hot Encoding. Esto será útil posteriormente para analizar individualmente cada uno de los valores y su relación con las variables objetivo."
      ],
      "metadata": {
        "id": "B9e_O6-uqwZY"
      },
      "id": "B9e_O6-uqwZY"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predicción de ventas"
      ],
      "metadata": {
        "id": "P73Ct457XCRm"
      },
      "id": "P73Ct457XCRm"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se ha planteado la hipótesis sobre la utilidad de obtener el mes en que fue estrenado un videojuego, pues puede ocurrir que existan fechas festivas en las que la gente suela comprar o regalar más videojuegos."
      ],
      "metadata": {
        "id": "7bU2tbgd5-os"
      },
      "id": "7bU2tbgd5-os"
    },
    {
      "cell_type": "code",
      "source": [
        "df_train[\"release_month\"] = df_train.release_date.dt.month\n",
        "df_test[\"release_month\"] = df_test.release_date.dt.month"
      ],
      "metadata": {
        "id": "3cBwOvjNqb6-"
      },
      "id": "3cBwOvjNqb6-",
      "execution_count": 343,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.histogram(df_train, x=\"release_month\", y=\"estimated_sells\", title=\"Ventas estimadas por mes\")\n",
        "fig.update_layout(bargap=0.2)\n",
        "fig.show()\n",
        "fig.write_image(\"ventas_mes.png\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "V1PJmKuDt-C4",
        "outputId": "b739c658-5382-4435-f7e8-b5e23531cffe"
      },
      "id": "V1PJmKuDt-C4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.16.1.min.js\"></script>                <div id=\"c69a1956-0f5f-4d94-b58a-fe3d4b39656b\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"c69a1956-0f5f-4d94-b58a-fe3d4b39656b\")) {                    Plotly.newPlot(                        \"c69a1956-0f5f-4d94-b58a-fe3d4b39656b\",                        [{\"alignmentgroup\":\"True\",\"bingroup\":\"x\",\"histfunc\":\"sum\",\"hovertemplate\":\"release_month=%{x}<br>sum of estimated_sells=%{y}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[3,6,8,10,3,12,10,1,4,8,10,12,8,5,4,10,5,2,10,9,11,2,5,3,10,3,5,4,7,2,3,10,3,3,2,3,4,4,1,11,4,11,4,4,8,8,7,11,8,10,11,3,2,10,11,1,1,7,7,5,7,11,5,3,8,11,1,8,10,11,8,3,2,2,12,1,9,3,8,7,4,8,2,5,10,4,11,9,4,3,3,2,4,6,4,1,3,8,7,9,12,12,11,5,9,1,1,4,3,11,9,9,1,5,5,4,3,12,12,7,2,10,2,5,12,5,12,1,4,7,8,7,11,1,3,12,7,12,9,3,4,8,8,11,4,8,7,10,2,1,9,3,4,10,1,4,10,3,7,1,7,12,5,5,5,4,11,2,9,9,3,9,9,10,7,10,11,8,8,2,11,7,9,5,5,7,7,6,11,7,10,5,3,10,1,1,2,5,1,5,10,4,7,7,2,6,8,8,2,2,12,1,7,10,5,2,10,3,10,4,12,2,3,1,9,5,12,7,7,2,8,1,3,6,6,9,11,9,5,6,6,5,7,12,7,3,8,1,4,8,5,3,6,7,6,2,2,7,5,3,10,2,8,11,12,9,4,10,8,11,2,8,6,2,2,12,4,8,6,8,11,1,3,8,9,1,3,3,7,4,5,11,10,10,3,7,1,10,3,5,2,5,9,12,8,5,10,12,4,12,4,1,5,1,11,11,2,8,5,1,10,2,4,8,11,11,7,4,2,10,6,4,12,5,1,1,1,10,4,2,2,12,10,6,2,12,5,5,8,8,12,9,4,2,2,7,5,4,4,11,10,11,9,3,8,12,5,8,5,5,2,4,11,12,6,7,4,6,4,3,9,10,4,9,12,3,11,10,5,3,10,7,10,9,2,5,12,5,12,10,11,12,10,8,3,8,10,5,5,10,10,7,9,6,3,5,11,1,7,8,4,4,7,10,12,12,5,5,7,6,12,1,12,9,2,10,5,5,10,1,7,8,6,4,2,2,3,4,8,4,2,3,10,8,8,5,5,5,3,9,1,2,2,5,5,6,4,5,10,10,5,1,2,6,5,12,11,10,1,6,11,12,6,5,3,8,5,4,8,2,11,10,8,4,4,3,8,4,8,7,1,4,4,1,6,12,6,2,7,5,11,2,5,11,3,6,8,4,10,9,1,1,8,6,11,10,12,3,9,4,9,10,5,3,3,8,8,10,4,10,12,8,3,2,3,2,11,10,4,5,4,10,10,7,12,2,9,7,12,1,3,11,4,9,3,8,12,5,10,3,4,6,1,5,1,9,7,11,2,9,6,2,8,2,9,8,12,12,5,9,12,8,12,2,2,10,10,3,2,8,3,2,11,11,3,9,9,2,5,10,7,7,8,11,9,8,4,4,5,12,6,9,8,2,9,3,3,9,7,12,5,11,3,8,12,8,9,4,11,1,1,10,9,3,10,1,4,8,10,6,12,3,5,4,4,2,12,1,8,12,5,4,12,8,6,3,5,5,12,5,9,7,9,12,6,11,4,10,8,8,4,3,3,12,5,1,3,9,1,12,8,8,6,1,2,4,5,12,9,7,3,10,7,10,12,6,9,9,12,7,9,6,4,10,2,10,11,6,2,3,10,2,11,8,4,6,9,10,11,1,11,10,9,2,4,9,12,6,6,3,9,11,5,4,3,10,8,5,5,6,4,9,2,10,2,10,7,10,10,3,3,5,10,12,10,9,7,4,7,10,5,12,8,6,11,2,12,4,10,11,4,1,4,3,5,4,2,4,11,9,1,12,3,11,10,3,5,8,3,6,7,4,2,7,4,2,7,2,10,7,11,11,6,2,4,8,8,1,1,3,6,2,10,8,9,12,4,11,9,1,12,4,2,9,5,4,8,8,2,6,2,1,5,6,2,1,3,7,11,7,10,6,9,9,3,10,8,4,12,12,10,5,3,9,2,9,10,3,9,9,5,7,12,3,5,9,9,9,3,11,2,3,11,4,12,9,5,5,10,5,12,10,9,8,12,5,9,4,8,11,10,12,10,1,4,7,7,2,3,5,1,2,6,8,6,5,9,9,7,12,9,7,9,4,11,4,8,12,5,9,2,11,12,9,8,4,11,2,9,9,9,4,5,10,2,10,4,2,4,3,3,7,7,4,5,5,9,5,5,8,12,2,4,4,3,8,3,3,7,2,11,5,7,1,10,4,12,7,3,12,5,5,4,4,11,8,2,10,5,12,10,7,10,2,10,9,10,8,6,6,2,5,4,9,9,10,6,8,5,5,12,11,1,3,10,2,10,2,7,12,4,9,7,4,8,10,4,2,6,8,2,3,9,10,8,7,3,6,6,10,6,10,4,9,12,12,3,9,10,6,11,3,6,1,6,11,9,2,7,9,10,9,8,7,4,10,11,8,6,11,12,4,8,10,7,8,7,2,11,4,6,2,12,9,12,9,5,7,5,6,9,11,5,6,6,9,10,8,8,3,2,8,6,12,7,1,4,5,5,6,10,7,2,3,2,5,1,1,2,10,3,2,2,6,1,10,4,1,6,11,10,8,9,7,2,8,11,11,3,9,6,8,6,11,3,2,4,3,8,7,12,9,10,3,7,5,6,9,10,5,10,9,9,11,2,6,11,3,3,4,7,9,8,12,5,3,10,3,8,5,6,1,3,8,5,8,3,3,12,9,3,3,11,9,10,11,5,12,8,10,8,4,5,2,10,6,7,11,6,4,1,8,9,9,8,6,1,12,6,10,5,4,10,9,4,3,7,3,8,4,12,11,9,9,1,4,3,12,5,5,9,9,7,10,12,9,5,7,1,6,6,4,1,11,4,5,7,12,7,12,8,5,10,6,8,4,2,4,8,6,1,3,11,6,12,3,6,10,1,1,2,4,10,7,7,5,6,8,5,3,8,9,12,8,9,8,1,2,1,4,7,12,8,12,12,8,8,12,11,1,9,1,11,2,1,9,10,7,7,2,9,5,4,3,2,5,9,12,2,1,8,6,1,7,4,12,4,4,2,5,11,5,7,3,7,6,1,3,4,1,11,7,10,9,2,10,12,10,6,11,3,1,3,4,4,7,8,4,2,2,1,5,10,1,12,8,9,7,9,4,3,1,2,3,6,2,8,9,8,8,12,8,1,8,5,11,11,7,8,7,4,9,4,11,6,6,7,12,4,4,4,4,2,8,10,11,5,2,2,10,3,2,9,1,12,11,12,3,10,4,4,4,9,12,7,10,6,2,4,7,4,4,5,11,10,4,8,9,6,7,3,5,8,11,12,3,3,5,5,8,10,5,8,1,11,6,4,4,2,2,1,4,8,1,11,7,8,11,10,12,9,5,6,7,10,4,5,5,2,9,9,9,10,12,10,5,5,11,2,2,4,7,7,2,1,8,2,10,9,3,4,3,9,5,9,5,2,1,10,5,12,2,6,10,2,12,9,1,6,6,6,5,12,9,12,5,1,12,2,4,12,5,2,1,8,9,1,7,4,10,6,8,7,3,4,9,1,11,10,5,2,8,10,8,4,11,10,5,5,7,12,2,2,10,10,7,2,6,7,9,12,6,7,12,12,12,10,10,2,4,4,12,12,4,6,4,1,6,11,7,12,12,1,1,3,4,9,11,11,2,10,11,2,6,3,3,2,3,4,11,7,1,3,4,5,10,3,1,10,7,11,9,1,10,11,8,8,5,6,2,3,3,10,10,12,8,4,12,12,11,4,6,12,11,3,9,7,10,2,1,8,8,10,12,10,1,9,8,5,9,5,10,4,8,2,3,11,2,4,11,10,4,4,4,7,4,10,6,5,4,2,2,4,2,10,5,7,11,12,4,6,7,11,9,8,10,9,12,3,11,6,7,9,4,9,4,3,8,11,4,5,9,9,5,5,3,3,3,7,9,1,3,5,6,12,10,3,7,12,12,7,8,1,3,2,2,7,3,4,4,7,10,10,11,7,12,8,11,3,7,1,12,7,6,5,3,8,4,11,2,7,9,4,7,5,3,7,4,5,2,9,4,10,12,1,12,9,6,10,2,4,12,7,7,11,4,11,7,3,7,4,5,3,8,9,3,5,12,2,3,7,4,6,12,1,7,11,10,1,7,10,7,12,11,8,11,8,9,7,3,2,5,10,4,2,9,12,6,6,7,6,12,10,2,9,7,10,11,9,10,3,3,6,10,8,2,12,10,11,10,12,7,5,2,2,11,12,12,6,2,10,3,12,5,5,5,11,10,8,2,8,5,6,5,9,8,11,5,9,10,1,11,3,3,11,3,8,10,5,10,2,5,1,12,5,8,11,6,1,10,5,2,4,5,5,10,2,12,6,10,7,9,7,3,2,7,10,11,9,12,9,11,5,3,12,9,4,4,11,12,3,4,5,9,7,7,1,8,10,9,11,6,2,9,11,5,6,4,10,4,7,1,11,3,9,11,3,5,12,5,11,11,7,1,5,5,1,8,3,3,10,11,4,9,10,6,6,12,6,11,5,8,7,3,5,12,7,2,11,9,1,1,2,11,4,5,6,4,9,1,2,2,12,4,6,4,2,9,12,1,4,4,10,10,10,12,8,9,8,12,11,11,12,4,6,8,1,9,2,10,12,9,5,12,5,3,7,1,5,12,7,2,7,6,8,4,4,12,12,11,10,6,7,1,7,6,8,11,7,1,8,5,11,8,3,2,11,12,11,1,9,12,5,6,2,8,7,4,7,4,5,10,9,2,7,3,9,6,10,7,6,10,3,10,4,8,5,7,11,12,11,5,4,12,2,12,4,6,1,8,8,9,12,9,11,9,8,3,10,4,7,3,1,4,10,1,10,10,3,11,7,8,3,3,1,10,12,1,6,9,5,11,3,8,5,4,6,9,12,6,3,4,5,1,9,8,12,3,3,7,12,3,11,9,8,2,2,5,3,4,11,10,9,12,10,9,2,2,8,4,9,5,6,3,2,7,5,4,1,8,1,5,4,10,5,5,4,9,1,2,9,2,7,3,9,3,4,2,12,7,7,4,4,6,12,2,12,2,7,6,2,7,6,2,11,5,5,7,7,10,2,7,6,11,9,5,10,4,5,9,6,12,11,9,6,7,9,8,7,3,3,12,8,8,11,3,5,3,6,8,10,11,10,1,6,8,4,6,4,1,12,4,2,9,4,8,7,2,1,12,5,8,11,4,9,7,5,6,2,1,11,7,8,8,3,9,12,11,4,4,1,2,11,11,9,5,11,10,4,7,7,1,12,8,8,3,8,4,7,3,11,8,2,1,11,3,3,5,6,6,5,9,6,3,9,5,4,2,3,4,12,1,1,8,4,5,12,8,7,8,3,8,12,9,9,1,6,2,10,7,4,8,3,2,8,9,6,10,10,6,7,9,12,10,9,4,2,11,7,5,4,7,8,3,6,4,8,3,8,12,9,10,5,3,3,1,5,4,3,3,5,8,8,7,8,8,9,8,9,8,6,6,10,7,5,12,6,3,5,1,3,4,6,5,3,3,3,3,9,7,2,5,9,8,8,11,5,6,7,2,3,11,4,10,11,5,6,2,8,3,8,9,12,1,12,4,6,9,6,5,6,8,1,10,3,1,4,7,10,10,3,8,4,6,8,10,10,6,4,1,7,2,8,9,9,3,11,1,2,2,3,11,6,2,3,11,8,8,3,3,3,9,12,6,11,6,11,4,4,12,1,5,1,5,12,9,3,8,7,7,11,10,8,10,3,9,4,2,4,2,8,12,10,10,9,1,6,9,2,7,1,10,10,12,7,1,12,8,8,8,10,8,12,4,1,5,5,6,5,8,7,2,8,5,9,6,9,5,10,3,12,9,11,10,11,11,2,5,12,11,4,7,5,11,11,9,10,10,12,5,5,8,8,6,12,9,2,12,4,1,11,3,10,4,2,1,8,10,8,7,2,10,9,3,12,3,11,6,4,10,4,7,4,10,8,10,7,5,6,7,2,9,7,7,9,11,12,6,9,2,2,12,2,8,10,4,9,6,1,11,11,5,8,9,12,7,10,5,4,7,7,3,1,11,8,4,4,8,12,10,7,5,2,12,9,4,2,11,1,3,8,12,10,10,8,7,5,1,1,9,1,7,8,8,10,10,12,6,2,3,7,10,2,3,10,3,10,7,9,11,2,7,10,1,7,3,2,5,3,7,1,10,7,2,10,7,11,12,4,11,1,4,1,5,10,9,2,12,12,12,11,10,10,8,8,11,11,4,10,3,10,3,9,1,5,1,8,4,12,4,7,7,4,12,10,3,8,9,7,8,1,9,4,4,4,10,2,8,8,10,12,3,1,7,1,10,11,9,1,7,2,5,3,10,3,9,5,10,4,7,10,7,11,11,3,9,8,12,8,10,2,1,6,2,12,5,11,4,4,12,1,2,5,11,8,1,11,8,4,10,8,12,3,4,2,6,2,6,8,2,1,8,2,4,1,11,7,2,8,8,2,10,2,2,8,2,12,4,10,3,10,3,7,9,7,12,9,3,7,3,1,9,7,8,2,12,3,11,7,4,11,5,3,3,9,11,8,10,6,11,9,12,9,12,7,12,3,5,1,7,5,8,7,11,1,4,7,12,9,9,10,6,2,9,6,2,4,1,9,2,11,6,10,12,9,10,2,9,1,11,3,2,1,1,3,3,10,12,4,3,1,4,5,1,8,9,1,2,5,12,2,6,8,1,10,12,11,12,6,12,11,6,7,4,1,10,2,5,11,4,8,9,1,7,3,3,7,8,9,10,9,2,1,1,5,10,4,3,9,1,12,2,1,1,10,10,12,11,4,12,6,2,3,12,2,2,4,10,4,2,1,3,10,11,12,7,4,7,6,3,11,11,2,4,2,11,11,8,10,1,11,6,12,11,9,2,8,2,7,1,10,5,12,7,12,11,3,8,2,4,10,5,3,1,10,10,8,9,2,3,1,8,7,5,8,9,8,11,9,6,12,9,11,1,8,6,4,11,5,12,4,2,2,10,7,4,10,12,7,11,3,11,6,12,7,10,3,9,3,1,1,8,8,11,10,5,11,5,2,4,2,5,2,10,5,7,9,6,8,3,1,1,5,7,8,4,11,8,4,10,2,7,6,3,12,9,11,12,2,4,3,12,6,4,1,11,5,4,6,6,6,1,4,6,9,8,3,3,5,3,10,6,12,9,10,3,7,7,2,4,5,8,6,7,9,9,4,10,2,7,8,8,3,1,2,1,11,5,5,1,10,3,9,3,1,4,11,5,3,8,8,6,9,2,2,9,4,10,3,8,4,7,11,12,2,2,8,9,7,2,11,3,3,4,8,2,6,3,8,11,7,7,5,5,1,9,11,11,3,11,11,5,4,5,5,5,5,10,3,8,8,10,12,6,1,7,9,4,8,3,6,5,5,7,12,8,2,7,2,2,9,1,5,7,5,4,6,3,4,7,2,4,9,6,9,4,6,3,6,8,4,1,5,11,3,8,12,10,5,3,10,5,4,11,10,4,5,10,7,9,10,5,5,11,12,5,9,3,12,5,3,8,12,12,9,10,5,1,12,3,4,3,9,5,8,2,3,10,9,8,4,10,1,4,10,8,2,9,2,8,11,3,10,11,4,6,10,2,4,9,10,3,1,8,6,6,5,1,7,5,10,12,1,3,5,4,5,3,5,4,11,7,10,1,7,12,5,4,4,6,9,9,6,8,11,3,12,9,12,5,3,6,3,8,9,5,9,10,2,5,10,6,5,4,9,11,10,4,5,12,3,8,10,4,1,6,11,2,9,3,10,10,10,2,11,3,3,5,8,10,8,11,3,8,5,9,5,5,9,6,10,4,6,12,8,3,7,6,4,2,11,2,3,12,8,10,1,11,9,9,4,3,5,5,11,3,2,2,6,10,7,8,3,2,6,5,2,7,3,2,8,12,7,2,12,2,5,4,7,9,3,8,4,3,9,9,8,12,10,12,8,3,9,9,7,5,11,6,4,7,12,4,9,6,10,7,6,5,4,1,6,12,9,9,11,5,9,9,6,4,4,5,9,1,9,3,10,4,11,4,8,3,8,9,3,9,8,8,4,6,8,5,5,1,7,12,12,5,1,3,10,7,4,10,11,2,9,8,12,1,9,10,4,4,4,2,8,6,2,9,10,1,9,3,2,12,2,7,3,12,10,12,11,5,5,9,9,11,2,5,3,7,8,2,2,10,7,10,12,1,1,3,11,11,10,5,11,9,7,9,3,4,10,4,8,5,11,2,9,10,1,3,10,6,8,9,5,8,4,3,1,7,12,12,10,12,7,12,5,9,4,3,10,2,5,10,12,4,1,11,8,6,5,2,7,11,8,4,6,9,6,11,7,6,2,1,2,1,11,11,8,5,3,12,5,10,4,4,8,4,8,5,3,4,6,10,4,4,2,6,7,12,3,8,7,8,7,5,5,2,12,8,6,2,12,11,5,10,4,12,5,10,11,6,7,5,8,2,2,5,5,12,4,8,4,12,8,11,8,10,4,7,5,10,7,1,3,8,9,3,1,1,6,9,6,12,11,4,9,11,1,10,8,5,4,1,1,4,12,8,8,11,6,3,2,3,6,10,12,2,1,9,5,10,5,12,5,10,11,6,3,10,3,8,11,6,8,3,10,12,7,9,5,4,3,2,3,10,6,1,8,9,10,1,4,1,12,11,6,12,11,8,10,10,2,3,12,7,9,7,9,9,7,4,10,9,7,10,5,6,11,4,5,1,2,11,9,12,6,6,9,10,7,4,10,12,12,5,3,10,10,1,9,9,9,8,10,5,11,11,8,8,10,7,3,3,8,10,1,9,11,11,1,1,5,8,4,2,5,2,10,9,3,12,5,12,4,1,11,7,12,12,11,9,9,9,11,11,7,10,5,3,12,2,8,8,6,3,12,9,2,3,5,5,1,9,7,11,6,6,1,2,5,6,3,4,9,5,2,5,7,2,2,3,10,11,9,3,3,3,4,8,6,2,7,10,1,3,8,5,4,2,9,4,6,7,7,9,9,1,9,2,4,5,9,9,10,1,12,10,5,3,10,6,7,12,2,3,7,3,9,6,8,6,8,3,12,10,5,1,2,6,11,8,3,6,5,8,2,11,1,8,4,11,11,2,10,7,7,10,10,11,11,12,8,5,7,12,6,2,1,7,6,8,9,5,6,1,8,4,7,4,1,7,7,4,2,1,10,2,5,7,11,7,12,10,4,8,10,1,8,6,5,3,11,2,5,11,8,5,8,3,11,4,12,1,1,6,10,5,9,8,9,5,12,8,10,9,3,4,3,12,11,11,5,9,1,11,12,3,5,12,4,8,6,9,4,12,2,10,9,9,1,10,1,6,2,5,8,8,10,8,8,9,9,5,7,11,2,7,1,7,1,3,2,9,3,10,2,5,5,2,12,2,6,9,2,12,5,3,12,3,11,7,5,2,6,11,8,1,9,6,6,11,5,12,8,5,5,10,6,5,9,6,6,4,1,7,11,7,2,8,12,12,6,4,9,4,8,8,4,3,3,7,11,7,11,8,9,9,6,10,5,3,7,8,11,11,10,9,7,4,6,6,9,2,5,8,4,3,8,6,7,11,6,7,7,11,2,9,2,3,11,6,11,10,10,5,5,7,10,2,11,3,8,5,11,11,3,11,1,3,5,11,2,1,9,10,2,11,12,9,5,12,4,9,8,9,11,1,8,11,12,6,6,11,2,2,9,2,10,3,9,4,5,9,7,2,5,2,10,12,6,8,10,7,1,5,1,7,12,11,2,8,1,10,1,3,11,2,4,9,5,9,12,10,3,5,11,4,2,10,11,5,9,9,3,10,10,3,2,5,4,3,4,9,10,9,2,9,9,3,4,8,4,5,4,7,12,10,6,12,5,7,11,3,11,6,4,2,5,3,10,3,11,3,5,1,2,9,5,11,7,5,3,4,8,10,3,1,9,8,1,3,10,10,2,3,1,4,2,2,11,10,11,11,11,5,7,7,10,11,9,7,3,12,12,8,12,5,9,4,4,6,9,3,12,4,10,1,3,5,10,9,6,2,1,3,9,9,1,7,8,5,9,8,10,1,9,7,3,2,10,4,1,9,4,5,12,11,11,9,9,1,5,12,5,1,12,9,8,4,7,8,2,11,7,12,8,9,3,7,9,1,4,10,10,10,1,10,9,5,2,5,11,7,9,3,10,3,7,6,9,4,11,2,5,1,5,11,8,5,3,8,5,3,6,8,9,2,6,9,9,10,2,11,8,3,2,3,5,12,12,6,10,7,9,10,3,3,10,6,6,4,4,6,4,3,12,1,6,9,3,7,2,7,2,10,2,11,6,3,6,1,11,4,2,1,6,6,11,9,11,4,3,3,2,10,6,5,3,10,4,4,11,7,4,3,10,6,12,8,6,10,10,7,11,2,7,9,9,9,8,11,3,6,10,10,8,3,5,10,3,2,6,11,1,1,10,8,6,8,6,12,1,2,8,10,4,10,2,4,10,4,12,9,6,11,3,11,11,12,3,8,10,11,9,7,2,9,7,4,4,12,11,6,1,3,3,9,5,8,4,4,7,4,5,4,7,8,5,4,1,10,4,6,4,11,8,7,8,4,4,7,3,4,6,9,3,11,7,2,8,3,1,8,9,7,3,5,11,5,3,1,3,2,8,10,6,3,5,9,3,3,7,11,4,8,4,11,3,2,12,10,5,12,7,1,3,12,1,4,4,12,8,8,7,10,4,10,11,10,6,3,5,2,11,9,11,12,10,6,9,1,10,12,5,8,8,9,12,2,1,4,12,3,9,2,4,4,2,5,11,11,8,10,2,4,6,1,10,9,12,12,4,9,3,1,3,11,11,12,7,8,4,6,9,10,5,8,8,11,10,4,7,6,6,9,8,1,5,5,7,10,5,6,12,8,9,9,7,4,2,12,6,12,1,3,2,3,10,3,9,12,10,10,1,10,9,9,6,2,2,8,9,10,12,2,12,10,12,3,2,5,4,1,3,2,3,9,9,2,9,1,4,3,9,11,9,1,8,3,2,3,5,3,12,6,11,4,4,10,4,2,5,4,2,12,10,2,2,5,11,8,5,12,11,4,8,5,2,6,11,10,6,10,10,7,11,3,11,5,11,8,10,6,1,7,10,4,2,11,12,7,6,6,2,10,11,8,8,4,12,2,6,11,9,1,6,3,9,3,11,2,12,5,8,6,11,1,7,12,3,3,6,3,11,9,7,1,2,5,3,9,1,12,10,8,3,9,10,9,3,2,8,7,9,11,7,3,3,9,4,4,6,8,10,9,3,9,2,4,6,4,12,4,3,10,5,6,3,10,1,7,6,5,8,9,10,7,5,7,11,2,5,7,5,5,7,11,9,2,5,6,7,6,2,9,6,3,7,3,4,4,5,2,7,1,4,7,6,2,6,3,7,12,11,12,11,7,11,3,8,10,4,11,5,10,3,10,11,8,2,1,6,10,1,3,8,5,4,8,8,6,6,1,4,11,8,8,8,8,3,3,2,4,9,10,3,4,2,12,5,5,9,10,1,3,2,9,11,6,11,4,2,2,5,3,11,5,5,11,4,3,3,9,5,3,4,12,8,10,10,10,9,8,5,9,5,1,4,7,12,8,11,5,12,11,2,6,10,9,4,12,1,5,7,10,9,10,12,10,2,8,12,12,10,11,10,2,2,3,12,5,5,5,5,1,10,3,1,7,7,1,10,11,4,4,2,2,11,11,8,5,4,11,2,2,9,2,11,7,8,1,11,7,7,3,10,11,3,8,2,4,2,11,7,11,3,1,5,10,5,9,3,2,8,8,8,6,7,4,3,3,11,10,9,7,9,2,10,4,12,11,6,9,3,11,4,2,11,6,1,10,6,12,4,9,7,7,3,10,7,12,7,3,4,5,8,12,12,8,8,4,3,2,7,3,2,11,8,7,4,5,9,4,10,9,4,7,1,3,3,10,6,12,9,1,12,11,11,12,7,9,4,7,3,12,11,10,12,10,6,9,2,12,3,3,12,3,11,10,4,9,10,5,1,1,1,12,10,3,11,6,2,10,4,8,10,6,10,7,5,6,8,8,5,11,4,4,9,2,9,6,8,3,11,8,10,7,2,2,7,4,8,11,3,12,2,3,11,10,2,4,2,8,4,2,6,2,10,2,4,9,7,6,7,4,7,4,5,10,1,11,6,9,2,7,1,10,3,2,4,4,12,1,5,7,8,9,12,7,1,4,12,8,7,12,8,9,7,1,10,4,3,9,4,12,10,4,1,6,6,12,3,9,11,4,1,9,5,11,3,4,1,4,10,10,3,10,5,10,8,1,7,2,11,5,11,6,7,3,11,9,3,5,3,5,2,4,8,5,6,5,7,4,4,4,11,4,10,10,2,6,5,7,2,9,9,10,11,8,8,9,3,1,2,10,4,9,9,10,3,10,6,1,7,7,9,5,3,7,7,7,1,3,3,10,8,11,2,4,6,1,2,2,11,3,5,1,4,12,8,11,1,5,11,1,12,6,7,4,6,5,2,11,1,10,4,6,10,6,2,3,3,1,5,9,8,5,3,10,8,8,4,6,10,3,3,4,6,11,5,10,8,6,5,7,6,8,11,10,5,2,10,7,9,7,11,11,4,1,12,2,11,6,4,5,3,4,11,1,12,1,4,10,8,12,3,2,5,12,12,7,7,6,12,10,11,8,9,2,1,7,3,11,12,4,6,3,6,4,12,7,10,1,7,8,10,1,3,11,10,11,9,1,1,7,4,11,2,12,12,11,4,9,8,6,10,2,11,8,5,12,9,3,8,7,10,2,11,3,11,11,6,1,9,10,2,8,9,6,2,5,1,2,6,3,9,8,4,7,3,7,10,10,3,3,1,11,10,10,8,3,9,1,9,7,8,10,10,2,9,11,2,3,12,9,3,4,5,3,12,4,5,8,5,2,3,2,2,3,6,7,6,2,8,3,7,8,12,11,9,1,4,7,5,6,2,8,8,10,11,6,8,12,1,1,10,10,11,9,6,8,4,9,8,5,8,9,11,12,6,2,11,8,7,9,9,12,6,10,8,3,3,9,6,11,10,3,3,10,8,4,10,10,1,12,2,11,8,11,4,11,4,4,5,5,5,2,8,6,3,5,12,4,1,1,1,1,7,1,5,5,5,4,12,3,2,5,5,11,5,6,12,4,10,5,10,2,11,6,5,12,5,2,6,9,1,2,2,3,8,1,12,10,2,6,6,7,5,7,10,1,12,5,3,1,11,8,3,3,10,10,5,7,8,4,8,9,1,11,10,3,9,3,6,5,9,2,4,2,5,10,7,7,9,7,4,9,5,7,2,4,1,1,5,12,4,12,8,1,7,10,10,10,2,9,3,12,5,10,6,8,8,1,3,8,12,6,9,5,11,3,2,6,11,5,10,10,6,12,3,9,8,3,5,12,2,2,9,4,12,4,5,2,9,10,5,2,4,3,10,3,11,2,10,5,12,5,3,12,4,10,8,7,2,7,4,11,6,4,5,5,3,4,10,11,9,5,9,3,5,7,6,12,11,4,4,2,4,8,5,12,3,8,10,9,9,12,10,3,9,8,2,12,6,2,2,5,2,11,2,3,11,2,3,10,4,7,2,5,2,9,3,2,7,4,5,10,7,8,3,2,2,9,1,4,6,10,8,2,9,1,4,2,8,8,11,7,1,6,7,11,9,8,9,11,4,6,11,9,4,10,8,3,7,7,8,4,1,11,4,6,8,9,6,2,4,12,5,2,8,4,7,8,1,5,3,3,3,11,9,9,6,2,8,6,10,8,11,6,3,1,3,12,2,7,4,8,3,8,12,12,9,3,10,9,3,2,7,12,10,1,9,8,6,12,6,7,12,9,2,2,12,1,8,2,6,9,1,8,10,8,7,1,5,7,2,3,5,7,7,9,8,8,10,10,12,1,10,6,11,8,8,8,9,1,5,8,5,11,2,4,6,10,8,3,11,2,9,3,10,6,12,9,8,3,10,5,10,11,2,9,8,12,9,3,8,9,6,4,12,4,5,7,12,8,8,9,3,7,7,5,7,2,9,7,11,10,4,7,3,10,3,10,12,1,1,4,5,5,5,10,8,3,2,8,3,9,11,9,8,1,6,4,4,4,11,5,6,8,9,2,8,3,8,9,11,4,8,10,7,9,2,4,11,8,9,4,11,12,5,12,8,7,2,10,6,12,3,5,9,9,12,12,7,10,7,10,12,5,9,7,6,12,10,5,2,1,1,2,1,7,10,1,9,3,5,5,5,8,10,10,9,12,2,6,5,4,4,11,3,3,4,7,11,3,11,12,2,2,10,6,1,9,3,2,9,8,7,7,12,11,11,9,7,12,6,2,3,2,11,2,5,2,10,10,1,2,1,8,12,7,8,11,1,5,12,2,12,2,2,3,9,8,2,4,4,9,4,5,1,4,3,2,6,1,3,3,10,6,7,6,3,11,5,12,10,9,8,5,1,11,3,5,9,5,9,10,6,7,5,4,5,2,4,11,4,5,3,7,11,9,11,5,1,6,1,7,10,7,1,3,9,7,12,12,8,7,7,3,11,10,3,3,1,4,11,9,8,7,7,6,1,3,1,2,10,9,8,5,4,11,11,9,5,6,4,11,4,2,3,10,5,9,9,3,10,10,6,3,12,8,10,8,10,8,3,1,2,1,3,11,4,9,10,7,1,11,6,7,10,9,4,10,10,10,8,3,12,3,8,8,2,1,8,1,10,2,4,8,9,10,1,1,8,7,9,3,5,5,9,9,2,11,7,2,12,5,6,3,2,2,8,10,1,10,2,11,11,1,7,3,8,1,12,10,7,3,5,4,2,4,5,9,7,5,2,12,10,11,7,4,2,5,11,8,5,6,3,12,4,6,8,4,9,11,3,12,12,2,9,9,7,9,4,11,11,6,12,11,11,2,7,10,6,11,10,9,4,4,3,1,2,5,8,9,6,11,7,4,11,10,12,9,9,12,8,12,3,10,6,3,4,1,3,2,2,4,8,3,6,7,10,10,8,8,1,10,6,6,5,5,8,6,3,12,6,3,7,5,2,2,4,2,10,3,9,8,10,2,2,3,9,7,5,9,3,9,11,12,9,4,4,10,6,6,11,3,7,5,3,1,4,2,2,6,11,9,5,5,12,3,10,5,12,2,11,9,3,3,10,4,1,6,3,2,6,8,4,10,10,8,11,4,11,4,6,2,10,4,5,5,5,2,11,5,4,5,10,8,11,8,11,4,9,9,5,12,5,11,5,11,6,8,10,11,4,10,9,7,10,4,10,12,7,9,4,8,1,7,7,9,3,8,5,5,11,4,4,8,5,5,2,8,5,2,6,7,6,5,4,10,7,3,9,7,7,1,5,8,10,3,10,10,5,12,2,1,3,8,5,9,8,11,9,2,10,8,9,8,3,9,11,10,10,10,9,3,12,3,3,5,3,7,10,10,1,1,1,6,11,9,11,12,4,10,5,7,5,2,4,5,1,5,4,3,7,8,9,1,9,8,1,12,8,12,2,5,8,6,10,5,2,3,2,10,2,12,7,6,6,6,7,12,3,11,7,3,1,6,5,12,11,4,6,8,5,5,9,11,1,4,1,8,6,12,3,9,3,8,2,12,11,12,12,7,11,3,4,11,11,3,3,9,5,4,12,10,4,2,12,4,6,10,4,4,4,4,12,7,7,11,9,8,5,3,3,6,9,11,8,7,5,1,3,10,6,7,8,11,2,10,9,1,12,2,6,10,3,6,9,11,2,4,3,1,2,5,12,4,12,2,10,5,8,7,4,4,11,12,2,2,6,12,9,7,1,4,11,7,9,7,3,2,2,7,2,9,9,7,2,10,2,9,2,8,12,5,10,10,6,3,6,4,3,8,3,12,11,6,9,3,9,3,7,1,3,1,11,6,7,11,5,11,7,3,6,2,8,5,3,5,11,11,10,9,3,1,4,2,12,2,6,1,12,11,9,6,6,2,6,10,8,4,5,4,8,8,4,12,10,6,11,11,4,9,9,6,2,2,4,3,4,11,9,8,7,8,12,10,7,11,5,3,9,8,10,7,8,1,9,4,3,4,12,8,10,6,12,11,11,11,9,5,6,12,8,8,8,2,7,9,11,1,9,1,4,4,6,7,3,8,9,12,7,3,6,3,6,12,7,3,12,9,9,4,10,12,3,5,8,9,9,12,2,4,7,7,7,1,10,2,1,8,5,4,3,4,2,6,9,9,1,8,3,8,6,3,2,4,10,3,12,10,10,6,5,1,7,10,11,6,12,5,9,4,9,4,8,1,2,10,3,7,4,2,1,11,10,6,1,2,5,9,12,6,1,11,8,6,3,10,7,10,4,4,6,9,11,8,8,10,4,1,6,7,9,7,3,11,7,7,3,9,3,9,4,12,2,4,1,8,1,9,12,1,12,3,4,1,6,4,12,6,12,12,3,6,4,10,10,12,6,5,12,8,11,11,9,8,2,1,8,3,8,4,3,11,11,2,5,6,6,6,4,10,4,10,1,1,9,1,8,10,11,7,1,8,12,3,1,4,12,5,9,12,6,7,4,11,8,11,6,7,1,2,10,3,1,9,4,9,5,7,4,2,6,3,3,8,4,3,5,6,10,4,7,10,7,11,8,7,9,6,4,4,5,7,4,11,8,2,6,10,10,8,2,3,3,9,10,9,10,10,10,4,12,9,12,4,11,6,7,6,12,6,10,12,10,4,7,8,6,12,11,1,8,2,5,7,3,1,1,2,5,4,11,9,5,3,7,3,2,3,9,7,4,3,6,7,3,3,9,5,6,6,7,5,10,9,1,4,2,1,2,5,4,4,9,9,7,3,4,8,8,6,10,1,4,7,4,10,8,11,8,7,5,11,3,6,12,1,3,10,5,9,12,11,4,8,2,10,3,7,5,11,2,12,5,5,5,6,8,5,11,10,4,4,10,5,6,1,5,4,4,11,6,10,11,8,7,9,8,10,6,7,5,9,8,8,12,8,10,10,9,12,10,4,9,3,11,8,9,10,2,6,10,7,12,8,8,1,11,9,9,6,12,3,5,6,5,6,11,4,1,10,6,10,11,1,5,7,3,4,1,4,10,4,4,8,9,12,8,4,1,10,2,2,9,2,10,5,8,2,4,4,11,8,7,5,10,2,3,4,10,8,3,1,2,11,4,12,10,8,5,1,6,10,8,4,4,12,7,4,3,6,10,6,3,4,3,10,9,11,10,3,8,4,6,2,2,8,7,4,1,5,4,9,10,10,11,11,10,2,5,5,3,10,7,3,8,1,9,12,12,9,4,12,2,10,4,9,9,5,5,9,9,8,10,4,1,5,8,11,9,4,9,3,9,11,12,6,5,8,11,11,4,12,4,1,7,7,4,4,6,10,4,2,2,6,1,10,9,9,8,6,4,12,8,8,6,3,2,1,6,6,4,8,4,8,3,4,7,5,10,10,3,7,9,6,7,2,10,2,10,9,8,4,5,7,11,11,1,2,5,3,5,11,4,5,6,1,10,3,4,2,9,9,2,6,8,12,6,12,5,1,2,12,11,8,1,10,4,1,4,2,7,12,9,4,4,6,7,11,2,4,5,11,4,3,6,3,8,4,4,7,5,9,6,12,6,9,12,1,2,7,5,2,1,12,3,10,6,8,4,8,4,6,2,9,8,1,5,2,7,10,8,2,8,5,7,9,8,7,6,6,4,3,7,10,4,3,10,3,5,6,5,9,4,8,5,4,9,4,10,12,5,12,3,7,12,10,8,8,3,7,3,11,11],\"xaxis\":\"x\",\"y\":[3914,10728,635792,253864,49818,11966,1497694,12532,3914,49837,27176,93694,52572,62764,101824,134416,26544,16182,16211,4816,12896,70200,78884,22344,15326,702956,57460,17732,176540,14896,8643,10507,10008,57784,6758,29541,44020,8424,8604,350997,9362,34918,4294,5676,34216,6106,79711,40486,78964,225624,14144,157914,16568,39312,11594,936900,3631584,6240,6042,18012,9568,137643,16297,6262,1293336,155918,14040,6364,47424,6696,72936,236500,3924,4028,5246,24024,511841,20304,6084,12245,5246,14319,18876,41648,8428,42952,27924,198369,43004,13032,11448,4320,4750,27156,70176,15748,14018,12482,7254,6968,6063,10406,42966,48982,4859,4248,6386,4524172,30573,40092,5304,76836,10664,6278,18791,29388,7668,14756,6262,116356,15084,5805,109512,24128,57474,14446,98540,16776,13416,75672,26208,778545,72680,4446,101308,40964,6324,132870,5824,130500,14248,147098,10912,363084,7502,13020,13373,9196,885422,9724,12943,9559,8246,30524,18802,24095,21804,607724,12403,4066,61628,20398,41065,148441,10712,6344,282948,8664,33440,99634,6372,4134544,31261,147651,49612,48880,11524,4687,31868,14544,5510,12064,69678,7525,80484,53692,3990,153418,15247,1279326,19656,74046,11020,54720,11128,285200,37658,4066,52344,4636,451422,3838,6188,117676,861032,229416,872318,30702,4945,28260,6880,195768,8556,28086,50165,100835,195156,25844,14516,654192,33488,27413,41184,3744,7353,39832,5130,4218,22828,12324,306590,18824,4788,5824,18920,559152,19396,5876,97632,4332,8684,20167,11718,12636,6552,37696,28462,44978,19836,7998,4343,143052,334366,5408,50955,45792,4104,11692,470808,19440,223028,23564,22458,109148,10354,52668,262438,10922,6149,11137,5724,48418,7790,121892,189504,72432,98280,35234,19448,17568,15696,201172,20160,229892,47716,3636,64464,11818,12744,22204,121458,13680,68536,160528,56268,13934408,7900,35313,78289,18658,6292,6498,26728,14405,23858,10816,13144,38710,13702,10981,15394,24804,11804,42897,4560,50220,164260,6916,52030,24056,10816,12772,14446,1195744,698400,5203,24928,5054,39384,117676,151446,19968,24264,126880,20540,15300,18356,10712,17004,6084,19344,1418688,8640,263149,18576,10244,166216,11438,8216,37232,36103,32472,11376,1039492,60528,8496,338840,251136,166032,177460,450379,20066,5356,26149,55068,95906,51088,39216,29488,11248,14664,27612,6384,7697,9610,17696,12096,31304,7344,32916,224992,22594,4066,11818,7998,38528,9216,140920,76322,3996,7936,9204,8684,39096,140976,31806,26164,12428,10656,15824,90534,54954,234732,28892,128804,132408,373591,18000,17784,11904,19096,24984,872784,34162,212836,355579,26064,10191,53234,37368,8320,12168,9030,192918,34844,37539,15958,45198,649472,11880,78192,27456,59768,9287082,11448,6968,560652,37656,53878,180804,44161,393908,204048,6012,8436,6696,15562,43920,312998,23760,15168,13520,6634,59148,14964,8901,13392,4522,26424,19197,11051,21476,29588,23472,13104,5332,149136,19368,24964,601016,4408,4515,5436,12384,20646,14782,21142,5504,11448,7560,49104,121518,10224,1951813,4140,19522,13454,47386,8060,5358,8184,231154,10586,16802,18060,33891,9724,7488,4343,94068,134628,94428,158237,75445,134142,15934,162136,91542,95728,11284,16872,40394,13373,34529,17628,168428,154960,144216,480952,93912,5890,338436,6448,12152,18144,287370,55853,16530,5700,68809,2691358,34424,9620,24727,4104,23940,185938,11997,10602,19080,10664,692744,10716,19684,750421,7992,7182,14136,11664,20769,218400,85162,696299,6200,6604,5652,104201,10368,19197,10540,48856,24332,7704,9620,16297,32040,8385,5564,9202,7072,16454,7592,53483,335952,11016,11222,50616,5980,8892,25012,16068,2747784,7748,10080,119536,857956,4279114,311116,28348,17856,187200,83898,501642,5461,5805,192049,45346,473817,6342856,7904,20482,454248,47196,38236,10944,115577,11266,13114,56072,15190,14018,9238,23472,58320,24885,6063,12692,476397,321382,18060,15444,8769,11248,68510,219085,17992,11904,15428,4262856,77376,70626,40032,54194,9796,16120,280800,12350,9504,55695,5512,533696,17628,17673,22308,31442,9672,6344,273600,718189,176802,155746,3876,140620,29154,10277,5564,151048,35464,9006,19908,15872,8112,20644,10008,12482,8712,289140,200592,405954,12324,52390,28424,19722,67071,15523,71416,20880,220410,19908,2108510,96301,5564,17459,40104,6136,6324,51688,28704,918788,4343,16641,8295,41400,5976,4472,9072,21638,49724,9216,130260,18616,75551,7632,337156,20212,8856,5160,858572,14328,28334,475106,21543,306362,20026,5966,9486,859125,6688,10816,327455,49375,36378,4332,20488,152312,178144,8684,9360,9300,8122,10800,213409,4294,98568,8996,44772,15548,55796,13676,66992,96933,1665162,4452361,17108,75981,11346,17680,6292,115541,21018,28582,37841,12152,18723,5200,889632,9734,343097,8996,4320,1315113,18662,18328,17673,45662,21888,21962,27590,11594,261934,62372,26531,16899,9932,9234,19902,6552,4464,11613,16432,40536,154284,10908,13206,70784,7748,9766,8684,754134,413170,1071288,23750,9308,25438,35155,6536,75168,13826,5928,25128,8804,28835,20026,105710,6968,78819,7030,17352,76946,20088,19032,22704,92132,1066464,12584,265440,5720,382044,5976,64688,15190,4176,221760,25482,13392,7540,51342,14174,22575,4032,571814,11524,9006,7192,1033075,20640,2555424,9360,48450,9144,14402,25200,7866,10602,98784,6572,78605,11532,32612,280618,123264,299568,39579,6751,1309252,16796,16484,200668,880771,103806,34844,37080,9847,155304,7697,7052,7296,317896,63898,6042,22360,52762,29146,3952,5332,51350,259064,23296,6080,9100,16120,917111,32390,19671,18565,29283,13826,20448,11780,10504,65188,32262,22104,757136,5590,13186,34200,177987,22680,6460,6136,165044,10234,178452,13889,18447,528984,7696,121888,60888,35352,6552,20368,20832,32723,6324,16112,12046,3952,216638,15552,62062,7482,102621,5168,10088,390290,12087,6192,77896,4572,11016,8788,2152750,107543,74218,6688,48568,5719,32544,14560,37202,66508,17415,11218,37076,57304,398908,201213,195676,12642,10728,5408,9734,16856,53884,48360,15840,10184,17670,35313,26445,61383,115754,727669,39596,49538,31679,12024,4066,5928,18091,9932,4472,32548,40456,203164,325006,1473802,5876,14384,5246,37752,133431,5332,115026,24358,11309,44878,12768,65333,23560,28124,6292,48111,13728,35030,10292,162582,12245,293968,23384,11752,151580,5624,918375,7130,30889,13454,7600,96064,7224,5230816,21736,3248336,4598,24804,3780,6696,227582,39308,167164,5966,124776,12482,15652,8604,81792,27492,6572,4816,41317,36577,18460,43272,1451704,38950,7956,9348,19608,5356,72759,20800,27404,16692,8778,103272,6572,13104,860976,11297,17784,6278,11128,1086488,7124,139176,12586,30616,26520,47400,49556,6572,17243,10449,125689,75528,6760,403056,39263,55774,27396,9880,16037,13889,12561,7697,262694,10507,17964,7280,19592,71337,7334,38184,3785601,5289,17160,61383,11481,9610,179181,27504,13832,10556,13104,5460,13536,28595,21372,60202,17112,33332,64844,55986,124930,32904,4386,12688,86742,13509,7372,54288,19500,23244,10348,31304,10664,15136,7812,10044,181718,7310,51745,891820,164880,10912,35647,30628,592844,155420,30876,53957,37324,44856,25948,4859,2491660,85570,3439502,32508,8127,164715,15800,119527,21684,28348,10540,51745,37296,6407,17544,4261023,4386,5203,9374,58708,21584,26875,11492,9717,43206,4446,26486,23250,60320,470208,4472,16560,26474,9417,7316,15438,178312,597896,53641,13640,39816,10368,8684,236447,126666,17696,21112,16560,16848,13244,726089,56287,21156,5184,5824,13072,579120,1886836,97802,692128,7296,6696,43524,150653,21758,40976,1810042,18407,1348925,26860,11139,4864,17064,21700,38141,20026,34271,150722,46384,8892,16037,30816,961362,100168,14256,38664,78416,1152531,20232,16848,25704,11552,15128,5805,4028,148678,67756,1246304,8736,13516,4816,4142,55490,13072,5246,11476,29512,55774,62173,183481,153260,75816,9776,43416,10608,36972,21762,9085,5016,11088,1216800,19114,12255,2275911,59112,69368,363874,38448,14196,39888,15496,205321,741960,19840,82560,15879,10244,5848,20020,42423,111241,15340,16488,54498,7332,146010,12654,27590,7750,49794,5289,970416,27962,8246,755793,16168,525587,20894,10608,7095,164304,9890,51116,8112,872526,1931392,53784,4446,145992,18644,20088,26228,29025,16226,7488,129580,55512,20016,13826,9216,10974,38786,30240,4028,9362,15264,4750,5934,8360,14858,24232,23932,8170,21840,290641,17244,205632,216980,506602,34732,556416,20736,20592,25992,5375,9761,4978,7224,31044,13248,30400,73865,56012,5376240,11970,27892,60264,9417,736112,77584,156104,5668,91547,263160,12384,5252,6136,401076,10972,27352,33228,41610,105696,211562,45714,44252,4104,14276,24358,22833,17160,69254,24940,13248,14570,4902,38626,10664,9216,18050,8712,376154,15704,227599,18146,6156,4558,21892,13452,10578,19604,877084,155880,291462,37656,14256,6321,122832,30384,4902,31680,11739,15120,16920,5980,5676,29842,20664,11016,34344,63990,5289,37354,18582,20770,13032,6751,70432,967460,42280180,16906,9576,16344,25359,10108,31916,93353,147146,13932,87216,504099,6510,38532,30600,36270,8742,70704,5031,22176,7540,49059,6572,5548,16120,13312,4078274,4218,9638,153748,27821,53072,40132,16120,6188,60624,82950,449136,59724,14060,90250,14248,7912,11284,7611,5890,45144,4522,5719,250952,7130,93930,17632,15010,12740,24806,144612,24037,12816,281294,22176,15872,13788,538222,34365,19158,4730,23400,14615,4294,16426,5244,51264,206568,29038878,34684,36464,12428,11352,21762,142201,12168,7072,14196,191208,5633,15552,33384,109908,354394,8987,13608,46624,131112,18316,18091,30784,100738,211668,282978,181779,12888,66248,178966,119392,3501504,145281,3952,170956,17544,128016,7502,10540,13520,319160,22910,9424,33136,5375,3577673,3914,7904,7254,160128,982338,4787921,9576,72443,124504,742392,14328,10944,216934,5624,22464,10191,102180,16834,8172,100152,5548,12084,34602,5130,8094,10230,8320,143069,16380,13676,13338,253440,81282,48418,135098,1190276,7353,397606,6192,11856,10088,12028,18720,63550,9300,949240,8784,53300,31679,159692,1229240,11534,80659,1457682,9724,20748,346476,54994,6574,20540,726657,50112,11352,57190,12482,76393,8927,13888,3600,10744,17459,11476,13780,23932,9576,122450,11929,38520,144965,95542,45448,25194,14630,321451,18404,17775,5184,66528,299160,5244,14536,47795,80414,38502,14880,124668,7182,82056,16802,6916,5472,13780,12400,10368,17775,10296,41949,2154014,38076,53621,63752,188889,32422,10070,7228,20862,9576,92035,9954,47684,31464,65246,5130,15184,9864,7800,122544,63498,10415002,8901,36498,19866,16276,5848,44764,1875376,12599,354710,75888,10222,9176,212115,40291,30616,8618,13932,7224,16669,400192,14976,5848,13392,10850,6136,182676,76824,956332,8580,26524,61938,15132,9500,7711348,10192,82713,6500,9675,3952,406297,29016,76235,24467,24411,6916,28132,13392,5928,14364,13896,5976,179883,19902,24253,16864,6080,38868,19500,10556,596711,79484,9954,8094,9766,81528,4472,45030,131924,4343,16306,46512,8372,1071161,85020,3838,218922,26070,891041,14198,27144,73268,19092,5805,19654,15958,12276,42344,55670,42532,137206,7998,9828,36182,9176,14288,16952,40774,44200,58464,32943,22248,6450,38270,5460,7936,11970,24244,4902,58178,30889,40608,18720,4218,11139,59400,7144,19269476,287496,443269,33338,3960,6156,72488,360158,25792,8320,16692,39263,17316,33048,386136,16380,8170,395604,25517,14615,28614,6156,5848,4773,10191,19928066,9100,166752,10478,5418,12648,5461,18864,335916,18772,4522,11552,66994,46784,10836,17628,12008,16272,550185,51034,5512,30573,6232,5117,85696,23478,10504,5976,265734,6696,129704,14322,114939,251292,225792,31320,6966,811172,31096,8268,7783,23832,271918,13110,165505,24048,66248,4988,12152,112060,9412,8690,13000,84925,19874,4598,10712,279186,302188,6574,4988,29388,14773,28638,76153,139040,15872,16016,18648,7440,30628,46698,25413,6235,5396,1356212,5633,9516,5408,434668,947376,7525,5206,36656,11376,6080,32224,6708,11376,73530,21027,53246,102856,12096,1408752,1861184,32566,46398,9114,7344,16992,67624,13364,11352,17594,19708,7416,30628,15934,25346,26600,15184,5092,49928,29520,12152,15984,73584,8990,43645,4687,49920,21424,11592,108252,58144,460096,297960,16058,63279,131219,56992,4066,62805,79608,798769,10608,5054,13536,2141136,46314,5332,12096,6032,123324,17028,1493021,5720,24804,15563,24700,20160,34128,14560,7592,12896,13889,32736,4386,19355,7448,10868,4687,21514,50560,23068,6536,20016,16302,16195,19656,34049,7396,90516,5977,21008,39364,7525,7790,14104,3395520,12400,31218,33136,23068,73910,20880,42344,74214,8496,6384,11180,27360,5977,262596,5652,22824,24381,122140,31540,36890,134230,6020,804615,5772,16120,1989704,11966,350207,9504,124754,163866,4750,8928,92579,43134,22420,5676,53496,656885,3914,32034,3744,27864,9216,7280,19197,127286,6837,7696,288917,7439,34916,14694,8643,4788,9048,17784,174580,117728,13244,16254,10965,217672,10535,13208,93252,13115,3876,12900,181068,18166,99303,6880,142168,4712,7440,20808,6450,67392,5252,20145,209932,8460,4788,46170,5624,40362,9272,16985,10922,126100,73584,37128,12298,6500,9776,4104,7384,8987,11648,14456,19152,12685,16590,115656,7095,468884,113602,53630,11856,30008,550393,6764,119784,177750,161476,5396,37920,15066,4859,71982,423708,94886,8996,12212,8256,32832,23736,145584,947842,29713,13502,13578,5662,786780,6878,14768,411985,192386,7410,7800,56564,55800,15872,252168,4558,52706,44304,18648,640212,6118,200564,10602,481954,25675,31540,151443,4560,9864,13020,42840,38710,136697,27413,70980,25344,4332,18662,19995,30168,119952,3744,10108,25420,6880,749552,171120,118598,15028,20425,301306,48190,73573,8618,35880,5244,9804,11088,114550,158328,22989,6572,16432,35984,78884,8280,6344,8184,10836,113760,3838,4896,101804,3996,5738,9724,8632,464318,55872,30020,10184,118664,349259,1742317,34906,80352,8436,4256,7790,35392,28196,11804,6878,14446,13588,4598,21476,25704,11352,46956,397008,45899,46368,8084,18848,42011,64930,23328,48891,20904,46488,480240,6278,7812,535651,346652,62124,11592,4429,121368,10036,5928,4408,7828,193128,30312,5418,403374,7998,49217,86387,191654,60198,17243,70408,26273,122740,23972,886854,177568,214848,19522,14694,132088,7525,70942,30315,5130,128592,58996,6923,36480,6240,29808,5092,4864,12532,26000,23976,22032,20224,19190,8626,22116,18240,9052,52576,5504,6882,9196,1177848,11340,49324,7334,146880,4484,326823,23688,64414,81449,5168,494326,21166,19136,96222,11952,29467,6758,298034,64844,66664,19694,117154,79670,13320,127368,87516,119536,5590,37200,30600,61462,80969,16120,6820,559320,436852,13224,195672,18414,171950,12616,94385,53404,43946,49556,239904,963802,7852,4680,15800,42696,3378752,38270,380376,15879,424625,17143,112891,995665,138566,393016,661072,14580,6149,235152,22594,24336,21576,7750,7904,33060,22932,44194,12688,100172,23521,52693,14092,6820,154584,279000,14098,9920,53010,217208,6240,30004,16492,27000,99944,43766,13640,31320,9486,17480,118336,143312,6063,28598,5616,64440,10868,8840,10368,62884,26860,15247,14688,162029,95288,25327,10348,153338,117552,33934,10354,10412,291589,30336,194256,7540,1227976,32344,10348,5934,48348,60164,24648,3914,19497911,10234,5760,27576,47558,22724,237460,49290,8372,57190,19512,6448,80106,8424,8424,6536,38304,43834,17632,85952,6916,81840,74808,8295,15563,19039,24862,71416,12636,226610,4028,10400,11594,13244,44082,23134,71208,40680,3720312,11096,22516,7790,4484,90948,16856,53612,5160,325884,5160,8928,46664,6665,11908,6696,12274,67500,8532,241034,6574,10088,14560,9776,25116,5460,18648,7502,4902,13020,9734,5662,37202,30336,262260,67906,103392,71939,83018,66766,116774,11297,33418,1062014,21268,3708,23263,8686,19916,9880,31920,102114,55432,5564,885794,12728,186319,7176,9796,188928,2703014,28234,7020,37762,14456,34602,10354,256987,15048,2912493,7072,14018,32968,10088,26524,56916,53444,14457,12844,43529,9417,1932696,461088,29232,8320,9108,68414,26136,14560,24332,34920,271128,8927,169594,8474,684140,598345,11455,35064,7164,77328,965808,9880,4598,9100434,15996,46228,32760,5928,12084,8690,5776,9000,2987504,13072,106652,5564,3602092,123635,235894,5460,247052,53754,13193,19646,28086,106887,745920,9546,5074,12896,59976,21684,18460,141963,71188,67526,11700,16952,12744,149872,28644,777712,120317,7540,13104,22392,14319,5700,66994,27097,89544,5977,42120,7006,6634,76464,4902,11180,93654,16416,14190,4386,5662,11352,71362,21600,16555,779730,26781,172694,4256,478503,45899,93299,5928,32452,59128,225990,216562,16678,17794,10348,36144,4068,5472,7095,11856,23305,7181,39263,76756,201514,81449,25916,19158,49348,47479,10602,6149,5054,35155,70992,19584,241552,8471,26208,117046,29625,338910,92235,4284,132096,5805,13454,7942,125517,86060,44352,61704,326244,1054614,20026,44460,25978,33583,93000,415423,36704,163176,16039,54747,410332,4142,222480,48384,402268,8772,16640,4408,14144,27492,84604,575172,494145,754992,28656,1210356,515317,58104,4142,388864,12024,10277,7828,56886,130591,13186,17316,67704,5590,149389,11137,25848,64372,9900,597528,45980,8514,80969,14326,40824,222490,11098,8476,31284,68940,973517,149358,168302,10191,100409,1756723,5668,15480,15552,126716,22199,286936,399024,20592,7912,73628,13702,14716,35774,18044,19964,6384,7124,22306,9766,29736,348074,911090,5016,20066,56327,28024,488299,8772,127111,2482046,9576,14060,142386,132440,20384,69502,4294,19552,28756,939238,218096,5564,81270,4484,424908,23700,50639,11514,6292,4256,13490,7697,17822,88198,6020,8164,5460,61857,13029,9464,12888,9548,24984,33232,1918831,18565,212668,20026,67466,4674,2289815,8927,143464,17518,9559,29488,28800,17856,110916,11309,59469,27300,131688,8213,6232,14632,101093,7338600,19584,19760,1379040,9720,33669,8987,62173,4902,117864,22747,449565,49248,186519,23832,14508,76712,13052,14256,6992,13680,23005,9114,10296,172328,47953,6552,80724,6882,6510,10640,12636,17100,74418,161120,23688,47736,60216,117648,12220,45267,8788,54036,23218,9540,41292,44640,4558,8816,4446,5700,9360,10504,5824,11180,119606,67642,167717,12888,4300,7439,39026,46728,30168,7396,2417163,104594,13468,5289,61778,830717,456404,11016,8618,5160,89156,4674,1106237,9568,25517,1094071,120776,31205,21567,9690,230601,199008,26496,633256,12532,15132,1934473,5436,60435,22489,18936,46311,6084,26273,17174,8927,7144,146415,934648,28519,26102,1520640,12090,15132,140146,23940,1001088,13825,145578,210900,38736,19476,31679,293472,20150,21576,7439,243568,10354,8476,45714,163852,42904,4680,32976,4332,11020,227240,4446,88504,25675,5200,49770,168259,9245,32550,18000,10452,75603,8008,72106,36024,46764,6042,81133,8736,37288,15265,29704,35100,509787,131021,5112,68472,15964,57252,8996,61304,5762,80848,15437,50998,56520,20748,1289160,8127,7866,14319,381900,15652,4902,298857,6232,7310,17856,61936,137088,9272,140554,8840,6450,8018,10230,45881,182806,17556,37440,7296,8611,8385,66960,15314,37604,7592,4294,41366,147146,5408,1709876,22152,289952,4515,31126,12350,5720,33480,116130,9652,46956,12400,119764,701896,1120220,4750,7562,6500,87668,293959,46500,126432,96876,25740,33332,36894,7344,198328,44333,5320,19592,14976,4644,18600,18881,8729,37754,10152,17933,47652,12083,191338,956004,89856,247884,16340,6292,9462,13268,12350,7344,153813,23036,22403,7562,7272,15336,4212,18834,8424,177630,199836,3922828,41306,186248,220884,3819510,775806,78447,9804,18644,65556,8930,133859,930620,2279545,14544,1019258,9638,6188,17050,13459,106210,124030,44763,29796,233064,7992,31668,325510,16864,149832,6912,40979,34701,14706,237711,14061,9976,7828,70520,93931,20644,28496,7920,346890,37262,26860,36146,18216,51127,21672,6726,5031,245186,25026,48060,52417,740808,7416,9462,157526,16678,745444,5246,1027710,12220,42186,7874,8736,116057,198432,180041,9620,38998,40334,7095,132192,59555,22752,63426,9648,820728,11128,32072,26676,97881,29848,8742,37368,31428,15132,24986,7384,24552,7904,11036,7596,11532,81936,151759,14322,92579,6080,31691,8164,1119588,20511,6880,10222,21070,3952,31668,30020,16827,80640,288350,7410,12771,2937062,196664,10792,72664,13114,37752,54826,16740,27432,45562,23305,15238,3636,593290,198360,47795,32976,24776,88236,24336,228888,220058,5203,15656,18616,35152,14544,30816,9256,20232,574184,9612,35280,16948,140223,5564,24192,49176,4730,4978,41572,12168,84878,5966,9766,7998,19872,32528,30744,41194,5738980,17420,689184,1516958,27072,41044,60946,6032,6262,18668,52030,7280,41600,9072,29448,26568,31205,146808,33840,69574,86060,4773,5418,6751,18506,282899,6084,11929,56412,305809,112654,13832,9976,12896,414355,6321,163846,20777,10981,49538,6020,57600,194814,12245,6650,8295,2359296,4177599,17112,50544,16616,32736,7942,5876,367744,41416,1861704,499658,138503,9672,6764,118121,68284,11532,10660,209324,352160,83886,454646,8213,507936,10106,7228,7750,12792,122450,11596,21514,52832,492881,6510,145080,131193,10112,233366,9030,11068769,28148,18228,33153,20274,57252,34424,19708,20436,10507,7611,4294,9048,34271,55142,8132,4826,74971,11532,8930,8686,59882,38952,13338,25359,108288,20232,32074,13760,6192,37525,405964,4968,9348,26350,13392,17472,18408,223886,4560,82088,72850,10452,44677,7192,12168,61146,132088,7904,15500,12772,6751,134300,36720,6194,313404,6536,35136,7316,882828,12008,234000,36348,18802,88556,2832545,8588,1082830,85557,6820,36244,187941,293485,6063,66439,10168,7488,45267,147992,168020,14756,3600,60496,32908,873496,542160,92588,133300,13888,59328,18960,13490,10728,39780,25438,4663844,222196,22464,9412,15050,71258,32616,7632,26226,7783,31464,63200,62489,15562,19500,582660,23712,142595,268632,18962,6192,40014,20016,58104,87096,19158,9417,19530,4180,10664,22534,23972,12126,21543,77862,12768,17696,21080,62640,7812,4218,11160,11395,292448,49894,14196,73948,14820,4978,9890,119908,16432,16340,12814,68328,6880,9196,7272,5547,7644,7564,8928,65728,23370,3249823,7611,199080,12586,4816,8742,45792,132088,30690,111176,2638363,716196,25284,28008,88350,18538,196352,28598,8094,42744,14508,62890,5548,19152,49296,10621,37336,30836,12688,9766,21567,11492,8680,24814,13946,5332,23976,5364,202635,24800,15010,47214,4859,202844,11248,30600,537753,81158,236220,512856,9052,153037,14668,22317,18600,30336,7124,6500,75287,108624,113839,6422,16128,11718,70942,9672,10504,51460,21744,77443,5408,224755,85083,18920,34996,675936,58136,32860,35724,144566,7852,57888,15652,3852,15624,275394,1997320,8930,81054,17732,81792,154656,10712,163787,48070,4988,42696,9245,7228,74734,41496,1202581,7068,158808,16872,4408,55588,27716,6168715,85464,7704,25978,18928,5168,47728,52000,10868,6696,4978,7560,12376,10656,9204,10602,437502,19468,7181,551973,89225,61070,122608,8532,12642,88776,63284,4284,65884,13115,10974,10707,301320,16016,5700,120652,16306,46136,6020,4940,12160,7228,1298032,8064,200660,14964,5252,9880,71653,318291,68696,6794,48585,154368,1623024,31616,10728,10621,3952,4142,8428,41791,19872,24586,171144,51584,13330,50353,36022,5772,27976,61189,5461,27413,5304,4932,19049,5130,68651,3952,25776,20304,98696,96933,113100,8352,10140,176886,147368,5547,285348,6235,175248,7776,25428,19380,6188,993852,285192,21112,12324,140144,10036,8684,41344,77672,22704,159831,376593,20224,4370,390624,8164,19684,16068,81686,7254,5700,38812,61304,27820,150495,5555359,63042,22458,40092,59882,14749,9994,23560,7740,3800,18504,17898,55584,74932,65304,64410,12040,4816,6612,12744,31916,997770,13764,146946,29716,10754,9006,3914,164448,7525,244872,9648,25048,5738,18724,4212,43608,4180,75504,44346,8385,7372,5004,297228,4788,20520,59508,242208,13728,8769,10879,4356,2513880,9804,11966,13193,88882,50778,23622,21371,201818,153381,8476,81449,9000,9672,295195,12008,11223,22152,34580,6364,118248,6923,120228,28466,8453,9796,4429,16244,14012,28028,25754,60909,3744,28440,45240,6292,176042,71574,438529,20592,12648,3708,362318,8216,8840,64543,16188,158498,13760,25840,36868,70512,14012,11088,29264,31198,30494,54126,5928,107068,13144,862358,31824,59487,25584,6136,12168,195780,1035648,22680,7848,234522,10088,17484,12312,7752,12376,168516,9300,13824,47690,6396,8742,67983,11160,352893,17064,15252,34056,16116,22444,217566,6308,62248,9424,254448,76235,4687,10920,13364,16340,22496,221676,42226,1807204,33540,2408315,15800,148994,977904,6650,8453,22444,59812,63911,14198,22831,6696,135720,173166,174384,8476,26660,40546,16112,17640,8246,21762,12502,50464,164715,15314,44802,53167,153983,46810,39816,5289,11024,7396,10192,4945,9672,8815,11160,26728,14577,16827,5891,7525,11395,37752,8611,204373,11388,19276,4824,4752,226352,114712,28860,237460,580808,12616,73530,37634,6149,5848,16727,7378,122845,161634,27838,39888,9204,8736,523296,5408,5700,9880,22392,65175,7236,16632,38055,9766,16956,28086,104000,53879,38592,36024,6240,179452,60952,10332,11514,14976,136332,7280,877176,49849,7181,6408,62963,28582,26961,17422,7488,5252,7267,10712,11218,7884,13825,6300,8208,3387308,13186,11470,10788,25482,90139,16016,33970,53768,1978056,113956,5547,602732,31824,144096,51452,11739,86989,69204,212334,9331,140620,12198,4300,66404,29326,15352,70784,7979,12220,5876,30032166,17918,133418,221364,15548,73865,74958,10726,49248,7750,132768,6751,155168,35360,17856,8632,30172,8280,47244,41808,18648,4826,128375,5980,10036,14400,14260,47902,27413,269328,57970,108224,17587,370822,25168,168910,5512,5220,17424,88846,774086,19952,90954,33264,10488,53072,2552885,8640,21166,6708,28677,13312,19916,11438,15953,185887,8632,25116,14062,8788,10633005,477672,22515,17538,24095,9322,19750,4750,45666,120328,11736,48269,101400,16598,7540,69882,1352085,117612,5408,37872,233834,5510,80064,8170,16827,28282,11524,1582920,7228,33575,66220,13000,9804,29230,24120,9120,5200,21488,15500,7228,32328,40204,6572,4558,7611,8164,34400,26307,8686,242996,28954,15010,13520,7436,5824,13946,23920,8580,91010,9538,60610,13364,78520,8856,35720,10660,40053,58500,4601,142911,61699,4066,22506,1044854,19874,23472,14062,49848,6396,11952,58222,1817902,11771,44640,9610,15028,16328,24700,13826,412982,27864,9576,479598,18648,344519,22412,169100,995400,5814,18538,8360,7852,11532,45032,13884,1775556,11856,777852,249302,7688,106468,81720,7568,50718,10062,7254,124109,13870,36328,109512,6262,6696,183528,18620,5396,45562,5016,23332,103106,8424,11780,11904,13156,4068,11960,21014,8736,486008,18644,15128,12212,3683544,7410,537984,149683,21888,43524,508752,11268,1096110,12798,7228,6232,14942,19908,4773,138961,9717,50323,12688,6330823,6448,198843,118792,64440,13728,22360,5074,8804,7900,6552,10292,95532,1364544,4816,4294,4608,5624,17860,87048,53506,8858,13803,32422,22880,7095,10726,792370,14664,60192,5616,11336,41949,17802,13746,6448,7936,6650,28203,124109,250303,45000,10512,26617,306599,16796,14872,4816,8060,6136,25560,252148,4386,16920,91846,14663,16120,4816,19592,18644,113444,19220,53998,24411,13640,53732,48934,33540,10540,7783,7138,29072,5356,68894,17716,18166,11336,40114,6794,11590,19800,27962,25284,20597,61516,12169,25560,5472,63752,5633,34684,31980,5590,67824,16182,14022,182016,15264,214406,49320,92448,11594,9568,2930368,871224,424008,7644,24192,59013,7432952,55480,46436,38220,59760,37656,9675,5472,15048,200294,7272,301731,30960,5168,5203,19908,118800,857880,34944,7783,477660,120080,11395,222552,5054,19282,3990,37999,49286,5074,299304,482790,6916,566825,287481,10602,16492,736632,58344,157508,27664,3688273,14534,8532,5289,441531,9804,322457,10744,46246,63674,51192,4988,5092,40486,7611,23940,107694,173352,8680,6708,12166,8729,39052,82584,7006,48828,514520,8127,13032,72996,23822,42480,18928,28224,6622,6500,34314,9322,32798,13746,16182,12338,4142,6422,23816,122616,62264,14782,8643,43128,11470,24480,4601,27133,11128,9648,1973088,9503,120280,12772,14457,282910,17372,57288,88846,10105,13416,100296,4730,20461,12692,43648,326088,19778,45899,82460,26312,21948,22403,5720,18792,28964,23616,4522,3398975,68472,12341,11222,5772,4978,215498,86490,32311,562875,16568,8474,5418,5590,33022,127152,9234,28458,154682,7654,96459,402480,39816,17301,22176,6572,17316,229732,69564,18476,35712,27032,6235,70735,132652,8740,16900,371108,1253063,5512,21888,7380,6882,92340,101592,7852,94326,15236,37446,5547,288113,6407,6510,9245,18354,527404,185318,95784,9204,189284,32400,53280,248248,6228,4028,8557,2650104,12240,8643,15500,166764,32414,25972,181168,15910,822888,7009,197974,78921,7644,44856,130587,671816,335118,20336,164304,28124,22824,8736,13578,8600,1907424,20938,9500,6820,6139090,30240,7956,32032,604810,10296,119808,22724,117000,140040,40820,657384,6344,118342,13717,9164,31668,49824,10640,268560,10902,162130,47736,9052,15066,4386,13904,9300,21567,99066,1122432,81700,6321,1168410,7192,79128,6536,30968,98197,1440504,37446,22120,26728,7956,21052,13082,324942,108288,143260,4902,110679,6552,9120,20708,11098,13373,36270,10584,23779,1296469,694440,10712,12456,13988,1010568,421290,79441294,14756,2472384,27170,88064,22360,4515,2110999,69125,7638,10404,309601,64896,546838,6708,7030,51557,19823,110050,7052,44304,27404,14276,4864,37683,95073,163530,7714,35932,545495,12524,10981,59803,268836,21312,33800,7800,6048,10224,473688,5762,178932,105196,295802,7482,37446,15264,12152,998675,11532,6760,4218,133036,321516,8736,141015,52200,9984,36432,136710,19708,795801,4408,537911,5980,11309,14456,37512,20596,164016,53784,138675,297830,46748,35640,88848,103806,46080,12008,518328,4712,5940,28704,45360,5700,15912,4142,69998,6321,7848,6612,14835,11455,31744,4515,20696,11008,9728,15340,200298,7783,7568,6132217,32184,33192,537844,45694,47400,16744,22536,16036,54036,21330,291668,384648,6156,17422,7740,21414,18920,284696,15912,5876,45012,4028,7592,495876,8471,4343,34504,54360,23779,44928,92606,163873,10664,17784,21204,192386,186010,9073,11825,213044,89507,219024,274680,2113704,14615,5460,8280,9374,298512,8476,10192,148614,6498,12012,15580,26918,343790,176881,522743,15238,1181998,4343,27413,98434,42581,16616,54994,6696,28423,7200,59976,7020,32448,9052,70434,1247936,4028,14652,87453,520531,11266,13490,136462,28964,9100,9288,5547,97266,178002,162184,19800,31824,137618,66384,46018,9546,5289,4902,150048,104833,96928,18705,50592,13983,12740,65175,7128,13260,23244,3800,41002,224044,10640,6622,52851,23940,7750,42192,16952,6270,133200,7740,280292,27950,5074,679572,5408,11160,10184,100804,6344,205088,9932,14400,38948,562030,7068,8436,7912,1083959,12528,7181,238817,16598,105694,7296,19840,16297,27432,68286,11880,25480,24095,34918,6084,25596,12480,20336,35150,8184,173414,11036,57668,7611,8295,4826,20384,24490,14457,25628,3744,150746,11804,7006,51272,17004,75582,7254,513648,1116648,16770,4294,6136,7258,6235,27248,8632,5824,16058,3960,1591218,118637,17775,10664,6321,191180,50482,13908,33180,11160,14760,41949,1846728,180471,22568,8164,124141,14248,7009,41496,11232,108376,11856,60788,16182,290404,139514,8342,43258,10036,9417,35048,32968,7106,8816,14402,8295,19448,34013,29111,3708,100812,9504,26820,100254,19344,17980,162898,1382500,9920,10191,9159,14147,29070,87360,18096,38190,225288,10192,18288,15132,34944,756288,145813,14508,96965,66024,400536,3057458,13566,16740,142832,1267160,35076,8280,84630,13566,13832,7006,323020,76320,5824,23296,10428,5396,26832,9158,4644,39259,6344,61332,75680,51168,11648,63812,50184,141252,5976,90060,10965,12298,14364,11324,16068,31692,6820,301392,21892,167152,534909,14190,31949,18980,43416,47736,16588,160848,455830,4284,201292,34523,4636,27612,7410,12064,7258,9396,71760,12956,12586,8840,6656,33927,5848,598680,7267,25929,7776,36335,48633,9796,22608,94612,4356,15084,15066,12672,10912,4386,7068,14061,52061,41904,55536,14688,61566,163990,21944,6346,189679,21199,7750,6500,15484,24048,21008,23746,8060,16068,9310,7344,56406,18042,127452,52456,8892,56011,72384,7783,8112,92752,11856,8122,9256,145018,9724,13717,25359,20072,22356,32916,10816,12648,10320,53924,7052,8476,4028,153698,90864,61940,16530,28830,5246,1145264,7638,368136,9858,26496,118658,18354,12116,93496,138320,5358,10449,6156,11160,21973,5246,7900,50402,52632,7912,6688,7224,19952,11440,7192,6708,22648,12688,5668,124558,9982,4945,14534,5719,260463,142792,26226,9761,18328,6422,298699,22672,768196,548018,15428,4370,623626,37804,23091,6864,26752,774832,164808,5580,20770,69472,26220,180594,4730,113688,84778,9164,8804,5320,144096,4484,5168,45899,27056,31200,4392,729926,21758,200148,235578,4066,34959,17980,53009,10222,247832,7488,25201,10764,186835,15624,33356,18936,149530,21024,8060,20020,71712,20770,14694,6760,8804,19221,6364,5891,4978,14773,6708,13201,34352,58460,4472,23750,8424,10707,7740,76880,10008,100316,30456,6510,22230,8968,23370,9462,4864,13716,25929,44793,10296,21660,133194,33170,292932,6622,8213,17264,5522495,9082,7696,6802,408408,9880,7812,14424926,22962,63468,10836,10621,4515,37625,5203,20520,194016,92820,5891,209592,27792,11160,255012,140936,261288,7332,9159,2011606,18216,6968,72000,39895,22059,5418,17524,12403,546285,4636,8702,57660,11388,16524,10036,25840,6020,14061,34839,34164,15089,21251,10664,12948,68888,74464,74256,6020,1200610,27588,26208,108072,8208,3838,4392,80166,96854,844116,4515,3914,2156622,9234,29202,17696,4822192,592658,55252,201025,22536,4945,12728,5564,7176,42441,67680,68688,8436,7688,2529332,10726,14319,26187,56544,150722,19296,4773,38552,63216,31777,94815,42423,40176,26936,109944,7124,87420,11210,7750,432388,24814,114471,34892,7936,52820,840244,10234,13752,56592,13104,68744,7992,8028,150258,4644,10972,5246,86900,121148,2379480,7596,561168,189384,77184,5564,7296,22962,11966,7848,13020,36952,54028,67467,1160068,851067,6032,4300,25992,93444,35787,6240,247379,144017,19158,11096,21930,370584,8736,10270,38502,29025,57828,22831,59598,4932602,17748,43443285,12879136,10244,11932,6660,7904,8804,5738,65592,594828,10665,127920,62135,4066,26536,52488,6278,7254,146984,11908,4484,28849220,14942,404673,230308,70122,88660,324636,4484,7192,407482,83460,427492,9847,18824,36103,10440,21027,128217,30108,18104,6321,12920,73568,3497330,24076,105958,5719,46452,9412,12896,7502,83700,11718,6916,24336,19220,4859,11284,12578,57196,165110,12312,115498,16416,36498,8322,16254,8944,17243,16430,390139,4978,17108,9396,36898,23088,4104287,129636,127660,3888,16200,75578,24016,32798,15236,83187,19342,9374,13896,332272,5772,27612,640646,13968,62662,22464,5460,537437,233116,665575,40896,53424,6880,6032,7072,8060,5074,108864,988011,17546,34286,170976,10140,5206,59171,115752,29760,17056,15953,17420,430160,78572,31648,42269,94800,5016,64440,7776,8471,67580,460728,75384,44826,746313,80659,5977,34997,13984,3952,190368,28386,11248,19038,10374,333301,13459,9880,21584,17316,12708,18228,83876,18275,22940,16920,31096,5358,11492,30324,60822,22968,5054,270180,10974,5720,15910,17280,48906,1042964,109951,1067454,4066,783432,54548,9234,23126,6760,23328,12768,5220,17280,422097,8740,10965,8164,6120,11180,10621,17974,1597459,1465213,14632,3714580,16353,5356,6200,4978,8680,14292,1366092,8690,90720,20520,15810,184544,39618,8928,68098,1280088,394108,12806,20522,11137,46768,37200,3876,446982,7564,20634,15124,69746,253270,90472,9656686,10788,45648,17836,7920,403295,26846,28334,16120,14260,7436,37224,21801,120270,6579752,255291,30286,8512,23712,27968,14782,12341,42718,4712,26784,7524,1567296,12578,16112,379756,4752,7697,16796,47601,5928,12642,22692,48152,87984,6292,76000,13035,26728,65728,4636,222859,9672,29016,8184,4601,4386,4945,52018,53799,7334,15392,6020,12169,7912,83029,253448,6820,194814,19188,19228,65145,83503,10412,5031,13826,2510820,301378,204594,10578,7502,8557,28086,6136,90432,37152,4750,21008,10728,18848,7752,64464,29484,7224,9880,16125,149864,858676,34808,9464,231480,8375422,98857,8424,104359,4522,81468,233616,35880,877982,106912,24118,5928,5356,3838,17538,16306,345228,25416,10044,41688,327218,15192,5876,16211,15089,8213,9196,23134,279032,47842,7396,14632,16856,11818,40560,8928,5865964,30420,61560,20808363,387810,75354,33022,15192,791440,5252,10556,6948,6992,22176,56160,116525,522106,5966,77710,451440,51532,18460,541060,226486,116784,26928,4636,1082520,1239431,13312,16368,12692,35030,7697,85699,6764,16432,11376,94213,442479,67639,70566,24490,11534,244556,15089,5203,16430,13578,52824,2512753,398634,8640,9464,527592,15444,36214,26970,7688,11346,4343,6188,403992,8474,19909,22420,114088,8990,7448,361741,33912,16802,213221,22680,5246,30616,5004,8680,23712,79236,10088,328290,11266,70784,4332,6407,16848,4104,32250,14478,23760,9766,6820,17484,7488,856755,13268,16128,6386,7812,342237,4248,13604,17316,133984,1571184,3839400,7697,5720,2716336,70308,16988,9724,13728,505293,27280,11395,30020,13846,21886,199004,98671,79790,65782,5200,7436,15562,8213,102410,146604,8626,21962,91640,38947,14931,731724,51116,8712,117390,44824,16748,456878,43416,7482,27404,809782,39990,531179,139032,27097,12236,8060,26860,17918,122360,27288,32469,84846,15093,12600,6106,8018,364032,35048,23446,73512,27664,94326,750184,5460,5396,13676,10793,29698,89139,17544,301948,9116,34444,6802,21112,6235,5200,19276,8164,32328,5418,9792,34038,24840,7488,21762,11218,15548,11196,54481,12272,5396,170810,12744,15563,117312,20708,9432,9044,8568,74261,1569113,79636,41396,5848,38880,33604,10584,10512,59272,11596,17856,37758,9417,5054,9842,109800,16632,6966,8580,259992,6552,18565,14612,21164,6300,17222,16678,435240,341833,18126,16150,9331,100434,5814,8580,75516,28028,168646,6536,6916,10792,7998,23312,7440,8740,112812,10192,20556353,19264,64543,9656712,13248,295568,16985,7904,8840,21584,12599,3522294,54872,7006,5510,21142,59020,7654,21840,7254,14536,24244,184202,44635,122335,30336,48348,322582,11656,11718,18662,56576,8684,22878,7626,42532,135876,163080,12956,6240,25585,63270,68241,8729,24614,262446,6708,34788,22828,22199,11954,9030,121432,1490572,4712,5203,6948,27735,13702,9920,44240,11076,89784,148986,76536,9568,26040,8643,122976,10062,3952,26101,5504,63550,275157,4515,26149,85320,9460,288143,2858324,423398,24016,6572,31558,232066,314352,64656,116604,14664,38844,768018,886143,10868,18476,8041,7228,19292,11997,798424,1494578,34782,15996,70742,11804,92983,29941,401241,16378,10140,14835,11596,753186,64220,1612627,14924,8216,30744,13545,7224,20145,11008,27300,10868,6232,23180,190706,40248,21725,17236,61857,18360,8060,10440,27792,4218,9994,11438,18430,26638,210930,48724,101136,40796,14554,5168,8848,7144,36577,20808,17458,18000,75960,367564,41882,37656,23472,5332,7181,333372,31521,279792,48724,5203,14835,7384,8632,1118000,11098,5289,15824,14012,11336,39744,23296,27248,81406,6794,21700,427320,21172,12648,4370,11058,80422,71337,7688,14400,142012,16195,123552,54720,23126,22754,332444,33904,26156,54560,32414,11139,39600,7568,18146,175392,47637,68651,166656,44044,61814,14782,10816,60610,6916,9559,13884,31752,14174,5590,13764,7955,97774,19512,3012665,6240,575989,19866,31720,138456,14536,4826,19264,11868,22968,8788,19750,62282,193544,90396,12341,8600,1925368,273208,10296,7228,4429,57722,860705,35092,4644,6665,4598,6794,11052,128098,524016,5356,34224,9362,4940,23580,8600,9576,21508,29016,7568,1153242,12640,68848,170877,31519,66774,6235,57164,90688,59400,128217,246844,34736,10507,22320,13680,58102,9362,125316,291668,10540,7654,63468,12152,15168,116920,5548,166611,9864,7776,235973,48152,110983,7688,5805,695952,24552,114076,255456,14144,82512,15912,463268,139384,393696,9792,164424,8432,8008,5719,66123,87880,1570441,214458,30816,375092,592105,10526,3924,967104,70128,12958,9589,5092,250900,92588,45741,150822,53072,50052,163956,12771,7502,2078024,15028,6732,7956,15964,18616,80352,10354,13780,3453959,13020,6063,1255176,10621,19656,34884,4687,13680,677730,6878,49880,13114,230412,29450,17928,8494,6156,16948,265124,44454,26312,561279,36792,61828,25359,8424,5460,63516,5616,31248,9360,16692,54696,1614548,5928,18000,33402,17888,37130,52772,227664,8018,112812,12948,4750,58867,7525,114504,36608,6552,20824,630894,14749,11024,4940,8640,28656,50592,16813,35412,264168,12376,11613,291408,7956,675614,3990,215928,422650,428792,106578,11160,9216,14612,10260,10602,408667,191575,20253,68019,67166,33418,5633,148738,11739,13932,29108,75998,34596,64666,704520,4386,296092,73075,164320,28122,7592,737781,6422,15314,6916,10507,6032,7439,50353,43896,8712,14706,472750,198120,6084,20488,209664,4068,802152,14074,5200,7626,13984,155472,14716,9288,10400,5117,55728,1215084,30992,7488,13082,596068,45448,6192,87152,13824,469339,13490,8208,134106,40144,4636,10586,397277,6552,469023,99386,47272,24885,290108,6278,34830,8690,321152,1529320,27072,3587688,34560,7704,6278,4902,482804,122512,7416,32178,5876,10140,6188,82440,106742,14706,9486,8580,8928,18772,29541,35424,161856,451152,7688,5633,574824,15010,4370,14322,10044,28548,7280,52920,9243,7138,257688,5160,527325,121024,10192,38157,35733,4644,22278,16416,25776,223820,570960,1386529,197972,7482,4300,60268,2610530,6878,4256,5928,9724,185115,49059,30780,60912,14248,43628,298566,18791,17160,35836,25110,6665,199001,14260,67104,8360,24209,17680,6235,8424,315456,46696,5616,25596,121660,13260,33552,431972,75140,36784,10088,7138,23250,10707,25201,26939,15010,12428,11596,4558,3990,18202,31104,21926,6820,2050445,12384,198606,8170,9158,76128,31248,6622,5624,7592,4968,117990,1425424,33101,5586,36576,23674,6292,70618,77976,44252,76669,14760,97696,17424,239295,7812,128180,5356,7488,690934,19654,32760,40536,16172,11782,52056,36244,5548,25194,14092,15696,9272,4988,50902,1291264,14276,17050,18290,17759,8352,12958,11481,1055440,107045,5200,16120,84882,7884,17372,16848,5375,5852,8094,107414,8550,25069,158711,9073,102960,5472,18723,312129,811014,417487,32860,9516,45942,13459,4256,15721,77748,11268,51840,12168,35402,12996,294851,4408,250667,12168,3838,81096,14457,10974,312481,40280,11309,8164,45012,78289,29484,4028,25740,198273,73216,555449,63612,5092,49348,8216,21964,88288,7344,4343,5512,33812,28340,1070888,24388,13373,142200,63437,21199,12744,542098,18275,24624,11088,226670,38750,8901,251299,34944,926484,30566,61152,9417,9048,27648,609768,15066,61048,5934,21166,4773,12513,85241,76700,6063,114638,1127883,112892,333640,53320,122044,17286,27056,12806,9256,16454,58344,6840,7874,5652,12084,415079,424574,23296,12480,102297,96668,13148,235657,57433,7334,21672,4370,4066,35948,388296,7920,49063,51116,7006,695968,8132,218088,12958,26445,4750,12400,1016280,2434104,42470,12502,162316,2064608,29625,32968,9256,5436,41791,25413,38088,2494346,323280,31564,7783,11058,33101,6084,10412,6688,70866,7717724,936944,12083,81528,17587,58368,18920,28124,1081184,9202,2223218,6136,33259,6812,8901,28912,6262,1268208,28830,6324,6324,7396,5244,43416,320952,107224,5246,11139,161772,8840,1886544,492404,110448,4515,4256,425258,5547,4945,20296,5160,6726,67704,71796,35774,285758,17264,6536,139356,11160,5117,55771,150021,12960,187467,5504,32034,600795,8626,10972,7332,86903,6448,41882,308396,10191,15264,97344,120317,19307,9516,20664,4370,13452,11804,179409,9331,61978,55063,324360,9331,7228,9796,15376,122766,122450,23392,21508,7634060,13201,139277,116288,8112,23504,7998,12943,7564,6923,19479,7956,5112,7626,675800,14074,13578,7525,64232,5016,80422,140146,53246,12986,19512,10152,8028,53167,9424,39960,11856,124920,8424,38952,21024,452876,79050,14760,7448,9216,32656,19152,871607,55728,33046,480624,19188,10222,19396,5282,152134,840086,17222,16120,23435,11440,155808,12040,256824,35561,6136,31758,1131552,54352,20640,15394,5130,5824,54264,23036,240002,8854,17992,39579,456699,25280,15168,149081,552064,32078,11514,198328,28124,16900,10404,76456,8496,9216,7332,8901,35561,59688,124583,19080,12168,6236464,832581,8496,19434,115111,18538,165416,6634,24490,6634,10070,56340,11058,30992,131298,13788,14384,472812,382123,45425,6579,840718,17062,6665,20210,25896,6916,45408,12556,9204,42739,51858,14400,437684,39494,13624,93783,7353,4826,29536,6696,6063,20708,193180,159264,13110,17174,63792,267264,192608,84538,1094178,8060,24966,16380,47994,28132,7869,335671,12920,33356,25064,7334,6760,197856,4598,68335,14896,7332,3952,10296,207762,7488,15438,15808,6552,7267,99424,136276,22464,87768,9976,11594,216697,37281,15652,102068,14688,4940,35256,66716,3914,4940,5289,6840,17174,15484,7644,95666,107440,30058,20640,5616,17538,8320,10707,27334,108432,5772,4180,3914,24624,5356,43524,40320,11932,79128,6536,11692,720502,31564,110542,23384,12502,105552,11324,156302,4534958,35672,485857,10902,11952,42581,51398,9776,36034,5738,10292,462528,38532,19656,79128,6923,20448,75096,51794,48980,56373,202802,4730,28086,13588,133510,14300,5252,311240,13794,4142,5289,64030,278720,11060,29068,5676,32379,425010,15089,126953,1689128,19604,6760,16328,14362,6408,42120,16328,118924,46689,6278,43316,378138,8816,8385,8374,4644,54684,50869,7144,4218,10902,10152,44268,121520,636272,10348,4212,13832,26496,112902,7980,13728,776644,62568,21328,69230,4515,56674,9048,2339585,9516,8784,12312,15336,13020,16560,10416,17784,10836,638058,56760,15192,6396,9308,24467,55728,582941,8742,7676,17160,20212,11567,30780,110032,7956,8060,155272,170196,91246,19592,26574,2004187,421860,10449,14760,18662,250704,59436,82947,9085,45583,7448,28272,4142,309776,210444,76235,34128,44714,7776,445176,402628,35776,15704,32153,56012,5928,198290,10270,3672,28768,62816,2098443,21576,7800,13764,8094,7998,278080,7904,22204,48484,19513,70876,537887,28810,62186,86040,8058,9116,12900,8892,13144,20232,30312,49928,5396,370352,19522,841745,5934,4142,4560,19872,7009,5054,8360,14184,13728,406348,10191,36332,110304,221052,12087,24054,2762946,4788,13644,17174,7482,9464,10044,6968,130884,23978,29172,5805,44136,6292,3708,71592,304200,32500,187302,109415,6760,66464,7384,8041,158474,115596,9724,117360,7740,4386,86490,93931,190112,10504,9072,15998,224992,8600,47874,10868,11076,42978,1014676,20336,8136,122845,30968,146232,25848,19292,89642,31600,16016,11088,7688,20336,8428,7095,15768,6200,106255,9073,4472,9890,19393,29952,12524,22356,35308,19866,21488,738966,16802,240864,17759,13224,20708,45074,4212,9300,21096,16056,436321,9030,4472,3566850,28598,13104,37969,7600,146940,6080,81432,102672,35392,59830,49770,650547,13320,17222,6536,62252,5616,139464,23908,7564,13156,5966,4320,1039464,84940,16469,93384,18619,48960,4601,50046,21164,6194,13870,7410,74304,6820,5160,10296,12524,14260,23746,16536,337156,18506,10764,194145,7696,7956,49680,9828,104036,5719,6574,12376,17420,6656,18318,248534,5662,4028,7852,28954,11908,41236,11232,55536,9401,13825,6080,9460,16416,8626,68944,8740,361267,8856,14136,6188,26149,29016,7750,27477,6344336,8928,4464,4522,13373,27056,42104,62479,18166,5117,6966,15964,1188606,6188,10726,39246,64414,31521,6864,9052,818763,26714,20461,1618993,5289,5676,11970,19080,2358876,70704,13052,71208,77584,25542,14744,53618,11139,17160,9648,13825,28210,21251,28203,5934,85952,12338,71574,5966,9386,43632,181896,5876,12462,80580,15562,13676,4028,913951,117473,7378,7254,4644,6396,6579,27512,16536,8170,1452204,8372,10492,812520,712975,11232,19096,8432,18724,39780,9546,28656,44424,9548,187426,6321,8664,5876,9308,15405,131254,2437034,15652,6448,23112,8476,159912,120120,15028,5548,7200,166152,116762,16391374,16616,12168,5891,7848,110916,7378,363320,56628,45537,59706,141768,307942,5547,2630700,10823,54622,38916,32240,478345,15132,6882,18810,222227,5668,9620,903997,18091,82713,5928,238248,77634,12896,2306484,6240,5460,6510,4408,4104,14668,17422,34918,19912,44578,340318,10478,47400,46136,22776,25628,22360,9880,23244,34162,2303238,19656,83898,267592,190008,91846,118800,7998,56169,9717,3852,3708,460917,1268856,6660,12688,493064,20862,37584,1157587,10764,118248,13208,9006,7176,16039,62496,38829,32184,4066,13330,5772,293169,893234,5112,8772,1062234,12814,625352,919274,113088,44556,22436,12719,368037,7440,30336,10478,2106326,1039561,28196,68112,165663,57350,28519,29704,365456,130910,39658,6032,291826,16692,1204412,400214,105768,49665,19722,44763,4066,15428,185966,86268,421496,17856,103329,218808,95202,5206,7904,40166,33748,8122,25438,61017,20736,722736,9933,342409,4560,12240,124682,22256,72842,12245,130312,67464,244110,44793,32627,23932,21488,5772,10452,13832,234422,8686,7848,72360,100152,91728,20376,10750,46624,18936,17212,32798,12255,10406,34996,7130,7675506,12502,459000,48111,4294,19522,20683,7280,20952,374539,18565,9503,118512,15552,4773,21844,9030,34048,15496,69757,10922,10902,17280,1191636,4687,5160,53878,4859,49849,34684,16432,49400,11180,82646,6758,40053,13752,9620,18490,64368,9159,7410,49770,218178,10080,210485,5418,8632,14554,42294,4142,9672,79116,8996,55214,252864,11696,37446,24130,550368,10906,18876,29625],\"yaxis\":\"y\",\"type\":\"histogram\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"release_month\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"sum of estimated_sells\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Ventas estimadas por mes\"},\"barmode\":\"relative\",\"bargap\":0.2},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('c69a1956-0f5f-4d94-b58a-fe3d4b39656b');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Del gráfico anterior se observa que existe una diferencia lo suficientemente grande entre las ventas por mes, por lo que se ha decidido utilizar esta variable para el entrenamiento."
      ],
      "metadata": {
        "id": "xeBr_n8-6OzB"
      },
      "id": "xeBr_n8-6OzB"
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.box(df_train, y=\"estimated_sells\", color=\"english\", log_y=True, title=\"estimated_sells según disponibilidad de inglés\")\n",
        "fig.show()\n",
        "fig.write_image(\"english_sells.png\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "8-A-J8hTLxGA",
        "outputId": "a5a20ffa-c199-4198-bc4d-bbb39818f8b9"
      },
      "id": "8-A-J8hTLxGA",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.16.1.min.js\"></script>                <div id=\"2236d6f1-34b4-49a7-977b-f994ca21fdc9\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"2236d6f1-34b4-49a7-977b-f994ca21fdc9\")) {                    Plotly.newPlot(                        \"2236d6f1-34b4-49a7-977b-f994ca21fdc9\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"english=1<br>estimated_sells=%{y}<extra></extra>\",\"legendgroup\":\"1\",\"marker\":{\"color\":\"#636efa\"},\"name\":\"1\",\"notched\":false,\"offsetgroup\":\"1\",\"orientation\":\"v\",\"showlegend\":true,\"x0\":\" \",\"xaxis\":\"x\",\"y\":[3914,10728,635792,253864,49818,11966,1497694,12532,3914,49837,27176,93694,52572,62764,101824,134416,26544,16182,16211,4816,12896,70200,78884,22344,15326,702956,57460,17732,176540,14896,8643,10507,10008,57784,6758,29541,44020,8424,8604,350997,9362,34918,4294,5676,34216,6106,79711,40486,78964,225624,14144,157914,16568,39312,11594,936900,3631584,6240,6042,18012,9568,137643,16297,6262,1293336,155918,14040,6364,47424,6696,72936,236500,3924,4028,5246,24024,511841,20304,6084,12245,5246,14319,18876,41648,8428,42952,27924,198369,43004,13032,11448,4320,4750,27156,70176,15748,14018,12482,7254,6968,6063,10406,42966,48982,4859,4248,6386,4524172,30573,5304,76836,10664,6278,18791,29388,7668,14756,6262,116356,15084,5805,109512,24128,57474,14446,98540,16776,13416,75672,26208,778545,72680,4446,101308,40964,6324,132870,5824,130500,14248,147098,10912,363084,7502,13020,13373,9196,885422,9724,12943,9559,8246,30524,18802,24095,21804,607724,12403,4066,61628,20398,41065,148441,10712,6344,282948,8664,99634,6372,4134544,147651,49612,48880,11524,4687,31868,5510,12064,69678,7525,80484,53692,3990,153418,15247,1279326,19656,74046,11020,54720,11128,285200,37658,4066,52344,4636,451422,3838,6188,117676,861032,229416,872318,30702,4945,28260,6880,195768,8556,28086,50165,100835,195156,25844,14516,654192,33488,27413,41184,3744,7353,39832,5130,4218,22828,12324,306590,18824,4788,5824,18920,559152,19396,5876,97632,4332,8684,20167,11718,12636,6552,37696,28462,44978,19836,7998,4343,143052,334366,5408,50955,45792,11692,470808,19440,223028,23564,22458,109148,52668,262438,10922,6149,11137,5724,48418,7790,121892,189504,72432,98280,35234,19448,17568,15696,201172,20160,229892,47716,3636,64464,11818,12744,22204,121458,13680,68536,160528,56268,13934408,7900,35313,78289,18658,6292,6498,26728,14405,23858,10816,13144,38710,13702,10981,24804,11804,42897,4560,50220,164260,6916,52030,24056,10816,12772,14446,1195744,698400,5203,24928,5054,39384,117676,151446,19968,126880,20540,15300,18356,10712,17004,6084,19344,1418688,8640,263149,18576,10244,166216,11438,8216,37232,36103,32472,11376,1039492,60528,8496,338840,251136,166032,177460,450379,20066,5356,26149,55068,95906,51088,39216,29488,11248,14664,27612,6384,7697,9610,17696,12096,31304,7344,32916,224992,22594,4066,11818,7998,38528,9216,140920,76322,3996,7936,9204,8684,39096,140976,31806,26164,12428,10656,15824,90534,54954,234732,28892,128804,132408,373591,18000,17784,11904,19096,24984,872784,34162,212836,355579,26064,10191,53234,37368,8320,12168,9030,192918,34844,37539,15958,45198,649472,11880,78192,27456,59768,9287082,11448,6968,560652,37656,53878,180804,44161,393908,204048,6012,8436,6696,15562,43920,312998,23760,15168,13520,6634,59148,14964,8901,13392,4522,26424,19197,11051,21476,29588,23472,13104,5332,149136,19368,24964,601016,4408,4515,5436,12384,20646,14782,21142,5504,11448,7560,49104,121518,10224,1951813,4140,19522,13454,47386,8060,5358,8184,231154,10586,16802,18060,33891,9724,7488,4343,94068,134628,94428,158237,75445,134142,15934,162136,91542,95728,11284,16872,40394,13373,34529,17628,168428,154960,144216,480952,93912,5890,338436,6448,12152,18144,287370,55853,16530,5700,68809,2691358,34424,9620,24727,4104,185938,11997,10602,19080,10664,692744,10716,19684,750421,7992,7182,14136,11664,20769,218400,85162,696299,6200,6604,5652,104201,10368,19197,10540,48856,24332,7704,9620,16297,32040,8385,5564,9202,7072,16454,7592,53483,335952,11016,11222,50616,5980,8892,25012,16068,2747784,7748,10080,119536,857956,4279114,311116,28348,17856,187200,83898,501642,5461,5805,192049,45346,473817,6342856,7904,20482,454248,47196,38236,10944,115577,11266,13114,56072,15190,14018,9238,23472,58320,24885,6063,12692,476397,321382,18060,15444,8769,11248,68510,219085,17992,11904,15428,4262856,77376,70626,40032,54194,9796,16120,280800,12350,9504,55695,5512,533696,17628,17673,22308,31442,9672,6344,273600,718189,176802,155746,140620,29154,10277,5564,151048,35464,9006,19908,15872,8112,20644,10008,12482,8712,289140,200592,405954,12324,52390,28424,19722,67071,15523,71416,20880,220410,19908,2108510,96301,5564,17459,40104,6136,6324,51688,28704,918788,4343,16641,8295,41400,5976,4472,9072,21638,49724,9216,130260,18616,75551,7632,337156,20212,8856,5160,858572,14328,28334,475106,21543,306362,20026,5966,9486,859125,6688,10816,327455,49375,36378,4332,20488,152312,178144,8684,9360,9300,8122,10800,213409,4294,98568,8996,44772,15548,55796,13676,66992,96933,1665162,4452361,17108,75981,11346,17680,6292,115541,21018,28582,37841,12152,18723,5200,889632,9734,343097,8996,4320,1315113,18662,18328,17673,45662,21888,21962,27590,11594,261934,62372,26531,16899,9932,19902,6552,4464,11613,16432,40536,154284,13206,70784,7748,9766,8684,754134,413170,1071288,23750,9308,25438,35155,6536,75168,13826,5928,25128,8804,28835,20026,105710,6968,78819,7030,17352,76946,20088,19032,22704,92132,1066464,12584,265440,5720,382044,64688,15190,4176,221760,25482,13392,7540,51342,14174,22575,4032,571814,11524,9006,7192,1033075,20640,2555424,9360,48450,9144,14402,25200,7866,10602,98784,6572,78605,11532,32612,280618,123264,299568,39579,6751,1309252,16796,16484,200668,880771,103806,34844,37080,9847,155304,7697,7052,7296,317896,63898,6042,22360,52762,29146,3952,5332,51350,259064,23296,6080,9100,16120,917111,32390,19671,18565,29283,13826,20448,11780,10504,65188,32262,22104,757136,5590,13186,34200,177987,22680,6460,6136,165044,10234,13889,18447,528984,7696,121888,60888,35352,6552,20832,32723,6324,16112,12046,3952,216638,15552,62062,7482,102621,5168,10088,390290,12087,6192,77896,4572,11016,8788,2152750,107543,74218,6688,48568,5719,32544,14560,37202,66508,17415,11218,37076,57304,398908,201213,195676,12642,10728,5408,9734,16856,53884,48360,15840,10184,17670,35313,26445,61383,115754,727669,39596,49538,31679,12024,4066,5928,18091,9932,4472,32548,40456,203164,325006,1473802,5876,14384,5246,37752,133431,5332,24358,11309,44878,12768,65333,23560,28124,6292,48111,13728,35030,10292,162582,12245,293968,23384,11752,151580,5624,918375,7130,30889,13454,7600,96064,7224,5230816,21736,3248336,4598,24804,3780,6696,227582,39308,167164,5966,124776,12482,15652,8604,81792,27492,6572,4816,41317,36577,18460,43272,1451704,38950,7956,9348,19608,5356,72759,20800,27404,16692,8778,103272,6572,13104,860976,11297,17784,6278,11128,1086488,7124,139176,12586,30616,26520,47400,49556,6572,17243,10449,125689,75528,6760,403056,39263,55774,27396,16037,13889,12561,7697,262694,10507,17964,7280,19592,71337,38184,3785601,5289,17160,61383,11481,9610,27504,13832,10556,13104,5460,13536,28595,21372,60202,17112,33332,64844,55986,124930,32904,4386,12688,86742,13509,7372,54288,19500,23244,10348,31304,15136,7812,10044,181718,7310,51745,891820,164880,10912,35647,30628,592844,155420,30876,53957,37324,44856,25948,4859,2491660,85570,3439502,32508,8127,164715,15800,119527,21684,28348,10540,51745,37296,6407,17544,4261023,4386,5203,9374,58708,21584,26875,11492,9717,43206,26486,23250,60320,470208,4472,26474,9417,7316,15438,178312,597896,53641,13640,39816,10368,8684,236447,126666,17696,21112,16560,16848,13244,726089,56287,21156,5184,5824,13072,579120,1886836,97802,692128,7296,6696,43524,150653,21758,40976,1810042,18407,1348925,26860,11139,4864,17064,21700,38141,20026,34271,150722,46384,8892,16037,30816,961362,100168,14256,38664,78416,1152531,20232,16848,25704,11552,15128,5805,4028,148678,67756,1246304,8736,13516,4816,4142,55490,13072,5246,11476,29512,55774,62173,183481,153260,75816,9776,43416,10608,21762,9085,5016,11088,1216800,19114,2275911,59112,69368,363874,38448,14196,39888,15496,205321,741960,19840,82560,15879,10244,5848,20020,42423,111241,15340,16488,54498,7332,146010,12654,27590,7750,49794,5289,970416,27962,8246,755793,16168,525587,20894,10608,7095,164304,9890,51116,8112,872526,1931392,53784,4446,145992,18644,20088,26228,29025,16226,7488,129580,55512,20016,13826,9216,10974,38786,30240,4028,9362,15264,4750,5934,8360,14858,24232,23932,8170,21840,290641,17244,205632,216980,506602,34732,556416,20736,20592,25992,5375,9761,4978,7224,31044,13248,30400,73865,56012,5376240,11970,27892,60264,9417,736112,77584,156104,5668,91547,263160,12384,5252,6136,401076,10972,27352,33228,41610,105696,211562,45714,44252,4104,14276,24358,22833,17160,69254,24940,13248,14570,4902,38626,10664,9216,18050,8712,376154,15704,227599,18146,6156,4558,21892,13452,10578,19604,877084,155880,291462,37656,14256,6321,122832,30384,4902,31680,11739,15120,16920,5980,5676,29842,20664,11016,34344,63990,5289,37354,18582,20770,13032,6751,70432,967460,42280180,16906,9576,16344,25359,10108,31916,93353,147146,13932,87216,504099,6510,38532,30600,36270,8742,70704,5031,22176,7540,49059,6572,5548,16120,13312,4078274,4218,9638,153748,27821,53072,40132,16120,6188,60624,82950,449136,59724,90250,14248,7912,11284,7611,5890,45144,4522,5719,250952,7130,93930,17632,15010,12740,24806,144612,24037,12816,281294,22176,15872,13788,538222,34365,19158,4730,23400,14615,4294,16426,5244,51264,206568,29038878,34684,36464,12428,11352,21762,142201,12168,7072,14196,191208,5633,15552,33384,109908,354394,8987,13608,46624,131112,18316,18091,100738,211668,282978,181779,12888,66248,178966,119392,3501504,145281,3952,170956,17544,7502,10540,13520,319160,22910,9424,33136,5375,3577673,3914,7904,7254,160128,982338,4787921,9576,72443,124504,742392,14328,10944,216934,5624,22464,10191,102180,16834,8172,100152,5548,12084,34602,5130,8094,10230,8320,143069,16380,13676,13338,253440,81282,48418,135098,1190276,7353,397606,6192,11856,10088,12028,18720,63550,9300,949240,8784,53300,31679,159692,1229240,11534,80659,1457682,9724,20748,346476,54994,6574,20540,726657,50112,11352,57190,12482,76393,8927,13888,3600,10744,17459,11476,13780,23932,9576,122450,11929,38520,144965,95542,45448,25194,14630,321451,18404,17775,5184,66528,299160,5244,14536,47795,80414,38502,14880,124668,7182,82056,16802,6916,5472,13780,12400,10368,17775,10296,41949,2154014,38076,53621,63752,188889,32422,7228,20862,9576,92035,9954,47684,31464,65246,5130,15184,9864,7800,122544,63498,10415002,8901,36498,19866,16276,5848,44764,1875376,12599,354710,75888,10222,9176,212115,30616,8618,13932,7224,16669,400192,14976,5848,13392,10850,6136,182676,76824,956332,8580,26524,61938,15132,9500,7711348,10192,82713,6500,9675,3952,406297,29016,76235,24467,24411,6916,28132,13392,5928,14364,13896,5976,179883,19902,24253,16864,6080,38868,19500,10556,596711,79484,9954,8094,9766,81528,4472,45030,131924,4343,16306,46512,8372,1071161,85020,3838,218922,26070,891041,14198,27144,19092,5805,19654,15958,12276,42344,55670,42532,137206,7998,9828,36182,9176,14288,16952,40774,44200,58464,32943,22248,6450,38270,5460,7936,11970,24244,4902,58178,30889,40608,18720,4218,11139,59400,7144,19269476,287496,443269,33338,3960,6156,72488,360158,25792,8320,16692,39263,17316,33048,386136,16380,8170,395604,25517,14615,28614,6156,5848,4773,10191,19928066,9100,166752,10478,5418,12648,5461,18864,335916,18772,4522,11552,66994,46784,10836,17628,12008,16272,550185,51034,5512,30573,6232,5117,85696,10504,5976,265734,6696,129704,14322,114939,251292,225792,31320,6966,811172,31096,8268,7783,23832,271918,13110,165505,24048,66248,4988,12152,112060,9412,8690,13000,84925,19874,4598,10712,279186,302188,6574,4988,29388,14773,28638,76153,139040,15872,16016,18648,7440,30628,46698,25413,6235,5396,1356212,5633,9516,5408,434668,947376,7525,5206,36656,11376,6080,32224,6708,11376,73530,21027,53246,102856,12096,1408752,1861184,32566,46398,9114,7344,16992,67624,13364,11352,17594,19708,7416,30628,15934,25346,26600,15184,5092,49928,29520,12152,15984,73584,8990,43645,4687,49920,21424,11592,108252,58144,460096,297960,16058,63279,131219,56992,4066,62805,79608,798769,10608,13536,2141136,46314,5332,12096,6032,123324,17028,1493021,5720,24804,15563,24700,20160,34128,14560,7592,12896,13889,32736,4386,19355,7448,10868,4687,21514,50560,23068,6536,20016,16302,16195,19656,34049,7396,90516,5977,21008,39364,7525,7790,14104,3395520,12400,31218,33136,23068,73910,20880,42344,74214,8496,6384,11180,27360,5977,262596,5652,22824,24381,122140,31540,36890,134230,6020,804615,5772,16120,1989704,11966,350207,9504,124754,163866,4750,8928,92579,43134,22420,5676,53496,656885,3914,32034,3744,27864,9216,7280,19197,127286,6837,7696,288917,7439,34916,14694,8643,4788,9048,17784,174580,117728,13244,16254,10965,217672,10535,13208,93252,13115,3876,12900,181068,18166,99303,6880,142168,4712,7440,20808,6450,67392,5252,20145,209932,8460,4788,46170,5624,40362,9272,16985,10922,126100,73584,37128,12298,6500,9776,4104,7384,8987,11648,14456,19152,12685,16590,115656,7095,468884,113602,53630,11856,30008,550393,6764,119784,177750,161476,5396,37920,15066,4859,71982,423708,94886,8996,12212,8256,32832,23736,145584,947842,13502,13578,5662,786780,6878,14768,411985,192386,7410,7800,56564,55800,15872,252168,4558,52706,44304,18648,640212,6118,200564,10602,481954,25675,31540,151443,4560,9864,13020,42840,38710,136697,27413,70980,25344,4332,18662,19995,30168,119952,3744,10108,25420,6880,749552,171120,118598,15028,20425,301306,48190,73573,8618,35880,5244,9804,11088,114550,158328,22989,6572,16432,35984,78884,8280,6344,8184,10836,113760,3838,4896,101804,3996,5738,9724,8632,464318,55872,30020,10184,118664,349259,1742317,34906,80352,8436,4256,7790,35392,28196,11804,6878,14446,13588,4598,21476,25704,11352,46956,397008,45899,46368,8084,18848,42011,64930,23328,48891,20904,46488,480240,6278,7812,535651,346652,62124,11592,4429,121368,10036,5928,4408,7828,193128,30312,5418,403374,7998,49217,86387,191654,60198,17243,70408,26273,122740,23972,886854,177568,214848,19522,14694,132088,7525,70942,30315,5130,128592,58996,6923,36480,6240,29808,5092,4864,12532,26000,23976,22032,20224,19190,8626,22116,18240,9052,52576,5504,6882,9196,1177848,11340,49324,7334,146880,4484,326823,23688,64414,81449,5168,494326,21166,19136,96222,11952,29467,6758,298034,64844,66664,19694,117154,79670,13320,127368,87516,119536,5590,37200,30600,61462,80969,16120,6820,559320,436852,13224,195672,18414,171950,12616,94385,53404,43946,49556,239904,963802,7852,4680,15800,42696,3378752,38270,380376,15879,424625,17143,112891,995665,138566,393016,661072,14580,6149,235152,22594,24336,21576,7750,7904,33060,22932,44194,12688,100172,23521,52693,14092,6820,154584,279000,14098,9920,53010,217208,6240,30004,16492,27000,99944,43766,13640,31320,9486,17480,118336,143312,6063,28598,5616,64440,10868,8840,10368,62884,26860,15247,14688,162029,95288,25327,10348,153338,117552,33934,10354,10412,291589,30336,194256,7540,1227976,32344,10348,5934,48348,60164,24648,3914,19497911,10234,5760,27576,47558,22724,237460,49290,8372,57190,19512,6448,80106,8424,8424,6536,38304,43834,17632,85952,6916,81840,74808,8295,15563,19039,24862,71416,12636,226610,4028,10400,11594,13244,44082,23134,71208,40680,3720312,11096,22516,7790,4484,90948,16856,53612,5160,325884,5160,8928,46664,6665,11908,6696,67500,8532,241034,6574,10088,14560,9776,25116,5460,18648,7502,4902,13020,9734,5662,37202,30336,262260,67906,103392,71939,83018,66766,116774,11297,33418,1062014,21268,3708,23263,8686,19916,9880,31920,102114,55432,5564,885794,12728,186319,7176,9796,188928,2703014,28234,7020,37762,14456,34602,10354,256987,15048,2912493,7072,14018,32968,10088,26524,56916,53444,14457,12844,43529,9417,1932696,461088,29232,8320,68414,26136,14560,24332,34920,271128,8927,169594,8474,684140,598345,11455,35064,7164,77328,965808,9880,4598,9100434,15996,46228,32760,5928,12084,8690,5776,9000,2987504,13072,106652,5564,3602092,123635,235894,5460,247052,53754,13193,19646,28086,106887,745920,9546,5074,12896,59976,21684,18460,141963,71188,67526,11700,16952,12744,149872,28644,777712,120317,7540,13104,22392,14319,5700,66994,27097,89544,5977,42120,7006,6634,76464,4902,11180,93654,16416,14190,4386,5662,11352,71362,21600,16555,779730,26781,172694,4256,478503,45899,93299,5928,32452,59128,225990,216562,16678,17794,10348,36144,4068,5472,7095,11856,23305,7181,39263,76756,201514,81449,25916,19158,49348,47479,10602,6149,5054,35155,70992,19584,241552,8471,26208,117046,29625,338910,92235,4284,132096,5805,13454,7942,125517,86060,44352,61704,326244,1054614,20026,44460,25978,33583,93000,415423,36704,163176,16039,54747,410332,4142,222480,48384,402268,8772,16640,4408,14144,27492,84604,575172,494145,754992,28656,1210356,515317,58104,4142,388864,12024,10277,56886,130591,13186,17316,67704,5590,149389,11137,25848,64372,9900,597528,45980,8514,80969,14326,40824,222490,11098,8476,31284,68940,973517,149358,168302,10191,100409,1756723,5668,15480,15552,126716,22199,286936,399024,20592,7912,73628,13702,14716,35774,18044,19964,6384,7124,22306,29736,348074,911090,5016,20066,56327,28024,488299,8772,127111,2482046,9576,14060,142386,132440,20384,69502,4294,19552,28756,939238,218096,5564,81270,4484,424908,23700,50639,11514,6292,4256,7697,17822,88198,6020,8164,5460,61857,13029,9464,12888,9548,24984,33232,1918831,18565,212668,20026,67466,2289815,8927,143464,17518,9559,29488,28800,17856,110916,11309,59469,27300,131688,8213,6232,14632,101093,7338600,19584,19760,1379040,9720,33669,8987,62173,4902,117864,22747,449565,49248,186519,23832,14508,76712,13052,14256,6992,13680,23005,9114,10296,172328,47953,6552,80724,6882,6510,10640,12636,17100,74418,161120,23688,47736,60216,117648,12220,45267,8788,54036,23218,9540,41292,44640,4558,8816,4446,5700,9360,10504,5824,11180,119606,67642,167717,12888,4300,7439,39026,46728,30168,7396,2417163,104594,13468,5289,61778,830717,456404,11016,8618,5160,89156,4674,1106237,9568,25517,1094071,120776,31205,21567,9690,230601,199008,26496,633256,12532,15132,1934473,5436,60435,22489,18936,46311,6084,26273,17174,8927,7144,146415,934648,28519,26102,1520640,12090,15132,140146,23940,1001088,13825,145578,210900,38736,19476,31679,293472,20150,21576,7439,243568,10354,8476,45714,163852,42904,4680,32976,11020,4446,88504,25675,5200,49770,168259,9245,32550,18000,10452,75603,8008,72106,36024,46764,6042,81133,8736,37288,15265,29704,35100,509787,131021,5112,68472,15964,57252,8996,61304,5762,80848,15437,50998,56520,20748,1289160,8127,14319,381900,15652,4902,298857,6232,7310,17856,61936,137088,9272,140554,8840,6450,10230,45881,182806,17556,37440,7296,8611,8385,66960,15314,37604,7592,4294,41366,147146,5408,1709876,22152,289952,4515,31126,12350,5720,33480,116130,9652,46956,12400,119764,701896,1120220,4750,7562,6500,87668,293959,46500,126432,96876,25740,33332,36894,7344,198328,44333,5320,19592,14976,4644,18600,18881,8729,37754,10152,17933,47652,12083,191338,956004,89856,247884,16340,6292,9462,13268,12350,7344,153813,23036,22403,7562,7272,15336,4212,18834,8424,177630,199836,3922828,41306,186248,220884,3819510,775806,78447,9804,18644,65556,8930,133859,930620,2279545,14544,1019258,9638,6188,17050,13459,106210,124030,44763,29796,233064,7992,31668,325510,16864,149832,6912,40979,34701,14706,237711,14061,9976,7828,70520,93931,20644,28496,7920,346890,37262,26860,36146,18216,51127,21672,6726,5031,245186,25026,48060,52417,740808,7416,9462,157526,16678,745444,5246,1027710,12220,42186,7874,8736,116057,198432,180041,9620,38998,40334,7095,132192,59555,22752,63426,9648,820728,11128,32072,26676,97881,29848,8742,37368,31428,15132,24986,7384,24552,7904,11036,7596,11532,81936,151759,14322,92579,6080,31691,8164,1119588,20511,6880,10222,21070,3952,31668,30020,16827,80640,288350,7410,12771,2937062,196664,10792,72664,13114,37752,54826,16740,27432,45562,23305,15238,3636,593290,198360,47795,32976,24776,88236,24336,228888,220058,5203,15656,18616,35152,14544,30816,9256,20232,574184,9612,35280,16948,140223,5564,24192,49176,4730,4978,41572,12168,84878,5966,9766,7998,19872,32528,30744,41194,5738980,17420,689184,1516958,27072,41044,60946,6032,6262,18668,52030,7280,41600,9072,29448,26568,31205,146808,33840,69574,86060,4773,5418,6751,18506,282899,6084,11929,56412,305809,112654,13832,9976,12896,414355,6321,163846,20777,10981,49538,6020,57600,194814,12245,6650,8295,2359296,4177599,17112,50544,16616,32736,7942,5876,367744,41416,1861704,499658,138503,9672,6764,118121,68284,11532,10660,209324,352160,83886,454646,8213,507936,10106,7228,7750,12792,122450,11596,21514,52832,492881,6510,145080,131193,10112,233366,9030,11068769,28148,18228,33153,20274,57252,34424,19708,20436,10507,7611,4294,9048,34271,55142,8132,4826,74971,11532,8930,8686,59882,38952,13338,25359,108288,20232,32074,6192,37525,405964,4968,9348,26350,13392,17472,18408,223886,4560,82088,72850,10452,7192,12168,61146,132088,7904,15500,12772,6751,134300,36720,6194,313404,6536,35136,7316,882828,12008,234000,36348,18802,88556,2832545,8588,1082830,85557,6820,36244,187941,293485,66439,10168,7488,45267,147992,168020,14756,3600,60496,32908,873496,542160,92588,133300,13888,59328,18960,13490,10728,39780,25438,4663844,222196,22464,9412,15050,71258,32616,7632,26226,7783,31464,63200,62489,15562,19500,582660,23712,142595,268632,18962,40014,20016,58104,87096,19158,9417,19530,10664,22534,23972,12126,21543,77862,12768,17696,21080,62640,7812,4218,11160,11395,292448,49894,14196,73948,14820,4978,9890,119908,16432,16340,12814,68328,6880,9196,7272,5547,7644,7564,8928,65728,23370,3249823,7611,199080,12586,4816,8742,45792,132088,30690,111176,2638363,716196,25284,28008,88350,18538,196352,28598,8094,42744,14508,62890,5548,19152,49296,10621,37336,30836,12688,9766,21567,11492,8680,24814,13946,5332,23976,5364,202635,24800,47214,4859,202844,11248,30600,537753,81158,236220,512856,9052,153037,14668,22317,18600,30336,7124,6500,75287,108624,113839,16128,11718,70942,9672,10504,51460,21744,77443,5408,224755,85083,18920,34996,675936,58136,32860,35724,144566,7852,57888,15652,15624,275394,1997320,8930,81054,17732,81792,154656,10712,163787,48070,4988,42696,9245,7228,74734,41496,1202581,7068,158808,16872,4408,55588,27716,6168715,85464,7704,25978,18928,5168,47728,52000,10868,6696,4978,7560,12376,10656,9204,10602,437502,19468,7181,551973,89225,61070,122608,8532,12642,88776,63284,4284,65884,13115,10974,10707,301320,16016,5700,120652,16306,46136,6020,4940,12160,7228,1298032,8064,200660,14964,5252,9880,71653,318291,68696,6794,48585,154368,1623024,31616,10728,10621,3952,4142,8428,41791,19872,24586,171144,51584,13330,50353,36022,5772,27976,61189,5461,27413,5304,4932,19049,5130,68651,3952,25776,20304,98696,96933,113100,8352,10140,176886,147368,5547,285348,175248,7776,25428,19380,6188,993852,285192,21112,12324,140144,10036,8684,41344,77672,22704,159831,376593,20224,4370,390624,8164,19684,16068,81686,7254,5700,38812,61304,27820,150495,5555359,63042,40092,59882,14749,9994,23560,7740,3800,18504,17898,55584,74932,65304,64410,12040,4816,6612,12744,31916,997770,13764,146946,29716,9006,3914,164448,7525,244872,9648,25048,5738,18724,4212,43608,4180,75504,44346,8385,7372,5004,297228,4788,20520,59508,242208,13728,8769,10879,2513880,9804,11966,13193,88882,50778,23622,201818,153381,8476,81449,9000,9672,295195,12008,11223,22152,34580,6364,118248,6923,120228,28466,8453,9796,4429,16244,14012,28028,25754,60909,3744,28440,45240,6292,176042,71574,438529,20592,12648,3708,362318,8216,8840,64543,16188,158498,13760,25840,36868,70512,14012,11088,29264,31198,30494,54126,5928,107068,13144,862358,31824,59487,25584,6136,12168,195780,1035648,22680,7848,234522,10088,17484,12312,7752,12376,168516,9300,13824,47690,6396,8742,67983,11160,352893,17064,15252,34056,16116,22444,217566,6308,62248,9424,254448,76235,4687,10920,13364,16340,22496,221676,42226,1807204,33540,2408315,15800,148994,977904,6650,8453,22444,59812,63911,14198,22831,6696,135720,173166,174384,8476,26660,40546,16112,17640,8246,21762,12502,50464,164715,15314,44802,53167,153983,46810,39816,5289,11024,7396,10192,4945,9672,8815,11160,26728,14577,16827,5891,7525,11395,37752,8611,204373,11388,19276,4824,4752,226352,114712,28860,237460,580808,12616,73530,37634,6149,5848,16727,7378,122845,161634,27838,39888,8736,523296,5408,5700,9880,22392,65175,7236,16632,38055,9766,16956,28086,104000,53879,38592,36024,6240,179452,60952,10332,11514,14976,136332,7280,877176,49849,7181,6408,62963,28582,26961,17422,7488,5252,7267,10712,11218,7884,13825,6300,8208,3387308,13186,11470,10788,25482,90139,16016,33970,53768,1978056,113956,5547,602732,31824,144096,51452,11739,86989,69204,212334,9331,140620,12198,4300,66404,29326,15352,70784,7979,12220,5876,30032166,17918,133418,221364,15548,73865,74958,10726,49248,7750,132768,6751,155168,35360,17856,8632,30172,8280,47244,41808,18648,4826,128375,5980,10036,14400,14260,47902,27413,269328,57970,108224,17587,370822,25168,168910,5512,5220,17424,88846,774086,19952,90954,33264,10488,53072,2552885,8640,21166,6708,28677,13312,19916,11438,15953,185887,8632,25116,14062,8788,10633005,477672,22515,17538,24095,9322,19750,4750,45666,120328,11736,48269,101400,16598,7540,69882,1352085,117612,5408,37872,233834,5510,80064,8170,16827,28282,11524,1582920,7228,33575,66220,13000,9804,29230,24120,9120,5200,21488,15500,7228,32328,40204,6572,4558,7611,8164,34400,26307,8686,242996,28954,15010,13520,7436,5824,13946,23920,8580,91010,60610,13364,78520,8856,35720,10660,40053,58500,4601,142911,61699,4066,22506,1044854,19874,23472,14062,49848,6396,11952,58222,1817902,11771,44640,9610,15028,16328,24700,13826,412982,27864,9576,479598,18648,344519,22412,169100,995400,5814,18538,8360,7852,11532,45032,13884,1775556,11856,777852,249302,7688,106468,81720,7568,50718,10062,7254,124109,13870,36328,109512,6262,6696,183528,18620,5396,45562,5016,23332,103106,8424,11780,11904,13156,4068,11960,21014,8736,486008,18644,15128,12212,3683544,7410,537984,149683,21888,43524,508752,11268,1096110,12798,7228,6232,14942,19908,4773,138961,9717,50323,12688,6330823,6448,198843,118792,64440,13728,22360,5074,8804,7900,6552,10292,95532,1364544,4816,4294,4608,5624,17860,87048,53506,8858,13803,32422,22880,7095,10726,792370,14664,60192,5616,11336,41949,17802,13746,6448,7936,6650,28203,124109,250303,45000,10512,26617,306599,16796,14872,4816,8060,6136,25560,252148,4386,16920,91846,14663,16120,4816,19592,18644,113444,19220,24411,13640,53732,48934,33540,10540,7783,7138,29072,5356,68894,17716,18166,11336,40114,6794,11590,19800,27962,25284,61516,12169,25560,5472,63752,5633,34684,31980,5590,67824,16182,14022,182016,15264,214406,49320,92448,11594,9568,2930368,871224,424008,7644,24192,59013,7432952,55480,46436,38220,59760,37656,9675,15048,200294,7272,301731,30960,5168,5203,19908,118800,857880,34944,7783,477660,120080,11395,222552,5054,19282,3990,37999,49286,5074,299304,482790,6916,566825,287481,16492,736632,58344,157508,27664,3688273,14534,8532,5289,441531,9804,322457,10744,46246,63674,51192,4988,5092,40486,7611,23940,107694,173352,8680,6708,12166,8729,39052,82584,7006,48828,514520,8127,13032,72996,42480,18928,28224,6622,6500,34314,9322,32798,13746,16182,12338,6422,23816,122616,62264,14782,8643,43128,11470,24480,4601,27133,11128,9648,1973088,9503,120280,12772,14457,282910,17372,57288,88846,10105,13416,100296,4730,20461,12692,43648,326088,19778,45899,82460,26312,21948,22403,5720,18792,28964,23616,4522,3398975,68472,12341,11222,5772,4978,215498,86490,32311,562875,16568,8474,5418,5590,33022,127152,9234,28458,154682,7654,96459,402480,39816,17301,22176,6572,17316,229732,69564,18476,35712,27032,6235,70735,132652,16900,371108,1253063,5512,21888,7380,6882,92340,101592,7852,94326,15236,37446,5547,288113,6407,6510,9245,18354,527404,185318,95784,9204,189284,32400,53280,248248,6228,4028,8557,2650104,12240,8643,15500,166764,32414,25972,181168,15910,822888,7009,197974,78921,7644,44856,130587,671816,335118,20336,164304,28124,22824,8736,13578,8600,1907424,20938,9500,6820,6139090,30240,7956,32032,604810,10296,119808,22724,117000,140040,40820,657384,6344,118342,13717,9164,31668,49824,10640,268560,10902,162130,47736,9052,15066,4386,13904,9300,21567,99066,1122432,81700,6321,1168410,7192,79128,6536,30968,98197,1440504,37446,22120,26728,7956,21052,13082,324942,108288,143260,110679,6552,9120,20708,11098,13373,36270,10584,1296469,694440,10712,12456,13988,1010568,421290,79441294,14756,2472384,27170,88064,22360,4515,2110999,69125,7638,10404,309601,64896,546838,6708,7030,51557,19823,110050,7052,44304,27404,14276,4864,37683,95073,163530,7714,35932,545495,12524,10981,59803,268836,21312,33800,7800,6048,10224,473688,5762,178932,105196,295802,7482,37446,15264,12152,998675,11532,6760,4218,133036,321516,8736,141015,52200,9984,36432,136710,19708,795801,4408,537911,5980,11309,14456,37512,20596,164016,53784,138675,297830,46748,35640,88848,103806,46080,12008,518328,4712,5940,28704,45360,5700,15912,4142,69998,6321,7848,6612,14835,11455,31744,4515,20696,11008,9728,15340,200298,7783,7568,6132217,32184,33192,537844,45694,47400,16744,22536,16036,54036,21330,291668,384648,6156,17422,7740,21414,18920,284696,15912,5876,45012,4028,7592,495876,8471,4343,34504,54360,23779,44928,92606,163873,10664,17784,21204,192386,186010,9073,11825,213044,89507,219024,274680,2113704,14615,5460,8280,9374,298512,8476,10192,148614,6498,12012,15580,26918,343790,176881,522743,15238,1181998,4343,27413,98434,42581,16616,54994,6696,28423,7200,59976,7020,32448,9052,70434,1247936,4028,14652,87453,520531,11266,13490,136462,28964,9100,9288,5547,97266,178002,162184,19800,31824,137618,66384,46018,9546,5289,4902,150048,104833,96928,18705,50592,13983,12740,65175,13260,23244,3800,41002,224044,10640,6622,52851,23940,7750,42192,16952,6270,133200,7740,280292,27950,5074,679572,5408,11160,10184,100804,6344,205088,9932,14400,38948,562030,7068,8436,7912,1083959,12528,7181,238817,16598,105694,7296,19840,16297,27432,68286,11880,25480,24095,34918,6084,25596,12480,20336,35150,8184,173414,11036,57668,8295,4826,20384,24490,14457,25628,3744,150746,11804,7006,51272,17004,75582,7254,513648,1116648,16770,4294,6136,7258,6235,27248,8632,5824,16058,3960,1591218,118637,17775,10664,6321,191180,50482,33180,11160,14760,41949,1846728,180471,22568,8164,124141,14248,7009,41496,11232,108376,11856,60788,16182,290404,139514,43258,10036,9417,35048,32968,7106,8816,14402,8295,19448,34013,29111,3708,100812,9504,26820,100254,19344,17980,162898,1382500,9920,10191,9159,14147,29070,87360,18096,38190,225288,10192,18288,15132,34944,756288,145813,14508,96965,66024,400536,3057458,13566,16740,142832,1267160,35076,8280,84630,13566,13832,7006,323020,76320,5824,23296,10428,5396,26832,9158,4644,39259,6344,61332,75680,51168,11648,63812,50184,141252,5976,90060,10965,12298,14364,11324,16068,31692,6820,301392,21892,167152,534909,14190,31949,18980,43416,47736,16588,160848,455830,4284,201292,34523,4636,27612,7410,12064,7258,9396,71760,12956,12586,8840,6656,33927,5848,598680,7267,25929,7776,36335,48633,9796,22608,94612,4356,15084,15066,12672,10912,4386,7068,14061,52061,41904,55536,14688,61566,163990,21944,6346,189679,21199,7750,6500,15484,24048,21008,23746,8060,16068,9310,7344,56406,18042,127452,52456,8892,56011,72384,7783,8112,92752,11856,8122,9256,145018,9724,13717,25359,20072,22356,32916,10816,12648,10320,53924,7052,8476,4028,153698,90864,61940,16530,28830,5246,1145264,7638,368136,9858,26496,118658,18354,12116,93496,138320,5358,10449,6156,11160,21973,5246,7900,50402,52632,7912,6688,7224,19952,11440,7192,6708,22648,12688,5668,124558,9982,4945,14534,5719,260463,142792,26226,9761,18328,6422,298699,22672,768196,548018,15428,4370,623626,37804,23091,6864,26752,774832,164808,5580,20770,69472,26220,180594,4730,113688,84778,9164,8804,144096,4484,5168,45899,27056,31200,4392,729926,21758,200148,235578,4066,34959,17980,53009,10222,247832,7488,25201,10764,186835,15624,33356,18936,149530,21024,8060,20020,71712,20770,14694,6760,8804,19221,6364,5891,4978,14773,6708,13201,34352,58460,4472,23750,8424,7740,76880,10008,100316,30456,6510,22230,8968,23370,9462,4864,13716,25929,44793,10296,21660,133194,33170,292932,6622,8213,17264,5522495,7696,6802,408408,9880,7812,14424926,22962,10836,10621,37625,5203,20520,194016,92820,5891,209592,27792,11160,255012,140936,261288,7332,9159,2011606,18216,6968,72000,39895,22059,5418,17524,12403,546285,4636,8702,57660,11388,16524,10036,25840,6020,14061,34839,34164,15089,21251,10664,12948,68888,74464,74256,6020,1200610,27588,26208,108072,8208,3838,4392,80166,96854,844116,4515,3914,2156622,9234,29202,17696,4822192,592658,55252,201025,22536,4945,12728,5564,7176,67680,68688,8436,7688,2529332,10726,14319,26187,56544,150722,19296,4773,38552,63216,31777,94815,42423,40176,26936,109944,7124,87420,11210,7750,432388,24814,114471,34892,7936,52820,840244,10234,13752,56592,13104,68744,7992,8028,150258,4644,10972,5246,86900,121148,2379480,7596,561168,189384,77184,5564,7296,22962,11966,7848,13020,36952,54028,67467,1160068,851067,6032,4300,25992,93444,35787,6240,247379,144017,19158,11096,21930,370584,8736,10270,38502,29025,57828,22831,59598,4932602,17748,43443285,12879136,10244,11932,6660,7904,8804,5738,65592,594828,10665,127920,62135,26536,52488,6278,7254,146984,11908,28849220,14942,404673,230308,70122,88660,324636,4484,7192,407482,83460,427492,9847,18824,36103,10440,21027,128217,30108,18104,6321,12920,73568,3497330,24076,105958,5719,46452,9412,12896,7502,83700,11718,6916,24336,19220,4859,11284,12578,57196,165110,12312,115498,16416,36498,8322,16254,8944,17243,16430,390139,4978,17108,9396,36898,23088,4104287,129636,127660,3888,16200,75578,24016,32798,15236,83187,19342,9374,13896,332272,5772,27612,640646,13968,62662,22464,5460,537437,233116,665575,40896,53424,6880,6032,7072,8060,5074,108864,988011,17546,34286,170976,10140,5206,59171,115752,29760,17056,15953,17420,430160,78572,31648,42269,94800,5016,64440,7776,8471,67580,460728,75384,44826,746313,80659,5977,34997,13984,3952,190368,28386,11248,19038,10374,333301,13459,9880,21584,12708,18228,83876,18275,22940,16920,31096,5358,11492,30324,60822,22968,5054,270180,10974,5720,15910,17280,48906,1042964,109951,1067454,4066,783432,54548,9234,23126,6760,23328,12768,5220,17280,422097,8740,10965,8164,6120,11180,10621,17974,1597459,1465213,14632,3714580,16353,5356,6200,4978,8680,14292,1366092,8690,90720,20520,15810,184544,39618,8928,68098,1280088,394108,12806,20522,11137,46768,37200,3876,446982,7564,20634,15124,69746,253270,90472,9656686,10788,45648,17836,7920,403295,26846,28334,16120,14260,7436,37224,21801,120270,6579752,255291,30286,8512,23712,27968,14782,12341,42718,4712,26784,7524,1567296,12578,16112,379756,4752,7697,16796,5928,12642,22692,48152,87984,6292,76000,13035,26728,65728,4636,222859,9672,29016,8184,4601,4386,4945,52018,53799,7334,15392,6020,7912,83029,253448,6820,194814,19188,19228,65145,83503,10412,5031,13826,2510820,301378,204594,10578,7502,8557,28086,6136,90432,37152,4750,21008,10728,18848,64464,29484,7224,9880,16125,149864,858676,34808,9464,231480,8375422,98857,8424,104359,4522,81468,233616,35880,877982,106912,24118,5928,5356,3838,17538,16306,345228,25416,10044,41688,327218,15192,5876,16211,15089,8213,9196,23134,279032,47842,7396,14632,16856,11818,40560,8928,5865964,30420,61560,20808363,387810,75354,33022,15192,791440,5252,10556,6948,6992,22176,56160,116525,522106,5966,451440,51532,18460,541060,226486,116784,26928,4636,1082520,1239431,13312,16368,12692,35030,7697,85699,6764,16432,11376,94213,442479,67639,70566,24490,11534,244556,15089,5203,16430,13578,52824,2512753,398634,8640,9464,527592,15444,36214,26970,7688,11346,4343,6188,403992,8474,19909,22420,114088,8990,7448,361741,33912,16802,213221,22680,5246,30616,5004,8680,23712,79236,10088,328290,11266,70784,4332,6407,16848,4104,32250,14478,23760,9766,6820,17484,7488,856755,13268,16128,6386,7812,342237,13604,17316,133984,1571184,3839400,7697,5720,2716336,70308,16988,9724,13728,505293,27280,11395,30020,13846,21886,199004,98671,79790,65782,5200,7436,15562,8213,102410,146604,8626,21962,91640,38947,14931,731724,51116,8712,117390,44824,16748,456878,43416,7482,27404,809782,39990,531179,139032,27097,12236,8060,26860,17918,122360,27288,32469,84846,15093,12600,6106,8018,364032,35048,23446,73512,27664,94326,750184,5460,5396,13676,10793,29698,89139,17544,301948,9116,34444,6802,21112,6235,5200,19276,8164,32328,5418,9792,34038,24840,7488,21762,11218,15548,11196,54481,12272,170810,12744,15563,117312,20708,9432,9044,8568,74261,1569113,79636,41396,5848,38880,33604,10584,10512,59272,11596,17856,37758,9417,5054,9842,109800,16632,6966,8580,259992,6552,18565,14612,21164,6300,17222,16678,435240,341833,18126,16150,9331,100434,5814,8580,75516,28028,168646,6536,6916,10792,7998,23312,7440,8740,112812,10192,20556353,19264,64543,9656712,13248,295568,16985,7904,8840,12599,3522294,7006,5510,21142,59020,7654,21840,7254,14536,184202,44635,122335,30336,48348,322582,11656,11718,18662,56576,8684,22878,7626,42532,135876,163080,12956,6240,25585,63270,68241,8729,24614,262446,6708,34788,22828,22199,11954,9030,121432,1490572,4712,5203,6948,27735,13702,9920,44240,11076,89784,148986,76536,9568,26040,8643,122976,10062,3952,26101,5504,63550,275157,4515,26149,85320,9460,288143,2858324,423398,24016,6572,31558,232066,314352,64656,116604,14664,38844,886143,10868,18476,7228,19292,11997,798424,1494578,34782,15996,70742,11804,92983,29941,401241,16378,10140,14835,11596,753186,64220,1612627,14924,8216,30744,13545,7224,20145,11008,27300,10868,6232,23180,190706,40248,21725,17236,61857,18360,8060,10440,27792,4218,9994,11438,18430,26638,210930,48724,101136,40796,14554,5168,8848,7144,36577,20808,17458,18000,75960,367564,23472,5332,7181,333372,31521,279792,5203,14835,7384,8632,1118000,11098,5289,15824,14012,11336,39744,23296,27248,81406,6794,21700,427320,21172,12648,4370,11058,80422,71337,7688,14400,142012,16195,123552,54720,23126,22754,332444,33904,26156,54560,32414,11139,39600,7568,18146,175392,47637,68651,166656,44044,61814,14782,10816,60610,6916,9559,13884,31752,14174,5590,13764,7955,97774,19512,3012665,6240,575989,31720,138456,14536,4826,19264,11868,22968,8788,19750,62282,193544,90396,12341,8600,1925368,273208,10296,7228,4429,57722,860705,35092,4644,6665,4598,6794,11052,128098,524016,5356,34224,9362,4940,23580,8600,9576,21508,29016,1153242,12640,68848,170877,31519,66774,6235,57164,90688,59400,128217,246844,34736,10507,22320,13680,58102,9362,125316,291668,10540,7654,63468,12152,15168,116920,5548,166611,9864,7776,235973,48152,110983,7688,5805,695952,114076,255456,14144,82512,15912,463268,139384,393696,9792,164424,8432,8008,5719,66123,87880,1570441,214458,30816,375092,592105,10526,3924,967104,70128,12958,9589,5092,250900,92588,45741,150822,53072,50052,163956,12771,7502,2078024,15028,6732,7956,15964,18616,80352,10354,13780,3453959,13020,1255176,10621,19656,34884,4687,13680,677730,6878,49880,13114,230412,29450,17928,8494,6156,16948,265124,44454,26312,561279,36792,61828,25359,8424,5460,63516,5616,31248,9360,16692,54696,1614548,5928,18000,33402,17888,37130,52772,227664,8018,112812,12948,4750,58867,7525,114504,36608,6552,630894,14749,11024,4940,8640,28656,50592,16813,35412,264168,12376,11613,291408,7956,675614,3990,215928,422650,428792,106578,11160,9216,14612,10260,10602,408667,191575,20253,68019,67166,33418,5633,148738,11739,13932,29108,75998,34596,64666,704520,4386,296092,73075,164320,28122,7592,737781,6422,15314,6916,10507,6032,7439,50353,43896,8712,472750,198120,6084,20488,209664,4068,802152,14074,5200,7626,13984,155472,14716,9288,10400,5117,55728,1215084,30992,7488,13082,596068,45448,6192,87152,13824,469339,13490,8208,134106,40144,4636,10586,397277,6552,469023,99386,47272,24885,290108,6278,34830,8690,321152,1529320,27072,3587688,34560,7704,6278,4902,482804,122512,7416,32178,5876,10140,6188,82440,106742,14706,9486,8580,8928,18772,29541,35424,161856,451152,7688,5633,574824,15010,4370,14322,10044,28548,7280,52920,9243,7138,257688,5160,527325,121024,10192,38157,35733,4644,22278,16416,25776,223820,570960,1386529,197972,7482,4300,60268,2610530,6878,4256,5928,9724,185115,49059,30780,60912,14248,43628,298566,18791,17160,35836,25110,6665,199001,14260,67104,8360,24209,17680,6235,8424,315456,46696,5616,25596,121660,13260,33552,431972,75140,36784,10088,7138,23250,10707,25201,26939,15010,12428,11596,4558,3990,18202,31104,21926,6820,2050445,12384,198606,8170,9158,76128,31248,6622,5624,7592,4968,117990,1425424,33101,5586,36576,23674,6292,70618,77976,44252,76669,14760,97696,17424,239295,7812,128180,5356,7488,690934,19654,32760,40536,16172,11782,52056,36244,5548,25194,14092,15696,9272,4988,50902,1291264,14276,17050,18290,17759,8352,12958,11481,1055440,107045,5200,16120,84882,7884,17372,16848,5375,5852,8094,107414,8550,25069,158711,9073,102960,5472,18723,312129,811014,417487,32860,9516,45942,13459,4256,15721,77748,11268,51840,12168,35402,12996,294851,4408,250667,12168,3838,81096,14457,10974,312481,40280,11309,8164,45012,78289,29484,4028,25740,198273,73216,555449,63612,5092,49348,8216,21964,88288,7344,4343,5512,33812,28340,1070888,24388,13373,142200,63437,21199,12744,542098,18275,24624,11088,226670,38750,8901,251299,34944,926484,30566,61152,9417,9048,27648,609768,15066,61048,5934,21166,4773,12513,85241,76700,6063,114638,1127883,112892,333640,53320,122044,17286,27056,9256,16454,58344,6840,7874,5652,415079,424574,23296,12480,102297,96668,13148,235657,57433,7334,21672,4370,4066,35948,388296,7920,49063,51116,7006,695968,8132,218088,12958,26445,4750,12400,1016280,2434104,42470,12502,162316,2064608,29625,32968,9256,5436,41791,25413,38088,2494346,323280,31564,7783,11058,6084,10412,6688,70866,7717724,936944,12083,81528,17587,58368,18920,28124,1081184,9202,2223218,6136,33259,6812,8901,28912,6262,1268208,28830,6324,6324,7396,5244,43416,320952,107224,5246,11139,161772,8840,1886544,492404,110448,4515,4256,425258,5547,4945,20296,5160,6726,67704,71796,35774,285758,17264,6536,139356,11160,5117,55771,150021,12960,187467,5504,32034,600795,8626,10972,7332,86903,6448,41882,308396,10191,15264,97344,120317,19307,9516,20664,13452,11804,179409,9331,61978,55063,324360,9331,7228,9796,15376,122766,122450,23392,21508,7634060,13201,139277,116288,8112,23504,7998,12943,7564,6923,19479,7956,7626,675800,14074,13578,7525,64232,5016,80422,140146,53246,12986,19512,10152,8028,53167,9424,39960,11856,124920,8424,38952,21024,452876,79050,14760,7448,9216,32656,19152,871607,55728,33046,480624,19188,10222,19396,5282,152134,840086,17222,16120,23435,11440,155808,12040,256824,35561,6136,31758,1131552,54352,20640,15394,5130,5824,54264,23036,240002,8854,17992,39579,456699,25280,15168,149081,552064,32078,11514,198328,28124,16900,76456,8496,9216,7332,8901,35561,59688,124583,19080,12168,6236464,832581,8496,19434,115111,18538,165416,6634,24490,6634,10070,56340,11058,30992,131298,13788,14384,472812,382123,45425,6579,840718,17062,6665,20210,25896,6916,45408,12556,9204,42739,51858,14400,437684,39494,13624,93783,7353,4826,29536,6696,6063,20708,193180,159264,13110,17174,63792,267264,192608,84538,1094178,8060,24966,16380,47994,28132,7869,335671,12920,33356,25064,7334,6760,197856,4598,68335,14896,7332,3952,10296,207762,7488,15438,15808,6552,7267,99424,136276,22464,87768,9976,11594,216697,37281,15652,102068,14688,4940,35256,66716,3914,4940,5289,6840,17174,15484,7644,95666,107440,30058,20640,5616,17538,8320,10707,27334,108432,5772,4180,3914,24624,5356,43524,40320,11932,79128,6536,11692,720502,31564,110542,23384,12502,105552,11324,156302,4534958,35672,485857,10902,11952,42581,51398,9776,36034,5738,10292,462528,38532,19656,79128,6923,20448,75096,51794,48980,56373,202802,4730,28086,13588,133510,14300,5252,311240,13794,4142,5289,64030,278720,11060,29068,5676,32379,425010,15089,126953,1689128,19604,6760,16328,14362,6408,42120,16328,118924,46689,6278,43316,378138,8816,8385,8374,4644,54684,50869,7144,4218,10902,10152,44268,121520,636272,10348,4212,13832,26496,112902,7980,13728,776644,62568,21328,69230,4515,56674,9048,2339585,9516,8784,12312,15336,13020,16560,10416,17784,10836,638058,56760,15192,6396,9308,24467,55728,582941,8742,7676,17160,20212,11567,30780,110032,7956,8060,155272,170196,91246,19592,26574,2004187,421860,10449,14760,18662,250704,59436,82947,9085,45583,7448,28272,4142,309776,210444,76235,34128,44714,7776,445176,402628,35776,15704,32153,56012,5928,198290,10270,3672,28768,62816,2098443,21576,7800,13764,7998,278080,7904,22204,48484,19513,70876,537887,28810,62186,86040,8058,9116,12900,8892,13144,20232,30312,49928,5396,370352,19522,841745,5934,4142,4560,19872,7009,5054,8360,14184,13728,406348,10191,36332,110304,221052,12087,24054,2762946,4788,13644,17174,7482,9464,10044,6968,130884,23978,29172,5805,44136,6292,3708,71592,304200,32500,187302,109415,6760,66464,7384,8041,158474,115596,9724,117360,7740,4386,86490,93931,190112,10504,9072,15998,224992,8600,47874,10868,11076,42978,1014676,20336,8136,122845,30968,146232,25848,19292,89642,31600,16016,11088,7688,20336,8428,7095,15768,6200,106255,9073,4472,9890,19393,29952,12524,22356,35308,19866,21488,738966,16802,240864,17759,13224,20708,45074,4212,9300,21096,16056,436321,9030,4472,3566850,28598,13104,37969,7600,146940,6080,81432,102672,35392,59830,49770,650547,13320,17222,6536,62252,5616,139464,23908,7564,13156,5966,4320,1039464,84940,16469,93384,18619,48960,4601,50046,21164,13870,7410,74304,6820,5160,10296,12524,14260,23746,16536,337156,18506,10764,194145,7696,7956,49680,9828,104036,5719,6574,12376,17420,6656,18318,248534,5662,4028,7852,28954,11908,41236,11232,55536,9401,13825,6080,9460,16416,8626,68944,8740,361267,8856,14136,6188,26149,29016,7750,27477,6344336,8928,4464,4522,13373,27056,42104,62479,18166,5117,6966,15964,1188606,6188,10726,39246,64414,31521,6864,9052,818763,26714,20461,1618993,5289,11970,19080,2358876,70704,13052,71208,77584,25542,14744,53618,11139,17160,9648,13825,28210,21251,28203,5934,85952,12338,71574,9386,43632,181896,5876,12462,80580,15562,13676,4028,913951,117473,7378,7254,4644,6396,6579,27512,16536,8170,1452204,8372,10492,812520,712975,11232,19096,8432,18724,39780,9546,28656,44424,9548,187426,6321,8664,5876,9308,15405,131254,2437034,15652,6448,23112,8476,159912,120120,15028,5548,7200,166152,116762,16391374,16616,12168,5891,7848,110916,7378,363320,56628,45537,59706,141768,307942,2630700,10823,54622,38916,32240,478345,15132,6882,18810,222227,5668,9620,903997,18091,82713,5928,238248,77634,12896,2306484,6240,5460,6510,4408,4104,14668,17422,34918,19912,44578,340318,10478,47400,46136,22776,25628,22360,9880,23244,34162,2303238,19656,83898,267592,190008,91846,118800,7998,56169,9717,3852,3708,460917,1268856,6660,12688,493064,20862,37584,1157587,10764,118248,13208,9006,7176,16039,62496,38829,32184,4066,13330,5772,293169,893234,5112,8772,1062234,12814,625352,919274,113088,44556,22436,12719,368037,7440,30336,10478,2106326,1039561,28196,68112,165663,57350,28519,29704,365456,130910,39658,6032,291826,16692,1204412,400214,105768,49665,19722,44763,4066,15428,185966,86268,421496,17856,103329,218808,95202,5206,7904,40166,33748,8122,25438,61017,20736,722736,9933,342409,4560,12240,124682,22256,72842,12245,130312,67464,244110,44793,32627,23932,21488,5772,10452,13832,234422,8686,7848,72360,100152,91728,20376,10750,46624,18936,17212,32798,12255,10406,34996,7130,7675506,12502,459000,48111,4294,19522,20683,7280,20952,374539,18565,9503,118512,15552,4773,21844,9030,34048,15496,69757,10922,10902,17280,1191636,4687,5160,53878,4859,49849,34684,16432,49400,11180,82646,6758,40053,13752,9620,18490,64368,9159,7410,49770,218178,10080,210485,5418,8632,14554,42294,4142,9672,79116,8996,55214,252864,11696,37446,550368,10906,18876,29625],\"y0\":\" \",\"yaxis\":\"y\",\"type\":\"box\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"english=0<br>estimated_sells=%{y}<extra></extra>\",\"legendgroup\":\"0\",\"marker\":{\"color\":\"#EF553B\"},\"name\":\"0\",\"notched\":false,\"offsetgroup\":\"0\",\"orientation\":\"v\",\"showlegend\":true,\"x0\":\" \",\"xaxis\":\"x\",\"y\":[40092,33440,31261,14544,4104,10354,15394,24264,23940,3876,9234,10908,5976,178452,20368,115026,9880,7334,179181,10664,4446,16560,36972,12255,14060,30784,128016,10070,40291,73268,23478,5054,29713,12274,9108,7828,9766,13490,4674,4332,227240,7866,8018,13760,44677,6063,6192,4180,15010,6422,3852,6235,22458,10754,4356,21371,9204,9538,53998,20597,5472,10602,23822,4142,8740,4902,23779,7128,7611,13908,8342,5320,10707,9082,63468,4515,42441,4066,4484,17316,47601,12169,7752,77710,4248,5396,21584,54872,24244,768018,8041,41882,37656,48724,19866,7568,24552,6063,20824,14706,12806,12084,33101,4370,5112,10404,8094,6194,5676,5966,5547,24130],\"y0\":\" \",\"yaxis\":\"y\",\"type\":\"box\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"estimated_sells\"},\"type\":\"log\"},\"legend\":{\"title\":{\"text\":\"english\"},\"tracegroupgap\":0},\"title\":{\"text\":\"estimated_sells seg\\u00fan disponibilidad de ingl\\u00e9s\"},\"boxmode\":\"group\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('2236d6f1-34b4-49a7-977b-f994ca21fdc9');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Existe una diferencia entre las ventas estimadas de juegos con idioma inglés y sin inglés, por lo que podría ser útil utilizarla para el regresor."
      ],
      "metadata": {
        "id": "GSDsmYxGMa97"
      },
      "id": "GSDsmYxGMa97"
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.box(df_train, y=\"estimated_sells\", color=\"platforms\", log_y=True)\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "pPYL0jlc23rs",
        "outputId": "24f6a105-1098-4e86-d4d5-e6317c774125"
      },
      "id": "pPYL0jlc23rs",
      "execution_count": 354,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.16.1.min.js\"></script>                <div id=\"3cfde5b9-91c2-4679-a12c-323d810839e8\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"3cfde5b9-91c2-4679-a12c-323d810839e8\")) {                    Plotly.newPlot(                        \"3cfde5b9-91c2-4679-a12c-323d810839e8\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"platforms=windows<br>estimated_sells=%{y}<extra></extra>\",\"legendgroup\":\"windows\",\"marker\":{\"color\":\"#636efa\"},\"name\":\"windows\",\"notched\":false,\"offsetgroup\":\"windows\",\"orientation\":\"v\",\"showlegend\":true,\"x0\":\" \",\"xaxis\":\"x\",\"y\":[3914,253864,3914,27176,52572,62764,101824,26544,78884,15326,702956,17732,14896,8643,10008,6758,44020,8424,8604,350997,9362,34216,78964,16568,936900,18012,9568,137643,6262,1293336,14040,47424,6696,72936,236500,3924,4028,5246,12245,5246,14319,41648,198369,11448,4320,27156,70176,14018,12482,7254,6063,10406,48982,4859,4524172,30573,40092,5304,76836,10664,29388,6262,116356,15084,24128,57474,16776,26208,72680,4446,40964,132870,5824,130500,10912,363084,13373,9196,885422,9559,8246,30524,24095,21804,607724,12403,4066,6344,8664,33440,6372,31261,147651,48880,11524,14544,5510,12064,69678,7525,80484,3990,153418,15247,1279326,19656,4066,52344,451422,861032,229416,872318,30702,6880,195768,8556,50165,100835,25844,14516,33488,41184,3744,7353,5130,18824,18920,559152,4332,8684,12636,37696,19836,143052,50955,45792,4104,11692,470808,19440,23564,22458,10354,52668,5724,7790,189504,98280,35234,20160,3636,64464,11818,22204,160528,56268,7900,35313,78289,18658,6292,6498,26728,14405,23858,13144,38710,10981,15394,24804,11804,42897,50220,164260,698400,5203,24928,39384,117676,19968,24264,126880,20540,15300,18356,1418688,8640,263149,18576,166216,11438,37232,32472,11376,60528,8496,338840,251136,166032,177460,20066,5356,26149,55068,95906,39216,29488,11248,27612,6384,9610,17696,12096,31304,7344,32916,224992,4066,11818,7998,9216,76322,3996,9204,140976,31806,12428,15824,90534,54954,28892,373591,17784,212836,26064,8320,12168,192918,37539,15958,45198,78192,27456,59768,9287082,560652,37656,53878,44161,393908,6696,15562,312998,23760,15168,13520,6634,14964,8901,4522,26424,19197,11051,5332,149136,19368,601016,4408,12384,14782,21142,5504,49104,121518,10224,4140,8060,231154,10586,16802,33891,7488,94068,134628,15934,11284,16872,40394,13373,34529,17628,168428,154960,93912,5890,338436,6448,287370,55853,16530,2691358,34424,4104,23940,185938,11997,10602,19080,10664,10716,19684,750421,7992,11664,20769,218400,696299,6604,5652,104201,10368,10540,7704,16297,9202,16454,7592,53483,11016,11222,50616,8892,25012,16068,7748,10080,857956,4279114,28348,17856,83898,501642,5461,192049,473817,7904,20482,454248,47196,115577,11266,13114,15190,14018,23472,24885,6063,12692,476397,321382,18060,15444,8769,68510,219085,17992,11904,15428,40032,54194,9796,16120,280800,12350,9504,55695,5512,17628,6344,718189,176802,155746,3876,140620,29154,10277,5564,151048,9006,19908,8112,20644,10008,12482,8712,405954,12324,28424,19722,67071,15523,71416,20880,96301,5564,17459,40104,6136,6324,28704,4343,16641,8295,5976,4472,9072,21638,49724,9216,7632,858572,14328,21543,306362,10816,36378,20488,152312,178144,8684,9360,10800,213409,4294,98568,8996,55796,13676,96933,1665162,17108,17680,115541,28582,37841,12152,18723,5200,889632,9734,8996,17673,45662,21962,11594,261934,62372,9234,4464,11613,40536,10908,70784,7748,9766,413170,1071288,23750,9308,25438,35155,6536,13826,5928,25128,28835,6968,78819,20088,19032,22704,92132,12584,265440,5720,5976,64688,15190,4176,25482,22575,571814,11524,9006,20640,48450,9144,14402,25200,10602,6572,280618,6751,1309252,16484,34844,155304,7052,7296,63898,6042,29146,3952,5332,51350,23296,917111,32390,19671,29283,20448,65188,5590,34200,22680,6460,6136,165044,10234,178452,528984,7696,35352,6552,20368,32723,6324,16112,12046,15552,62062,7482,5168,10088,12087,6192,4572,11016,8788,6688,5719,32544,14560,57304,10728,5408,16856,15840,10184,35313,61383,115754,727669,39596,31679,12024,4066,18091,4472,32548,40456,203164,5246,37752,133431,115026,11309,44878,12768,65333,23560,28124,6292,48111,35030,293968,151580,5624,7130,13454,7600,96064,3248336,39308,5966,12482,8604,81792,6572,4816,41317,36577,18460,43272,1451704,38950,9348,5356,72759,27404,8778,13104,860976,6278,11128,1086488,7124,139176,12586,47400,49556,6572,125689,75528,6760,403056,27396,9880,16037,12561,7697,17964,7280,71337,7334,38184,17160,11481,9610,179181,13104,13536,21372,33332,124930,32904,4386,12688,86742,7372,19500,23244,10348,10664,15136,7812,891820,35647,592844,30876,37324,4859,2491660,8127,164715,119527,51745,6407,5203,9374,26875,11492,9717,4446,26486,4472,16560,26474,9417,15438,178312,597896,13640,236447,126666,17696,21112,16560,13244,726089,5824,579120,1886836,692128,7296,6696,43524,150653,18407,26860,11139,4864,17064,21700,38141,34271,8892,961362,100168,14256,38664,78416,1152531,5805,148678,1246304,13516,4816,55490,13072,11476,55774,183481,9776,43416,10608,36972,21762,9085,11088,1216800,12255,59112,363874,14196,15496,205321,741960,19840,82560,15879,15340,54498,7332,12654,27590,5289,8246,7095,164304,51116,8112,872526,18644,20088,26228,129580,55512,20016,10974,38786,30240,4028,15264,8360,14858,24232,290641,17244,205632,556416,20736,20592,25992,9761,4978,31044,27892,60264,9417,736112,5668,12384,6136,10972,27352,41610,105696,211562,24358,22833,13248,10664,9216,18050,15704,18146,6156,4558,13452,10578,877084,155880,37656,14256,6321,4902,11739,16920,5980,29842,20664,11016,63990,37354,20770,13032,42280180,16906,9576,16344,25359,10108,31916,93353,38532,30600,8742,70704,5031,22176,7540,6572,5548,4078274,4218,9638,153748,53072,40132,16120,6188,14060,14248,7912,11284,5890,45144,4522,5719,250952,7130,93930,17632,15010,12740,24806,24037,12816,22176,15872,13788,538222,34365,4730,23400,4294,5244,51264,206568,29038878,34684,36464,21762,142201,12168,5633,15552,18316,18091,30784,100738,282978,181779,12888,178966,119392,3952,170956,17544,128016,319160,5375,3914,7904,160128,982338,9576,72443,124504,742392,14328,5624,22464,10191,102180,8172,34602,5130,8094,10230,8320,143069,13338,253440,81282,48418,1190276,11856,18720,9300,949240,8784,53300,31679,159692,1229240,11534,1457682,9724,20748,346476,54994,6574,20540,726657,50112,11352,57190,12482,76393,8927,3600,17459,13780,11929,38520,95542,25194,14630,5184,66528,5244,14536,80414,38502,7182,82056,16802,5472,13780,10368,17775,10296,41949,2154014,38076,53621,32422,10070,20862,9576,92035,9954,47684,31464,65246,15184,7800,63498,8901,19866,16276,5848,44764,1875376,12599,40291,8618,13932,16669,14976,6136,76824,956332,8580,26524,61938,9500,10192,6500,9675,406297,29016,76235,24467,24411,28132,13392,5928,5976,179883,19902,16864,6080,38868,19500,10556,79484,9954,8094,4472,45030,4343,16306,46512,8372,218922,26070,891041,14198,73268,19092,5805,19654,15958,12276,42532,9176,14288,58464,32943,38270,5460,24244,58178,40608,18720,11139,7144,19269476,287496,443269,3960,8320,16692,17316,33048,386136,395604,25517,14615,28614,6156,10191,19928066,166752,5418,12648,5461,335916,18772,11552,66994,10836,16272,550185,51034,5512,30573,6232,5117,265734,129704,14322,114939,6966,811172,31096,23832,13110,165505,24048,12152,112060,9412,19874,4598,279186,6574,4988,29388,14773,76153,139040,15872,16016,18648,7440,25413,5396,1356212,5633,5408,947376,7525,11376,6080,32224,73530,21027,12096,9114,7344,16992,13364,11352,17594,30628,26600,15184,49928,12152,73584,8990,4687,49920,460096,56992,4066,79608,798769,10608,5054,2141136,46314,5332,6032,5720,24804,24700,20160,34128,7592,12896,4386,7448,50560,23068,6536,16302,16195,19656,34049,7396,90516,5977,39364,7525,7790,14104,3395520,12400,31218,33136,23068,73910,20880,42344,6384,11180,27360,5652,22824,24381,36890,134230,6020,804615,16120,350207,124754,163866,8928,92579,53496,656885,3914,32034,3744,9216,7280,127286,6837,288917,7439,14694,8643,4788,117728,13244,16254,10965,217672,13208,3876,12900,99303,142168,20808,67392,5252,20145,209932,4788,40362,16985,10922,12298,9776,11648,14456,19152,16590,115656,7095,113602,53630,11856,30008,550393,6764,119784,177750,161476,5396,37920,71982,423708,94886,8996,947842,29713,13578,5662,6878,14768,7410,56564,55800,15872,52706,44304,18648,640212,200564,481954,151443,4560,9864,13020,136697,27413,70980,25344,4332,19995,30168,3744,10108,25420,6880,118598,15028,20425,48190,5244,9804,11088,114550,158328,6572,16432,8280,8184,3838,4896,101804,5738,9724,8632,464318,55872,30020,10184,34906,80352,7790,11804,6878,13588,4598,11352,397008,45899,46368,8084,42011,64930,23328,46488,480240,6278,7812,535651,346652,121368,10036,5928,4408,193128,5418,403374,7998,49217,86387,191654,70408,122740,23972,886854,177568,214848,132088,30315,5130,58996,36480,5092,4864,22032,20224,19190,8626,22116,52576,9196,1177848,11340,49324,7334,146880,4484,326823,23688,81449,5168,494326,21166,19136,96222,6758,298034,66664,117154,13320,119536,5590,30600,16120,559320,13224,18414,12616,53404,43946,49556,239904,7852,4680,15800,38270,15879,424625,17143,995665,393016,661072,14580,6149,22594,7750,44194,12688,100172,52693,14092,6820,14098,53010,217208,6240,30004,99944,13640,31320,9486,17480,6063,28598,5616,64440,10868,26860,15247,95288,25327,10348,153338,10354,291589,30336,7540,48348,60164,24648,3914,19497911,10234,5760,27576,47558,49290,80106,8424,8424,43834,17632,6916,81840,74808,19039,71416,226610,4028,13244,44082,23134,71208,40680,11096,4484,90948,5160,8928,46664,6665,12274,8532,10088,4902,9734,5662,37202,30336,262260,71939,116774,11297,33418,1062014,3708,23263,8686,31920,102114,885794,12728,186319,2703014,28234,37762,34602,15048,2912493,14018,10088,26524,53444,14457,12844,9417,1932696,461088,29232,9108,68414,271128,8927,169594,11455,7164,965808,9880,4598,15996,46228,12084,8690,5776,13072,106652,5564,3602092,235894,5460,13193,106887,5074,18460,141963,71188,149872,28644,777712,13104,14319,5700,5977,42120,7006,6634,4902,11180,93654,14190,4386,5662,11352,16555,172694,4256,478503,45899,93299,5928,32452,59128,216562,16678,17794,10348,36144,5472,11856,39263,201514,19158,6149,5054,241552,26208,117046,29625,4284,132096,5805,13454,7942,125517,1054614,20026,44460,33583,415423,36704,163176,16039,54747,410332,48384,402268,8772,4408,27492,575172,494145,754992,28656,1210356,515317,58104,4142,388864,12024,7828,56886,130591,13186,17316,67704,5590,149389,64372,9900,80969,14326,222490,8476,31284,68940,149358,10191,100409,1756723,5668,15552,126716,22199,73628,14716,18044,19964,6384,9766,28024,8772,14060,142386,20384,4294,19552,28756,939238,4484,424908,23700,50639,11514,13490,7697,17822,6020,8164,13029,212668,67466,4674,8927,9559,29488,17856,11309,27300,131688,8213,6232,33669,8987,62173,4902,117864,49248,186519,23832,14508,76712,6992,13680,23005,10296,172328,47953,6552,10640,12636,17100,161120,23688,60216,117648,12220,54036,23218,41292,4558,5700,5824,11180,119606,12888,4300,7439,39026,46728,30168,61778,456404,11016,5160,89156,4674,1106237,9568,25517,31205,21567,9690,26496,633256,12532,1934473,5436,60435,22489,17174,8927,7144,146415,934648,15132,140146,23940,1001088,13825,145578,38736,20150,8476,45714,163852,42904,4680,4332,227240,4446,88504,25675,5200,9245,18000,10452,75603,8008,72106,46764,6042,8736,37288,15265,29704,509787,5112,57252,8996,61304,15437,50998,20748,1289160,7866,14319,381900,15652,4902,298857,17856,137088,9272,140554,6450,8018,10230,45881,182806,7296,8611,8385,37604,4294,147146,5408,22152,31126,12350,5720,116130,119764,1120220,7562,87668,293959,126432,96876,7344,44333,5320,19592,14976,4644,18600,18881,37754,10152,17933,47652,956004,89856,247884,6292,13268,12350,7344,153813,23036,22403,15336,4212,8424,199836,3922828,41306,78447,18644,65556,8930,930620,14544,9638,17050,13459,106210,124030,44763,233064,31668,325510,6912,40979,237711,14061,9976,7828,93931,28496,346890,26860,36146,18216,51127,5031,25026,48060,52417,740808,7416,9462,157526,745444,5246,1027710,12220,42186,116057,9620,38998,59555,22752,63426,820728,11128,8742,37368,31428,15132,7384,24552,7596,81936,151759,92579,6080,31691,1119588,20511,3952,30020,80640,288350,7410,12771,2937062,10792,72664,13114,16740,15238,3636,593290,198360,32976,24776,88236,24336,228888,18616,35152,14544,30816,35280,5564,24192,49176,4978,41572,12168,5966,9766,7998,41194,5738980,689184,1516958,60946,6032,6262,52030,7280,29448,146808,4773,5418,18506,6084,11929,56412,305809,13832,414355,6321,163846,20777,10981,49538,6020,57600,12245,8295,41416,1861704,138503,9672,6764,118121,11532,10660,352160,8213,10106,7750,12792,21514,52832,492881,10112,233366,28148,33153,57252,19708,10507,7611,9048,34271,55142,8132,4826,74971,11532,8686,13338,25359,13760,37525,4968,26350,17472,18408,223886,72850,44677,61146,7904,6751,134300,313404,6536,35136,882828,12008,234000,18802,88556,1082830,85557,36244,187941,6063,45267,147992,168020,3600,873496,13888,18960,13490,25438,22464,9412,32616,7783,31464,63200,62489,19500,23712,142595,268632,18962,6192,40014,58104,87096,19158,9417,19530,4180,22534,23972,21543,12768,17696,21080,62640,7812,4218,11395,73948,4978,16432,16340,12814,6880,9196,7272,5547,7611,199080,12586,4816,132088,30690,2638363,28008,88350,28598,8094,42744,62890,5548,19152,49296,37336,30836,12688,11492,8680,24814,15010,4859,202844,11248,30600,14668,18600,30336,75287,108624,113839,6422,70942,9672,10504,51460,5408,85083,675936,35724,7852,15652,3852,275394,81054,17732,163787,4988,9245,7228,74734,41496,1202581,158808,16872,4408,55588,85464,52000,10868,6696,4978,7560,12376,9204,10602,19468,8532,88776,4284,65884,13115,10974,10707,5700,4940,7228,14964,5252,71653,318291,6794,154368,1623024,10728,10621,3952,4142,41791,171144,51584,27976,61189,5461,5304,19049,5130,68651,3952,20304,5547,285348,6235,993852,12324,10036,8684,41344,159831,376593,4370,390624,16068,81686,7254,5700,61304,27820,63042,22458,40092,59882,14749,9994,7740,3800,18504,55584,74932,64410,12744,997770,13764,29716,9006,3914,7525,9648,5738,18724,4212,75504,8385,7372,5004,4788,242208,8769,4356,2513880,11966,13193,23622,21371,153381,12008,11223,22152,34580,118248,6923,120228,28466,8453,9796,4429,14012,28028,25754,3744,438529,3708,362318,8216,8840,64543,16188,13760,25840,36868,14012,29264,31198,30494,54126,5928,107068,862358,25584,12168,195780,1035648,22680,7848,10088,17484,7752,9300,13824,47690,6396,8742,67983,11160,17064,15252,34056,16116,22444,217566,254448,4687,13364,16340,22496,1807204,33540,2408315,15800,6650,8453,59812,63911,14198,135720,174384,16112,8246,12502,15314,44802,153983,39816,5289,11024,7396,9672,8815,11160,26728,16827,5891,11395,37752,204373,19276,114712,580808,12616,122845,27838,39888,5408,5700,9880,65175,16632,38055,9766,16956,104000,36024,6240,179452,60952,11514,136332,7280,877176,49849,6408,62963,17422,5252,7267,10712,11218,7884,13825,6300,8208,3387308,13186,11470,16016,53768,1978056,602732,144096,51452,11739,86989,212334,9331,4300,29326,15352,70784,7979,5876,17918,133418,15548,73865,74958,49248,132768,6751,35360,17856,18648,128375,5980,14400,14260,47902,27413,57970,108224,17587,168910,5220,17424,90954,33264,10488,8640,21166,28677,13312,19916,11438,15953,185887,14062,477672,22515,9322,4750,120328,11736,48269,101400,7540,1352085,117612,5408,233834,80064,8170,9804,24120,9120,5200,21488,15500,7228,32328,6572,34400,26307,242996,15010,7436,5824,8580,91010,9538,60610,78520,35720,10660,58500,4601,19874,23472,14062,6396,11952,58222,11771,44640,9610,16328,13826,479598,344519,995400,5814,18538,8360,11532,1775556,777852,249302,7688,81720,7568,50718,10062,7254,124109,13870,36328,6262,6696,18620,5396,45562,5016,8424,11780,11904,21014,8736,18644,12212,7410,149683,21888,508752,11268,1096110,12798,6232,14942,19908,4773,9717,50323,12688,118792,5074,7900,6552,10292,95532,4608,5624,17860,8858,13803,32422,7095,792370,5616,7936,6650,28203,124109,306599,4816,8060,6136,91846,14663,4816,18644,53998,24411,53732,10540,7783,7138,29072,5356,68894,18166,25284,20597,61516,25560,5472,63752,5633,34684,31980,14022,182016,15264,214406,92448,11594,871224,7644,24192,59013,7432952,59760,5472,15048,7272,301731,30960,5168,5203,19908,118800,857880,7783,477660,222552,3990,5074,299304,482790,566825,10602,16492,58344,8532,5289,441531,9804,10744,46246,4988,107694,8680,6708,514520,13032,72996,23822,18928,28224,6622,34314,32798,13746,12338,4142,23816,122616,62264,14782,8643,43128,11470,27133,11128,1973088,9503,120280,14457,57288,10105,13416,20461,12692,43648,19778,82460,22403,5720,23616,3398975,12341,11222,5772,4978,16568,8474,5590,33022,9234,154682,7654,17301,22176,35712,27032,6235,8740,371108,1253063,7380,6882,92340,94326,37446,5547,288113,6407,9245,18354,189284,32400,53280,248248,6228,2650104,12240,8643,15500,32414,822888,7644,130587,164304,28124,13578,8600,20938,6820,6139090,30240,604810,22724,118342,9164,31668,10640,268560,10902,13904,9300,21567,99066,81700,6321,79128,6536,98197,1440504,108288,4902,9120,20708,13373,10584,23779,1296469,694440,10712,12456,1010568,14756,27170,22360,2110999,7638,309601,546838,7030,19823,27404,14276,4864,37683,95073,163530,7714,35932,545495,10981,59803,21312,10224,105196,15264,11532,6760,321516,52200,9984,136710,795801,537911,5980,11309,37512,20596,164016,88848,12008,518328,4712,5940,28704,45360,5700,4142,6612,14835,11455,31744,4515,11008,9728,200298,7568,33192,537844,47400,16744,16036,291668,6156,17422,7740,21414,18920,284696,15912,7592,495876,8471,34504,23779,44928,92606,163873,192386,186010,9073,89507,219024,274680,14615,5460,8280,6498,12012,15580,26918,343790,522743,1181998,98434,16616,6696,28423,59976,70434,4028,14652,87453,520531,13490,28964,9288,97266,178002,31824,137618,46018,9546,5289,4902,150048,96928,50592,13983,12740,65175,13260,23244,3800,41002,6622,7750,6270,133200,5074,679572,5408,10184,100804,6344,205088,14400,38948,7068,8436,7912,7181,16598,105694,7296,16297,27432,68286,24095,34918,6084,25596,12480,20336,173414,57668,7611,8295,20384,24490,14457,3744,11804,7006,75582,16770,4294,6136,6235,27248,8632,16058,3960,17775,6321,13908,33180,11160,14760,41949,1846728,7009,60788,8342,43258,10036,9417,35048,7106,8816,34013,29111,3708,100812,9504,26820,100254,17980,162898,1382500,87360,18288,15132,34944,756288,14508,13566,16740,142832,1267160,8280,84630,13566,13832,323020,76320,5824,23296,10428,5396,9158,4644,6344,61332,75680,63812,50184,90060,10965,12298,11324,16068,301392,21892,534909,14190,18980,455830,4284,201292,7410,12064,7258,9396,71760,6656,33927,5848,9796,4356,15066,12672,7068,14688,61566,163990,21944,21199,6500,15484,9310,7344,56406,18042,127452,52456,8892,56011,72384,8112,9724,25359,20072,22356,32916,10816,12648,7052,90864,61940,28830,5246,26496,118658,18354,93496,10449,6156,11160,5246,7900,50402,7224,19952,7192,22648,12688,9982,4945,5719,260463,142792,26226,9761,18328,6422,768196,15428,37804,23091,6864,4730,9164,5320,4484,4392,729926,21758,235578,34959,17980,7488,25201,10764,15624,33356,149530,21024,8060,20770,6760,19221,5891,4978,14773,13201,34352,58460,23750,7740,76880,10008,6510,23370,9462,4864,13716,25929,44793,10296,21660,133194,292932,6622,8213,17264,5522495,9082,6802,9880,7812,22962,63468,10621,4515,20520,92820,5891,27792,11160,255012,140936,7332,9159,2011606,18216,6968,22059,5418,17524,12403,4636,8702,25840,6020,14061,34164,15089,21251,10664,12948,68888,74464,74256,6020,1200610,27588,26208,3838,4392,80166,96854,9234,17696,55252,4945,12728,5564,42441,67680,68688,10726,14319,26187,56544,19296,42423,109944,7124,87420,11210,7750,432388,24814,114471,7936,52820,840244,13752,56592,13104,68744,7992,150258,10972,86900,121148,2379480,7596,77184,5564,7848,54028,67467,851067,6032,4300,93444,6240,144017,11096,370584,10270,29025,57828,22831,17748,12879136,10244,65592,594828,10665,127920,62135,26536,52488,6278,7254,11908,4484,404673,88660,324636,4484,7192,407482,83460,18824,128217,30108,6321,12920,73568,24076,5719,46452,9412,7502,83700,11718,6916,24336,19220,11284,12578,57196,165110,12312,16416,36498,17243,17108,36898,23088,4104287,3888,16200,75578,19342,9374,13896,332272,5772,27612,640646,13968,22464,5460,233116,6880,7072,5074,108864,988011,17546,170976,10140,5206,59171,17056,17420,430160,31648,5016,64440,7776,8471,67580,44826,80659,5977,13984,190368,28386,11248,19038,333301,13459,9880,21584,12708,83876,18275,16920,5358,11492,60822,270180,5720,15910,17280,48906,4066,54548,9234,23126,6760,23328,12768,17280,8740,8164,6120,11180,10621,17974,1597459,1465213,14632,16353,8680,14292,1366092,8690,184544,68098,12806,11137,46768,37200,3876,253270,9656686,10788,28334,21801,120270,255291,30286,8512,23712,7524,1567296,12578,16112,379756,4752,7697,16796,47601,5928,48152,87984,6292,13035,26728,29016,4386,53799,7334,15392,6020,12169,7912,83029,253448,83503,10412,5031,13826,301378,8557,28086,37152,4750,18848,7752,64464,29484,9880,149864,858676,8424,4522,81468,877982,5928,5356,3838,17538,16306,10044,41688,15192,5876,16211,15089,8213,9196,7396,14632,16856,11818,40560,8928,61560,75354,791440,6948,6992,22176,5966,451440,51532,541060,26928,4636,16368,12692,85699,6764,16432,11376,94213,24490,11534,244556,52824,2512753,8640,527592,26970,11346,4343,6188,8474,19909,22420,114088,7448,361741,33912,213221,30616,5004,23712,79236,10088,328290,6407,16848,14478,9766,17484,7488,856755,16128,342237,4248,17316,1571184,7697,70308,16988,13728,505293,27280,13846,98671,65782,7436,15562,102410,146604,21962,38947,14931,51116,8712,117390,44824,16748,456878,7482,531179,139032,27288,15093,6106,8018,364032,23446,73512,27664,94326,750184,5460,5396,13676,89139,17544,301948,9116,34444,6802,21112,6235,5200,8164,5418,9792,54481,5396,15563,20708,8568,1569113,5848,33604,10584,10512,17856,9417,109800,6966,8580,6300,16678,341833,18126,16150,8580,168646,6536,6916,10792,7998,23312,112812,10192,19264,64543,9656712,16985,7904,8840,21584,12599,54872,5510,59020,7654,7254,14536,24244,44635,122335,30336,48348,11656,11718,18662,22878,7626,12956,6240,25585,63270,68241,8729,24614,6708,34788,22828,22199,11954,9030,4712,5203,89784,148986,76536,9568,26040,8643,122976,3952,5504,63550,275157,26149,9460,2858324,24016,6572,31558,232066,314352,64656,116604,14664,38844,768018,886143,8041,7228,11997,798424,1494578,34782,15996,70742,29941,401241,10140,14835,753186,8216,7224,20145,10868,23180,21725,17236,61857,8060,10440,9994,11438,18430,5168,8848,7144,36577,20808,17458,18000,367564,41882,37656,23472,7181,14835,7384,15824,14012,11336,23296,81406,6794,21172,4370,11058,71337,7688,14400,142012,16195,23126,22754,26156,32414,11139,39600,7568,18146,175392,47637,166656,10816,60610,6916,13884,14174,5590,13764,97774,19512,575989,31720,14536,4826,19264,11868,22968,8788,193544,8600,1925368,273208,10296,7228,4429,57722,860705,6665,4598,6794,11052,128098,5356,34224,4940,21508,29016,12640,170877,6235,59400,128217,246844,34736,22320,13680,58102,9362,125316,10540,63468,116920,5548,166611,9864,48152,110983,7688,24552,114076,255456,82512,463268,139384,393696,9792,5719,66123,87880,214458,30816,375092,592105,967104,12958,9589,45741,150822,50052,163956,12771,15028,6732,15964,80352,13780,3453959,6063,10621,19656,34884,4687,677730,6878,49880,13114,230412,8494,6156,561279,36792,5460,63516,9360,16692,5928,18000,37130,52772,8018,112812,12948,4750,58867,7525,114504,6552,20824,14749,50592,16813,35412,264168,12376,11613,291408,7956,675614,215928,428792,106578,14612,10260,408667,20253,68019,5633,148738,13932,29108,704520,4386,296092,73075,28122,737781,6422,6916,10507,7439,14706,472750,198120,20488,4068,802152,5200,14716,9288,10400,30992,7488,596068,45448,87152,13824,8208,40144,4636,10586,469023,24885,290108,6278,321152,1529320,27072,122512,5876,10140,6188,82440,106742,14706,9486,8928,18772,29541,451152,574824,15010,4370,10044,7280,52920,9243,7138,5160,527325,10192,4644,22278,16416,223820,7482,4300,60268,2610530,4256,5928,9724,49059,30780,298566,25110,14260,67104,24209,17680,33552,431972,36784,7138,23250,10707,25201,26939,15010,12428,11596,4558,3990,18202,21926,6820,2050445,12384,198606,9158,76128,31248,6622,5624,36576,23674,6292,70618,77976,44252,97696,17424,7812,7488,690934,19654,16172,52056,36244,5548,25194,14092,9272,50902,1291264,18290,17759,8352,12958,1055440,107045,5200,7884,5375,5852,8094,8550,102960,5472,18723,811014,417487,32860,9516,13459,4256,77748,12168,294851,4408,12168,3838,312481,40280,11309,78289,29484,4028,198273,73216,555449,63612,88288,4343,33812,1070888,12744,18275,24624,11088,8901,251299,34944,926484,61152,9417,27648,15066,5934,21166,4773,85241,76700,114638,112892,53320,122044,17286,27056,5652,12084,415079,424574,102297,96668,13148,235657,57433,35948,51116,695968,8132,218088,1016280,2434104,12502,29625,9256,5436,41791,25413,38088,2494346,7783,11058,33101,6688,70866,7717724,81528,58368,18920,28124,1081184,6136,33259,6812,28912,6262,1268208,28830,6324,7396,5244,43416,107224,161772,492404,4515,4256,5547,5160,6726,71796,285758,17264,139356,55771,150021,12960,187467,600795,8626,10972,7332,6448,41882,10191,15264,19307,20664,4370,13452,179409,9331,55063,7228,15376,13201,139277,116288,8112,7998,12943,7564,5112,7626,13578,64232,5016,80422,140146,53246,12986,10152,53167,9424,11856,124920,8424,38952,21024,452876,7448,9216,32656,19152,871607,55728,33046,19396,5282,152134,840086,17222,23435,11440,155808,12040,35561,31758,1131552,54352,20640,15394,5130,54264,240002,39579,456699,25280,15168,149081,11514,28124,16900,10404,8496,8901,35561,59688,19080,6236464,832581,8496,19434,18538,24490,10070,56340,11058,13788,472812,382123,45425,840718,17062,6665,6916,45408,12556,42739,39494,13624,7353,4826,29536,6063,20708,159264,13110,63792,1094178,24966,16380,7869,335671,12920,6760,4598,68335,14896,7332,3952,10296,207762,7488,15808,6552,7267,22464,87768,216697,37281,102068,14688,35256,66716,3914,17174,7644,107440,30058,5616,17538,8320,10707,27334,108432,5772,4180,3914,5356,43524,40320,11932,6536,31564,23384,11324,156302,4534958,35672,10902,42581,51398,36034,5738,19656,79128,6923,20448,75096,51794,56373,28086,13588,133510,14300,13794,4142,64030,11060,29068,5676,32379,425010,16328,6408,16328,118924,46689,8816,8374,54684,7144,4218,10902,44268,10348,4212,7980,21328,4515,56674,2339585,9516,8784,12312,15336,13020,16560,10416,17784,10836,638058,15192,6396,9308,24467,582941,8742,7676,17160,20212,11567,30780,110032,7956,8060,155272,91246,421860,18662,82947,9085,45583,7448,28272,4142,309776,76235,34128,44714,7776,402628,32153,56012,5928,10270,3672,62816,2098443,7800,13764,8094,7998,278080,7904,22204,537887,28810,62186,86040,8058,9116,13144,20232,30312,5396,19522,19872,7009,5054,13728,10191,24054,4788,17174,7482,6968,130884,23978,29172,5805,71592,304200,32500,109415,6760,158474,115596,117360,4386,93931,190112,15998,8600,47874,10868,8136,122845,30968,16016,11088,7688,8428,15768,6200,106255,9890,19393,35308,21488,738966,16802,17759,4212,9300,21096,16056,28598,13104,37969,7600,146940,102672,35392,17222,6536,62252,5616,13156,5966,4320,1039464,93384,18619,4601,50046,21164,6194,13870,74304,5160,12524,23746,16536,10764,7696,7956,5719,17420,6656,18318,248534,5662,4028,28954,11908,9401,13825,9460,8626,8740,14136,26149,29016,27477,4522,13373,42104,62479,5117,6188,10726,64414,31521,6864,818763,20461,1618993,5676,19080,53618,11139,17160,9648,13825,28210,21251,28203,5934,85952,12338,5966,9386,181896,5876,80580,15562,13676,4028,7378,6579,27512,16536,1452204,8372,10492,19096,9548,5876,15405,131254,6448,8476,120120,15028,166152,116762,5891,110916,56628,141768,307942,5547,54622,38916,32240,478345,15132,6882,18810,222227,9620,18091,82713,5928,12896,2306484,6240,4408,4104,14668,34918,44578,46136,22776,25628,9880,23244,34162,2303238,267592,118800,7998,56169,9717,3852,1268856,6660,12688,493064,37584,1157587,10764,13208,9006,7176,16039,62496,32184,4066,13330,5772,8772,1062234,12814,625352,113088,44556,22436,12719,368037,30336,10478,28196,165663,57350,28519,29704,130910,39658,6032,16692,1204412,400214,49665,19722,4066,15428,86268,421496,17856,5206,7904,33748,25438,20736,342409,4560,124682,72842,12245,130312,67464,244110,32627,23932,21488,5772,10452,13832,234422,8686,7848,91728,10750,12255,10406,7675506,20683,7280,374539,18565,9503,118512,15552,21844,9030,34048,10922,17280,53878,4859,49849,34684,16432,49400,11180,82646,6758,13752,7410,10080,5418,8632,14554,9672,8996,55214,252864,11696,37446,24130,550368,10906,18876],\"y0\":\" \",\"yaxis\":\"y\",\"type\":\"box\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"platforms=windows;mac;linux<br>estimated_sells=%{y}<extra></extra>\",\"legendgroup\":\"windows;mac;linux\",\"marker\":{\"color\":\"#EF553B\"},\"name\":\"windows;mac;linux\",\"notched\":false,\"offsetgroup\":\"windows;mac;linux\",\"orientation\":\"v\",\"showlegend\":true,\"x0\":\" \",\"xaxis\":\"x\",\"y\":[10728,635792,1497694,12532,49837,93694,12896,22344,176540,4294,5676,79711,40486,225624,14144,157914,39312,11594,6240,6042,16297,155918,24024,511841,20304,6084,18876,8428,42952,13032,15748,6968,42966,6386,5805,109512,14446,98540,13416,75672,778545,6324,14248,147098,13020,12943,61628,20398,41065,99634,31868,53692,74046,54720,11128,285200,117676,4945,28260,28086,654192,39832,306590,5876,97632,20167,11718,6552,28462,44978,7998,4343,5408,223028,109148,262438,48418,19448,15696,229892,121458,13680,13934408,10816,13702,4560,6916,52030,24056,12772,14446,1195744,5054,6084,8216,36103,1039492,51088,22594,140920,8684,234732,128804,132408,11904,19096,24984,34162,34844,6968,204048,43920,59148,13392,21476,29588,23472,24964,5436,20646,7560,19522,47386,5358,8184,18060,9724,4343,94428,158237,75445,134142,162136,95728,144216,480952,18144,5700,9620,85162,6200,48856,24332,5564,7072,335952,5980,2747784,119536,187200,5805,6342856,38236,9238,11248,4262856,533696,31442,9672,273600,35464,15872,52390,220410,19908,2108510,51688,918788,41400,75551,20212,8856,5160,28334,20026,5966,9486,859125,49375,4332,9300,44772,15548,66992,4452361,75981,11346,4320,1315113,18662,18328,27590,26531,16899,9932,19902,6552,13206,8684,75168,8804,17352,76946,382044,221760,13392,7540,51342,7192,2555424,98784,78605,32612,123264,299568,200668,37080,9847,7697,317896,259064,6080,16120,13826,10504,32262,22104,177987,13889,18447,121888,60888,20832,102621,390290,77896,17415,398908,201213,195676,12642,17670,5928,9932,325006,1473802,24358,10292,12245,11752,918375,5230816,21736,4598,6696,167164,124776,27492,7956,19608,20800,16692,30616,26520,10449,39263,55774,10507,3785601,5289,13832,10556,5460,28595,60202,64844,31304,10044,7310,10912,25948,3439502,21684,28348,17544,4261023,4386,58708,21584,60320,470208,7316,39816,10368,8684,16848,21156,21758,1810042,1348925,20026,150722,46384,16037,16848,11552,15128,153260,5016,2275911,69368,38448,39888,16488,146010,7750,49794,970416,27962,16168,525587,9890,1931392,53784,145992,7488,13826,9216,9362,4750,5934,21840,216980,34732,7224,73865,5376240,11970,156104,263160,5252,33228,45714,44252,14276,17160,69254,24940,38626,227599,21892,19604,291462,122832,30384,31680,15120,5676,6751,147146,13932,87216,504099,49059,13312,27821,60624,82950,90250,7611,144612,19158,14615,16426,7072,14196,191208,109908,354394,46624,211668,66248,3501504,145281,10540,13520,22910,4787921,10944,216934,16834,5548,13676,135098,7353,6192,12028,63550,80659,11476,122450,144965,47795,6916,63752,7228,5130,36498,354710,75888,9176,212115,30616,400192,5848,13392,182676,7711348,82713,3952,6916,14364,24253,596711,81528,1071161,3838,27144,42344,55670,7998,9828,36182,16952,40774,44200,22248,11970,4902,30889,59400,33338,360158,39263,16380,8170,5848,4773,10478,4522,46784,85696,10504,251292,225792,31320,271918,4988,8690,84925,10712,302188,28638,30628,46698,9516,434668,5206,6708,11376,102856,1408752,1861184,46398,67624,19708,15934,25346,29520,15984,21424,11592,108252,58144,63279,62805,12096,14560,32736,20016,21008,74214,8496,262596,122140,31540,5772,1989704,9504,43134,5676,27864,7696,9048,17784,174580,10535,93252,13115,181068,18166,8460,5624,9272,126100,4104,7384,8987,12685,4859,8256,32832,23736,145584,13502,786780,411985,7800,252168,4558,6118,25675,42840,38710,18662,301306,73573,8618,35984,10836,349259,4256,28196,14446,21476,25704,62124,11592,4429,30312,60198,70942,128592,6240,12532,26000,18240,9052,5504,64414,11952,64844,19694,127368,87516,80969,6820,195672,171950,94385,963802,42696,3378752,380376,138566,235152,24336,21576,23521,279000,27000,43766,118336,143312,8840,10368,62884,14688,33934,10412,1227976,10348,5934,22724,237460,8372,57190,6448,6536,38304,85952,24862,12636,10400,11594,3720312,16856,53612,325884,11908,241034,14560,25116,5460,18648,7502,103392,21268,9880,7176,188928,7020,10354,7072,32968,43529,8320,34920,684140,598345,77328,9100434,32760,9000,2987504,123635,28086,745920,12896,59976,21684,16952,12744,120317,27097,76464,16416,26781,7095,7181,76756,81449,25916,49348,47479,10602,35155,19584,8471,92235,86060,44352,25978,222480,16640,10277,11137,25848,597528,8514,40824,168302,286936,399024,20592,7912,7124,29736,348074,911090,5016,2482046,9576,132440,69502,218096,81270,88198,5460,9464,12888,9548,1918831,18565,2289815,143464,17518,110916,59469,101093,7338600,19584,19760,1379040,9720,449565,13052,14256,80724,6882,74418,47736,8788,9540,44640,9360,167717,104594,5289,830717,1094071,120776,230601,199008,15132,18936,46311,28519,26102,1520640,12090,210900,31679,21576,7439,243568,32976,49770,168259,32550,36024,81133,35100,131021,68472,15964,80848,8127,6232,7310,61936,17556,66960,7592,289952,33480,9652,46956,701896,4750,25740,33332,36894,12083,191338,16340,9462,7562,7272,18834,177630,775806,9804,133859,2279545,1019258,29796,7992,34701,14706,20644,7920,37262,21672,245186,7874,198432,40334,7095,132192,97881,29848,24986,11036,11532,14322,8164,6880,31668,16827,196664,54826,27432,47795,220058,574184,9612,140223,4730,84878,30744,17420,41044,18668,41600,31205,86060,112654,9976,194814,2359296,4177599,50544,32736,7942,367744,83886,507936,7228,122450,145080,131193,9030,11068769,18228,34424,20436,4294,38952,108288,405964,13392,12168,15500,12772,36348,2832545,293485,66439,10168,542160,59328,10728,39780,222196,15050,26226,582660,10664,12126,77862,11160,292448,9890,68328,7644,7564,8928,3249823,8742,111176,25284,18538,10621,5332,5364,202635,47214,537753,81158,236220,512856,22317,7124,6500,16128,21744,224755,18920,34996,32860,144566,57888,15624,1997320,81792,154656,48070,42696,6168715,7704,25978,18928,47728,437502,551973,89225,12642,63284,120652,6020,12160,8064,200660,68696,31616,8428,19872,24586,13330,36022,5772,4932,25776,98696,113100,8352,10140,176886,147368,175248,25428,19380,21112,140144,77672,22704,8164,150495,5555359,4816,31916,244872,25048,43608,44346,297228,10879,9804,88882,50778,201818,8476,9000,295195,6364,16244,28440,6292,176042,71574,12648,158498,70512,13144,59487,6136,234522,12312,168516,352893,6308,62248,10920,42226,148994,977904,22831,26660,17640,21762,164715,53167,4945,14577,4824,4752,28860,237460,73530,37634,5848,16727,7378,8736,523296,7236,53879,38592,10332,14976,7181,28582,25482,113956,5547,69204,140620,12220,30032166,221364,10726,155168,8632,41808,269328,5512,88846,774086,19952,2552885,6708,8632,25116,10633005,17538,24095,19750,16827,11524,1582920,7228,40204,4558,8686,28954,13520,13364,8856,40053,142911,61699,22506,49848,1817902,15028,24700,412982,27864,18648,22412,7852,45032,13884,106468,183528,23332,103106,13156,11960,15128,537984,43524,7228,138961,6330823,198843,64440,1364544,53506,22880,10726,14664,11336,41949,6448,10512,26617,14872,25560,4386,16920,16120,19220,13640,33540,40114,6794,11590,19800,27962,67824,16182,9568,424008,34944,120080,5054,37999,49286,6916,287481,736632,27664,14534,322457,63674,51192,5092,173352,7006,8127,42480,6500,9322,16182,6422,4601,12772,282910,17372,88846,100296,4730,326088,21948,86490,32311,5418,127152,28458,402480,39816,6572,17316,229732,69564,18476,70735,132652,16900,5512,21888,101592,6510,8557,166764,25972,181168,197974,78921,335118,20336,22824,1907424,7956,32032,10296,40820,657384,6344,162130,9052,15066,4386,1122432,1168410,7192,7956,21052,13082,324942,143260,110679,6552,11098,36270,421290,79441294,2472384,88064,4515,64896,51557,12524,268836,33800,7800,6048,473688,5762,178932,295802,37446,12152,998675,4218,8736,141015,4408,14456,53784,138675,297830,35640,103806,6321,7848,6132217,32184,22536,54036,4343,17784,11825,213044,2113704,9374,8476,148614,54994,7200,7020,9052,1247936,11266,136462,9100,5547,162184,19800,66384,104833,224044,10640,23940,11160,1083959,12528,238817,11880,25480,35150,8184,51272,7254,513648,5824,1591218,191180,22568,14248,41496,108376,11856,16182,139514,32968,8295,19448,19344,9920,9159,38190,225288,10192,145813,96965,66024,400536,3057458,35076,7006,39259,51168,11648,5976,6820,167152,16588,160848,12956,25929,36335,22608,10912,4386,14061,52061,55536,6346,189679,7750,24048,23746,16068,7783,92752,11856,8122,145018,13717,4028,153698,1145264,7638,368136,9858,12116,138320,5358,52632,7912,6688,11440,124558,298699,22672,548018,774832,164808,5580,20770,26220,180594,113688,8804,144096,5168,45899,27056,4066,10222,247832,186835,18936,71712,6708,8424,10707,100316,30456,22230,8968,7696,14424926,10836,37625,5203,209592,39895,546285,57660,11388,16524,34839,108072,8208,844116,4515,3914,2156622,29202,592658,201025,8436,7688,2529332,150722,63216,40176,26936,10234,4644,5246,561168,36952,1160068,25992,247379,21930,8736,4932602,43443285,8804,4066,146984,14942,70122,427492,10440,21027,18104,3497330,105958,12896,16430,390139,9396,129636,127660,24016,15236,537437,665575,40896,53424,6032,8060,34286,29760,78572,460728,10374,18228,22940,31096,1067454,3714580,5356,6200,4978,90720,20520,15810,1280088,446982,7564,20634,90472,45648,17836,7920,26846,16120,14260,7436,37224,6579752,27968,14782,12341,42718,22692,76000,65728,222859,9672,8184,52018,6820,194814,19188,65145,2510820,204594,10578,6136,90432,21008,10728,7224,16125,34808,9464,8375422,98857,104359,233616,25416,279032,47842,5865964,30420,20808363,387810,33022,10556,116525,77710,18460,226486,1239431,13312,35030,442479,70566,15089,5203,16430,9464,15444,36214,403992,22680,8680,70784,4104,23760,6820,6386,7812,13604,3839400,5720,2716336,9724,11395,30020,199004,8626,91640,731724,43416,27404,809782,39990,27097,12236,8060,26860,17918,122360,84846,12600,35048,10793,29698,19276,34038,24840,21762,11218,170810,9432,9044,74261,79636,41396,59272,37758,5054,9842,16632,259992,14612,9331,100434,75516,28028,7440,8740,20556353,13248,295568,3522294,7006,21142,21840,184202,322582,56576,8684,42532,135876,163080,121432,27735,9920,26101,4515,85320,288143,423398,10868,19292,11804,16378,11596,1612627,11008,27300,6232,18360,27792,26638,48724,101136,40796,5332,333372,31521,279792,48724,5203,1118000,11098,39744,27248,21700,427320,54720,332444,33904,54560,68651,61814,31752,7955,3012665,90396,35092,4644,524016,8600,1153242,68848,31519,57164,90688,291668,7654,15168,695952,15912,1570441,10526,3924,70128,250900,53072,7502,2078024,7956,18616,10354,13020,17928,265124,44454,26312,5616,31248,54696,227664,630894,11024,28656,10602,191575,67166,11739,75998,164320,6032,50353,8712,209664,14074,13984,155472,1215084,13082,6192,469339,13490,134106,397277,6552,99386,47272,8690,3587688,34560,7704,6278,482804,35424,161856,7688,14322,28548,257688,38157,25776,1386529,185115,60912,14248,43628,18791,35836,199001,8360,8424,315456,46696,25596,121660,13260,75140,10088,31104,7592,4968,1425424,33101,5586,14760,239295,5356,40536,4988,14276,11481,16120,17372,16848,158711,312129,51840,250667,14457,10974,8164,45012,25740,49348,8216,21964,7344,28340,24388,13373,142200,63437,21199,542098,226670,38750,30566,9048,61048,12513,9256,16454,58344,23296,7334,4066,388296,49063,12958,4750,12400,42470,162316,2064608,323280,6084,10412,12083,17587,9202,6324,1886544,425258,4945,20296,6536,11160,86903,308396,9516,11804,324360,9331,9796,122766,23392,21508,7634060,6923,19479,7956,675800,14074,7525,19512,8028,79050,14760,480624,19188,10222,23036,552064,76456,9216,124583,12168,115111,165416,6634,30992,14384,6579,9204,51858,93783,6696,17174,267264,8060,47994,28132,25064,7334,197856,15438,99424,136276,11594,15652,4940,6840,15484,95666,20640,79128,110542,12502,485857,11952,9776,10292,462528,48980,202802,5252,5289,278720,15089,126953,1689128,19604,6760,14362,42120,43316,378138,8385,13832,112902,776644,69230,56760,55728,170196,19592,26574,250704,210444,445176,15704,21576,12900,8892,49928,370352,841745,5934,4560,8360,36332,221052,2762946,9464,10044,44136,6292,187302,66464,86490,10504,9072,42978,1014676,146232,19292,20336,7095,9073,29952,240864,13224,45074,9030,4472,6080,81432,59830,650547,13320,23908,7564,84940,16469,48960,7410,10296,14260,337156,194145,49680,104036,6574,12376,41236,55536,6080,68944,8856,6188,7750,6344336,27056,18166,39246,26714,5289,2358876,70704,71208,25542,14744,43632,12462,913951,117473,6396,712975,18724,39780,187426,6321,8664,9308,2437034,23112,16391374,16616,12168,7378,363320,59706,5668,903997,77634,5460,6510,17422,340318,10478,47400,19656,83898,190008,91846,118248,38829,293169,893234,5112,919274,7440,2106326,365456,291826,105768,44763,103329,95202,40166,8122,61017,22256,72360,46624,18936,32798,34996,12502,459000,4294,19522,20952,4773,15496,40053,9620,18490,64368,49770,218178,79116],\"y0\":\" \",\"yaxis\":\"y\",\"type\":\"box\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"platforms=windows;mac<br>estimated_sells=%{y}<extra></extra>\",\"legendgroup\":\"windows;mac\",\"marker\":{\"color\":\"#00cc96\"},\"name\":\"windows;mac\",\"notched\":false,\"offsetgroup\":\"windows;mac\",\"orientation\":\"v\",\"showlegend\":true,\"x0\":\" \",\"xaxis\":\"x\",\"y\":[49818,134416,16182,16211,4816,70200,57460,10507,57784,29541,34918,6106,3631584,6364,27924,43004,4750,4248,6278,7668,14756,101308,7502,9724,18802,148441,10712,282948,4134544,49612,4687,11020,3838,6188,195156,27413,4218,22828,12324,4788,19396,334366,10922,6149,121892,17568,201172,47716,12744,68536,10816,151446,10712,17004,10244,450379,14664,7697,38528,7936,39096,26164,10656,18000,872784,355579,10191,53234,37368,9030,649472,11880,11448,180804,6012,8436,4515,11448,1951813,13454,91542,12152,68809,24727,692744,7182,14136,19197,9620,32040,8385,311116,45346,10944,56072,58320,77376,70626,17673,22308,289140,130260,337156,475106,6688,327455,21018,343097,21888,16432,754134,20026,105710,7030,1066464,14174,4032,1033075,7866,11532,39579,16796,880771,103806,22360,52762,9100,757136,13186,3952,216638,2152750,107543,74218,37202,11218,37076,9734,53884,48360,26445,49538,5876,14384,5332,13728,162582,30889,7224,24804,3780,227582,103272,6572,11297,17784,17243,19592,61383,27504,17112,55986,13509,54288,181718,51745,164880,30628,155420,53957,85570,32508,15800,10540,37296,43206,23250,53641,56287,5184,13072,40976,30816,20232,25704,4028,67756,8736,4142,5246,29512,75816,19114,10244,20020,42423,111241,755793,20894,10608,4446,16226,23932,8170,506602,30400,56012,77584,91547,401076,4104,4902,8712,376154,34344,5289,18582,70432,967460,6510,36270,16120,449136,59724,281294,12428,11352,33384,13608,131112,7502,9424,33136,3577673,7254,100152,12084,16380,10088,10744,45448,321451,18404,17775,299160,124668,12400,188889,9864,122544,10415002,10222,15132,13896,9766,131924,85020,137206,6450,7936,4218,6156,72488,25792,18864,17628,12008,23478,5976,6696,7783,66248,13000,6235,36656,53246,43645,16058,131219,13536,123324,17028,1493021,15563,13889,19355,10868,4687,21514,11966,4750,22420,19197,34916,6880,4712,7440,6450,46170,73584,37128,468884,15066,12212,192386,10602,31540,119952,749552,171120,35880,22989,78884,6344,113760,3996,118664,1742317,8436,35392,18848,48891,7828,26273,19522,14694,7525,6923,29808,23976,6882,29467,37200,112891,33060,22932,154584,9920,16492,162029,117552,194256,32344,19512,8295,15563,22516,7790,5160,6696,6574,9776,13020,67906,19916,14456,256987,56916,26136,14560,24332,8474,35064,5928,247052,53754,19646,9546,67526,11700,66994,89544,71362,21600,225990,4068,23305,70992,338910,61704,326244,4142,14144,84604,45980,11098,15480,13702,35774,22306,20066,56327,127111,6292,61857,24984,33232,20026,28800,6510,45267,8816,4446,10504,67642,2417163,13468,8618,6084,26273,19476,293472,10354,11020,5762,56520,8840,37440,41366,1709876,12400,6500,46500,198328,8729,186248,220884,3819510,6188,16864,149832,70520,16678,8736,180041,9648,32072,26676,7904,10222,21070,37752,45562,23305,5203,15656,9256,20232,16948,19872,32528,27072,9072,26568,33840,69574,282899,12896,6650,17112,5876,499658,68284,209324,454646,11596,6510,20274,8930,59882,20232,32074,6192,9348,4560,82088,10452,7192,132088,36720,6194,7316,8588,6820,14756,60496,32908,92588,71258,7632,15562,20016,49894,14196,14820,119908,65728,23370,45792,716196,196352,14508,13946,23976,24800,9052,153037,77443,58136,8930,10712,27716,5168,10656,7181,61070,122608,301320,16016,16306,46136,1298032,9880,48585,50353,27413,96933,7776,6188,285192,20224,38812,23560,17898,65304,12040,6612,146946,10754,164448,4180,20520,59508,81449,9672,60909,45240,20592,11088,12376,9424,76235,221676,22444,6696,173166,40546,50464,46810,10192,7525,8611,11388,226352,6149,22392,28086,26961,10788,33970,31824,12198,66404,7750,30172,8280,47244,4826,10036,370822,25168,8788,16598,69882,37872,5510,28282,33575,66220,29230,8164,13946,23920,4066,1044854,9576,169100,11856,109512,4068,486008,3683544,6448,13728,22360,4816,4294,87048,60192,17802,13746,16796,252148,19592,113444,48934,17716,11336,5590,49320,2930368,55480,38220,37656,9675,200294,11395,157508,40486,7611,23940,12166,8729,82584,48828,24480,9648,45899,18792,28964,4522,68472,215498,562875,96459,7852,527404,185318,95784,9204,15910,7009,44856,671816,8736,9500,119808,117000,140040,13717,49824,47736,30968,37446,22120,26728,13988,69125,10404,6708,110050,7052,7482,133036,36432,19708,46748,46080,15912,69998,20696,15340,7783,45694,21330,384648,5876,45012,54360,10664,21204,298512,10192,176881,15238,4343,27413,42581,32448,18705,7128,52851,42192,16952,7740,280292,9932,562030,19840,4826,25628,150746,17004,1116648,7258,118637,10664,50482,180471,8164,124141,11232,290404,14402,10191,14147,29070,18096,141252,14364,31692,31949,43416,47736,34523,4636,27612,12586,8840,598680,7267,7776,48633,94612,15084,41904,21008,8060,53924,8476,16530,21973,6708,5668,4370,623626,26752,69472,84778,31200,200148,53009,20020,14694,8804,6364,4472,33170,408408,194016,261288,10036,4822192,22536,4773,38552,31777,94815,34892,8028,189384,7296,22962,11966,13020,35787,19158,59598,11932,6660,7904,5738,230308,9847,36103,4859,115498,8322,16254,8944,4978,32798,83187,62662,115752,15953,42269,94800,75384,746313,34997,3952,17316,22968,5054,10974,1042964,109951,783432,422097,10965,39618,8928,394108,20522,15124,69746,403295,4712,26784,12642,4636,4601,4945,7502,35880,106912,24118,345228,327218,23134,5252,56160,522106,116784,1082520,7697,67639,13578,398634,7688,8990,16802,5246,4332,13268,133984,21886,79790,8213,32469,32328,7488,15548,11196,12272,12744,117312,38880,11596,18565,21164,17222,435240,262446,1490572,6948,13702,44240,11076,10062,18476,14924,30744,190706,40248,210930,14554,75960,8632,5289,12648,80422,123552,44044,14782,9559,6240,19866,138456,19750,62282,12341,9362,23580,9576,7568,66774,10507,12152,7776,235973,14144,164424,8432,8008,5092,92588,1255176,13680,16948,25359,8424,1614548,33402,4940,8640,11160,9216,33418,34596,64666,7592,15314,43896,6084,7626,55728,34830,4902,7416,32178,8580,5633,121024,35733,570960,197972,6878,17160,6665,6235,5616,8170,117990,76669,128180,32760,11782,15696,17050,84882,107414,25069,9073,45942,15721,11268,35402,12996,81096,5092,609768,6063,1127883,333640,12806,6840,7874,12480,4370,7920,7006,26445,32968,31564,2223218,8901,320952,5246,11139,8840,110448,67704,35774,5117,5504,32034,97344,120317,61978,122450,39960,16120,256824,6136,5824,8854,17992,32078,198328,7332,6634,131298,20210,14400,193180,192608,84538,33356,4940,5289,24624,11692,720502,105552,38532,4730,311240,6278,50869,10152,636272,26496,13728,62568,9048,2004187,10449,14760,59436,35776,198290,48484,19513,14184,110304,12087,13644,3708,7384,224992,11076,20336,25848,89642,31600,4472,12524,22356,19866,20708,436321,3566850,49770,6820,18506,9828,11232,16416,361267,4464,15964,1188606,9052,11970,13052,77584,71574,8170,812520,11232,9546,28656,44424,15652,5548,7200,7848,45537,2630700,10823,238248,19912,22360,3708,460917,20862,1039561,68112,185966,218808,9933,12240,44793,100152,20376,17212,48111,69757,10902,1191636,4687,5160,210485,42294,4142,29625],\"y0\":\" \",\"yaxis\":\"y\",\"type\":\"box\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"platforms=windows;linux<br>estimated_sells=%{y}<extra></extra>\",\"legendgroup\":\"windows;linux\",\"marker\":{\"color\":\"#ab63fa\"},\"name\":\"windows;linux\",\"notched\":false,\"offsetgroup\":\"windows;linux\",\"orientation\":\"v\",\"showlegend\":true,\"x0\":\" \",\"xaxis\":\"x\",\"y\":[11966,18791,37658,4636,5824,11137,72432,19344,13104,200592,18616,8122,6292,154284,9360,18565,11780,48568,66508,23384,15652,13889,262694,44856,97802,62173,5848,29025,5375,13248,14570,8987,397606,13888,23932,9576,14880,7224,10850,9100,8268,32566,7416,5092,297960,5977,6500,46956,20904,17243,79670,61462,436852,7904,67500,83018,66766,55432,5564,9796,7540,22392,779730,93000,973517,488299,5564,4256,14632,22747,9114,7396,15314,4515,6726,6751,16616,7488,133300,4663844,9766,11718,7068,19684,13728,31824,8476,161634,9204,7488,90139,53072,45666,13000,7611,8804,250303,45000,12169,46436,19282,3688273,39052,26312,15236,4028,44304,4028,27950,11036,26832,9256,10320,14534,72000,7176,38502,28849220,30324,5220,19228,231480,15192,11266,32250,5200,6552,5814,92983,64220,13545,4218,5805,29450,61828,17888,36608,3990,422650,5117,5512,21672,936944,23504,25896,437684,9976,4644,121520,28768,70876,4142,406348,8041,9724,7740,139464,7852,8928,6966,7254,4644,8432,159912,722736,7130,9159],\"y0\":\" \",\"yaxis\":\"y\",\"type\":\"box\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"platforms=mac<br>estimated_sells=%{y}<extra></extra>\",\"legendgroup\":\"mac\",\"marker\":{\"color\":\"#FFA15A\"},\"name\":\"mac\",\"notched\":false,\"offsetgroup\":\"mac\",\"orientation\":\"v\",\"showlegend\":true,\"x0\":\" \",\"xaxis\":\"x\",\"y\":[21567],\"y0\":\" \",\"yaxis\":\"y\",\"type\":\"box\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"estimated_sells\"},\"type\":\"log\"},\"legend\":{\"title\":{\"text\":\"platforms\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"boxmode\":\"group\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('3cfde5b9-91c2-4679-a12c-323d810839e8');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Las estadísticas para las ventas de juego de acuerdo a su disponibilidad en plataformas entregan una ligera diferencia. Si bien es cierto no es tan grande, es posible que la plataforma en que se encuentra un videojuego sea un buen indicador para estimar sus ventas."
      ],
      "metadata": {
        "id": "OTxTeJe_69sI"
      },
      "id": "OTxTeJe_69sI"
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.scatter(df_train, y=\"estimated_sells\", x=\"required_age\", log_y=True)\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "Bz4BUNZ6jbB7",
        "outputId": "a3c422e4-bb3f-4f4d-b8c7-2d9d6b4d00b1"
      },
      "id": "Bz4BUNZ6jbB7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.16.1.min.js\"></script>                <div id=\"b87424db-deee-485d-ace4-0f920cdf2186\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"b87424db-deee-485d-ace4-0f920cdf2186\")) {                    Plotly.newPlot(                        \"b87424db-deee-485d-ace4-0f920cdf2186\",                        [{\"hovertemplate\":\"required_age=%{x}<br>estimated_sells=%{y}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"\",\"showlegend\":false,\"x\":[0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,18,18,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,12,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,18,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,12,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,16,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,18,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,12,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,16,0,16,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,18,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,16,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,12,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,18,0,0,0,0,0,0,0,0,0,12,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,12,0,16,0,0,0,0,0,0,0,0,0,16,18,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,16,0,0,0,18,0,0,0,0,0,0,0,0,0,12,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,18,0,0,0,0,18,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,12,0,0,0,0,0,0,0,0,0,0,0,0,0,0,12,0,0,0,0,0,0,0,12,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,18,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,16,0,18,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,12,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,12,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,18,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,12,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,18,0,0,0,0,0,0,0,0,18,0,0,18,0,0,18,18,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,3,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,18,18,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,12,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,16,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,18,0,0,16,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,18,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,12,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,12,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,12,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,12,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,12,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,18,0,16,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,18,0,0,0,0,0,0,0,0,12,18,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,16,0,12,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,16,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,18,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,12,0,0,0,18,0,0,0,0,0,0,0,12,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,7,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,18,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,12,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,12,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,16,18,0,0,0,0,0,0,0,0,0,0,0,16,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,18,7,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,12,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,12,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,18,0,0,0,0,0,0,0,0,0,0,0,12,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,12,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,18,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,18,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,18,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,16,0,0,0,0,0,16,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,16,0,0,0,0,0,0,0,16,18,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,18,0,18,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,12,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,16,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,12,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,16,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,16,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,16,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,12,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,12,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,12,0,0,0,0,0,0,0,0,7,0,0,0,0,0,0,0,0,0,18,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,16,0,0,0,0,16,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\"xaxis\":\"x\",\"y\":[3914,10728,635792,253864,49818,11966,1497694,12532,3914,49837,27176,93694,52572,62764,101824,134416,26544,16182,16211,4816,12896,70200,78884,22344,15326,702956,57460,17732,176540,14896,8643,10507,10008,57784,6758,29541,44020,8424,8604,350997,9362,34918,4294,5676,34216,6106,79711,40486,78964,225624,14144,157914,16568,39312,11594,936900,3631584,6240,6042,18012,9568,137643,16297,6262,1293336,155918,14040,6364,47424,6696,72936,236500,3924,4028,5246,24024,511841,20304,6084,12245,5246,14319,18876,41648,8428,42952,27924,198369,43004,13032,11448,4320,4750,27156,70176,15748,14018,12482,7254,6968,6063,10406,42966,48982,4859,4248,6386,4524172,30573,40092,5304,76836,10664,6278,18791,29388,7668,14756,6262,116356,15084,5805,109512,24128,57474,14446,98540,16776,13416,75672,26208,778545,72680,4446,101308,40964,6324,132870,5824,130500,14248,147098,10912,363084,7502,13020,13373,9196,885422,9724,12943,9559,8246,30524,18802,24095,21804,607724,12403,4066,61628,20398,41065,148441,10712,6344,282948,8664,33440,99634,6372,4134544,31261,147651,49612,48880,11524,4687,31868,14544,5510,12064,69678,7525,80484,53692,3990,153418,15247,1279326,19656,74046,11020,54720,11128,285200,37658,4066,52344,4636,451422,3838,6188,117676,861032,229416,872318,30702,4945,28260,6880,195768,8556,28086,50165,100835,195156,25844,14516,654192,33488,27413,41184,3744,7353,39832,5130,4218,22828,12324,306590,18824,4788,5824,18920,559152,19396,5876,97632,4332,8684,20167,11718,12636,6552,37696,28462,44978,19836,7998,4343,143052,334366,5408,50955,45792,4104,11692,470808,19440,223028,23564,22458,109148,10354,52668,262438,10922,6149,11137,5724,48418,7790,121892,189504,72432,98280,35234,19448,17568,15696,201172,20160,229892,47716,3636,64464,11818,12744,22204,121458,13680,68536,160528,56268,13934408,7900,35313,78289,18658,6292,6498,26728,14405,23858,10816,13144,38710,13702,10981,15394,24804,11804,42897,4560,50220,164260,6916,52030,24056,10816,12772,14446,1195744,698400,5203,24928,5054,39384,117676,151446,19968,24264,126880,20540,15300,18356,10712,17004,6084,19344,1418688,8640,263149,18576,10244,166216,11438,8216,37232,36103,32472,11376,1039492,60528,8496,338840,251136,166032,177460,450379,20066,5356,26149,55068,95906,51088,39216,29488,11248,14664,27612,6384,7697,9610,17696,12096,31304,7344,32916,224992,22594,4066,11818,7998,38528,9216,140920,76322,3996,7936,9204,8684,39096,140976,31806,26164,12428,10656,15824,90534,54954,234732,28892,128804,132408,373591,18000,17784,11904,19096,24984,872784,34162,212836,355579,26064,10191,53234,37368,8320,12168,9030,192918,34844,37539,15958,45198,649472,11880,78192,27456,59768,9287082,11448,6968,560652,37656,53878,180804,44161,393908,204048,6012,8436,6696,15562,43920,312998,23760,15168,13520,6634,59148,14964,8901,13392,4522,26424,19197,11051,21476,29588,23472,13104,5332,149136,19368,24964,601016,4408,4515,5436,12384,20646,14782,21142,5504,11448,7560,49104,121518,10224,1951813,4140,19522,13454,47386,8060,5358,8184,231154,10586,16802,18060,33891,9724,7488,4343,94068,134628,94428,158237,75445,134142,15934,162136,91542,95728,11284,16872,40394,13373,34529,17628,168428,154960,144216,480952,93912,5890,338436,6448,12152,18144,287370,55853,16530,5700,68809,2691358,34424,9620,24727,4104,23940,185938,11997,10602,19080,10664,692744,10716,19684,750421,7992,7182,14136,11664,20769,218400,85162,696299,6200,6604,5652,104201,10368,19197,10540,48856,24332,7704,9620,16297,32040,8385,5564,9202,7072,16454,7592,53483,335952,11016,11222,50616,5980,8892,25012,16068,2747784,7748,10080,119536,857956,4279114,311116,28348,17856,187200,83898,501642,5461,5805,192049,45346,473817,6342856,7904,20482,454248,47196,38236,10944,115577,11266,13114,56072,15190,14018,9238,23472,58320,24885,6063,12692,476397,321382,18060,15444,8769,11248,68510,219085,17992,11904,15428,4262856,77376,70626,40032,54194,9796,16120,280800,12350,9504,55695,5512,533696,17628,17673,22308,31442,9672,6344,273600,718189,176802,155746,3876,140620,29154,10277,5564,151048,35464,9006,19908,15872,8112,20644,10008,12482,8712,289140,200592,405954,12324,52390,28424,19722,67071,15523,71416,20880,220410,19908,2108510,96301,5564,17459,40104,6136,6324,51688,28704,918788,4343,16641,8295,41400,5976,4472,9072,21638,49724,9216,130260,18616,75551,7632,337156,20212,8856,5160,858572,14328,28334,475106,21543,306362,20026,5966,9486,859125,6688,10816,327455,49375,36378,4332,20488,152312,178144,8684,9360,9300,8122,10800,213409,4294,98568,8996,44772,15548,55796,13676,66992,96933,1665162,4452361,17108,75981,11346,17680,6292,115541,21018,28582,37841,12152,18723,5200,889632,9734,343097,8996,4320,1315113,18662,18328,17673,45662,21888,21962,27590,11594,261934,62372,26531,16899,9932,9234,19902,6552,4464,11613,16432,40536,154284,10908,13206,70784,7748,9766,8684,754134,413170,1071288,23750,9308,25438,35155,6536,75168,13826,5928,25128,8804,28835,20026,105710,6968,78819,7030,17352,76946,20088,19032,22704,92132,1066464,12584,265440,5720,382044,5976,64688,15190,4176,221760,25482,13392,7540,51342,14174,22575,4032,571814,11524,9006,7192,1033075,20640,2555424,9360,48450,9144,14402,25200,7866,10602,98784,6572,78605,11532,32612,280618,123264,299568,39579,6751,1309252,16796,16484,200668,880771,103806,34844,37080,9847,155304,7697,7052,7296,317896,63898,6042,22360,52762,29146,3952,5332,51350,259064,23296,6080,9100,16120,917111,32390,19671,18565,29283,13826,20448,11780,10504,65188,32262,22104,757136,5590,13186,34200,177987,22680,6460,6136,165044,10234,178452,13889,18447,528984,7696,121888,60888,35352,6552,20368,20832,32723,6324,16112,12046,3952,216638,15552,62062,7482,102621,5168,10088,390290,12087,6192,77896,4572,11016,8788,2152750,107543,74218,6688,48568,5719,32544,14560,37202,66508,17415,11218,37076,57304,398908,201213,195676,12642,10728,5408,9734,16856,53884,48360,15840,10184,17670,35313,26445,61383,115754,727669,39596,49538,31679,12024,4066,5928,18091,9932,4472,32548,40456,203164,325006,1473802,5876,14384,5246,37752,133431,5332,115026,24358,11309,44878,12768,65333,23560,28124,6292,48111,13728,35030,10292,162582,12245,293968,23384,11752,151580,5624,918375,7130,30889,13454,7600,96064,7224,5230816,21736,3248336,4598,24804,3780,6696,227582,39308,167164,5966,124776,12482,15652,8604,81792,27492,6572,4816,41317,36577,18460,43272,1451704,38950,7956,9348,19608,5356,72759,20800,27404,16692,8778,103272,6572,13104,860976,11297,17784,6278,11128,1086488,7124,139176,12586,30616,26520,47400,49556,6572,17243,10449,125689,75528,6760,403056,39263,55774,27396,9880,16037,13889,12561,7697,262694,10507,17964,7280,19592,71337,7334,38184,3785601,5289,17160,61383,11481,9610,179181,27504,13832,10556,13104,5460,13536,28595,21372,60202,17112,33332,64844,55986,124930,32904,4386,12688,86742,13509,7372,54288,19500,23244,10348,31304,10664,15136,7812,10044,181718,7310,51745,891820,164880,10912,35647,30628,592844,155420,30876,53957,37324,44856,25948,4859,2491660,85570,3439502,32508,8127,164715,15800,119527,21684,28348,10540,51745,37296,6407,17544,4261023,4386,5203,9374,58708,21584,26875,11492,9717,43206,4446,26486,23250,60320,470208,4472,16560,26474,9417,7316,15438,178312,597896,53641,13640,39816,10368,8684,236447,126666,17696,21112,16560,16848,13244,726089,56287,21156,5184,5824,13072,579120,1886836,97802,692128,7296,6696,43524,150653,21758,40976,1810042,18407,1348925,26860,11139,4864,17064,21700,38141,20026,34271,150722,46384,8892,16037,30816,961362,100168,14256,38664,78416,1152531,20232,16848,25704,11552,15128,5805,4028,148678,67756,1246304,8736,13516,4816,4142,55490,13072,5246,11476,29512,55774,62173,183481,153260,75816,9776,43416,10608,36972,21762,9085,5016,11088,1216800,19114,12255,2275911,59112,69368,363874,38448,14196,39888,15496,205321,741960,19840,82560,15879,10244,5848,20020,42423,111241,15340,16488,54498,7332,146010,12654,27590,7750,49794,5289,970416,27962,8246,755793,16168,525587,20894,10608,7095,164304,9890,51116,8112,872526,1931392,53784,4446,145992,18644,20088,26228,29025,16226,7488,129580,55512,20016,13826,9216,10974,38786,30240,4028,9362,15264,4750,5934,8360,14858,24232,23932,8170,21840,290641,17244,205632,216980,506602,34732,556416,20736,20592,25992,5375,9761,4978,7224,31044,13248,30400,73865,56012,5376240,11970,27892,60264,9417,736112,77584,156104,5668,91547,263160,12384,5252,6136,401076,10972,27352,33228,41610,105696,211562,45714,44252,4104,14276,24358,22833,17160,69254,24940,13248,14570,4902,38626,10664,9216,18050,8712,376154,15704,227599,18146,6156,4558,21892,13452,10578,19604,877084,155880,291462,37656,14256,6321,122832,30384,4902,31680,11739,15120,16920,5980,5676,29842,20664,11016,34344,63990,5289,37354,18582,20770,13032,6751,70432,967460,42280180,16906,9576,16344,25359,10108,31916,93353,147146,13932,87216,504099,6510,38532,30600,36270,8742,70704,5031,22176,7540,49059,6572,5548,16120,13312,4078274,4218,9638,153748,27821,53072,40132,16120,6188,60624,82950,449136,59724,14060,90250,14248,7912,11284,7611,5890,45144,4522,5719,250952,7130,93930,17632,15010,12740,24806,144612,24037,12816,281294,22176,15872,13788,538222,34365,19158,4730,23400,14615,4294,16426,5244,51264,206568,29038878,34684,36464,12428,11352,21762,142201,12168,7072,14196,191208,5633,15552,33384,109908,354394,8987,13608,46624,131112,18316,18091,30784,100738,211668,282978,181779,12888,66248,178966,119392,3501504,145281,3952,170956,17544,128016,7502,10540,13520,319160,22910,9424,33136,5375,3577673,3914,7904,7254,160128,982338,4787921,9576,72443,124504,742392,14328,10944,216934,5624,22464,10191,102180,16834,8172,100152,5548,12084,34602,5130,8094,10230,8320,143069,16380,13676,13338,253440,81282,48418,135098,1190276,7353,397606,6192,11856,10088,12028,18720,63550,9300,949240,8784,53300,31679,159692,1229240,11534,80659,1457682,9724,20748,346476,54994,6574,20540,726657,50112,11352,57190,12482,76393,8927,13888,3600,10744,17459,11476,13780,23932,9576,122450,11929,38520,144965,95542,45448,25194,14630,321451,18404,17775,5184,66528,299160,5244,14536,47795,80414,38502,14880,124668,7182,82056,16802,6916,5472,13780,12400,10368,17775,10296,41949,2154014,38076,53621,63752,188889,32422,10070,7228,20862,9576,92035,9954,47684,31464,65246,5130,15184,9864,7800,122544,63498,10415002,8901,36498,19866,16276,5848,44764,1875376,12599,354710,75888,10222,9176,212115,40291,30616,8618,13932,7224,16669,400192,14976,5848,13392,10850,6136,182676,76824,956332,8580,26524,61938,15132,9500,7711348,10192,82713,6500,9675,3952,406297,29016,76235,24467,24411,6916,28132,13392,5928,14364,13896,5976,179883,19902,24253,16864,6080,38868,19500,10556,596711,79484,9954,8094,9766,81528,4472,45030,131924,4343,16306,46512,8372,1071161,85020,3838,218922,26070,891041,14198,27144,73268,19092,5805,19654,15958,12276,42344,55670,42532,137206,7998,9828,36182,9176,14288,16952,40774,44200,58464,32943,22248,6450,38270,5460,7936,11970,24244,4902,58178,30889,40608,18720,4218,11139,59400,7144,19269476,287496,443269,33338,3960,6156,72488,360158,25792,8320,16692,39263,17316,33048,386136,16380,8170,395604,25517,14615,28614,6156,5848,4773,10191,19928066,9100,166752,10478,5418,12648,5461,18864,335916,18772,4522,11552,66994,46784,10836,17628,12008,16272,550185,51034,5512,30573,6232,5117,85696,23478,10504,5976,265734,6696,129704,14322,114939,251292,225792,31320,6966,811172,31096,8268,7783,23832,271918,13110,165505,24048,66248,4988,12152,112060,9412,8690,13000,84925,19874,4598,10712,279186,302188,6574,4988,29388,14773,28638,76153,139040,15872,16016,18648,7440,30628,46698,25413,6235,5396,1356212,5633,9516,5408,434668,947376,7525,5206,36656,11376,6080,32224,6708,11376,73530,21027,53246,102856,12096,1408752,1861184,32566,46398,9114,7344,16992,67624,13364,11352,17594,19708,7416,30628,15934,25346,26600,15184,5092,49928,29520,12152,15984,73584,8990,43645,4687,49920,21424,11592,108252,58144,460096,297960,16058,63279,131219,56992,4066,62805,79608,798769,10608,5054,13536,2141136,46314,5332,12096,6032,123324,17028,1493021,5720,24804,15563,24700,20160,34128,14560,7592,12896,13889,32736,4386,19355,7448,10868,4687,21514,50560,23068,6536,20016,16302,16195,19656,34049,7396,90516,5977,21008,39364,7525,7790,14104,3395520,12400,31218,33136,23068,73910,20880,42344,74214,8496,6384,11180,27360,5977,262596,5652,22824,24381,122140,31540,36890,134230,6020,804615,5772,16120,1989704,11966,350207,9504,124754,163866,4750,8928,92579,43134,22420,5676,53496,656885,3914,32034,3744,27864,9216,7280,19197,127286,6837,7696,288917,7439,34916,14694,8643,4788,9048,17784,174580,117728,13244,16254,10965,217672,10535,13208,93252,13115,3876,12900,181068,18166,99303,6880,142168,4712,7440,20808,6450,67392,5252,20145,209932,8460,4788,46170,5624,40362,9272,16985,10922,126100,73584,37128,12298,6500,9776,4104,7384,8987,11648,14456,19152,12685,16590,115656,7095,468884,113602,53630,11856,30008,550393,6764,119784,177750,161476,5396,37920,15066,4859,71982,423708,94886,8996,12212,8256,32832,23736,145584,947842,29713,13502,13578,5662,786780,6878,14768,411985,192386,7410,7800,56564,55800,15872,252168,4558,52706,44304,18648,640212,6118,200564,10602,481954,25675,31540,151443,4560,9864,13020,42840,38710,136697,27413,70980,25344,4332,18662,19995,30168,119952,3744,10108,25420,6880,749552,171120,118598,15028,20425,301306,48190,73573,8618,35880,5244,9804,11088,114550,158328,22989,6572,16432,35984,78884,8280,6344,8184,10836,113760,3838,4896,101804,3996,5738,9724,8632,464318,55872,30020,10184,118664,349259,1742317,34906,80352,8436,4256,7790,35392,28196,11804,6878,14446,13588,4598,21476,25704,11352,46956,397008,45899,46368,8084,18848,42011,64930,23328,48891,20904,46488,480240,6278,7812,535651,346652,62124,11592,4429,121368,10036,5928,4408,7828,193128,30312,5418,403374,7998,49217,86387,191654,60198,17243,70408,26273,122740,23972,886854,177568,214848,19522,14694,132088,7525,70942,30315,5130,128592,58996,6923,36480,6240,29808,5092,4864,12532,26000,23976,22032,20224,19190,8626,22116,18240,9052,52576,5504,6882,9196,1177848,11340,49324,7334,146880,4484,326823,23688,64414,81449,5168,494326,21166,19136,96222,11952,29467,6758,298034,64844,66664,19694,117154,79670,13320,127368,87516,119536,5590,37200,30600,61462,80969,16120,6820,559320,436852,13224,195672,18414,171950,12616,94385,53404,43946,49556,239904,963802,7852,4680,15800,42696,3378752,38270,380376,15879,424625,17143,112891,995665,138566,393016,661072,14580,6149,235152,22594,24336,21576,7750,7904,33060,22932,44194,12688,100172,23521,52693,14092,6820,154584,279000,14098,9920,53010,217208,6240,30004,16492,27000,99944,43766,13640,31320,9486,17480,118336,143312,6063,28598,5616,64440,10868,8840,10368,62884,26860,15247,14688,162029,95288,25327,10348,153338,117552,33934,10354,10412,291589,30336,194256,7540,1227976,32344,10348,5934,48348,60164,24648,3914,19497911,10234,5760,27576,47558,22724,237460,49290,8372,57190,19512,6448,80106,8424,8424,6536,38304,43834,17632,85952,6916,81840,74808,8295,15563,19039,24862,71416,12636,226610,4028,10400,11594,13244,44082,23134,71208,40680,3720312,11096,22516,7790,4484,90948,16856,53612,5160,325884,5160,8928,46664,6665,11908,6696,12274,67500,8532,241034,6574,10088,14560,9776,25116,5460,18648,7502,4902,13020,9734,5662,37202,30336,262260,67906,103392,71939,83018,66766,116774,11297,33418,1062014,21268,3708,23263,8686,19916,9880,31920,102114,55432,5564,885794,12728,186319,7176,9796,188928,2703014,28234,7020,37762,14456,34602,10354,256987,15048,2912493,7072,14018,32968,10088,26524,56916,53444,14457,12844,43529,9417,1932696,461088,29232,8320,9108,68414,26136,14560,24332,34920,271128,8927,169594,8474,684140,598345,11455,35064,7164,77328,965808,9880,4598,9100434,15996,46228,32760,5928,12084,8690,5776,9000,2987504,13072,106652,5564,3602092,123635,235894,5460,247052,53754,13193,19646,28086,106887,745920,9546,5074,12896,59976,21684,18460,141963,71188,67526,11700,16952,12744,149872,28644,777712,120317,7540,13104,22392,14319,5700,66994,27097,89544,5977,42120,7006,6634,76464,4902,11180,93654,16416,14190,4386,5662,11352,71362,21600,16555,779730,26781,172694,4256,478503,45899,93299,5928,32452,59128,225990,216562,16678,17794,10348,36144,4068,5472,7095,11856,23305,7181,39263,76756,201514,81449,25916,19158,49348,47479,10602,6149,5054,35155,70992,19584,241552,8471,26208,117046,29625,338910,92235,4284,132096,5805,13454,7942,125517,86060,44352,61704,326244,1054614,20026,44460,25978,33583,93000,415423,36704,163176,16039,54747,410332,4142,222480,48384,402268,8772,16640,4408,14144,27492,84604,575172,494145,754992,28656,1210356,515317,58104,4142,388864,12024,10277,7828,56886,130591,13186,17316,67704,5590,149389,11137,25848,64372,9900,597528,45980,8514,80969,14326,40824,222490,11098,8476,31284,68940,973517,149358,168302,10191,100409,1756723,5668,15480,15552,126716,22199,286936,399024,20592,7912,73628,13702,14716,35774,18044,19964,6384,7124,22306,9766,29736,348074,911090,5016,20066,56327,28024,488299,8772,127111,2482046,9576,14060,142386,132440,20384,69502,4294,19552,28756,939238,218096,5564,81270,4484,424908,23700,50639,11514,6292,4256,13490,7697,17822,88198,6020,8164,5460,61857,13029,9464,12888,9548,24984,33232,1918831,18565,212668,20026,67466,4674,2289815,8927,143464,17518,9559,29488,28800,17856,110916,11309,59469,27300,131688,8213,6232,14632,101093,7338600,19584,19760,1379040,9720,33669,8987,62173,4902,117864,22747,449565,49248,186519,23832,14508,76712,13052,14256,6992,13680,23005,9114,10296,172328,47953,6552,80724,6882,6510,10640,12636,17100,74418,161120,23688,47736,60216,117648,12220,45267,8788,54036,23218,9540,41292,44640,4558,8816,4446,5700,9360,10504,5824,11180,119606,67642,167717,12888,4300,7439,39026,46728,30168,7396,2417163,104594,13468,5289,61778,830717,456404,11016,8618,5160,89156,4674,1106237,9568,25517,1094071,120776,31205,21567,9690,230601,199008,26496,633256,12532,15132,1934473,5436,60435,22489,18936,46311,6084,26273,17174,8927,7144,146415,934648,28519,26102,1520640,12090,15132,140146,23940,1001088,13825,145578,210900,38736,19476,31679,293472,20150,21576,7439,243568,10354,8476,45714,163852,42904,4680,32976,4332,11020,227240,4446,88504,25675,5200,49770,168259,9245,32550,18000,10452,75603,8008,72106,36024,46764,6042,81133,8736,37288,15265,29704,35100,509787,131021,5112,68472,15964,57252,8996,61304,5762,80848,15437,50998,56520,20748,1289160,8127,7866,14319,381900,15652,4902,298857,6232,7310,17856,61936,137088,9272,140554,8840,6450,8018,10230,45881,182806,17556,37440,7296,8611,8385,66960,15314,37604,7592,4294,41366,147146,5408,1709876,22152,289952,4515,31126,12350,5720,33480,116130,9652,46956,12400,119764,701896,1120220,4750,7562,6500,87668,293959,46500,126432,96876,25740,33332,36894,7344,198328,44333,5320,19592,14976,4644,18600,18881,8729,37754,10152,17933,47652,12083,191338,956004,89856,247884,16340,6292,9462,13268,12350,7344,153813,23036,22403,7562,7272,15336,4212,18834,8424,177630,199836,3922828,41306,186248,220884,3819510,775806,78447,9804,18644,65556,8930,133859,930620,2279545,14544,1019258,9638,6188,17050,13459,106210,124030,44763,29796,233064,7992,31668,325510,16864,149832,6912,40979,34701,14706,237711,14061,9976,7828,70520,93931,20644,28496,7920,346890,37262,26860,36146,18216,51127,21672,6726,5031,245186,25026,48060,52417,740808,7416,9462,157526,16678,745444,5246,1027710,12220,42186,7874,8736,116057,198432,180041,9620,38998,40334,7095,132192,59555,22752,63426,9648,820728,11128,32072,26676,97881,29848,8742,37368,31428,15132,24986,7384,24552,7904,11036,7596,11532,81936,151759,14322,92579,6080,31691,8164,1119588,20511,6880,10222,21070,3952,31668,30020,16827,80640,288350,7410,12771,2937062,196664,10792,72664,13114,37752,54826,16740,27432,45562,23305,15238,3636,593290,198360,47795,32976,24776,88236,24336,228888,220058,5203,15656,18616,35152,14544,30816,9256,20232,574184,9612,35280,16948,140223,5564,24192,49176,4730,4978,41572,12168,84878,5966,9766,7998,19872,32528,30744,41194,5738980,17420,689184,1516958,27072,41044,60946,6032,6262,18668,52030,7280,41600,9072,29448,26568,31205,146808,33840,69574,86060,4773,5418,6751,18506,282899,6084,11929,56412,305809,112654,13832,9976,12896,414355,6321,163846,20777,10981,49538,6020,57600,194814,12245,6650,8295,2359296,4177599,17112,50544,16616,32736,7942,5876,367744,41416,1861704,499658,138503,9672,6764,118121,68284,11532,10660,209324,352160,83886,454646,8213,507936,10106,7228,7750,12792,122450,11596,21514,52832,492881,6510,145080,131193,10112,233366,9030,11068769,28148,18228,33153,20274,57252,34424,19708,20436,10507,7611,4294,9048,34271,55142,8132,4826,74971,11532,8930,8686,59882,38952,13338,25359,108288,20232,32074,13760,6192,37525,405964,4968,9348,26350,13392,17472,18408,223886,4560,82088,72850,10452,44677,7192,12168,61146,132088,7904,15500,12772,6751,134300,36720,6194,313404,6536,35136,7316,882828,12008,234000,36348,18802,88556,2832545,8588,1082830,85557,6820,36244,187941,293485,6063,66439,10168,7488,45267,147992,168020,14756,3600,60496,32908,873496,542160,92588,133300,13888,59328,18960,13490,10728,39780,25438,4663844,222196,22464,9412,15050,71258,32616,7632,26226,7783,31464,63200,62489,15562,19500,582660,23712,142595,268632,18962,6192,40014,20016,58104,87096,19158,9417,19530,4180,10664,22534,23972,12126,21543,77862,12768,17696,21080,62640,7812,4218,11160,11395,292448,49894,14196,73948,14820,4978,9890,119908,16432,16340,12814,68328,6880,9196,7272,5547,7644,7564,8928,65728,23370,3249823,7611,199080,12586,4816,8742,45792,132088,30690,111176,2638363,716196,25284,28008,88350,18538,196352,28598,8094,42744,14508,62890,5548,19152,49296,10621,37336,30836,12688,9766,21567,11492,8680,24814,13946,5332,23976,5364,202635,24800,15010,47214,4859,202844,11248,30600,537753,81158,236220,512856,9052,153037,14668,22317,18600,30336,7124,6500,75287,108624,113839,6422,16128,11718,70942,9672,10504,51460,21744,77443,5408,224755,85083,18920,34996,675936,58136,32860,35724,144566,7852,57888,15652,3852,15624,275394,1997320,8930,81054,17732,81792,154656,10712,163787,48070,4988,42696,9245,7228,74734,41496,1202581,7068,158808,16872,4408,55588,27716,6168715,85464,7704,25978,18928,5168,47728,52000,10868,6696,4978,7560,12376,10656,9204,10602,437502,19468,7181,551973,89225,61070,122608,8532,12642,88776,63284,4284,65884,13115,10974,10707,301320,16016,5700,120652,16306,46136,6020,4940,12160,7228,1298032,8064,200660,14964,5252,9880,71653,318291,68696,6794,48585,154368,1623024,31616,10728,10621,3952,4142,8428,41791,19872,24586,171144,51584,13330,50353,36022,5772,27976,61189,5461,27413,5304,4932,19049,5130,68651,3952,25776,20304,98696,96933,113100,8352,10140,176886,147368,5547,285348,6235,175248,7776,25428,19380,6188,993852,285192,21112,12324,140144,10036,8684,41344,77672,22704,159831,376593,20224,4370,390624,8164,19684,16068,81686,7254,5700,38812,61304,27820,150495,5555359,63042,22458,40092,59882,14749,9994,23560,7740,3800,18504,17898,55584,74932,65304,64410,12040,4816,6612,12744,31916,997770,13764,146946,29716,10754,9006,3914,164448,7525,244872,9648,25048,5738,18724,4212,43608,4180,75504,44346,8385,7372,5004,297228,4788,20520,59508,242208,13728,8769,10879,4356,2513880,9804,11966,13193,88882,50778,23622,21371,201818,153381,8476,81449,9000,9672,295195,12008,11223,22152,34580,6364,118248,6923,120228,28466,8453,9796,4429,16244,14012,28028,25754,60909,3744,28440,45240,6292,176042,71574,438529,20592,12648,3708,362318,8216,8840,64543,16188,158498,13760,25840,36868,70512,14012,11088,29264,31198,30494,54126,5928,107068,13144,862358,31824,59487,25584,6136,12168,195780,1035648,22680,7848,234522,10088,17484,12312,7752,12376,168516,9300,13824,47690,6396,8742,67983,11160,352893,17064,15252,34056,16116,22444,217566,6308,62248,9424,254448,76235,4687,10920,13364,16340,22496,221676,42226,1807204,33540,2408315,15800,148994,977904,6650,8453,22444,59812,63911,14198,22831,6696,135720,173166,174384,8476,26660,40546,16112,17640,8246,21762,12502,50464,164715,15314,44802,53167,153983,46810,39816,5289,11024,7396,10192,4945,9672,8815,11160,26728,14577,16827,5891,7525,11395,37752,8611,204373,11388,19276,4824,4752,226352,114712,28860,237460,580808,12616,73530,37634,6149,5848,16727,7378,122845,161634,27838,39888,9204,8736,523296,5408,5700,9880,22392,65175,7236,16632,38055,9766,16956,28086,104000,53879,38592,36024,6240,179452,60952,10332,11514,14976,136332,7280,877176,49849,7181,6408,62963,28582,26961,17422,7488,5252,7267,10712,11218,7884,13825,6300,8208,3387308,13186,11470,10788,25482,90139,16016,33970,53768,1978056,113956,5547,602732,31824,144096,51452,11739,86989,69204,212334,9331,140620,12198,4300,66404,29326,15352,70784,7979,12220,5876,30032166,17918,133418,221364,15548,73865,74958,10726,49248,7750,132768,6751,155168,35360,17856,8632,30172,8280,47244,41808,18648,4826,128375,5980,10036,14400,14260,47902,27413,269328,57970,108224,17587,370822,25168,168910,5512,5220,17424,88846,774086,19952,90954,33264,10488,53072,2552885,8640,21166,6708,28677,13312,19916,11438,15953,185887,8632,25116,14062,8788,10633005,477672,22515,17538,24095,9322,19750,4750,45666,120328,11736,48269,101400,16598,7540,69882,1352085,117612,5408,37872,233834,5510,80064,8170,16827,28282,11524,1582920,7228,33575,66220,13000,9804,29230,24120,9120,5200,21488,15500,7228,32328,40204,6572,4558,7611,8164,34400,26307,8686,242996,28954,15010,13520,7436,5824,13946,23920,8580,91010,9538,60610,13364,78520,8856,35720,10660,40053,58500,4601,142911,61699,4066,22506,1044854,19874,23472,14062,49848,6396,11952,58222,1817902,11771,44640,9610,15028,16328,24700,13826,412982,27864,9576,479598,18648,344519,22412,169100,995400,5814,18538,8360,7852,11532,45032,13884,1775556,11856,777852,249302,7688,106468,81720,7568,50718,10062,7254,124109,13870,36328,109512,6262,6696,183528,18620,5396,45562,5016,23332,103106,8424,11780,11904,13156,4068,11960,21014,8736,486008,18644,15128,12212,3683544,7410,537984,149683,21888,43524,508752,11268,1096110,12798,7228,6232,14942,19908,4773,138961,9717,50323,12688,6330823,6448,198843,118792,64440,13728,22360,5074,8804,7900,6552,10292,95532,1364544,4816,4294,4608,5624,17860,87048,53506,8858,13803,32422,22880,7095,10726,792370,14664,60192,5616,11336,41949,17802,13746,6448,7936,6650,28203,124109,250303,45000,10512,26617,306599,16796,14872,4816,8060,6136,25560,252148,4386,16920,91846,14663,16120,4816,19592,18644,113444,19220,53998,24411,13640,53732,48934,33540,10540,7783,7138,29072,5356,68894,17716,18166,11336,40114,6794,11590,19800,27962,25284,20597,61516,12169,25560,5472,63752,5633,34684,31980,5590,67824,16182,14022,182016,15264,214406,49320,92448,11594,9568,2930368,871224,424008,7644,24192,59013,7432952,55480,46436,38220,59760,37656,9675,5472,15048,200294,7272,301731,30960,5168,5203,19908,118800,857880,34944,7783,477660,120080,11395,222552,5054,19282,3990,37999,49286,5074,299304,482790,6916,566825,287481,10602,16492,736632,58344,157508,27664,3688273,14534,8532,5289,441531,9804,322457,10744,46246,63674,51192,4988,5092,40486,7611,23940,107694,173352,8680,6708,12166,8729,39052,82584,7006,48828,514520,8127,13032,72996,23822,42480,18928,28224,6622,6500,34314,9322,32798,13746,16182,12338,4142,6422,23816,122616,62264,14782,8643,43128,11470,24480,4601,27133,11128,9648,1973088,9503,120280,12772,14457,282910,17372,57288,88846,10105,13416,100296,4730,20461,12692,43648,326088,19778,45899,82460,26312,21948,22403,5720,18792,28964,23616,4522,3398975,68472,12341,11222,5772,4978,215498,86490,32311,562875,16568,8474,5418,5590,33022,127152,9234,28458,154682,7654,96459,402480,39816,17301,22176,6572,17316,229732,69564,18476,35712,27032,6235,70735,132652,8740,16900,371108,1253063,5512,21888,7380,6882,92340,101592,7852,94326,15236,37446,5547,288113,6407,6510,9245,18354,527404,185318,95784,9204,189284,32400,53280,248248,6228,4028,8557,2650104,12240,8643,15500,166764,32414,25972,181168,15910,822888,7009,197974,78921,7644,44856,130587,671816,335118,20336,164304,28124,22824,8736,13578,8600,1907424,20938,9500,6820,6139090,30240,7956,32032,604810,10296,119808,22724,117000,140040,40820,657384,6344,118342,13717,9164,31668,49824,10640,268560,10902,162130,47736,9052,15066,4386,13904,9300,21567,99066,1122432,81700,6321,1168410,7192,79128,6536,30968,98197,1440504,37446,22120,26728,7956,21052,13082,324942,108288,143260,4902,110679,6552,9120,20708,11098,13373,36270,10584,23779,1296469,694440,10712,12456,13988,1010568,421290,79441294,14756,2472384,27170,88064,22360,4515,2110999,69125,7638,10404,309601,64896,546838,6708,7030,51557,19823,110050,7052,44304,27404,14276,4864,37683,95073,163530,7714,35932,545495,12524,10981,59803,268836,21312,33800,7800,6048,10224,473688,5762,178932,105196,295802,7482,37446,15264,12152,998675,11532,6760,4218,133036,321516,8736,141015,52200,9984,36432,136710,19708,795801,4408,537911,5980,11309,14456,37512,20596,164016,53784,138675,297830,46748,35640,88848,103806,46080,12008,518328,4712,5940,28704,45360,5700,15912,4142,69998,6321,7848,6612,14835,11455,31744,4515,20696,11008,9728,15340,200298,7783,7568,6132217,32184,33192,537844,45694,47400,16744,22536,16036,54036,21330,291668,384648,6156,17422,7740,21414,18920,284696,15912,5876,45012,4028,7592,495876,8471,4343,34504,54360,23779,44928,92606,163873,10664,17784,21204,192386,186010,9073,11825,213044,89507,219024,274680,2113704,14615,5460,8280,9374,298512,8476,10192,148614,6498,12012,15580,26918,343790,176881,522743,15238,1181998,4343,27413,98434,42581,16616,54994,6696,28423,7200,59976,7020,32448,9052,70434,1247936,4028,14652,87453,520531,11266,13490,136462,28964,9100,9288,5547,97266,178002,162184,19800,31824,137618,66384,46018,9546,5289,4902,150048,104833,96928,18705,50592,13983,12740,65175,7128,13260,23244,3800,41002,224044,10640,6622,52851,23940,7750,42192,16952,6270,133200,7740,280292,27950,5074,679572,5408,11160,10184,100804,6344,205088,9932,14400,38948,562030,7068,8436,7912,1083959,12528,7181,238817,16598,105694,7296,19840,16297,27432,68286,11880,25480,24095,34918,6084,25596,12480,20336,35150,8184,173414,11036,57668,7611,8295,4826,20384,24490,14457,25628,3744,150746,11804,7006,51272,17004,75582,7254,513648,1116648,16770,4294,6136,7258,6235,27248,8632,5824,16058,3960,1591218,118637,17775,10664,6321,191180,50482,13908,33180,11160,14760,41949,1846728,180471,22568,8164,124141,14248,7009,41496,11232,108376,11856,60788,16182,290404,139514,8342,43258,10036,9417,35048,32968,7106,8816,14402,8295,19448,34013,29111,3708,100812,9504,26820,100254,19344,17980,162898,1382500,9920,10191,9159,14147,29070,87360,18096,38190,225288,10192,18288,15132,34944,756288,145813,14508,96965,66024,400536,3057458,13566,16740,142832,1267160,35076,8280,84630,13566,13832,7006,323020,76320,5824,23296,10428,5396,26832,9158,4644,39259,6344,61332,75680,51168,11648,63812,50184,141252,5976,90060,10965,12298,14364,11324,16068,31692,6820,301392,21892,167152,534909,14190,31949,18980,43416,47736,16588,160848,455830,4284,201292,34523,4636,27612,7410,12064,7258,9396,71760,12956,12586,8840,6656,33927,5848,598680,7267,25929,7776,36335,48633,9796,22608,94612,4356,15084,15066,12672,10912,4386,7068,14061,52061,41904,55536,14688,61566,163990,21944,6346,189679,21199,7750,6500,15484,24048,21008,23746,8060,16068,9310,7344,56406,18042,127452,52456,8892,56011,72384,7783,8112,92752,11856,8122,9256,145018,9724,13717,25359,20072,22356,32916,10816,12648,10320,53924,7052,8476,4028,153698,90864,61940,16530,28830,5246,1145264,7638,368136,9858,26496,118658,18354,12116,93496,138320,5358,10449,6156,11160,21973,5246,7900,50402,52632,7912,6688,7224,19952,11440,7192,6708,22648,12688,5668,124558,9982,4945,14534,5719,260463,142792,26226,9761,18328,6422,298699,22672,768196,548018,15428,4370,623626,37804,23091,6864,26752,774832,164808,5580,20770,69472,26220,180594,4730,113688,84778,9164,8804,5320,144096,4484,5168,45899,27056,31200,4392,729926,21758,200148,235578,4066,34959,17980,53009,10222,247832,7488,25201,10764,186835,15624,33356,18936,149530,21024,8060,20020,71712,20770,14694,6760,8804,19221,6364,5891,4978,14773,6708,13201,34352,58460,4472,23750,8424,10707,7740,76880,10008,100316,30456,6510,22230,8968,23370,9462,4864,13716,25929,44793,10296,21660,133194,33170,292932,6622,8213,17264,5522495,9082,7696,6802,408408,9880,7812,14424926,22962,63468,10836,10621,4515,37625,5203,20520,194016,92820,5891,209592,27792,11160,255012,140936,261288,7332,9159,2011606,18216,6968,72000,39895,22059,5418,17524,12403,546285,4636,8702,57660,11388,16524,10036,25840,6020,14061,34839,34164,15089,21251,10664,12948,68888,74464,74256,6020,1200610,27588,26208,108072,8208,3838,4392,80166,96854,844116,4515,3914,2156622,9234,29202,17696,4822192,592658,55252,201025,22536,4945,12728,5564,7176,42441,67680,68688,8436,7688,2529332,10726,14319,26187,56544,150722,19296,4773,38552,63216,31777,94815,42423,40176,26936,109944,7124,87420,11210,7750,432388,24814,114471,34892,7936,52820,840244,10234,13752,56592,13104,68744,7992,8028,150258,4644,10972,5246,86900,121148,2379480,7596,561168,189384,77184,5564,7296,22962,11966,7848,13020,36952,54028,67467,1160068,851067,6032,4300,25992,93444,35787,6240,247379,144017,19158,11096,21930,370584,8736,10270,38502,29025,57828,22831,59598,4932602,17748,43443285,12879136,10244,11932,6660,7904,8804,5738,65592,594828,10665,127920,62135,4066,26536,52488,6278,7254,146984,11908,4484,28849220,14942,404673,230308,70122,88660,324636,4484,7192,407482,83460,427492,9847,18824,36103,10440,21027,128217,30108,18104,6321,12920,73568,3497330,24076,105958,5719,46452,9412,12896,7502,83700,11718,6916,24336,19220,4859,11284,12578,57196,165110,12312,115498,16416,36498,8322,16254,8944,17243,16430,390139,4978,17108,9396,36898,23088,4104287,129636,127660,3888,16200,75578,24016,32798,15236,83187,19342,9374,13896,332272,5772,27612,640646,13968,62662,22464,5460,537437,233116,665575,40896,53424,6880,6032,7072,8060,5074,108864,988011,17546,34286,170976,10140,5206,59171,115752,29760,17056,15953,17420,430160,78572,31648,42269,94800,5016,64440,7776,8471,67580,460728,75384,44826,746313,80659,5977,34997,13984,3952,190368,28386,11248,19038,10374,333301,13459,9880,21584,17316,12708,18228,83876,18275,22940,16920,31096,5358,11492,30324,60822,22968,5054,270180,10974,5720,15910,17280,48906,1042964,109951,1067454,4066,783432,54548,9234,23126,6760,23328,12768,5220,17280,422097,8740,10965,8164,6120,11180,10621,17974,1597459,1465213,14632,3714580,16353,5356,6200,4978,8680,14292,1366092,8690,90720,20520,15810,184544,39618,8928,68098,1280088,394108,12806,20522,11137,46768,37200,3876,446982,7564,20634,15124,69746,253270,90472,9656686,10788,45648,17836,7920,403295,26846,28334,16120,14260,7436,37224,21801,120270,6579752,255291,30286,8512,23712,27968,14782,12341,42718,4712,26784,7524,1567296,12578,16112,379756,4752,7697,16796,47601,5928,12642,22692,48152,87984,6292,76000,13035,26728,65728,4636,222859,9672,29016,8184,4601,4386,4945,52018,53799,7334,15392,6020,12169,7912,83029,253448,6820,194814,19188,19228,65145,83503,10412,5031,13826,2510820,301378,204594,10578,7502,8557,28086,6136,90432,37152,4750,21008,10728,18848,7752,64464,29484,7224,9880,16125,149864,858676,34808,9464,231480,8375422,98857,8424,104359,4522,81468,233616,35880,877982,106912,24118,5928,5356,3838,17538,16306,345228,25416,10044,41688,327218,15192,5876,16211,15089,8213,9196,23134,279032,47842,7396,14632,16856,11818,40560,8928,5865964,30420,61560,20808363,387810,75354,33022,15192,791440,5252,10556,6948,6992,22176,56160,116525,522106,5966,77710,451440,51532,18460,541060,226486,116784,26928,4636,1082520,1239431,13312,16368,12692,35030,7697,85699,6764,16432,11376,94213,442479,67639,70566,24490,11534,244556,15089,5203,16430,13578,52824,2512753,398634,8640,9464,527592,15444,36214,26970,7688,11346,4343,6188,403992,8474,19909,22420,114088,8990,7448,361741,33912,16802,213221,22680,5246,30616,5004,8680,23712,79236,10088,328290,11266,70784,4332,6407,16848,4104,32250,14478,23760,9766,6820,17484,7488,856755,13268,16128,6386,7812,342237,4248,13604,17316,133984,1571184,3839400,7697,5720,2716336,70308,16988,9724,13728,505293,27280,11395,30020,13846,21886,199004,98671,79790,65782,5200,7436,15562,8213,102410,146604,8626,21962,91640,38947,14931,731724,51116,8712,117390,44824,16748,456878,43416,7482,27404,809782,39990,531179,139032,27097,12236,8060,26860,17918,122360,27288,32469,84846,15093,12600,6106,8018,364032,35048,23446,73512,27664,94326,750184,5460,5396,13676,10793,29698,89139,17544,301948,9116,34444,6802,21112,6235,5200,19276,8164,32328,5418,9792,34038,24840,7488,21762,11218,15548,11196,54481,12272,5396,170810,12744,15563,117312,20708,9432,9044,8568,74261,1569113,79636,41396,5848,38880,33604,10584,10512,59272,11596,17856,37758,9417,5054,9842,109800,16632,6966,8580,259992,6552,18565,14612,21164,6300,17222,16678,435240,341833,18126,16150,9331,100434,5814,8580,75516,28028,168646,6536,6916,10792,7998,23312,7440,8740,112812,10192,20556353,19264,64543,9656712,13248,295568,16985,7904,8840,21584,12599,3522294,54872,7006,5510,21142,59020,7654,21840,7254,14536,24244,184202,44635,122335,30336,48348,322582,11656,11718,18662,56576,8684,22878,7626,42532,135876,163080,12956,6240,25585,63270,68241,8729,24614,262446,6708,34788,22828,22199,11954,9030,121432,1490572,4712,5203,6948,27735,13702,9920,44240,11076,89784,148986,76536,9568,26040,8643,122976,10062,3952,26101,5504,63550,275157,4515,26149,85320,9460,288143,2858324,423398,24016,6572,31558,232066,314352,64656,116604,14664,38844,768018,886143,10868,18476,8041,7228,19292,11997,798424,1494578,34782,15996,70742,11804,92983,29941,401241,16378,10140,14835,11596,753186,64220,1612627,14924,8216,30744,13545,7224,20145,11008,27300,10868,6232,23180,190706,40248,21725,17236,61857,18360,8060,10440,27792,4218,9994,11438,18430,26638,210930,48724,101136,40796,14554,5168,8848,7144,36577,20808,17458,18000,75960,367564,41882,37656,23472,5332,7181,333372,31521,279792,48724,5203,14835,7384,8632,1118000,11098,5289,15824,14012,11336,39744,23296,27248,81406,6794,21700,427320,21172,12648,4370,11058,80422,71337,7688,14400,142012,16195,123552,54720,23126,22754,332444,33904,26156,54560,32414,11139,39600,7568,18146,175392,47637,68651,166656,44044,61814,14782,10816,60610,6916,9559,13884,31752,14174,5590,13764,7955,97774,19512,3012665,6240,575989,19866,31720,138456,14536,4826,19264,11868,22968,8788,19750,62282,193544,90396,12341,8600,1925368,273208,10296,7228,4429,57722,860705,35092,4644,6665,4598,6794,11052,128098,524016,5356,34224,9362,4940,23580,8600,9576,21508,29016,7568,1153242,12640,68848,170877,31519,66774,6235,57164,90688,59400,128217,246844,34736,10507,22320,13680,58102,9362,125316,291668,10540,7654,63468,12152,15168,116920,5548,166611,9864,7776,235973,48152,110983,7688,5805,695952,24552,114076,255456,14144,82512,15912,463268,139384,393696,9792,164424,8432,8008,5719,66123,87880,1570441,214458,30816,375092,592105,10526,3924,967104,70128,12958,9589,5092,250900,92588,45741,150822,53072,50052,163956,12771,7502,2078024,15028,6732,7956,15964,18616,80352,10354,13780,3453959,13020,6063,1255176,10621,19656,34884,4687,13680,677730,6878,49880,13114,230412,29450,17928,8494,6156,16948,265124,44454,26312,561279,36792,61828,25359,8424,5460,63516,5616,31248,9360,16692,54696,1614548,5928,18000,33402,17888,37130,52772,227664,8018,112812,12948,4750,58867,7525,114504,36608,6552,20824,630894,14749,11024,4940,8640,28656,50592,16813,35412,264168,12376,11613,291408,7956,675614,3990,215928,422650,428792,106578,11160,9216,14612,10260,10602,408667,191575,20253,68019,67166,33418,5633,148738,11739,13932,29108,75998,34596,64666,704520,4386,296092,73075,164320,28122,7592,737781,6422,15314,6916,10507,6032,7439,50353,43896,8712,14706,472750,198120,6084,20488,209664,4068,802152,14074,5200,7626,13984,155472,14716,9288,10400,5117,55728,1215084,30992,7488,13082,596068,45448,6192,87152,13824,469339,13490,8208,134106,40144,4636,10586,397277,6552,469023,99386,47272,24885,290108,6278,34830,8690,321152,1529320,27072,3587688,34560,7704,6278,4902,482804,122512,7416,32178,5876,10140,6188,82440,106742,14706,9486,8580,8928,18772,29541,35424,161856,451152,7688,5633,574824,15010,4370,14322,10044,28548,7280,52920,9243,7138,257688,5160,527325,121024,10192,38157,35733,4644,22278,16416,25776,223820,570960,1386529,197972,7482,4300,60268,2610530,6878,4256,5928,9724,185115,49059,30780,60912,14248,43628,298566,18791,17160,35836,25110,6665,199001,14260,67104,8360,24209,17680,6235,8424,315456,46696,5616,25596,121660,13260,33552,431972,75140,36784,10088,7138,23250,10707,25201,26939,15010,12428,11596,4558,3990,18202,31104,21926,6820,2050445,12384,198606,8170,9158,76128,31248,6622,5624,7592,4968,117990,1425424,33101,5586,36576,23674,6292,70618,77976,44252,76669,14760,97696,17424,239295,7812,128180,5356,7488,690934,19654,32760,40536,16172,11782,52056,36244,5548,25194,14092,15696,9272,4988,50902,1291264,14276,17050,18290,17759,8352,12958,11481,1055440,107045,5200,16120,84882,7884,17372,16848,5375,5852,8094,107414,8550,25069,158711,9073,102960,5472,18723,312129,811014,417487,32860,9516,45942,13459,4256,15721,77748,11268,51840,12168,35402,12996,294851,4408,250667,12168,3838,81096,14457,10974,312481,40280,11309,8164,45012,78289,29484,4028,25740,198273,73216,555449,63612,5092,49348,8216,21964,88288,7344,4343,5512,33812,28340,1070888,24388,13373,142200,63437,21199,12744,542098,18275,24624,11088,226670,38750,8901,251299,34944,926484,30566,61152,9417,9048,27648,609768,15066,61048,5934,21166,4773,12513,85241,76700,6063,114638,1127883,112892,333640,53320,122044,17286,27056,12806,9256,16454,58344,6840,7874,5652,12084,415079,424574,23296,12480,102297,96668,13148,235657,57433,7334,21672,4370,4066,35948,388296,7920,49063,51116,7006,695968,8132,218088,12958,26445,4750,12400,1016280,2434104,42470,12502,162316,2064608,29625,32968,9256,5436,41791,25413,38088,2494346,323280,31564,7783,11058,33101,6084,10412,6688,70866,7717724,936944,12083,81528,17587,58368,18920,28124,1081184,9202,2223218,6136,33259,6812,8901,28912,6262,1268208,28830,6324,6324,7396,5244,43416,320952,107224,5246,11139,161772,8840,1886544,492404,110448,4515,4256,425258,5547,4945,20296,5160,6726,67704,71796,35774,285758,17264,6536,139356,11160,5117,55771,150021,12960,187467,5504,32034,600795,8626,10972,7332,86903,6448,41882,308396,10191,15264,97344,120317,19307,9516,20664,4370,13452,11804,179409,9331,61978,55063,324360,9331,7228,9796,15376,122766,122450,23392,21508,7634060,13201,139277,116288,8112,23504,7998,12943,7564,6923,19479,7956,5112,7626,675800,14074,13578,7525,64232,5016,80422,140146,53246,12986,19512,10152,8028,53167,9424,39960,11856,124920,8424,38952,21024,452876,79050,14760,7448,9216,32656,19152,871607,55728,33046,480624,19188,10222,19396,5282,152134,840086,17222,16120,23435,11440,155808,12040,256824,35561,6136,31758,1131552,54352,20640,15394,5130,5824,54264,23036,240002,8854,17992,39579,456699,25280,15168,149081,552064,32078,11514,198328,28124,16900,10404,76456,8496,9216,7332,8901,35561,59688,124583,19080,12168,6236464,832581,8496,19434,115111,18538,165416,6634,24490,6634,10070,56340,11058,30992,131298,13788,14384,472812,382123,45425,6579,840718,17062,6665,20210,25896,6916,45408,12556,9204,42739,51858,14400,437684,39494,13624,93783,7353,4826,29536,6696,6063,20708,193180,159264,13110,17174,63792,267264,192608,84538,1094178,8060,24966,16380,47994,28132,7869,335671,12920,33356,25064,7334,6760,197856,4598,68335,14896,7332,3952,10296,207762,7488,15438,15808,6552,7267,99424,136276,22464,87768,9976,11594,216697,37281,15652,102068,14688,4940,35256,66716,3914,4940,5289,6840,17174,15484,7644,95666,107440,30058,20640,5616,17538,8320,10707,27334,108432,5772,4180,3914,24624,5356,43524,40320,11932,79128,6536,11692,720502,31564,110542,23384,12502,105552,11324,156302,4534958,35672,485857,10902,11952,42581,51398,9776,36034,5738,10292,462528,38532,19656,79128,6923,20448,75096,51794,48980,56373,202802,4730,28086,13588,133510,14300,5252,311240,13794,4142,5289,64030,278720,11060,29068,5676,32379,425010,15089,126953,1689128,19604,6760,16328,14362,6408,42120,16328,118924,46689,6278,43316,378138,8816,8385,8374,4644,54684,50869,7144,4218,10902,10152,44268,121520,636272,10348,4212,13832,26496,112902,7980,13728,776644,62568,21328,69230,4515,56674,9048,2339585,9516,8784,12312,15336,13020,16560,10416,17784,10836,638058,56760,15192,6396,9308,24467,55728,582941,8742,7676,17160,20212,11567,30780,110032,7956,8060,155272,170196,91246,19592,26574,2004187,421860,10449,14760,18662,250704,59436,82947,9085,45583,7448,28272,4142,309776,210444,76235,34128,44714,7776,445176,402628,35776,15704,32153,56012,5928,198290,10270,3672,28768,62816,2098443,21576,7800,13764,8094,7998,278080,7904,22204,48484,19513,70876,537887,28810,62186,86040,8058,9116,12900,8892,13144,20232,30312,49928,5396,370352,19522,841745,5934,4142,4560,19872,7009,5054,8360,14184,13728,406348,10191,36332,110304,221052,12087,24054,2762946,4788,13644,17174,7482,9464,10044,6968,130884,23978,29172,5805,44136,6292,3708,71592,304200,32500,187302,109415,6760,66464,7384,8041,158474,115596,9724,117360,7740,4386,86490,93931,190112,10504,9072,15998,224992,8600,47874,10868,11076,42978,1014676,20336,8136,122845,30968,146232,25848,19292,89642,31600,16016,11088,7688,20336,8428,7095,15768,6200,106255,9073,4472,9890,19393,29952,12524,22356,35308,19866,21488,738966,16802,240864,17759,13224,20708,45074,4212,9300,21096,16056,436321,9030,4472,3566850,28598,13104,37969,7600,146940,6080,81432,102672,35392,59830,49770,650547,13320,17222,6536,62252,5616,139464,23908,7564,13156,5966,4320,1039464,84940,16469,93384,18619,48960,4601,50046,21164,6194,13870,7410,74304,6820,5160,10296,12524,14260,23746,16536,337156,18506,10764,194145,7696,7956,49680,9828,104036,5719,6574,12376,17420,6656,18318,248534,5662,4028,7852,28954,11908,41236,11232,55536,9401,13825,6080,9460,16416,8626,68944,8740,361267,8856,14136,6188,26149,29016,7750,27477,6344336,8928,4464,4522,13373,27056,42104,62479,18166,5117,6966,15964,1188606,6188,10726,39246,64414,31521,6864,9052,818763,26714,20461,1618993,5289,5676,11970,19080,2358876,70704,13052,71208,77584,25542,14744,53618,11139,17160,9648,13825,28210,21251,28203,5934,85952,12338,71574,5966,9386,43632,181896,5876,12462,80580,15562,13676,4028,913951,117473,7378,7254,4644,6396,6579,27512,16536,8170,1452204,8372,10492,812520,712975,11232,19096,8432,18724,39780,9546,28656,44424,9548,187426,6321,8664,5876,9308,15405,131254,2437034,15652,6448,23112,8476,159912,120120,15028,5548,7200,166152,116762,16391374,16616,12168,5891,7848,110916,7378,363320,56628,45537,59706,141768,307942,5547,2630700,10823,54622,38916,32240,478345,15132,6882,18810,222227,5668,9620,903997,18091,82713,5928,238248,77634,12896,2306484,6240,5460,6510,4408,4104,14668,17422,34918,19912,44578,340318,10478,47400,46136,22776,25628,22360,9880,23244,34162,2303238,19656,83898,267592,190008,91846,118800,7998,56169,9717,3852,3708,460917,1268856,6660,12688,493064,20862,37584,1157587,10764,118248,13208,9006,7176,16039,62496,38829,32184,4066,13330,5772,293169,893234,5112,8772,1062234,12814,625352,919274,113088,44556,22436,12719,368037,7440,30336,10478,2106326,1039561,28196,68112,165663,57350,28519,29704,365456,130910,39658,6032,291826,16692,1204412,400214,105768,49665,19722,44763,4066,15428,185966,86268,421496,17856,103329,218808,95202,5206,7904,40166,33748,8122,25438,61017,20736,722736,9933,342409,4560,12240,124682,22256,72842,12245,130312,67464,244110,44793,32627,23932,21488,5772,10452,13832,234422,8686,7848,72360,100152,91728,20376,10750,46624,18936,17212,32798,12255,10406,34996,7130,7675506,12502,459000,48111,4294,19522,20683,7280,20952,374539,18565,9503,118512,15552,4773,21844,9030,34048,15496,69757,10922,10902,17280,1191636,4687,5160,53878,4859,49849,34684,16432,49400,11180,82646,6758,40053,13752,9620,18490,64368,9159,7410,49770,218178,10080,210485,5418,8632,14554,42294,4142,9672,79116,8996,55214,252864,11696,37446,24130,550368,10906,18876,29625],\"yaxis\":\"y\",\"type\":\"scattergl\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"required_age\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"estimated_sells\"},\"type\":\"log\"},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('b87424db-deee-485d-ace4-0f920cdf2186');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se puede observar que existe una diferencia entre las ventas estimadas de acuerdo a la edad mínima. Aunque la diferencia entre las ventas de los juegos sin restricción de edad s¿y los que exigen +18 no es apreciable, se cree que al utilizar esta variable junto a otras puede ayudar a estimar la cantidad de ventas."
      ],
      "metadata": {
        "id": "yBVv7dIH7gE8"
      },
      "id": "yBVv7dIH7gE8"
    },
    {
      "cell_type": "code",
      "source": [
        "from plotly.io import write_image\n",
        "fig = px.scatter(df_train, y=\"estimated_sells\", x=\"achievements\", log_y=True, log_x=True, title=\"Scatter plot: estimated_sells vs achievements\")\n",
        "fig.show()\n",
        "fig.write_image(\"achievements_sells.png\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "de3OhUiyh81P",
        "outputId": "d7b56779-c5f1-4d5e-8840-9df7b592ce76"
      },
      "id": "de3OhUiyh81P",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.16.1.min.js\"></script>                <div id=\"2ff7d219-cab0-4ce4-8190-d86a5c9f3b27\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"2ff7d219-cab0-4ce4-8190-d86a5c9f3b27\")) {                    Plotly.newPlot(                        \"2ff7d219-cab0-4ce4-8190-d86a5c9f3b27\",                        [{\"hovertemplate\":\"achievements=%{x}<br>estimated_sells=%{y}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"\",\"showlegend\":false,\"x\":[23,53,19,121,7,0,0,5,24,87,0,25,0,0,48,96,14,0,26,15,24,0,38,78,17,45,15,15,84,0,21,30,64,16,0,22,0,0,26,22,0,16,103,20,0,27,15,37,21,0,42,22,58,55,0,43,17,16,12,25,0,48,0,0,0,67,8,11,27,13,24,25,11,0,0,25,7,70,15,10,97,34,0,57,22,1,19,38,39,38,0,0,25,46,60,0,0,15,0,25,24,32,0,0,20,90,10,294,12,5,12,0,21,13,118,32,25,0,0,18,16,29,24,36,39,63,28,0,50,22,33,33,0,12,44,6,15,51,8,44,16,47,45,0,35,70,23,15,50,22,60,0,0,16,30,52,0,68,0,50,39,10,39,17,48,0,23,0,9,50,27,12,294,50,0,24,0,24,7,11,1,11,0,0,36,6,13,0,20,0,60,36,133,33,17,47,0,0,0,11,16,31,14,20,133,709,412,0,22,10,0,45,55,35,20,12,4,45,88,0,9,32,0,0,0,48,4,21,30,51,0,7,0,164,10,14,8,0,16,19,0,1317,53,8,0,0,27,15,0,16,7,55,13,14,0,0,20,0,48,0,83,52,2,21,0,58,0,0,25,23,0,7,117,0,85,15,1,0,36,13,0,28,0,30,59,0,0,66,10,17,32,0,12,0,32,46,30,0,50,45,0,19,0,0,0,35,32,0,322,0,0,0,0,0,55,50,25,66,47,0,21,5,30,16,20,43,6,20,0,0,52,0,0,48,11,55,0,28,26,68,11,0,33,0,45,0,0,21,46,10,0,83,13,118,44,0,27,25,0,59,12,0,0,0,18,0,14,0,0,37,60,0,28,14,0,11,0,0,27,19,19,32,7,73,99,14,0,0,0,25,127,27,18,0,0,12,12,34,33,68,0,54,0,0,58,20,65,0,0,18,0,0,139,27,0,0,18,19,30,0,57,0,31,0,9,4,25,0,19,29,50,30,22,104,17,30,47,27,19,48,0,55,0,8,42,0,0,14,0,45,0,10,4,0,0,40,60,0,49,20,0,27,0,50,15,0,0,0,20,64,14,12,0,0,13,3,0,7,30,13,10,39,39,0,0,33,8,20,0,71,57,105,0,62,14,0,22,0,7,4,47,14,51,8,25,0,0,16,52,14,0,30,33,60,12,0,43,15,42,23,0,0,8,20,0,20,0,0,10,12,265,9,0,0,7,20,10,29,4,0,0,81,3006,0,38,0,0,0,28,43,85,18,80,0,23,56,35,14,0,12,29,0,90,0,500,0,0,16,33,32,0,20,0,26,19,0,0,9,23,0,47,143,0,23,9,0,0,72,17,0,12,0,0,0,23,103,12,67,40,15,19,31,0,15,0,12,0,0,0,51,31,43,0,37,0,0,29,9,69,30,0,0,19,4,0,0,0,46,51,58,54,30,0,0,52,50,0,45,175,5,27,0,602,20,14,7,41,0,54,71,21,0,26,11,11,0,29,0,0,0,0,0,0,0,0,0,53,41,0,0,0,0,0,0,11,32,43,30,1,13,0,15,0,0,0,0,67,4,39,55,39,0,17,0,30,35,24,15,6,13,0,20,0,30,13,10,35,70,12,40,0,0,49,21,37,37,0,51,13,0,40,0,15,50,14,31,0,8,86,29,22,42,0,0,0,25,128,37,0,22,0,0,285,9,10,0,0,60,50,0,18,0,11,0,13,56,18,16,39,0,30,0,16,55,125,30,25,28,0,0,0,13,82,0,0,16,23,19,0,29,0,55,80,0,0,0,31,11,0,0,60,0,30,12,0,0,20,37,0,35,26,12,21,17,14,30,0,15,30,0,1448,28,0,37,23,0,30,129,27,0,20,20,38,0,26,0,50,0,3,71,30,0,0,13,0,0,49,13,43,25,0,0,0,0,6,25,77,0,15,0,29,53,0,0,0,0,21,16,0,28,29,80,10,25,8,0,0,20,47,58,25,100,49,0,51,7,19,30,6,0,9,0,23,0,40,40,25,0,20,0,69,38,11,41,0,10,41,14,27,0,20,42,8,0,36,28,15,8,0,10,61,0,14,18,40,0,0,59,14,202,31,31,55,20,0,15,0,0,0,0,0,27,0,64,12,0,12,26,38,82,8,42,25,32,21,16,0,54,0,55,8,0,0,0,500,100,21,43,29,16,0,7,0,0,0,0,31,0,0,16,28,0,12,16,0,5,0,124,29,28,38,0,0,33,5,80,19,22,0,0,0,0,0,12,40,27,66,86,42,23,63,0,16,34,6,114,17,0,35,232,71,35,68,50,75,16,68,13,25,17,20,58,32,23,0,40,0,0,38,1,0,0,14,224,37,66,51,44,16,38,0,0,19,60,39,0,30,0,10,0,13,0,22,9,18,0,65,0,30,20,0,9,0,30,29,0,16,0,38,11,21,63,25,0,30,0,17,26,0,38,0,0,4,10,21,14,12,14,0,0,9,0,55,22,9,11,0,21,28,0,42,12,52,34,19,39,36,0,0,0,12,0,16,10,0,18,8,3,179,51,7,18,40,0,58,60,15,590,40,150,16,0,21,129,11,26,18,17,10,1,0,81,0,15,12,24,34,8,0,70,0,59,107,8,11,0,37,54,256,47,0,0,19,80,26,0,1,13,0,18,7,36,6,0,74,0,9,0,82,27,0,0,0,25,0,41,9,47,93,4,100,15,0,99,60,32,0,0,0,6,0,65,61,63,0,97,0,12,11,12,0,27,17,47,23,10,0,53,0,82,50,0,0,27,77,0,9,0,57,31,0,30,0,28,58,48,0,31,17,1,33,22,10,0,45,8,47,20,0,16,0,0,0,0,0,5000,30,14,46,1,35,0,17,0,6,28,22,20,50,48,0,38,0,0,13,22,0,59,39,0,48,7,16,47,35,29,16,0,42,15,104,70,5,0,13,5,0,0,0,0,17,0,59,84,0,28,0,1,13,14,11,13,35,0,18,7,0,9,48,30,0,0,0,52,37,26,0,0,16,24,608,58,10,53,72,6,27,77,0,0,30,9,20,0,8,12,15,18,18,0,403,20,45,54,43,64,11,12,21,17,45,0,4,5,16,3,0,1,0,25,0,0,19,0,76,49,23,22,8,60,0,13,2,28,13,10,0,13,44,0,1746,0,2306,56,50,13,0,50,12,17,141,0,0,0,30,34,58,12,480,20,0,0,32,0,26,0,0,0,24,51,86,16,0,19,0,34,37,33,0,15,47,27,12,17,19,1,13,73,12,0,9,5,35,40,33,52,0,23,0,32,18,50,50,9,0,35,78,40,0,0,38,18,15,12,26,37,32,11,0,12,0,0,3,22,6,0,0,17,0,0,7,0,47,41,44,27,42,50,14,21,0,31,32,0,17,16,26,51,32,56,77,0,0,0,0,28,0,31,16,11,40,20,0,39,38,123,0,1,18,0,0,0,10,0,76,0,0,51,20,0,41,30,36,16,46,7,222,0,31,0,13,80,23,0,0,188,9,12,0,0,0,43,0,0,0,88,20,32,29,0,36,0,0,7,32,32,50,41,20,4,0,0,0,0,7,35,15,45,45,2448,12,0,10,24,0,10,0,34,19,29,0,0,0,100,0,0,0,0,0,49,33,0,208,0,3,24,50,68,0,59,0,0,0,33,37,25,0,55,49,0,59,27,0,0,0,0,20,0,0,0,0,0,21,0,125,106,0,20,15,0,0,18,60,15,52,0,0,0,31,0,0,30,0,0,4,0,34,12,0,35,61,15,0,0,28,0,0,60,3,21,0,0,0,47,48,0,0,165,20,17,0,38,13,0,30,12,0,42,21,18,0,14,13,0,27,23,30,21,32,0,31,11,88,0,45,0,74,0,50,36,14,19,28,12,0,0,0,35,0,18,45,13,0,9,0,0,0,0,41,0,0,0,16,15,3,0,0,0,0,17,0,52,92,0,46,23,10,0,0,23,0,0,31,19,35,0,12,14,46,0,38,15,33,8,0,0,18,98,0,0,8,52,5,8,0,16,9,13,0,53,6,0,43,0,10,17,12,0,33,8,19,0,35,0,18,0,115,0,20,15,0,24,17,0,0,0,0,33,33,26,0,15,64,0,13,21,75,30,0,0,38,34,482,29,40,40,37,46,86,131,41,21,12,0,85,22,0,0,32,45,63,10,25,0,0,0,109,35,37,55,52,236,37,0,0,11,0,72,0,37,0,0,20,50,0,0,36,21,29,60,20,4,105,39,46,0,28,0,22,46,21,54,0,0,0,0,4,4094,44,0,0,50,0,16,0,31,14,73,13,0,0,70,0,20,0,0,16,52,36,22,15,88,77,12,44,23,0,19,14,20,20,14,14,1,13,26,30,9,140,13,0,0,24,23,20,0,63,18,64,0,20,0,43,103,13,38,60,34,0,11,25,0,0,0,14,50,0,0,18,23,39,0,73,10,0,0,0,21,38,0,12,8,10,0,1,14,74,20,15,57,0,0,13,0,33,0,0,12,6,24,12,38,21,0,0,34,30,0,46,22,29,0,9,0,9,0,0,14,30,22,20,14,0,43,25,0,0,85,24,0,73,0,17,0,0,37,0,24,30,0,18,35,0,16,34,98,16,69,12,43,4,0,0,48,0,20,19,20,30,75,15,0,25,15,50,9,0,0,222,0,49,0,12,34,31,64,150,15,12,20,18,33,0,8,0,23,185,37,198,33,0,0,60,20,20,0,10,1,28,29,14,5,0,65,0,0,17,0,101,14,0,0,0,47,0,25,0,17,0,0,48,0,56,22,0,11,40,0,13,5,41,0,33,40,30,4,0,64,0,41,9,58,10,33,0,0,62,32,17,0,14,40,8,0,48,21,0,45,46,0,41,39,0,0,16,17,0,24,76,0,0,18,0,0,1,1,172,10,24,35,0,0,45,6,50,20,13,0,20,0,29,8,26,15,0,14,48,10,0,0,44,180,0,16,0,526,27,9,8,20,20,4,12,61,50,61,15,160,70,247,28,0,47,0,37,25,0,32,0,10,9,0,995,18,20,0,29,0,0,20,0,0,35,40,56,41,11,0,8,15,0,69,38,15,20,15,21,0,46,0,4,42,48,998,0,11,29,21,0,20,26,0,16,0,13,0,61,33,16,12,0,8,220,18,35,12,1043,0,0,0,70,30,101,56,14,0,0,0,48,12,31,19,49,12,8,27,5,0,0,0,41,0,57,0,19,14,52,0,0,85,21,17,0,20,14,30,0,0,1,40,105,0,72,33,26,0,8,12,8,32,0,12,650,45,0,26,0,19,29,25,15,0,115,0,134,0,0,15,14,0,2880,72,0,0,27,0,29,0,7,0,49,0,0,40,5,22,0,49,0,43,54,26,0,0,0,5000,0,0,0,13,0,6,36,8,22,50,17,100,27,13,0,6,0,39,70,0,0,0,0,0,32,36,29,0,0,10,0,48,12,22,21,31,66,5,34,0,50,3000,0,10,41,0,25,28,0,0,26,187,51,19,29,48,22,23,27,27,12,0,0,12,12,0,36,60,32,9,60,32,20,19,0,38,0,24,64,37,26,0,20,0,60,0,0,22,21,127,0,44,17,5,0,0,31,0,9,30,0,36,26,24,0,12,84,0,62,36,18,9,25,0,17,100,0,0,0,0,38,10,0,35,0,0,175,65,81,39,0,2,14,12,50,0,43,26,19,27,50,39,31,39,50,67,6,15,0,42,41,50,30,28,19,32,0,4,50,88,4,17,6,23,0,7,0,20,1,0,159,46,36,21,0,12,40,23,43,88,0,0,50,21,37,0,0,43,69,12,490,0,0,32,0,20,18,19,13,15,49,0,241,78,0,0,257,0,29,0,36,11,0,31,17,0,70,15,52,75,50,136,0,0,12,20,11,10,39,58,0,38,11,8,0,130,81,0,23,40,15,14,240,44,8,21,0,16,0,0,34,0,56,0,38,57,0,67,0,0,0,95,0,0,30,22,13,50,46,95,0,0,0,50,27,32,0,23,0,0,30,14,0,45,21,84,14,20,50,0,14,0,0,28,27,12,12,0,0,31,41,49,0,22,16,70,120,0,38,35,0,4,74,31,36,20,51,6,0,252,64,0,191,39,64,0,0,0,0,13,0,11,0,0,5,0,54,0,0,12,56,52,26,0,13,53,47,0,5,26,20,206,0,42,0,40,3,57,46,0,17,52,0,7,47,23,0,46,45,0,0,0,0,19,46,0,0,13,23,0,34,35,18,48,12,53,28,0,0,19,0,79,24,44,5000,11,35,35,106,9,35,49,25,48,0,44,41,27,3,11,25,0,12,1,16,6,91,57,0,0,12,10,0,1,49,68,51,0,0,0,22,26,62,27,19,0,15,39,57,17,0,35,24,0,0,20,0,23,0,12,12,13,44,15,72,15,16,19,20,100,32,12,54,10,50,0,0,12,0,26,84,34,0,0,34,45,13,0,35,6,0,0,0,47,0,0,0,7,8,35,35,42,0,0,12,18,50,9,29,16,17,25,12,0,0,51,0,96,6,3,7,25,0,0,0,42,65,0,2,0,0,34,43,8,0,10,25,9,0,19,8,0,23,0,22,10,27,55,18,123,9,0,0,0,107,15,20,42,33,17,0,0,0,484,0,13,16,46,25,0,0,30,0,0,0,1,99,9,0,48,36,31,0,60,39,100,13,0,44,0,19,1,20,0,0,49,13,0,19,28,31,105,20,39,64,0,0,45,17,0,20,0,27,15,36,10,29,52,30,0,0,0,0,28,0,52,0,6,3,36,0,12,9,0,0,201,20,8,73,38,8,27,0,0,0,0,34,0,0,47,30,10,419,12,50,19,18,0,30,1,18,34,0,720,15,17,0,12,15,6,36,0,35,64,16,30,0,0,12,10,0,86,28,0,0,0,0,25,0,21,50,20,39,0,0,20,52,303,0,0,0,62,0,0,0,14,0,52,40,0,0,10,0,0,29,21,30,25,14,25,27,0,21,0,24,0,65,0,18,44,15,17,39,0,0,0,56,65,16,10,33,0,0,69,73,28,36,0,0,50,0,62,10,33,0,0,0,22,5,0,17,0,0,36,0,32,1095,2995,0,0,0,54,30,45,0,45,3,0,7,0,10,0,40,0,28,0,48,94,28,0,183,0,44,50,0,0,6,22,46,87,0,9,31,18,77,9,46,28,11,21,0,0,11,0,152,0,12,11,0,0,87,0,0,16,27,23,36,26,33,29,17,25,0,84,0,13,79,0,0,0,34,12,10,0,18,12,14,36,26,0,24,56,100,0,27,0,50,0,0,10,303,100,0,0,49,10,67,32,53,51,157,21,15,25,49,0,16,30,0,18,19,60,34,32,5,21,0,0,7,31,0,47,18,25,5,100,8,9,30,12,55,43,20,51,0,32,11,0,0,0,22,0,12,34,0,0,7,0,11,1,0,15,11,9,0,0,0,13,9,26,24,21,15,0,10,0,19,0,0,0,0,0,39,28,0,21,0,14,15,0,18,0,39,17,49,0,61,40,0,29,0,0,0,19,0,4,11,36,29,85,0,20,81,30,20,21,28,42,0,0,47,9,7,19,0,60,7,51,37,60,133,1,0,38,23,16,0,20,34,0,166,61,40,27,60,46,0,20,41,0,18,59,12,0,12,0,53,0,37,0,37,30,7,47,0,0,29,21,50,13,84,0,35,0,0,13,14,57,42,0,0,0,0,4977,0,24,34,0,36,29,0,30,161,18,108,13,6,51,49,0,0,129,0,27,0,0,42,30,0,0,11,45,46,0,0,34,11,0,0,11,32,36,73,51,16,0,0,25,0,0,13,13,11,26,27,60,12,11,51,0,27,0,73,69,17,0,20,0,38,23,45,44,31,15,15,14,13,0,0,24,0,78,1800,10,26,31,8,0,70,17,0,31,34,0,109,87,20,9821,106,8,71,4,0,13,0,50,52,27,0,12,10,2,51,0,26,36,12,65,10,53,18,22,256,0,34,0,9,42,0,0,6,35,0,0,0,0,68,16,0,0,0,90,26,0,10,17,27,13,36,27,28,10,0,0,40,33,10,129,50,24,0,0,43,8,0,0,0,0,8,0,36,6,14,65,0,20,11,21,52,0,0,67,20,32,56,48,0,19,0,0,41,0,10,36,44,13,17,26,30,50,20,10,25,20,0,0,102,53,6,0,0,0,0,5,80,0,24,0,42,9,30,0,36,0,8,1,9,7,25,20,0,56,0,19,33,40,29,45,21,40,46,44,1559,0,42,0,0,6,32,11,38,0,30,0,0,19,0,17,24,27,17,15,17,30,59,22,20,0,0,27,9,12,0,480,18,0,20,14,24,48,21,32,12,20,7,49,6,0,7,25,0,10,12,0,0,0,47,0,0,44,4,43,0,5,0,0,139,85,25,1172,0,75,237,4034,0,30,0,0,32,28,172,0,0,0,0,30,31,0,33,54,17,1,31,0,0,33,33,0,0,9,0,0,16,40,22,54,33,73,0,1002,37,35,25,27,30,0,12,0,0,0,27,22,0,12,0,11,0,8,10,0,0,14,13,0,10,53,20,30,0,24,20,34,100,96,44,0,0,0,27,45,0,0,31,16,28,40,55,53,37,10,0,12,77,308,38,100,0,16,43,30,50,10,0,0,64,28,0,0,0,42,0,13,0,24,15,0,27,23,31,30,0,43,0,0,0,61,17,13,24,30,33,0,0,52,59,29,26,5,11,1165,20,0,20,14,10,0,7,0,52,66,0,0,66,18,13,36,69,30,6,0,0,21,30,52,64,32,20,0,18,0,0,45,21,20,53,13,11,9,31,37,10,0,88,16,35,0,38,43,0,12,0,29,0,33,0,31,19,39,0,5,51,50,0,20,0,22,0,13,20,54,0,0,50,24,20,7,0,4,0,6,0,8,34,0,3,0,16,13,28,0,20,0,5,0,55,22,46,43,81,25,0,16,48,3,13,237,78,21,25,50,0,0,38,0,63,0,14,19,16,0,16,44,12,0,1,47,50,40,26,0,10,23,36,0,1,9,0,26,58,0,15,0,36,27,53,19,34,27,20,0,0,22,0,0,16,77,29,0,44,0,27,0,13,25,36,22,103,88,19,74,28,0,555,27,0,0,64,21,0,0,40,31,0,0,40,0,29,25,48,33,25,10,0,14,9,0,63,56,33,0,0,11,0,0,19,14,0,38,0,13,8,54,0,70,0,99,44,61,20,37,14,0,16,36,0,16,2,0,97,38,9,12,13,38,44,9,0,12,0,18,10,0,394,51,27,8,286,60,0,36,0,0,25,4757,126,42,0,0,7,0,30,100,0,32,0,74,48,0,35,55,59,6,58,63,58,0,104,15,0,27,12,0,15,0,0,26,0,0,44,505,46,26,13,35,25,33,0,0,0,34,18,0,73,0,12,19,0,20,33,26,8,13,26,56,500,73,19,42,0,50,0,21,0,43,0,34,39,20,0,0,0,8,53,0,14,131,36,20,13,8,0,160,29,36,18,9,31,24,160,13,0,73,11,13,43,0,0,0,31,0,604,29,40,20,15,16,11,0,0,0,50,0,0,15,319,0,50,22,6,54,9,0,46,22,0,20,0,98,11,0,0,0,50,81,56,26,0,31,40,0,0,5,83,0,0,0,147,0,48,0,0,65,21,0,25,12,0,0,0,57,0,34,0,5,0,12,12,20,26,39,34,22,0,0,14,21,0,13,16,29,0,20,23,10,10,0,33,0,0,0,115,8,0,0,30,0,17,5,29,23,22,3,10,44,37,0,0,10,0,24,282,42,75,0,24,13,0,0,0,15,18,45,16,35,28,20,0,8,0,13,0,21,0,58,20,0,14,0,7,24,1,30,30,14,19,30,80,0,16,111,66,10,26,20,0,0,8,56,2,48,79,24,0,30,37,0,62,0,0,24,26,0,0,0,137,125,0,11,28,15,21,6,44,11,29,0,35,21,58,8,0,51,37,24,32,34,83,20,10,6,15,17,12,0,51,35,40,60,31,16,51,56,53,0,0,15,0,0,7,80,19,0,0,0,0,0,32,0,17,31,0,3,31,0,15,0,37,44,18,3,0,0,41,52,59,31,0,15,4,33,0,0,0,27,22,25,0,30,36,0,14,35,20,18,40,32,37,8,24,0,0,0,15,0,0,0,33,31,43,0,80,42,36,40,0,5,55,78,20,93,11,72,14,7,0,22,44,32,48,12,0,47,22,0,0,0,57,61,10,25,35,38,25,0,5,0,12,55,0,6,46,0,9,50,53,40,0,0,0,0,50,0,30,3,16,62,49,55,124,0,0,19,229,24,100,37,50,0,30,0,0,0,47,77,1,18,50,0,10,0,34,0,0,0,15,27,0,18,0,0,0,50,29,36,45,120,22,15,66,0,0,30,17,69,15,13,34,0,0,9,0,84,30,25,52,0,60,8,20,19,1512,0,31,0,0,849,0,0,29,23,0,0,0,81,56,0,16,0,0,45,8,0,39,18,23,13,8,54,8,8,20,45,0,0,60,16,31,37,14,169,36,0,0,119,1070,36,17,14,0,0,50,0,0,69,0,0,0,12,0,21,13,44,13,25,32,0,74,16,14,8,0,6,0,0,58,0,40,47,39,0,60,29,15,54,90,4,9,52,10,34,0,0,29,0,43,0,44,42,30,0,29,40,42,1,0,0,44,6,0,0,26,33,35,64,10,19,40,322,8,5,0,0,12,89,50,0,0,0,27,0,0,29,75,0,0,48,572,0,10,7,44,23,0,43,19,0,70,50,12,13,24,54,47,14,25,34,0,26,0,45,47,0,10,8,21,40,78,50,7,10,51,33,24,14,49,41,18,0,34,33,23,0,26,12,0,31,45,49,260,8,52,10,23,0,20,86,30,159,0,0,42,0,0,8,60,13,0,20,10,19,0,7,21,38,0,18,0,21,2130,170,0,1,0,0,0,0,0,89,0,36,7,0,0,31,30,30,38,0,0,37,2,50,13,15,65,0,5,0,7,45,18,7,12,0,15,26,14,5000,17,29,8,0,32,27,30,19,26,3,0,0,27,8,43,0,11,59,15,12,18,0,14,0,40,59,49,14,93,12,54,17,67,10,0,15,0,13,0,29,0,0,0,0,0,55,31,17,38,32,0,26,28,0,26,57,0,77,0,15,50,82,42,0,1,0,38,0,12,9,0,43,30,1,0,0,92,6,0,20,30,16,56,0,0,0,63,22,40,5,25,11,2,11,0,11,0,17,10,0,19,0,15,0,50,0,52,0,0,7,30,32,0,23,21,38,45,35,0,32,78,15,0,0,0,46,19,6,25,27,43,0,29,0,9,34,0,0,59,59,5,15,24,16,85,0,29,0,68,11,0,0,7,17,0,109,58,21,33,0,26,12,0,20,26,0,33,21,60,12,91,10,0,34,17,5,10,0,5,39,101,14,62,51,35,0,41,116,0,33,31,109,10,69,0,20,0,10,0,2976,10,0,12,22,51,13,10,20,42,0,0,13,42,0,28,13,0,32,63,16,38,0,8,0,12,0,15,30,17,0,0,42,46,0,153,22,15,13,11,20,10,5,21,20,15,50,0,12,0,50,0,0,0,0,30,55,16,0,25,0,0,0,10,32,0,53,0,8,67,0,116,5000,11,46,30,0,50,75,16,42,20,18,18,30,0,0,10,28,45,29,6,12,18,0,17,15,0,0,0,22,95,34,19,10,12,96,21,9,13,0,40,46,100,0,110,48,22,10,20,18,42,27,61,53,42,22,35,0,0,53,52,0,35,144,36,0,12,14,0,21,42,0,0,0,0,38,13,16,37,28,5,43,0,49,0,0,14,17,13,33,73,16,17,0,145,0,0,59,99,30,25,67,12,0,0,10,10,0,5,0,30,33,21,0,0,0,16,41,57,0,11,20,0,16,23,12,17,0,0,10,0,10,225,0,10,100,14,14,0,19,10,0,75,7,42,0,2,0,16,67,0,39,0,20,30,37,14,0,48,50,0,105,25,0,0,0,110,0,38,0,0,20,46,25,0,0,13,37,12,36,11,0,9,11,45,7,0,0,23,10,0,28,40,19,50,7,0,0,25,0,0,31,4,3,38,11,0,27,0,4987,40,45,31,0,0,28,37,7,8,17,90,0,15,0,22,25,30,66,38,12,35,40,51,24,54,21,29,43,44,0,11,25,10,16,0,19,2,40,44,44,25,0,27,57,0,8,50,0,15,53,0,40,46,24,0,0,0,53,0,0,68,0,24,0,26,76,25,0,41,24,0,51,29,0,21,300,31,40,25,4,35,29,98,0,36,50,26,0,23,0,0,14,26,49,49,520,78,11,0,35,16,0,31,46,0,0,35,0,11,0,0,57,0,57,0,21,1130,0,0,0,14,29,354,20,11,49,35,24,18,44,0,11,15,49,162,0,53,0,40,0,17,12,10,28,26,10,9,111,0,18,26,50,37,21,0,0,0,1,0,0,45,34,0,44,50,0,54,0,1,14,11,0,0,24,31,0,0,38,34,4,21,0,12,18,0,0,29,0,0,0,0,0,0,0,50,13,18,28,15,0,18,3,0,19,52,7,0,41,16,34,0,102,5,10,26,0,0,226,28,24,220,24,20,29,50,0,19,0,30,71,50,0,12,0,102,70,0,14,6,22,35,0,30,34,38,0,40,1,45,23,0,50,0,21,0,12,0,15,87,20,0,33,0,7,0,30,10,0,39,9,109,50,0,0,10,10,47,29,0,61,0,0,21,21,30,0,70,0,35,0,24,18,14,15,0,0,0,60,28,58,22,49,22,50,90,0,8,40,33,38,5,20,38,12,16,18,40,89,42,84,11,29,15,0,61,13,0,72,24,50,0,14,114,80,47,55,6,10,0,18,14,43,8,50,24,45,0,20,12,24,0,0,140,0,9,20,42,32,0,32,0,10,51,0,27,14,8,20,10,23,74,22,50,0,0,0,20,6,25,10,63,29,71,14,106,0,0,229,16,104,84,51,31,14,0,0,13,34,14,0,16,38,0,0,17,3,100,34,9,79,57,35,0,42,46,31,0,0,0,0,46,19,0,17,18,15,0,33,0,30,36,14,52,9,66,0,48,38,16,0,0,21,17,26,39,0,31,0,9,33,0,0,12,88,47,41,30,30,0,0,25,11,19,0,7,0,60,0,6,0,28,5,0,0,21,50,0,35,30,16,0,0,20,21,10,30,36,32,40,25,0,0,0,12,0,210,12,48,0,0,60,21,0,16,62,25,50,15,20,0,6,15,74,0,37,0,51,13,13,0,0,43,0,74,70,17,34,5,27,0,21,0,37,26,9,9,0,18,40,9,13,10,18,36,13,60,23,36,49,13,408,0,89,38,35,0,295,101,15,10,23,17,63,30,71,32,36,30,0,36,29,0,6,6,23,0,0,20,80,63,0,0,35,0,18,54,21,0,123,60,0,45,5,64,30,37,22,24,12,27,2,25,0,11,93,0,0,14,0,0,100,0,34,28,21,27,11,0,0,29,103,10,17,30,18,0,34,41,12,62,15,0,13,0,0,15,49,0,36,10,0,24,12,38,30,45,15,11,31,17,15,15,0,24,0,0,50,0,0,11,5000,2,42,0,100,34,0,20,51,0,6,67,50,31,8,0,6,13,0,14,5,5,0,0,56,58,63,30,20,26,40,0,3,0,32,0,9,0,31,6,27,37,92,8,70,888,24,128,19,53,0,0,0,0,39,452,71,46,24,8,0,7,20,49,0,60,17,0,75,29,0,67,0,0,0,70,16,4,44,28,84,8,14,0,16,0,47,1505,20,48,0,32,21,0,0,12,99,54,0,16,25,13,66,3,51,24,0,49,0,14,14,42,15,76,0,101,243,50,82,16,0,9,45,1,113,1,57,35,0,44,0,17,0,0,30,0,0,40,38,0,0,6,24,176,71,53,15,27,24,14,0,0,28,17,21,7,0,11,6,0,12,0,72,21,0,6,28,15,0,0,0,46,0,0,14,63,25,0,20,7,14,63,8,0,0,45,11,83,22,27,0,8,0,0,7,0,25,22,0,0,0,11,32,10,17,39,14,53,41,0,22,199,16,31,4497,27,0,27,7,0,0,0,0,0,0,0,2007,0,0,0,40,42,30,0,50,0,10,47,27,35,44,0,0,0,0,47,13,59,15,47,49,0,10,54,6,6,11,21,47,16,6,3,0,13,0,0,89,20,21,8,0,0,0,0,0,1,27,13,37,59,10,29,40,23,36,0,0,0,0,29,50,0,24,43,0,0,0,50,32,6,24,35,47,0,8,6,37,0,66,22,46,17,0,27,12,78,20,6,37,0,37,24,30,0,0,0,22,50,8,16,20,464,0,0,12,0,80,0,15,300,12,26,0,18,85,9,51,59,0,0,42,20,49,33,0,0,0,0,20,0,17,0,35,7,0,0,0,36,12,17,0,9,17,47,0,22,7,12,0,1,0,20,92,0,0,24,0,9,0,0,50,0,12,0,59,0,6,2880,17,27,97,3452,0,0,8,0,15,0,42,21,0,45,21,44,18,35,6,0,15,45,9,11,0,0,13,55,0,95,3,10,0,0,0,35,0,4,5,12,20,17,46,42,0,13,97,0,0,45,11,0,21,0,53,55,0,53,16,0,10,20,75,49,21,20,0,21,43,5,0,24,43,0,45,19,0,14,0,0,22,11,12,7,35,11,0,51,20,0,18,0,20,0,18,0,18,12,6,50,54,20,8,0,0,4,23,71,0,22,0,44,31,27,0,4,0,10,13,81,11,0,0,45,20,0,17,0,10,12,57,165,0,28,51,26,11,50,22,0,0,0,11,19,25,118,178,36,42,40,0,9,0,8,8,0,0,15,31,12,36,75,19,22,0,6,20,35,32,20,0,19,18,29,13,36,100,14,19,10,12,0,0,0,7,0,31,81,0,10,0,0,0,17,0,75,62,75,0,0,21,0,83,9,0,0,30,75,121,74,18,21,0,0,2,24,0,29,39,0,60,0,0,18,40,29,18,302,0,23,0,0,0,0,5,2220,24,28,10,6,0,12,0,0,0,0,26,0,0,31,45,67,17,0,20,43,119,69,30,6,0,21,60,43,0,15,69,0,7,47,0,0,0,15,26,12,59,0,31,33,18,0,0,27,8,0,29,0,53,0,21,0,0,428,0,50,32,4,27,46,55,0,75,49,20,0,2,44,0,21,29,0,0,0,19,13,41,272,14,10,49,48,0,0,50,50,0,41,0,22,0,22,0,18,163,7,0,31,35,13,38,18,0,79,18,22,0,0,55,10,32,0,0,0,136,74,11,0,31,20,6,28,10,19,13,0,3,0,10,14,16,0,64,52,41,0,0,33,0,10,137,21,24,0,0,36,14,0,43,0,0,33,0,42,12,15,0,40,0,6,86,22,59,0,26,0,39,62,4293,47,0,35,0,0,54,50,13,18,50,54,25,32,0,13,0,49,37,44,28,65,50,14,24,30,27,19,0,10,29,0,0,16,8,0,38,37,54,10,185,48,31,0,4,0,89,25,0,0,24,0,0,0,0,107,11,28,0,25,27,48,590,23,74,26,53,35,31,50,0,32,1,55,12,709,57,0,5,3,21,26,0,45,0,0,25,20,17,98,88,25,5,128,0,13,6,0,0,32,0,24,0,25,59,0,32,6,52,0,52,0,27,114,0,76,0,0,5,30,18,31,10,0,0,0,92,24,0,22,20,10,0,0,28,23,10,34,28,0,0,34,0,0,29,60,26,50,0,10,10,0,17,20,13,25,0,0,0,34,6,21,44,23,20,0,0,0,11,178,38,27,35,0,46,0,69,0,59,13,20,9,18,28,0,0,43,0,0,15,45,8,17,7,0,35,50,16,23,12,66,20,36,11,15,34,0,43,32,34,21,23,0,99,24,0,14,97,0,0,0,0,70,133,34,24,13,0,19,9,23,0,35,39,14,0,25,41,0,23,27,0,0,0,24,14,0,38,0,82,18,55,1224,0,7,13,46,0,46,46,0,0,14,16,13,17,0,35,0,0,16,50,77,11,0,0,54,18,96,0,23,31,0,22,81,0,10,17,56,32,0,72,27,45,13,50,34,0,0,0,48,1,30,0,0,50,0,12,0,1203,0,0,10,20,0,0,0,10,136,0,323,20,24,12,36,6,0,0,15,0,5,0,0,36,11,0,64,19,28,0,37,43,12,0,44,0,0,30,55,0,0,20,10,13,0,22,22,10,0,0,14,19,62,38,25,0,41,45,10,60,0,0,0,11,0,26,36,12,0,12,0,22,13,20,12,54,0,10,29,26,0,50,0,35,7,24,28,10,2008,0,34,12,18,6,5,0,0,22,26,67,15,30,44,8,29,0,18,29,12,0,47,50,30,0,0,0,21,37,24,33,13,22,7,17,55,10,23,30,39,45,0,0,0,10,35,21,29,0,251,44,13,0,9,10,0,0,34,11,37,0,0,0,4,0,10,50,0,0,0,0,20,57,19,0,12,20,5,51,0,6,97,0,33,19,21,12,7,40,0,0,0,15,17,0,35,24,0,0,0,43,0,0,0,0,34,55,0,13,8,43,9,47,1,24,21,0,25,0,0,44,35,0,0,79,38,0,0,0,0,40,0,15,0,0,65,0,40,119,42,37,0,61,0,25,0,19,18,0,45,50,37,71,102,0,46,50,27,6,0,38,56,15,44,30,0,41,11,13,13,7,0,42,27,1080,22,0,33,0,0,0,21,21,0,0,0,141,0,0,25,23,20,100,13,30,31,22,0,0,14,36,0,0,30,23,21,0,44,0,0,30,20,22,34,0,10,0,0,5,7,0,20,40,0,0,16,12,68,0,22,7,35,49,8,0,0,0,0,106,85,32,99,0,27,365,0,0,29,10,17,0,20,0,84,16,0,0,0,0,58,0,13,10,4,21,152,46,1090,0,8,20,1009,63,57,0,39,29,35,4,0,65,10,27,19,0,28,33,3,0,6,0,24,27,8,0,18,25,0,33,9,12,0,6,0,0,11,21,10,30,11,14,10,0,45,29,64,18,11,15,0,17,0,18,0,20,0,0,100,45,0,20,0,0,15,17,69,24,28,7,23,30,0,12,0,14,35,0,0,67,5394,16,6,22,95,19,25,15,12,37,0,33,12,26,0,0,9,30,23,0,0,38,0,16,0,14,15,14,29,19,18,13,20,12,50,0,18,28,14,50,40,0,23,63,9,0,16,57,7,24,0,42,75,22,13,17,0,5,22,32,47,19,0,0,31,0,11,41,0,40,59,27,186,0,24,0,88,28,0,26,21,89,11,10,12,25,34,29,0,0,67,0,29,44,6,0,8,108,25,0,27,0,213,0,0,0,0,26,0,140,15,12,6,10,10,4,21,10,40,0,20,8,30,0,25,8,18,12,34,4,0,22,30,0,1,44,14,23,0,33,20,22,0,0,35,0,0,0,0,0,0,0,12,9,0,500,15,63,0,0,54,0,0,11,30,3,13,29,61,0,0,0,0,0,29,20,20,12,18,0,0,19,13,0,49,0,13,51,0,0,0,15,73,12,16,12,14,14,34,50,30,0,0,56,12,61,8,0,0,36,11,121,50,41,3,14,20,51,0,18,73,24,82,0,0,0,0,0,0,20,12,24,5,28,20,15,0,20,22,0,28,362,12,12,10,0,17,0,11,0,58,11,45,10,9,17,26,25,15,59,32,119,50,20,82,29,49,0,0,64,0,40,7,21,0,0,0,6,134,11,0,30,29,52,0,0,0,26,12,36,22,0,17,0,12,34,0,13,13,28,18,19,29,24,24,37,0,0,20,15,72,0,77],\"xaxis\":\"x\",\"y\":[3914,10728,635792,253864,49818,11966,1497694,12532,3914,49837,27176,93694,52572,62764,101824,134416,26544,16182,16211,4816,12896,70200,78884,22344,15326,702956,57460,17732,176540,14896,8643,10507,10008,57784,6758,29541,44020,8424,8604,350997,9362,34918,4294,5676,34216,6106,79711,40486,78964,225624,14144,157914,16568,39312,11594,936900,3631584,6240,6042,18012,9568,137643,16297,6262,1293336,155918,14040,6364,47424,6696,72936,236500,3924,4028,5246,24024,511841,20304,6084,12245,5246,14319,18876,41648,8428,42952,27924,198369,43004,13032,11448,4320,4750,27156,70176,15748,14018,12482,7254,6968,6063,10406,42966,48982,4859,4248,6386,4524172,30573,40092,5304,76836,10664,6278,18791,29388,7668,14756,6262,116356,15084,5805,109512,24128,57474,14446,98540,16776,13416,75672,26208,778545,72680,4446,101308,40964,6324,132870,5824,130500,14248,147098,10912,363084,7502,13020,13373,9196,885422,9724,12943,9559,8246,30524,18802,24095,21804,607724,12403,4066,61628,20398,41065,148441,10712,6344,282948,8664,33440,99634,6372,4134544,31261,147651,49612,48880,11524,4687,31868,14544,5510,12064,69678,7525,80484,53692,3990,153418,15247,1279326,19656,74046,11020,54720,11128,285200,37658,4066,52344,4636,451422,3838,6188,117676,861032,229416,872318,30702,4945,28260,6880,195768,8556,28086,50165,100835,195156,25844,14516,654192,33488,27413,41184,3744,7353,39832,5130,4218,22828,12324,306590,18824,4788,5824,18920,559152,19396,5876,97632,4332,8684,20167,11718,12636,6552,37696,28462,44978,19836,7998,4343,143052,334366,5408,50955,45792,4104,11692,470808,19440,223028,23564,22458,109148,10354,52668,262438,10922,6149,11137,5724,48418,7790,121892,189504,72432,98280,35234,19448,17568,15696,201172,20160,229892,47716,3636,64464,11818,12744,22204,121458,13680,68536,160528,56268,13934408,7900,35313,78289,18658,6292,6498,26728,14405,23858,10816,13144,38710,13702,10981,15394,24804,11804,42897,4560,50220,164260,6916,52030,24056,10816,12772,14446,1195744,698400,5203,24928,5054,39384,117676,151446,19968,24264,126880,20540,15300,18356,10712,17004,6084,19344,1418688,8640,263149,18576,10244,166216,11438,8216,37232,36103,32472,11376,1039492,60528,8496,338840,251136,166032,177460,450379,20066,5356,26149,55068,95906,51088,39216,29488,11248,14664,27612,6384,7697,9610,17696,12096,31304,7344,32916,224992,22594,4066,11818,7998,38528,9216,140920,76322,3996,7936,9204,8684,39096,140976,31806,26164,12428,10656,15824,90534,54954,234732,28892,128804,132408,373591,18000,17784,11904,19096,24984,872784,34162,212836,355579,26064,10191,53234,37368,8320,12168,9030,192918,34844,37539,15958,45198,649472,11880,78192,27456,59768,9287082,11448,6968,560652,37656,53878,180804,44161,393908,204048,6012,8436,6696,15562,43920,312998,23760,15168,13520,6634,59148,14964,8901,13392,4522,26424,19197,11051,21476,29588,23472,13104,5332,149136,19368,24964,601016,4408,4515,5436,12384,20646,14782,21142,5504,11448,7560,49104,121518,10224,1951813,4140,19522,13454,47386,8060,5358,8184,231154,10586,16802,18060,33891,9724,7488,4343,94068,134628,94428,158237,75445,134142,15934,162136,91542,95728,11284,16872,40394,13373,34529,17628,168428,154960,144216,480952,93912,5890,338436,6448,12152,18144,287370,55853,16530,5700,68809,2691358,34424,9620,24727,4104,23940,185938,11997,10602,19080,10664,692744,10716,19684,750421,7992,7182,14136,11664,20769,218400,85162,696299,6200,6604,5652,104201,10368,19197,10540,48856,24332,7704,9620,16297,32040,8385,5564,9202,7072,16454,7592,53483,335952,11016,11222,50616,5980,8892,25012,16068,2747784,7748,10080,119536,857956,4279114,311116,28348,17856,187200,83898,501642,5461,5805,192049,45346,473817,6342856,7904,20482,454248,47196,38236,10944,115577,11266,13114,56072,15190,14018,9238,23472,58320,24885,6063,12692,476397,321382,18060,15444,8769,11248,68510,219085,17992,11904,15428,4262856,77376,70626,40032,54194,9796,16120,280800,12350,9504,55695,5512,533696,17628,17673,22308,31442,9672,6344,273600,718189,176802,155746,3876,140620,29154,10277,5564,151048,35464,9006,19908,15872,8112,20644,10008,12482,8712,289140,200592,405954,12324,52390,28424,19722,67071,15523,71416,20880,220410,19908,2108510,96301,5564,17459,40104,6136,6324,51688,28704,918788,4343,16641,8295,41400,5976,4472,9072,21638,49724,9216,130260,18616,75551,7632,337156,20212,8856,5160,858572,14328,28334,475106,21543,306362,20026,5966,9486,859125,6688,10816,327455,49375,36378,4332,20488,152312,178144,8684,9360,9300,8122,10800,213409,4294,98568,8996,44772,15548,55796,13676,66992,96933,1665162,4452361,17108,75981,11346,17680,6292,115541,21018,28582,37841,12152,18723,5200,889632,9734,343097,8996,4320,1315113,18662,18328,17673,45662,21888,21962,27590,11594,261934,62372,26531,16899,9932,9234,19902,6552,4464,11613,16432,40536,154284,10908,13206,70784,7748,9766,8684,754134,413170,1071288,23750,9308,25438,35155,6536,75168,13826,5928,25128,8804,28835,20026,105710,6968,78819,7030,17352,76946,20088,19032,22704,92132,1066464,12584,265440,5720,382044,5976,64688,15190,4176,221760,25482,13392,7540,51342,14174,22575,4032,571814,11524,9006,7192,1033075,20640,2555424,9360,48450,9144,14402,25200,7866,10602,98784,6572,78605,11532,32612,280618,123264,299568,39579,6751,1309252,16796,16484,200668,880771,103806,34844,37080,9847,155304,7697,7052,7296,317896,63898,6042,22360,52762,29146,3952,5332,51350,259064,23296,6080,9100,16120,917111,32390,19671,18565,29283,13826,20448,11780,10504,65188,32262,22104,757136,5590,13186,34200,177987,22680,6460,6136,165044,10234,178452,13889,18447,528984,7696,121888,60888,35352,6552,20368,20832,32723,6324,16112,12046,3952,216638,15552,62062,7482,102621,5168,10088,390290,12087,6192,77896,4572,11016,8788,2152750,107543,74218,6688,48568,5719,32544,14560,37202,66508,17415,11218,37076,57304,398908,201213,195676,12642,10728,5408,9734,16856,53884,48360,15840,10184,17670,35313,26445,61383,115754,727669,39596,49538,31679,12024,4066,5928,18091,9932,4472,32548,40456,203164,325006,1473802,5876,14384,5246,37752,133431,5332,115026,24358,11309,44878,12768,65333,23560,28124,6292,48111,13728,35030,10292,162582,12245,293968,23384,11752,151580,5624,918375,7130,30889,13454,7600,96064,7224,5230816,21736,3248336,4598,24804,3780,6696,227582,39308,167164,5966,124776,12482,15652,8604,81792,27492,6572,4816,41317,36577,18460,43272,1451704,38950,7956,9348,19608,5356,72759,20800,27404,16692,8778,103272,6572,13104,860976,11297,17784,6278,11128,1086488,7124,139176,12586,30616,26520,47400,49556,6572,17243,10449,125689,75528,6760,403056,39263,55774,27396,9880,16037,13889,12561,7697,262694,10507,17964,7280,19592,71337,7334,38184,3785601,5289,17160,61383,11481,9610,179181,27504,13832,10556,13104,5460,13536,28595,21372,60202,17112,33332,64844,55986,124930,32904,4386,12688,86742,13509,7372,54288,19500,23244,10348,31304,10664,15136,7812,10044,181718,7310,51745,891820,164880,10912,35647,30628,592844,155420,30876,53957,37324,44856,25948,4859,2491660,85570,3439502,32508,8127,164715,15800,119527,21684,28348,10540,51745,37296,6407,17544,4261023,4386,5203,9374,58708,21584,26875,11492,9717,43206,4446,26486,23250,60320,470208,4472,16560,26474,9417,7316,15438,178312,597896,53641,13640,39816,10368,8684,236447,126666,17696,21112,16560,16848,13244,726089,56287,21156,5184,5824,13072,579120,1886836,97802,692128,7296,6696,43524,150653,21758,40976,1810042,18407,1348925,26860,11139,4864,17064,21700,38141,20026,34271,150722,46384,8892,16037,30816,961362,100168,14256,38664,78416,1152531,20232,16848,25704,11552,15128,5805,4028,148678,67756,1246304,8736,13516,4816,4142,55490,13072,5246,11476,29512,55774,62173,183481,153260,75816,9776,43416,10608,36972,21762,9085,5016,11088,1216800,19114,12255,2275911,59112,69368,363874,38448,14196,39888,15496,205321,741960,19840,82560,15879,10244,5848,20020,42423,111241,15340,16488,54498,7332,146010,12654,27590,7750,49794,5289,970416,27962,8246,755793,16168,525587,20894,10608,7095,164304,9890,51116,8112,872526,1931392,53784,4446,145992,18644,20088,26228,29025,16226,7488,129580,55512,20016,13826,9216,10974,38786,30240,4028,9362,15264,4750,5934,8360,14858,24232,23932,8170,21840,290641,17244,205632,216980,506602,34732,556416,20736,20592,25992,5375,9761,4978,7224,31044,13248,30400,73865,56012,5376240,11970,27892,60264,9417,736112,77584,156104,5668,91547,263160,12384,5252,6136,401076,10972,27352,33228,41610,105696,211562,45714,44252,4104,14276,24358,22833,17160,69254,24940,13248,14570,4902,38626,10664,9216,18050,8712,376154,15704,227599,18146,6156,4558,21892,13452,10578,19604,877084,155880,291462,37656,14256,6321,122832,30384,4902,31680,11739,15120,16920,5980,5676,29842,20664,11016,34344,63990,5289,37354,18582,20770,13032,6751,70432,967460,42280180,16906,9576,16344,25359,10108,31916,93353,147146,13932,87216,504099,6510,38532,30600,36270,8742,70704,5031,22176,7540,49059,6572,5548,16120,13312,4078274,4218,9638,153748,27821,53072,40132,16120,6188,60624,82950,449136,59724,14060,90250,14248,7912,11284,7611,5890,45144,4522,5719,250952,7130,93930,17632,15010,12740,24806,144612,24037,12816,281294,22176,15872,13788,538222,34365,19158,4730,23400,14615,4294,16426,5244,51264,206568,29038878,34684,36464,12428,11352,21762,142201,12168,7072,14196,191208,5633,15552,33384,109908,354394,8987,13608,46624,131112,18316,18091,30784,100738,211668,282978,181779,12888,66248,178966,119392,3501504,145281,3952,170956,17544,128016,7502,10540,13520,319160,22910,9424,33136,5375,3577673,3914,7904,7254,160128,982338,4787921,9576,72443,124504,742392,14328,10944,216934,5624,22464,10191,102180,16834,8172,100152,5548,12084,34602,5130,8094,10230,8320,143069,16380,13676,13338,253440,81282,48418,135098,1190276,7353,397606,6192,11856,10088,12028,18720,63550,9300,949240,8784,53300,31679,159692,1229240,11534,80659,1457682,9724,20748,346476,54994,6574,20540,726657,50112,11352,57190,12482,76393,8927,13888,3600,10744,17459,11476,13780,23932,9576,122450,11929,38520,144965,95542,45448,25194,14630,321451,18404,17775,5184,66528,299160,5244,14536,47795,80414,38502,14880,124668,7182,82056,16802,6916,5472,13780,12400,10368,17775,10296,41949,2154014,38076,53621,63752,188889,32422,10070,7228,20862,9576,92035,9954,47684,31464,65246,5130,15184,9864,7800,122544,63498,10415002,8901,36498,19866,16276,5848,44764,1875376,12599,354710,75888,10222,9176,212115,40291,30616,8618,13932,7224,16669,400192,14976,5848,13392,10850,6136,182676,76824,956332,8580,26524,61938,15132,9500,7711348,10192,82713,6500,9675,3952,406297,29016,76235,24467,24411,6916,28132,13392,5928,14364,13896,5976,179883,19902,24253,16864,6080,38868,19500,10556,596711,79484,9954,8094,9766,81528,4472,45030,131924,4343,16306,46512,8372,1071161,85020,3838,218922,26070,891041,14198,27144,73268,19092,5805,19654,15958,12276,42344,55670,42532,137206,7998,9828,36182,9176,14288,16952,40774,44200,58464,32943,22248,6450,38270,5460,7936,11970,24244,4902,58178,30889,40608,18720,4218,11139,59400,7144,19269476,287496,443269,33338,3960,6156,72488,360158,25792,8320,16692,39263,17316,33048,386136,16380,8170,395604,25517,14615,28614,6156,5848,4773,10191,19928066,9100,166752,10478,5418,12648,5461,18864,335916,18772,4522,11552,66994,46784,10836,17628,12008,16272,550185,51034,5512,30573,6232,5117,85696,23478,10504,5976,265734,6696,129704,14322,114939,251292,225792,31320,6966,811172,31096,8268,7783,23832,271918,13110,165505,24048,66248,4988,12152,112060,9412,8690,13000,84925,19874,4598,10712,279186,302188,6574,4988,29388,14773,28638,76153,139040,15872,16016,18648,7440,30628,46698,25413,6235,5396,1356212,5633,9516,5408,434668,947376,7525,5206,36656,11376,6080,32224,6708,11376,73530,21027,53246,102856,12096,1408752,1861184,32566,46398,9114,7344,16992,67624,13364,11352,17594,19708,7416,30628,15934,25346,26600,15184,5092,49928,29520,12152,15984,73584,8990,43645,4687,49920,21424,11592,108252,58144,460096,297960,16058,63279,131219,56992,4066,62805,79608,798769,10608,5054,13536,2141136,46314,5332,12096,6032,123324,17028,1493021,5720,24804,15563,24700,20160,34128,14560,7592,12896,13889,32736,4386,19355,7448,10868,4687,21514,50560,23068,6536,20016,16302,16195,19656,34049,7396,90516,5977,21008,39364,7525,7790,14104,3395520,12400,31218,33136,23068,73910,20880,42344,74214,8496,6384,11180,27360,5977,262596,5652,22824,24381,122140,31540,36890,134230,6020,804615,5772,16120,1989704,11966,350207,9504,124754,163866,4750,8928,92579,43134,22420,5676,53496,656885,3914,32034,3744,27864,9216,7280,19197,127286,6837,7696,288917,7439,34916,14694,8643,4788,9048,17784,174580,117728,13244,16254,10965,217672,10535,13208,93252,13115,3876,12900,181068,18166,99303,6880,142168,4712,7440,20808,6450,67392,5252,20145,209932,8460,4788,46170,5624,40362,9272,16985,10922,126100,73584,37128,12298,6500,9776,4104,7384,8987,11648,14456,19152,12685,16590,115656,7095,468884,113602,53630,11856,30008,550393,6764,119784,177750,161476,5396,37920,15066,4859,71982,423708,94886,8996,12212,8256,32832,23736,145584,947842,29713,13502,13578,5662,786780,6878,14768,411985,192386,7410,7800,56564,55800,15872,252168,4558,52706,44304,18648,640212,6118,200564,10602,481954,25675,31540,151443,4560,9864,13020,42840,38710,136697,27413,70980,25344,4332,18662,19995,30168,119952,3744,10108,25420,6880,749552,171120,118598,15028,20425,301306,48190,73573,8618,35880,5244,9804,11088,114550,158328,22989,6572,16432,35984,78884,8280,6344,8184,10836,113760,3838,4896,101804,3996,5738,9724,8632,464318,55872,30020,10184,118664,349259,1742317,34906,80352,8436,4256,7790,35392,28196,11804,6878,14446,13588,4598,21476,25704,11352,46956,397008,45899,46368,8084,18848,42011,64930,23328,48891,20904,46488,480240,6278,7812,535651,346652,62124,11592,4429,121368,10036,5928,4408,7828,193128,30312,5418,403374,7998,49217,86387,191654,60198,17243,70408,26273,122740,23972,886854,177568,214848,19522,14694,132088,7525,70942,30315,5130,128592,58996,6923,36480,6240,29808,5092,4864,12532,26000,23976,22032,20224,19190,8626,22116,18240,9052,52576,5504,6882,9196,1177848,11340,49324,7334,146880,4484,326823,23688,64414,81449,5168,494326,21166,19136,96222,11952,29467,6758,298034,64844,66664,19694,117154,79670,13320,127368,87516,119536,5590,37200,30600,61462,80969,16120,6820,559320,436852,13224,195672,18414,171950,12616,94385,53404,43946,49556,239904,963802,7852,4680,15800,42696,3378752,38270,380376,15879,424625,17143,112891,995665,138566,393016,661072,14580,6149,235152,22594,24336,21576,7750,7904,33060,22932,44194,12688,100172,23521,52693,14092,6820,154584,279000,14098,9920,53010,217208,6240,30004,16492,27000,99944,43766,13640,31320,9486,17480,118336,143312,6063,28598,5616,64440,10868,8840,10368,62884,26860,15247,14688,162029,95288,25327,10348,153338,117552,33934,10354,10412,291589,30336,194256,7540,1227976,32344,10348,5934,48348,60164,24648,3914,19497911,10234,5760,27576,47558,22724,237460,49290,8372,57190,19512,6448,80106,8424,8424,6536,38304,43834,17632,85952,6916,81840,74808,8295,15563,19039,24862,71416,12636,226610,4028,10400,11594,13244,44082,23134,71208,40680,3720312,11096,22516,7790,4484,90948,16856,53612,5160,325884,5160,8928,46664,6665,11908,6696,12274,67500,8532,241034,6574,10088,14560,9776,25116,5460,18648,7502,4902,13020,9734,5662,37202,30336,262260,67906,103392,71939,83018,66766,116774,11297,33418,1062014,21268,3708,23263,8686,19916,9880,31920,102114,55432,5564,885794,12728,186319,7176,9796,188928,2703014,28234,7020,37762,14456,34602,10354,256987,15048,2912493,7072,14018,32968,10088,26524,56916,53444,14457,12844,43529,9417,1932696,461088,29232,8320,9108,68414,26136,14560,24332,34920,271128,8927,169594,8474,684140,598345,11455,35064,7164,77328,965808,9880,4598,9100434,15996,46228,32760,5928,12084,8690,5776,9000,2987504,13072,106652,5564,3602092,123635,235894,5460,247052,53754,13193,19646,28086,106887,745920,9546,5074,12896,59976,21684,18460,141963,71188,67526,11700,16952,12744,149872,28644,777712,120317,7540,13104,22392,14319,5700,66994,27097,89544,5977,42120,7006,6634,76464,4902,11180,93654,16416,14190,4386,5662,11352,71362,21600,16555,779730,26781,172694,4256,478503,45899,93299,5928,32452,59128,225990,216562,16678,17794,10348,36144,4068,5472,7095,11856,23305,7181,39263,76756,201514,81449,25916,19158,49348,47479,10602,6149,5054,35155,70992,19584,241552,8471,26208,117046,29625,338910,92235,4284,132096,5805,13454,7942,125517,86060,44352,61704,326244,1054614,20026,44460,25978,33583,93000,415423,36704,163176,16039,54747,410332,4142,222480,48384,402268,8772,16640,4408,14144,27492,84604,575172,494145,754992,28656,1210356,515317,58104,4142,388864,12024,10277,7828,56886,130591,13186,17316,67704,5590,149389,11137,25848,64372,9900,597528,45980,8514,80969,14326,40824,222490,11098,8476,31284,68940,973517,149358,168302,10191,100409,1756723,5668,15480,15552,126716,22199,286936,399024,20592,7912,73628,13702,14716,35774,18044,19964,6384,7124,22306,9766,29736,348074,911090,5016,20066,56327,28024,488299,8772,127111,2482046,9576,14060,142386,132440,20384,69502,4294,19552,28756,939238,218096,5564,81270,4484,424908,23700,50639,11514,6292,4256,13490,7697,17822,88198,6020,8164,5460,61857,13029,9464,12888,9548,24984,33232,1918831,18565,212668,20026,67466,4674,2289815,8927,143464,17518,9559,29488,28800,17856,110916,11309,59469,27300,131688,8213,6232,14632,101093,7338600,19584,19760,1379040,9720,33669,8987,62173,4902,117864,22747,449565,49248,186519,23832,14508,76712,13052,14256,6992,13680,23005,9114,10296,172328,47953,6552,80724,6882,6510,10640,12636,17100,74418,161120,23688,47736,60216,117648,12220,45267,8788,54036,23218,9540,41292,44640,4558,8816,4446,5700,9360,10504,5824,11180,119606,67642,167717,12888,4300,7439,39026,46728,30168,7396,2417163,104594,13468,5289,61778,830717,456404,11016,8618,5160,89156,4674,1106237,9568,25517,1094071,120776,31205,21567,9690,230601,199008,26496,633256,12532,15132,1934473,5436,60435,22489,18936,46311,6084,26273,17174,8927,7144,146415,934648,28519,26102,1520640,12090,15132,140146,23940,1001088,13825,145578,210900,38736,19476,31679,293472,20150,21576,7439,243568,10354,8476,45714,163852,42904,4680,32976,4332,11020,227240,4446,88504,25675,5200,49770,168259,9245,32550,18000,10452,75603,8008,72106,36024,46764,6042,81133,8736,37288,15265,29704,35100,509787,131021,5112,68472,15964,57252,8996,61304,5762,80848,15437,50998,56520,20748,1289160,8127,7866,14319,381900,15652,4902,298857,6232,7310,17856,61936,137088,9272,140554,8840,6450,8018,10230,45881,182806,17556,37440,7296,8611,8385,66960,15314,37604,7592,4294,41366,147146,5408,1709876,22152,289952,4515,31126,12350,5720,33480,116130,9652,46956,12400,119764,701896,1120220,4750,7562,6500,87668,293959,46500,126432,96876,25740,33332,36894,7344,198328,44333,5320,19592,14976,4644,18600,18881,8729,37754,10152,17933,47652,12083,191338,956004,89856,247884,16340,6292,9462,13268,12350,7344,153813,23036,22403,7562,7272,15336,4212,18834,8424,177630,199836,3922828,41306,186248,220884,3819510,775806,78447,9804,18644,65556,8930,133859,930620,2279545,14544,1019258,9638,6188,17050,13459,106210,124030,44763,29796,233064,7992,31668,325510,16864,149832,6912,40979,34701,14706,237711,14061,9976,7828,70520,93931,20644,28496,7920,346890,37262,26860,36146,18216,51127,21672,6726,5031,245186,25026,48060,52417,740808,7416,9462,157526,16678,745444,5246,1027710,12220,42186,7874,8736,116057,198432,180041,9620,38998,40334,7095,132192,59555,22752,63426,9648,820728,11128,32072,26676,97881,29848,8742,37368,31428,15132,24986,7384,24552,7904,11036,7596,11532,81936,151759,14322,92579,6080,31691,8164,1119588,20511,6880,10222,21070,3952,31668,30020,16827,80640,288350,7410,12771,2937062,196664,10792,72664,13114,37752,54826,16740,27432,45562,23305,15238,3636,593290,198360,47795,32976,24776,88236,24336,228888,220058,5203,15656,18616,35152,14544,30816,9256,20232,574184,9612,35280,16948,140223,5564,24192,49176,4730,4978,41572,12168,84878,5966,9766,7998,19872,32528,30744,41194,5738980,17420,689184,1516958,27072,41044,60946,6032,6262,18668,52030,7280,41600,9072,29448,26568,31205,146808,33840,69574,86060,4773,5418,6751,18506,282899,6084,11929,56412,305809,112654,13832,9976,12896,414355,6321,163846,20777,10981,49538,6020,57600,194814,12245,6650,8295,2359296,4177599,17112,50544,16616,32736,7942,5876,367744,41416,1861704,499658,138503,9672,6764,118121,68284,11532,10660,209324,352160,83886,454646,8213,507936,10106,7228,7750,12792,122450,11596,21514,52832,492881,6510,145080,131193,10112,233366,9030,11068769,28148,18228,33153,20274,57252,34424,19708,20436,10507,7611,4294,9048,34271,55142,8132,4826,74971,11532,8930,8686,59882,38952,13338,25359,108288,20232,32074,13760,6192,37525,405964,4968,9348,26350,13392,17472,18408,223886,4560,82088,72850,10452,44677,7192,12168,61146,132088,7904,15500,12772,6751,134300,36720,6194,313404,6536,35136,7316,882828,12008,234000,36348,18802,88556,2832545,8588,1082830,85557,6820,36244,187941,293485,6063,66439,10168,7488,45267,147992,168020,14756,3600,60496,32908,873496,542160,92588,133300,13888,59328,18960,13490,10728,39780,25438,4663844,222196,22464,9412,15050,71258,32616,7632,26226,7783,31464,63200,62489,15562,19500,582660,23712,142595,268632,18962,6192,40014,20016,58104,87096,19158,9417,19530,4180,10664,22534,23972,12126,21543,77862,12768,17696,21080,62640,7812,4218,11160,11395,292448,49894,14196,73948,14820,4978,9890,119908,16432,16340,12814,68328,6880,9196,7272,5547,7644,7564,8928,65728,23370,3249823,7611,199080,12586,4816,8742,45792,132088,30690,111176,2638363,716196,25284,28008,88350,18538,196352,28598,8094,42744,14508,62890,5548,19152,49296,10621,37336,30836,12688,9766,21567,11492,8680,24814,13946,5332,23976,5364,202635,24800,15010,47214,4859,202844,11248,30600,537753,81158,236220,512856,9052,153037,14668,22317,18600,30336,7124,6500,75287,108624,113839,6422,16128,11718,70942,9672,10504,51460,21744,77443,5408,224755,85083,18920,34996,675936,58136,32860,35724,144566,7852,57888,15652,3852,15624,275394,1997320,8930,81054,17732,81792,154656,10712,163787,48070,4988,42696,9245,7228,74734,41496,1202581,7068,158808,16872,4408,55588,27716,6168715,85464,7704,25978,18928,5168,47728,52000,10868,6696,4978,7560,12376,10656,9204,10602,437502,19468,7181,551973,89225,61070,122608,8532,12642,88776,63284,4284,65884,13115,10974,10707,301320,16016,5700,120652,16306,46136,6020,4940,12160,7228,1298032,8064,200660,14964,5252,9880,71653,318291,68696,6794,48585,154368,1623024,31616,10728,10621,3952,4142,8428,41791,19872,24586,171144,51584,13330,50353,36022,5772,27976,61189,5461,27413,5304,4932,19049,5130,68651,3952,25776,20304,98696,96933,113100,8352,10140,176886,147368,5547,285348,6235,175248,7776,25428,19380,6188,993852,285192,21112,12324,140144,10036,8684,41344,77672,22704,159831,376593,20224,4370,390624,8164,19684,16068,81686,7254,5700,38812,61304,27820,150495,5555359,63042,22458,40092,59882,14749,9994,23560,7740,3800,18504,17898,55584,74932,65304,64410,12040,4816,6612,12744,31916,997770,13764,146946,29716,10754,9006,3914,164448,7525,244872,9648,25048,5738,18724,4212,43608,4180,75504,44346,8385,7372,5004,297228,4788,20520,59508,242208,13728,8769,10879,4356,2513880,9804,11966,13193,88882,50778,23622,21371,201818,153381,8476,81449,9000,9672,295195,12008,11223,22152,34580,6364,118248,6923,120228,28466,8453,9796,4429,16244,14012,28028,25754,60909,3744,28440,45240,6292,176042,71574,438529,20592,12648,3708,362318,8216,8840,64543,16188,158498,13760,25840,36868,70512,14012,11088,29264,31198,30494,54126,5928,107068,13144,862358,31824,59487,25584,6136,12168,195780,1035648,22680,7848,234522,10088,17484,12312,7752,12376,168516,9300,13824,47690,6396,8742,67983,11160,352893,17064,15252,34056,16116,22444,217566,6308,62248,9424,254448,76235,4687,10920,13364,16340,22496,221676,42226,1807204,33540,2408315,15800,148994,977904,6650,8453,22444,59812,63911,14198,22831,6696,135720,173166,174384,8476,26660,40546,16112,17640,8246,21762,12502,50464,164715,15314,44802,53167,153983,46810,39816,5289,11024,7396,10192,4945,9672,8815,11160,26728,14577,16827,5891,7525,11395,37752,8611,204373,11388,19276,4824,4752,226352,114712,28860,237460,580808,12616,73530,37634,6149,5848,16727,7378,122845,161634,27838,39888,9204,8736,523296,5408,5700,9880,22392,65175,7236,16632,38055,9766,16956,28086,104000,53879,38592,36024,6240,179452,60952,10332,11514,14976,136332,7280,877176,49849,7181,6408,62963,28582,26961,17422,7488,5252,7267,10712,11218,7884,13825,6300,8208,3387308,13186,11470,10788,25482,90139,16016,33970,53768,1978056,113956,5547,602732,31824,144096,51452,11739,86989,69204,212334,9331,140620,12198,4300,66404,29326,15352,70784,7979,12220,5876,30032166,17918,133418,221364,15548,73865,74958,10726,49248,7750,132768,6751,155168,35360,17856,8632,30172,8280,47244,41808,18648,4826,128375,5980,10036,14400,14260,47902,27413,269328,57970,108224,17587,370822,25168,168910,5512,5220,17424,88846,774086,19952,90954,33264,10488,53072,2552885,8640,21166,6708,28677,13312,19916,11438,15953,185887,8632,25116,14062,8788,10633005,477672,22515,17538,24095,9322,19750,4750,45666,120328,11736,48269,101400,16598,7540,69882,1352085,117612,5408,37872,233834,5510,80064,8170,16827,28282,11524,1582920,7228,33575,66220,13000,9804,29230,24120,9120,5200,21488,15500,7228,32328,40204,6572,4558,7611,8164,34400,26307,8686,242996,28954,15010,13520,7436,5824,13946,23920,8580,91010,9538,60610,13364,78520,8856,35720,10660,40053,58500,4601,142911,61699,4066,22506,1044854,19874,23472,14062,49848,6396,11952,58222,1817902,11771,44640,9610,15028,16328,24700,13826,412982,27864,9576,479598,18648,344519,22412,169100,995400,5814,18538,8360,7852,11532,45032,13884,1775556,11856,777852,249302,7688,106468,81720,7568,50718,10062,7254,124109,13870,36328,109512,6262,6696,183528,18620,5396,45562,5016,23332,103106,8424,11780,11904,13156,4068,11960,21014,8736,486008,18644,15128,12212,3683544,7410,537984,149683,21888,43524,508752,11268,1096110,12798,7228,6232,14942,19908,4773,138961,9717,50323,12688,6330823,6448,198843,118792,64440,13728,22360,5074,8804,7900,6552,10292,95532,1364544,4816,4294,4608,5624,17860,87048,53506,8858,13803,32422,22880,7095,10726,792370,14664,60192,5616,11336,41949,17802,13746,6448,7936,6650,28203,124109,250303,45000,10512,26617,306599,16796,14872,4816,8060,6136,25560,252148,4386,16920,91846,14663,16120,4816,19592,18644,113444,19220,53998,24411,13640,53732,48934,33540,10540,7783,7138,29072,5356,68894,17716,18166,11336,40114,6794,11590,19800,27962,25284,20597,61516,12169,25560,5472,63752,5633,34684,31980,5590,67824,16182,14022,182016,15264,214406,49320,92448,11594,9568,2930368,871224,424008,7644,24192,59013,7432952,55480,46436,38220,59760,37656,9675,5472,15048,200294,7272,301731,30960,5168,5203,19908,118800,857880,34944,7783,477660,120080,11395,222552,5054,19282,3990,37999,49286,5074,299304,482790,6916,566825,287481,10602,16492,736632,58344,157508,27664,3688273,14534,8532,5289,441531,9804,322457,10744,46246,63674,51192,4988,5092,40486,7611,23940,107694,173352,8680,6708,12166,8729,39052,82584,7006,48828,514520,8127,13032,72996,23822,42480,18928,28224,6622,6500,34314,9322,32798,13746,16182,12338,4142,6422,23816,122616,62264,14782,8643,43128,11470,24480,4601,27133,11128,9648,1973088,9503,120280,12772,14457,282910,17372,57288,88846,10105,13416,100296,4730,20461,12692,43648,326088,19778,45899,82460,26312,21948,22403,5720,18792,28964,23616,4522,3398975,68472,12341,11222,5772,4978,215498,86490,32311,562875,16568,8474,5418,5590,33022,127152,9234,28458,154682,7654,96459,402480,39816,17301,22176,6572,17316,229732,69564,18476,35712,27032,6235,70735,132652,8740,16900,371108,1253063,5512,21888,7380,6882,92340,101592,7852,94326,15236,37446,5547,288113,6407,6510,9245,18354,527404,185318,95784,9204,189284,32400,53280,248248,6228,4028,8557,2650104,12240,8643,15500,166764,32414,25972,181168,15910,822888,7009,197974,78921,7644,44856,130587,671816,335118,20336,164304,28124,22824,8736,13578,8600,1907424,20938,9500,6820,6139090,30240,7956,32032,604810,10296,119808,22724,117000,140040,40820,657384,6344,118342,13717,9164,31668,49824,10640,268560,10902,162130,47736,9052,15066,4386,13904,9300,21567,99066,1122432,81700,6321,1168410,7192,79128,6536,30968,98197,1440504,37446,22120,26728,7956,21052,13082,324942,108288,143260,4902,110679,6552,9120,20708,11098,13373,36270,10584,23779,1296469,694440,10712,12456,13988,1010568,421290,79441294,14756,2472384,27170,88064,22360,4515,2110999,69125,7638,10404,309601,64896,546838,6708,7030,51557,19823,110050,7052,44304,27404,14276,4864,37683,95073,163530,7714,35932,545495,12524,10981,59803,268836,21312,33800,7800,6048,10224,473688,5762,178932,105196,295802,7482,37446,15264,12152,998675,11532,6760,4218,133036,321516,8736,141015,52200,9984,36432,136710,19708,795801,4408,537911,5980,11309,14456,37512,20596,164016,53784,138675,297830,46748,35640,88848,103806,46080,12008,518328,4712,5940,28704,45360,5700,15912,4142,69998,6321,7848,6612,14835,11455,31744,4515,20696,11008,9728,15340,200298,7783,7568,6132217,32184,33192,537844,45694,47400,16744,22536,16036,54036,21330,291668,384648,6156,17422,7740,21414,18920,284696,15912,5876,45012,4028,7592,495876,8471,4343,34504,54360,23779,44928,92606,163873,10664,17784,21204,192386,186010,9073,11825,213044,89507,219024,274680,2113704,14615,5460,8280,9374,298512,8476,10192,148614,6498,12012,15580,26918,343790,176881,522743,15238,1181998,4343,27413,98434,42581,16616,54994,6696,28423,7200,59976,7020,32448,9052,70434,1247936,4028,14652,87453,520531,11266,13490,136462,28964,9100,9288,5547,97266,178002,162184,19800,31824,137618,66384,46018,9546,5289,4902,150048,104833,96928,18705,50592,13983,12740,65175,7128,13260,23244,3800,41002,224044,10640,6622,52851,23940,7750,42192,16952,6270,133200,7740,280292,27950,5074,679572,5408,11160,10184,100804,6344,205088,9932,14400,38948,562030,7068,8436,7912,1083959,12528,7181,238817,16598,105694,7296,19840,16297,27432,68286,11880,25480,24095,34918,6084,25596,12480,20336,35150,8184,173414,11036,57668,7611,8295,4826,20384,24490,14457,25628,3744,150746,11804,7006,51272,17004,75582,7254,513648,1116648,16770,4294,6136,7258,6235,27248,8632,5824,16058,3960,1591218,118637,17775,10664,6321,191180,50482,13908,33180,11160,14760,41949,1846728,180471,22568,8164,124141,14248,7009,41496,11232,108376,11856,60788,16182,290404,139514,8342,43258,10036,9417,35048,32968,7106,8816,14402,8295,19448,34013,29111,3708,100812,9504,26820,100254,19344,17980,162898,1382500,9920,10191,9159,14147,29070,87360,18096,38190,225288,10192,18288,15132,34944,756288,145813,14508,96965,66024,400536,3057458,13566,16740,142832,1267160,35076,8280,84630,13566,13832,7006,323020,76320,5824,23296,10428,5396,26832,9158,4644,39259,6344,61332,75680,51168,11648,63812,50184,141252,5976,90060,10965,12298,14364,11324,16068,31692,6820,301392,21892,167152,534909,14190,31949,18980,43416,47736,16588,160848,455830,4284,201292,34523,4636,27612,7410,12064,7258,9396,71760,12956,12586,8840,6656,33927,5848,598680,7267,25929,7776,36335,48633,9796,22608,94612,4356,15084,15066,12672,10912,4386,7068,14061,52061,41904,55536,14688,61566,163990,21944,6346,189679,21199,7750,6500,15484,24048,21008,23746,8060,16068,9310,7344,56406,18042,127452,52456,8892,56011,72384,7783,8112,92752,11856,8122,9256,145018,9724,13717,25359,20072,22356,32916,10816,12648,10320,53924,7052,8476,4028,153698,90864,61940,16530,28830,5246,1145264,7638,368136,9858,26496,118658,18354,12116,93496,138320,5358,10449,6156,11160,21973,5246,7900,50402,52632,7912,6688,7224,19952,11440,7192,6708,22648,12688,5668,124558,9982,4945,14534,5719,260463,142792,26226,9761,18328,6422,298699,22672,768196,548018,15428,4370,623626,37804,23091,6864,26752,774832,164808,5580,20770,69472,26220,180594,4730,113688,84778,9164,8804,5320,144096,4484,5168,45899,27056,31200,4392,729926,21758,200148,235578,4066,34959,17980,53009,10222,247832,7488,25201,10764,186835,15624,33356,18936,149530,21024,8060,20020,71712,20770,14694,6760,8804,19221,6364,5891,4978,14773,6708,13201,34352,58460,4472,23750,8424,10707,7740,76880,10008,100316,30456,6510,22230,8968,23370,9462,4864,13716,25929,44793,10296,21660,133194,33170,292932,6622,8213,17264,5522495,9082,7696,6802,408408,9880,7812,14424926,22962,63468,10836,10621,4515,37625,5203,20520,194016,92820,5891,209592,27792,11160,255012,140936,261288,7332,9159,2011606,18216,6968,72000,39895,22059,5418,17524,12403,546285,4636,8702,57660,11388,16524,10036,25840,6020,14061,34839,34164,15089,21251,10664,12948,68888,74464,74256,6020,1200610,27588,26208,108072,8208,3838,4392,80166,96854,844116,4515,3914,2156622,9234,29202,17696,4822192,592658,55252,201025,22536,4945,12728,5564,7176,42441,67680,68688,8436,7688,2529332,10726,14319,26187,56544,150722,19296,4773,38552,63216,31777,94815,42423,40176,26936,109944,7124,87420,11210,7750,432388,24814,114471,34892,7936,52820,840244,10234,13752,56592,13104,68744,7992,8028,150258,4644,10972,5246,86900,121148,2379480,7596,561168,189384,77184,5564,7296,22962,11966,7848,13020,36952,54028,67467,1160068,851067,6032,4300,25992,93444,35787,6240,247379,144017,19158,11096,21930,370584,8736,10270,38502,29025,57828,22831,59598,4932602,17748,43443285,12879136,10244,11932,6660,7904,8804,5738,65592,594828,10665,127920,62135,4066,26536,52488,6278,7254,146984,11908,4484,28849220,14942,404673,230308,70122,88660,324636,4484,7192,407482,83460,427492,9847,18824,36103,10440,21027,128217,30108,18104,6321,12920,73568,3497330,24076,105958,5719,46452,9412,12896,7502,83700,11718,6916,24336,19220,4859,11284,12578,57196,165110,12312,115498,16416,36498,8322,16254,8944,17243,16430,390139,4978,17108,9396,36898,23088,4104287,129636,127660,3888,16200,75578,24016,32798,15236,83187,19342,9374,13896,332272,5772,27612,640646,13968,62662,22464,5460,537437,233116,665575,40896,53424,6880,6032,7072,8060,5074,108864,988011,17546,34286,170976,10140,5206,59171,115752,29760,17056,15953,17420,430160,78572,31648,42269,94800,5016,64440,7776,8471,67580,460728,75384,44826,746313,80659,5977,34997,13984,3952,190368,28386,11248,19038,10374,333301,13459,9880,21584,17316,12708,18228,83876,18275,22940,16920,31096,5358,11492,30324,60822,22968,5054,270180,10974,5720,15910,17280,48906,1042964,109951,1067454,4066,783432,54548,9234,23126,6760,23328,12768,5220,17280,422097,8740,10965,8164,6120,11180,10621,17974,1597459,1465213,14632,3714580,16353,5356,6200,4978,8680,14292,1366092,8690,90720,20520,15810,184544,39618,8928,68098,1280088,394108,12806,20522,11137,46768,37200,3876,446982,7564,20634,15124,69746,253270,90472,9656686,10788,45648,17836,7920,403295,26846,28334,16120,14260,7436,37224,21801,120270,6579752,255291,30286,8512,23712,27968,14782,12341,42718,4712,26784,7524,1567296,12578,16112,379756,4752,7697,16796,47601,5928,12642,22692,48152,87984,6292,76000,13035,26728,65728,4636,222859,9672,29016,8184,4601,4386,4945,52018,53799,7334,15392,6020,12169,7912,83029,253448,6820,194814,19188,19228,65145,83503,10412,5031,13826,2510820,301378,204594,10578,7502,8557,28086,6136,90432,37152,4750,21008,10728,18848,7752,64464,29484,7224,9880,16125,149864,858676,34808,9464,231480,8375422,98857,8424,104359,4522,81468,233616,35880,877982,106912,24118,5928,5356,3838,17538,16306,345228,25416,10044,41688,327218,15192,5876,16211,15089,8213,9196,23134,279032,47842,7396,14632,16856,11818,40560,8928,5865964,30420,61560,20808363,387810,75354,33022,15192,791440,5252,10556,6948,6992,22176,56160,116525,522106,5966,77710,451440,51532,18460,541060,226486,116784,26928,4636,1082520,1239431,13312,16368,12692,35030,7697,85699,6764,16432,11376,94213,442479,67639,70566,24490,11534,244556,15089,5203,16430,13578,52824,2512753,398634,8640,9464,527592,15444,36214,26970,7688,11346,4343,6188,403992,8474,19909,22420,114088,8990,7448,361741,33912,16802,213221,22680,5246,30616,5004,8680,23712,79236,10088,328290,11266,70784,4332,6407,16848,4104,32250,14478,23760,9766,6820,17484,7488,856755,13268,16128,6386,7812,342237,4248,13604,17316,133984,1571184,3839400,7697,5720,2716336,70308,16988,9724,13728,505293,27280,11395,30020,13846,21886,199004,98671,79790,65782,5200,7436,15562,8213,102410,146604,8626,21962,91640,38947,14931,731724,51116,8712,117390,44824,16748,456878,43416,7482,27404,809782,39990,531179,139032,27097,12236,8060,26860,17918,122360,27288,32469,84846,15093,12600,6106,8018,364032,35048,23446,73512,27664,94326,750184,5460,5396,13676,10793,29698,89139,17544,301948,9116,34444,6802,21112,6235,5200,19276,8164,32328,5418,9792,34038,24840,7488,21762,11218,15548,11196,54481,12272,5396,170810,12744,15563,117312,20708,9432,9044,8568,74261,1569113,79636,41396,5848,38880,33604,10584,10512,59272,11596,17856,37758,9417,5054,9842,109800,16632,6966,8580,259992,6552,18565,14612,21164,6300,17222,16678,435240,341833,18126,16150,9331,100434,5814,8580,75516,28028,168646,6536,6916,10792,7998,23312,7440,8740,112812,10192,20556353,19264,64543,9656712,13248,295568,16985,7904,8840,21584,12599,3522294,54872,7006,5510,21142,59020,7654,21840,7254,14536,24244,184202,44635,122335,30336,48348,322582,11656,11718,18662,56576,8684,22878,7626,42532,135876,163080,12956,6240,25585,63270,68241,8729,24614,262446,6708,34788,22828,22199,11954,9030,121432,1490572,4712,5203,6948,27735,13702,9920,44240,11076,89784,148986,76536,9568,26040,8643,122976,10062,3952,26101,5504,63550,275157,4515,26149,85320,9460,288143,2858324,423398,24016,6572,31558,232066,314352,64656,116604,14664,38844,768018,886143,10868,18476,8041,7228,19292,11997,798424,1494578,34782,15996,70742,11804,92983,29941,401241,16378,10140,14835,11596,753186,64220,1612627,14924,8216,30744,13545,7224,20145,11008,27300,10868,6232,23180,190706,40248,21725,17236,61857,18360,8060,10440,27792,4218,9994,11438,18430,26638,210930,48724,101136,40796,14554,5168,8848,7144,36577,20808,17458,18000,75960,367564,41882,37656,23472,5332,7181,333372,31521,279792,48724,5203,14835,7384,8632,1118000,11098,5289,15824,14012,11336,39744,23296,27248,81406,6794,21700,427320,21172,12648,4370,11058,80422,71337,7688,14400,142012,16195,123552,54720,23126,22754,332444,33904,26156,54560,32414,11139,39600,7568,18146,175392,47637,68651,166656,44044,61814,14782,10816,60610,6916,9559,13884,31752,14174,5590,13764,7955,97774,19512,3012665,6240,575989,19866,31720,138456,14536,4826,19264,11868,22968,8788,19750,62282,193544,90396,12341,8600,1925368,273208,10296,7228,4429,57722,860705,35092,4644,6665,4598,6794,11052,128098,524016,5356,34224,9362,4940,23580,8600,9576,21508,29016,7568,1153242,12640,68848,170877,31519,66774,6235,57164,90688,59400,128217,246844,34736,10507,22320,13680,58102,9362,125316,291668,10540,7654,63468,12152,15168,116920,5548,166611,9864,7776,235973,48152,110983,7688,5805,695952,24552,114076,255456,14144,82512,15912,463268,139384,393696,9792,164424,8432,8008,5719,66123,87880,1570441,214458,30816,375092,592105,10526,3924,967104,70128,12958,9589,5092,250900,92588,45741,150822,53072,50052,163956,12771,7502,2078024,15028,6732,7956,15964,18616,80352,10354,13780,3453959,13020,6063,1255176,10621,19656,34884,4687,13680,677730,6878,49880,13114,230412,29450,17928,8494,6156,16948,265124,44454,26312,561279,36792,61828,25359,8424,5460,63516,5616,31248,9360,16692,54696,1614548,5928,18000,33402,17888,37130,52772,227664,8018,112812,12948,4750,58867,7525,114504,36608,6552,20824,630894,14749,11024,4940,8640,28656,50592,16813,35412,264168,12376,11613,291408,7956,675614,3990,215928,422650,428792,106578,11160,9216,14612,10260,10602,408667,191575,20253,68019,67166,33418,5633,148738,11739,13932,29108,75998,34596,64666,704520,4386,296092,73075,164320,28122,7592,737781,6422,15314,6916,10507,6032,7439,50353,43896,8712,14706,472750,198120,6084,20488,209664,4068,802152,14074,5200,7626,13984,155472,14716,9288,10400,5117,55728,1215084,30992,7488,13082,596068,45448,6192,87152,13824,469339,13490,8208,134106,40144,4636,10586,397277,6552,469023,99386,47272,24885,290108,6278,34830,8690,321152,1529320,27072,3587688,34560,7704,6278,4902,482804,122512,7416,32178,5876,10140,6188,82440,106742,14706,9486,8580,8928,18772,29541,35424,161856,451152,7688,5633,574824,15010,4370,14322,10044,28548,7280,52920,9243,7138,257688,5160,527325,121024,10192,38157,35733,4644,22278,16416,25776,223820,570960,1386529,197972,7482,4300,60268,2610530,6878,4256,5928,9724,185115,49059,30780,60912,14248,43628,298566,18791,17160,35836,25110,6665,199001,14260,67104,8360,24209,17680,6235,8424,315456,46696,5616,25596,121660,13260,33552,431972,75140,36784,10088,7138,23250,10707,25201,26939,15010,12428,11596,4558,3990,18202,31104,21926,6820,2050445,12384,198606,8170,9158,76128,31248,6622,5624,7592,4968,117990,1425424,33101,5586,36576,23674,6292,70618,77976,44252,76669,14760,97696,17424,239295,7812,128180,5356,7488,690934,19654,32760,40536,16172,11782,52056,36244,5548,25194,14092,15696,9272,4988,50902,1291264,14276,17050,18290,17759,8352,12958,11481,1055440,107045,5200,16120,84882,7884,17372,16848,5375,5852,8094,107414,8550,25069,158711,9073,102960,5472,18723,312129,811014,417487,32860,9516,45942,13459,4256,15721,77748,11268,51840,12168,35402,12996,294851,4408,250667,12168,3838,81096,14457,10974,312481,40280,11309,8164,45012,78289,29484,4028,25740,198273,73216,555449,63612,5092,49348,8216,21964,88288,7344,4343,5512,33812,28340,1070888,24388,13373,142200,63437,21199,12744,542098,18275,24624,11088,226670,38750,8901,251299,34944,926484,30566,61152,9417,9048,27648,609768,15066,61048,5934,21166,4773,12513,85241,76700,6063,114638,1127883,112892,333640,53320,122044,17286,27056,12806,9256,16454,58344,6840,7874,5652,12084,415079,424574,23296,12480,102297,96668,13148,235657,57433,7334,21672,4370,4066,35948,388296,7920,49063,51116,7006,695968,8132,218088,12958,26445,4750,12400,1016280,2434104,42470,12502,162316,2064608,29625,32968,9256,5436,41791,25413,38088,2494346,323280,31564,7783,11058,33101,6084,10412,6688,70866,7717724,936944,12083,81528,17587,58368,18920,28124,1081184,9202,2223218,6136,33259,6812,8901,28912,6262,1268208,28830,6324,6324,7396,5244,43416,320952,107224,5246,11139,161772,8840,1886544,492404,110448,4515,4256,425258,5547,4945,20296,5160,6726,67704,71796,35774,285758,17264,6536,139356,11160,5117,55771,150021,12960,187467,5504,32034,600795,8626,10972,7332,86903,6448,41882,308396,10191,15264,97344,120317,19307,9516,20664,4370,13452,11804,179409,9331,61978,55063,324360,9331,7228,9796,15376,122766,122450,23392,21508,7634060,13201,139277,116288,8112,23504,7998,12943,7564,6923,19479,7956,5112,7626,675800,14074,13578,7525,64232,5016,80422,140146,53246,12986,19512,10152,8028,53167,9424,39960,11856,124920,8424,38952,21024,452876,79050,14760,7448,9216,32656,19152,871607,55728,33046,480624,19188,10222,19396,5282,152134,840086,17222,16120,23435,11440,155808,12040,256824,35561,6136,31758,1131552,54352,20640,15394,5130,5824,54264,23036,240002,8854,17992,39579,456699,25280,15168,149081,552064,32078,11514,198328,28124,16900,10404,76456,8496,9216,7332,8901,35561,59688,124583,19080,12168,6236464,832581,8496,19434,115111,18538,165416,6634,24490,6634,10070,56340,11058,30992,131298,13788,14384,472812,382123,45425,6579,840718,17062,6665,20210,25896,6916,45408,12556,9204,42739,51858,14400,437684,39494,13624,93783,7353,4826,29536,6696,6063,20708,193180,159264,13110,17174,63792,267264,192608,84538,1094178,8060,24966,16380,47994,28132,7869,335671,12920,33356,25064,7334,6760,197856,4598,68335,14896,7332,3952,10296,207762,7488,15438,15808,6552,7267,99424,136276,22464,87768,9976,11594,216697,37281,15652,102068,14688,4940,35256,66716,3914,4940,5289,6840,17174,15484,7644,95666,107440,30058,20640,5616,17538,8320,10707,27334,108432,5772,4180,3914,24624,5356,43524,40320,11932,79128,6536,11692,720502,31564,110542,23384,12502,105552,11324,156302,4534958,35672,485857,10902,11952,42581,51398,9776,36034,5738,10292,462528,38532,19656,79128,6923,20448,75096,51794,48980,56373,202802,4730,28086,13588,133510,14300,5252,311240,13794,4142,5289,64030,278720,11060,29068,5676,32379,425010,15089,126953,1689128,19604,6760,16328,14362,6408,42120,16328,118924,46689,6278,43316,378138,8816,8385,8374,4644,54684,50869,7144,4218,10902,10152,44268,121520,636272,10348,4212,13832,26496,112902,7980,13728,776644,62568,21328,69230,4515,56674,9048,2339585,9516,8784,12312,15336,13020,16560,10416,17784,10836,638058,56760,15192,6396,9308,24467,55728,582941,8742,7676,17160,20212,11567,30780,110032,7956,8060,155272,170196,91246,19592,26574,2004187,421860,10449,14760,18662,250704,59436,82947,9085,45583,7448,28272,4142,309776,210444,76235,34128,44714,7776,445176,402628,35776,15704,32153,56012,5928,198290,10270,3672,28768,62816,2098443,21576,7800,13764,8094,7998,278080,7904,22204,48484,19513,70876,537887,28810,62186,86040,8058,9116,12900,8892,13144,20232,30312,49928,5396,370352,19522,841745,5934,4142,4560,19872,7009,5054,8360,14184,13728,406348,10191,36332,110304,221052,12087,24054,2762946,4788,13644,17174,7482,9464,10044,6968,130884,23978,29172,5805,44136,6292,3708,71592,304200,32500,187302,109415,6760,66464,7384,8041,158474,115596,9724,117360,7740,4386,86490,93931,190112,10504,9072,15998,224992,8600,47874,10868,11076,42978,1014676,20336,8136,122845,30968,146232,25848,19292,89642,31600,16016,11088,7688,20336,8428,7095,15768,6200,106255,9073,4472,9890,19393,29952,12524,22356,35308,19866,21488,738966,16802,240864,17759,13224,20708,45074,4212,9300,21096,16056,436321,9030,4472,3566850,28598,13104,37969,7600,146940,6080,81432,102672,35392,59830,49770,650547,13320,17222,6536,62252,5616,139464,23908,7564,13156,5966,4320,1039464,84940,16469,93384,18619,48960,4601,50046,21164,6194,13870,7410,74304,6820,5160,10296,12524,14260,23746,16536,337156,18506,10764,194145,7696,7956,49680,9828,104036,5719,6574,12376,17420,6656,18318,248534,5662,4028,7852,28954,11908,41236,11232,55536,9401,13825,6080,9460,16416,8626,68944,8740,361267,8856,14136,6188,26149,29016,7750,27477,6344336,8928,4464,4522,13373,27056,42104,62479,18166,5117,6966,15964,1188606,6188,10726,39246,64414,31521,6864,9052,818763,26714,20461,1618993,5289,5676,11970,19080,2358876,70704,13052,71208,77584,25542,14744,53618,11139,17160,9648,13825,28210,21251,28203,5934,85952,12338,71574,5966,9386,43632,181896,5876,12462,80580,15562,13676,4028,913951,117473,7378,7254,4644,6396,6579,27512,16536,8170,1452204,8372,10492,812520,712975,11232,19096,8432,18724,39780,9546,28656,44424,9548,187426,6321,8664,5876,9308,15405,131254,2437034,15652,6448,23112,8476,159912,120120,15028,5548,7200,166152,116762,16391374,16616,12168,5891,7848,110916,7378,363320,56628,45537,59706,141768,307942,5547,2630700,10823,54622,38916,32240,478345,15132,6882,18810,222227,5668,9620,903997,18091,82713,5928,238248,77634,12896,2306484,6240,5460,6510,4408,4104,14668,17422,34918,19912,44578,340318,10478,47400,46136,22776,25628,22360,9880,23244,34162,2303238,19656,83898,267592,190008,91846,118800,7998,56169,9717,3852,3708,460917,1268856,6660,12688,493064,20862,37584,1157587,10764,118248,13208,9006,7176,16039,62496,38829,32184,4066,13330,5772,293169,893234,5112,8772,1062234,12814,625352,919274,113088,44556,22436,12719,368037,7440,30336,10478,2106326,1039561,28196,68112,165663,57350,28519,29704,365456,130910,39658,6032,291826,16692,1204412,400214,105768,49665,19722,44763,4066,15428,185966,86268,421496,17856,103329,218808,95202,5206,7904,40166,33748,8122,25438,61017,20736,722736,9933,342409,4560,12240,124682,22256,72842,12245,130312,67464,244110,44793,32627,23932,21488,5772,10452,13832,234422,8686,7848,72360,100152,91728,20376,10750,46624,18936,17212,32798,12255,10406,34996,7130,7675506,12502,459000,48111,4294,19522,20683,7280,20952,374539,18565,9503,118512,15552,4773,21844,9030,34048,15496,69757,10922,10902,17280,1191636,4687,5160,53878,4859,49849,34684,16432,49400,11180,82646,6758,40053,13752,9620,18490,64368,9159,7410,49770,218178,10080,210485,5418,8632,14554,42294,4142,9672,79116,8996,55214,252864,11696,37446,24130,550368,10906,18876,29625],\"yaxis\":\"y\",\"type\":\"scattergl\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"achievements\"},\"type\":\"log\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"estimated_sells\"},\"type\":\"log\"},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Scatter plot: estimated_sells vs achievements\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('2ff7d219-cab0-4ce4-8190-d86a5c9f3b27');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.scatter(df_train, y=\"estimated_sells\", x=\"average_playtime\", log_y=True, log_x=True, title =\"Scatter plot: estimated_sells vs average_playtime\")\n",
        "fig.show()\n",
        "fig.write_image(\"avg_playtime_sells.png\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "AnU7eosI9GeM",
        "outputId": "a2d54c9b-d4e6-496f-ee80-e36724cf8e15"
      },
      "id": "AnU7eosI9GeM",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.16.1.min.js\"></script>                <div id=\"8c9c6571-8ca9-43de-9a85-7d857207a770\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"8c9c6571-8ca9-43de-9a85-7d857207a770\")) {                    Plotly.newPlot(                        \"8c9c6571-8ca9-43de-9a85-7d857207a770\",                        [{\"hovertemplate\":\"average_playtime=%{x}<br>estimated_sells=%{y}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"\",\"showlegend\":false,\"x\":[0,65,217,1240,245,237,5017,274,0,513,5,53,73,0,2910,581,0,0,0,0,224,0,146,0,61,232,14,556,46,0,0,4,247,64,227,875,374,0,0,91,0,85,0,0,5193,0,266,0,320,239,0,298,0,289,0,841,1446,0,0,0,0,0,0,0,474,94,0,0,0,0,0,245,0,0,0,0,100,276,308,82,0,28,54,1325,2,0,0,689,0,281,186,0,44,0,521,0,0,3,0,0,0,126,228,45,0,0,0,1569,6,2170,320,0,209,0,0,840,399,0,0,0,0,0,296,0,0,323,371,0,0,102,250,314,3,0,0,0,28,1737,235,1373,0,41,226,2218,0,333,14,229,2575,0,279,5,0,0,37,0,35,400,10,0,133,0,368,96,0,0,1164,0,1,684,244,1094,607,43,419,152,0,0,235,0,0,178,43,0,331,46,0,287,268,239,263,181,11,156,0,285,0,0,213,0,228,0,0,145,1409,12952,120,0,0,32,0,174,0,341,121,0,63,201,0,1702,305,123,0,0,0,80,0,1,5,0,13,330,0,0,762,185,0,0,39,0,327,232,325,0,0,36,49,42,0,0,0,1024,123,0,109,240,75,0,278,0,227,0,0,282,1,2834,77,0,0,0,0,2,0,281,184,245,139,0,0,0,0,64,204,47,111,0,0,0,55,223,0,6,1004,1636,0,3248,0,0,0,0,0,760,0,7,2,0,0,522,0,0,0,218,384,88,0,82,133,0,0,1,15,0,0,347,892,0,0,0,26,0,0,0,1,85,242,56,0,0,188,0,322,1686,212,229,0,0,115,0,0,236,0,162,0,2147,39,0,317,251,198,1716,165,191,0,0,323,305,517,0,67,0,0,122,0,0,0,127,0,43,2,1,235,135,0,0,0,17,0,3,83,0,6,0,268,0,1597,0,236,270,87,93,0,221,33,0,189,242,644,302,0,0,0,34,1045,1,2766,256,0,0,517,201,0,0,0,2511,249,3,382,4187,584,75,167,243,189,18823,0,0,826,207,130,26,0,1255,880,0,0,0,0,242,125,416,0,335,679,7,0,176,146,0,68,71,272,0,0,41,0,238,4048,89,228,993,3,0,0,0,280,321,427,0,162,0,287,6,0,10659,0,0,8,542,0,0,0,137,0,67,267,0,449,229,387,20,132,1624,157,0,229,141,222,951,171,0,0,382,0,16,347,518,2492,20,752,592,0,102,0,0,1,134,27,187,0,287,1954,272,12,260,0,140,317,0,0,161,0,881,0,82,234,0,0,517,347,0,1911,507,921,0,0,0,254,308,0,0,99,82,0,3,222,9,0,206,0,0,0,0,20,413,0,0,135,274,529,0,0,817,20,0,307,495,1255,538,0,0,367,36,39,268,0,338,1008,495,2868,0,483,192,18,221,4,166,0,0,230,0,75,0,0,26,112,0,5185,130,167,341,0,0,9,419,1560,0,0,0,3556,267,63,0,14,0,114,412,0,0,231,0,139,0,0,0,126,0,239,18,1360,12,556,0,180,227,4122,0,234,306,0,1350,0,484,30,0,0,0,16,731,1756,200,135,153,0,0,0,196,22,899,0,674,0,0,0,0,0,1084,0,0,323,0,0,541,337,0,0,82,0,261,0,85,0,73,664,1069,223,0,0,868,55,54,1254,157,1278,744,0,11,469,0,0,120,173,0,0,252,346,3958,0,0,0,0,163,227,0,8,0,863,139,252,0,21,306,2331,1328,16,0,0,274,197,490,0,0,111,0,0,0,456,0,705,0,0,3176,0,0,2,205,0,20,139,0,1273,130,200,195,230,0,359,0,0,0,1,0,3584,0,283,1584,0,174,0,1417,764,863,0,0,0,2,260,132,201,0,0,0,19,0,0,0,444,178,214,57,173,244,262,202,276,578,32,0,569,0,196,0,86,756,352,0,218,229,0,0,0,1712,256,0,0,3292,0,434,19,378,0,209,2380,0,13,0,0,121,112,53,645,0,207,0,95,1869,5,5,183,5123,101,0,0,0,464,0,16,0,177,0,0,0,5889,2819,0,0,151,211,0,0,223,209,493,182,0,87,76,385,0,0,0,143,162,0,201,0,0,21,73,150,0,0,2639,40,6332,0,134,6362,0,190,45,399,0,0,277,0,0,251,0,0,124,0,196,0,218,0,0,120,0,0,583,0,0,10,1554,341,15,0,210,6,0,212,970,0,0,0,267,153,417,313,324,0,0,261,0,282,0,100,0,439,118,142,0,11,38,4104,0,0,422,0,0,454,0,0,252,44,232,63,800,447,0,0,0,384,203,0,950,0,0,26,0,462,0,164,0,15,0,0,0,79,254,1413,280,211,216,0,1993,237,0,207,0,0,0,2033,465,2418,0,338,0,0,0,6,971,0,96,88,62,0,0,391,0,476,56,0,200,90,371,17,0,0,0,229,346,0,337,0,0,515,0,0,953,0,251,220,0,607,0,3601,0,0,0,2,16,394,326,0,70,221,206,2379,133,74,0,30,23,140,20,17,142,8,0,0,0,3233,9,2991,751,24,0,20,0,0,413,5,214,243,1520,0,0,799,0,49,165,0,117,0,50,0,0,2,988,11,0,117,221,255,137,0,0,324,0,0,257,0,178,823,951,670,289,0,3497,160,0,299,0,167,338,0,1731,296,200,55,6,752,1,17,0,0,246,120,0,0,0,2661,0,0,16,1616,0,1,0,0,8659,0,0,0,947,10,0,0,217,0,13,0,146,408,49,0,0,0,321,148,385,0,0,0,0,0,1772,439,0,0,0,0,672,538,159,15507,0,0,0,32,148,0,1286,81,421,0,0,0,0,2,172,130,235,1718,54,0,0,1232,3151,519,0,144,219,172,0,224,0,0,0,0,0,27,102,533,0,8,0,0,0,349,0,0,344,29,72,1545,124,275,0,3,10,9,59,58,8,0,526,0,310,807,21168,1,645,1,0,157,21,155,282,294,78,0,0,0,0,0,40,0,0,0,0,207,0,0,43,430,0,99,0,0,518,0,34,0,21,339,639,233,0,0,3498,999,186,0,87,1,0,1,288,223,0,957,206,0,0,0,0,1432,84,0,0,0,0,0,0,0,0,0,0,0,307,0,95,1536,15907,247,640,99,222,0,289,0,209,292,0,0,0,152,8,4583,0,475,0,0,2191,148,255,0,136,869,266,0,0,526,0,337,0,138,454,175,82,60,0,157,0,49,0,215,0,0,135,0,420,0,0,35,0,147,80,7117,0,0,0,891,0,0,208,116,173,471,132,0,1,373,5,0,90,223,0,75,0,0,21,224,0,43074,0,0,414,0,0,0,142,36,294,22938,94,0,0,8,0,298,17,230,0,69,628,0,611,0,161,0,143,501,272,275,0,0,0,274,0,6512,0,0,220,0,129,46,0,0,269,99,123,78,0,265,217,200,25,0,0,0,0,0,80,0,241,103,0,218,0,388,0,0,46,0,0,0,74,0,62,321,198,0,0,129,0,294,732,9837,0,43,205,0,0,362,0,0,222,341,0,27375,243,75,1293,0,0,0,5,0,65,805,291,303,405,2235,84,537,677,342,774,449,0,19,0,4164,4,247,240,140,68,0,282,1,5760,157,2,0,997,478,1369,0,58,228,596,0,1262,92,0,15,17,35,0,0,34,0,0,0,0,0,236,0,136,0,4,0,116,506,166,330,56,0,73,0,0,204,203,338,77,0,2755,0,252,0,95,902,0,446,1854,0,0,2356,4,0,0,3499,27,54,0,0,17,0,0,0,0,0,571,719,586,75,57,0,0,102,0,213,26,131,228,0,3,0,143,1127,0,0,0,501,404,0,667,0,174,253,135,0,216,218,415,0,0,34,3234,1687,303,143,61,10,0,0,505,0,548,91,13,320,490,0,15,0,213,297,2016,9352,282,204,355,3,300,0,3189,0,284,354,0,0,709,0,28,209,43,0,0,223,0,0,15,284,230,278,309,3609,235,67,232,80,0,527,0,466,0,187,289,803,0,196,233,10,0,0,0,478,0,206,17,414,364,1,0,0,319,261,342,169,12,0,0,0,229,0,175,108,0,216,156,964,427,2180,224,116,231,307,3,0,0,0,0,80,0,0,107,761,0,348,1,0,84,0,0,0,39,1,318,66,0,25,187,0,0,51,0,0,0,0,0,258,0,0,633,0,7504,1986,233,431,0,0,14,234,0,0,0,200,223,150,2107,88,0,8180,0,10,0,211,0,301,14,7089,218,97,768,0,304,0,82,311,0,0,0,85,350,0,912,0,0,522,10,0,13,0,0,437,0,0,0,0,6,297,1225,1103,13,137,0,0,319,0,294,24,0,175,0,90,0,203,1,0,5,242,121,0,185,0,0,0,280,150,1,0,2,0,0,190,1610,0,0,0,0,429,22,433,0,0,1117,429,223,211,622,455,0,163,48,0,0,106,222,0,129,0,82,143,0,193,1891,0,383,0,282,0,139,0,0,225,111,231,59,0,2,88,0,40,9,17,35,14,0,0,187,0,0,0,0,212,405,181,596,0,109,209,0,0,0,0,1135,0,0,345,539,212,0,0,0,0,0,897,253,476,255,50,0,278,0,0,0,8,158,0,83,0,0,0,0,18,0,0,217,0,66,0,132,9,133,0,177,0,29,2,0,949,0,0,0,0,8,0,222,189,0,0,0,0,12,129,0,386,0,75,0,276,1416,0,295,0,0,498,0,994,0,663,0,8,0,127,261,0,286,188,89,16,0,0,0,0,223,22,185,0,0,26,0,217,0,0,107,777,0,1164,0,8,3,0,447,0,219,386,6345,0,999,300,143,0,0,53,0,0,0,0,257,0,133,1930,0,0,222,0,586,0,0,0,133,5,0,178,0,0,0,0,0,0,0,0,0,1244,312,0,6704,226,0,211,11,1153,0,8,237,272,0,112,19,0,62,1854,0,0,0,0,229,0,248,669,2654,11,0,0,1218,282,0,213,7,4,0,41,0,212,359,0,227,162,551,1824,90,379,0,1160,152,0,22,0,0,273,199,346,7,0,0,15,0,28,52,0,37,0,0,0,0,4034,3,3824,0,185,187,21,81,0,31,0,315,0,1595,570,0,11,233,95,155,0,221,0,0,121,309,0,145,0,200,40,187,245,342,66,0,59,117,620,232,285,121,0,0,62,257,0,0,253,0,0,194,288,33,350,80,476,118,0,15,818,13,281,0,103,40,150,0,0,169,1149,8,0,256,111,257,0,0,0,128,282,0,408,0,144,116,1556,504,46,0,186,3925,95,431,135,254,9,14,545,0,249,14,93,80,187,33,453,0,0,175,0,51,1529,183,285,0,97,0,0,264,255,234,0,0,0,509,0,112,0,156,0,28,0,101,84,0,1571,0,0,124,358,281,0,173,94,231,91,348,0,0,0,494,478,0,303,0,701,65,0,0,107,180,1,157,0,386,3736,133,0,52,132,28,4721,0,0,0,128,9223,110,225,3,2580,0,356,216,65,181,897,0,0,906,101,220,435,0,0,0,347,2078,0,1520,204,0,227,0,150,228,0,0,256,301,238,0,0,0,11,329,0,1,9,0,230,28,218,134,202,99,35,0,0,53,682,0,495,9,561,29,0,308,168,0,359,0,309,241,77,0,90,352,250,443,82,42,7,0,5845,0,0,0,1868,0,325,257,0,29,0,266,98,0,258,0,358,0,59,0,0,284,291,0,217,175,0,42,0,82,0,0,0,139,30,0,232,0,309,0,0,0,0,204,6,67,0,134,0,343,21,0,254,0,0,587,0,837,0,0,292,222,16,3,250,0,0,0,272,0,0,384,12984,119,33,144,234,45,3967,0,0,469,50,0,0,0,388,5,11,100,0,0,1112,151,422,0,0,2957,3007,100,0,152,0,76,0,77,0,519,0,0,0,0,73,25,321,0,0,142,27,163,152,37,0,0,193,3,272,26,710,916,0,308,0,491,196,0,289,0,0,4678,0,393,14154,331,0,4420,0,0,0,0,0,3371,0,24,0,2967,256,207,263,125,225,0,0,0,13,292,0,0,0,202,744,36029,230,23,0,0,331,53,2622,0,381,0,317,0,0,714,0,617,9,102,0,305,0,0,208,0,0,759,0,277,0,0,0,134,4,13,627,3,28,0,572,1014,30,0,0,206,655,325,0,0,296,0,0,0,0,0,160,0,219,70,1034,303,0,268,54,183,0,0,0,4,82,0,2343,0,0,0,149,809,52,0,863,0,0,0,175,19,170,222,146,991,201,0,258,256,0,1299,148,233,25,64,113,0,130,0,175,25,221,0,18,9,214,949,435,167,213,1213,350,0,0,1445,268,0,0,0,54,1711,157,127,283,247,74,76,0,0,191,2259,0,0,0,0,1337,0,289,0,552,322,409,35,0,148,1242,205,0,28,413,13,59,258,53,0,220,14,688,0,0,0,45,223,0,0,0,169,326,0,23,0,0,948,0,239,1030,325,0,77,243,0,0,12,33,383,75,272,332,283,0,2094,2486,52,173,403,0,0,0,19,13,0,237,0,254,0,0,0,0,0,162,946,34,542,0,67,0,391,0,0,131,0,0,16,216,0,125,477,195,503,0,10,200,5442,712,188,0,1625,0,0,43,759,606,158,80,1433,310,37,0,0,148,132,0,250,0,282,13714,11,942,154,201,72,0,77,0,0,0,100,577,0,32,1136,345,0,0,0,76,0,0,9,74,0,0,18,0,64,2138,220,493,291,6704,125,0,0,0,0,269,309,0,773,2092,0,0,0,681,158,0,0,0,0,258,429,204,205,266,139,50,5,123,189,0,0,331,249,0,3830,0,1,217,0,0,9,14,0,0,0,891,2355,198,0,8,0,288,63,7,366,0,1108,2454,480,9,9,128,75,48,296,216,0,0,91,1228,7,0,259,0,1048,614,0,117,210,0,182,64,22,0,0,244,171,0,225,252,36,0,31,264,0,0,96,0,716,314,0,0,6,0,0,0,0,6,0,311,180,232,225,0,0,0,46,0,0,301,0,0,0,1,169,0,2273,241,365,0,0,17954,117,0,0,0,0,304,0,0,119,429,0,169,608,192,675,221,545,0,0,0,288,292,0,0,466,0,339,103,467,0,0,0,0,240,246,418,36,0,216,792,0,332,177,0,0,123,0,0,0,0,0,0,0,397,0,197,619,361,2577,0,0,0,0,0,0,209,264,0,15,169,530,0,16,10,17,1683,4252,0,388,85,2602,149,635,0,0,352,0,441,1264,1300,0,293,0,0,0,0,194,132,271,0,219,0,0,221,0,2974,0,0,164,337,362,5,0,0,402,143,233,183,55,133,388,3,226,0,78,0,0,0,873,74,0,139,450,0,0,1042,636,292,276,360,0,0,0,0,178,295,1234,244,0,0,0,233,21,3,862,0,1678,14,310,219,1177,319,0,217,0,202,75,2,0,6,0,0,0,319,0,286,69,0,133,0,4730,0,0,1866,0,0,62,0,135,165,365,0,2,444,193,0,0,124,586,1364,0,180,1541,0,0,0,165,98,84,637,0,47,7,112,3140,0,1334,214,0,365,4,0,510,240,0,172,0,530,351,0,86,0,0,0,962,647,0,0,0,0,0,54,8,4222,0,916,8488,0,76,255,0,0,0,74,1,0,0,0,0,831,202,0,0,0,0,38,0,0,136,0,0,0,113,238,237,0,0,575,252,25,0,0,76,0,110,203,0,0,27,249,288,0,302,95242,177,54,288,13,0,791,232,89,220,15,457,31,0,207,121,812,379,589,522,224,9,0,271,0,249,557,244,19,1834,0,1697,91,0,318,698,1102,0,0,292,0,193,281,239,0,0,0,0,213,178,65,0,0,1371,0,3,0,369,732,115,0,24,27,0,9,0,12,623,0,0,0,0,0,248,296,0,127,0,0,0,0,354,328,99,142,0,0,0,0,0,0,345,0,0,0,2059,0,4,0,0,1360,1366,0,1200,7,0,255,317,304,0,31,670,229,64,1543,180,0,0,0,0,793,564,214,2018,0,0,0,0,0,220,0,1279,199,136,227,0,35,1,0,0,0,1,935,312,0,241,327,137,501,3755,9,0,37,0,219,551,0,0,348,0,0,0,20,130,55,102,478,0,0,889,0,0,0,0,1617,0,0,0,54,0,0,255,0,100,3,168,0,375,0,0,215,0,0,256,0,838,0,188,0,1,0,305,69,2284,247,128,247,0,0,160,0,237,466,0,92,0,2721,0,0,147,93,0,210,0,0,0,0,0,0,0,0,0,0,158,275,0,364,8,327,0,333,311,1388,233,176,406,8508,0,49,242,71,0,0,167,3,396,437,0,0,98,0,0,577,0,0,0,219,22,11,109,835,64,275,114,1387,0,167,0,0,0,6516,206,73,1207,135,226,348,0,161,248,0,0,0,0,0,0,4823,0,109,0,28,115,215,7932,73,55,0,0,0,199,15906,0,0,0,0,862,0,0,169,624,215,0,76,778,17,30,0,0,274,97,0,220,44,0,15655,41,2,0,34,26,7,215,0,3,0,5439,0,260,0,203,0,0,207,154,11,173,174,1176,110,55,0,0,0,0,13,215,45,256,142,0,36,0,52,243,519,0,320,0,0,23,0,1329,0,282,0,794,108,20,0,273,188,98,0,4866,0,862,0,0,0,206,1084,332,0,0,284,7,0,0,0,0,592,140,0,0,385,0,0,278,11,0,0,0,149,23,972,691,0,0,278,307,201,177,0,0,0,0,0,72,157,518,0,0,13,0,44,0,588,0,229,3,0,0,0,229,253,7076,0,0,0,58,0,130,0,6,14,0,0,0,31,0,0,31,168,125,0,7,0,3739,278,285,0,17,282,195,0,2234,605,0,91,0,0,19379,0,40,51,127,0,171,0,166,225,0,0,0,318,0,0,14,95245,0,339,240,230,417,189,159,0,2,0,100,16,251,20,0,0,3,0,3,201,0,1,262,0,27,199,122,20,271,287,0,76,162,263,370,51,2038,244,13,41,0,0,397,0,198,334,0,0,0,0,400,435,369,381,0,174,24,0,56,167,0,36,0,472,315,0,220,44,0,278,14620,359,589,0,524,0,73,3034,0,21,0,0,113,271,0,0,214,5448,200,364,26,274,0,44,0,0,0,75,231,0,0,272,962,150,114,0,0,0,213,0,0,242,3,0,0,0,332,5,258,229,0,646,0,0,0,96,135,175,822,282,313,25,8,0,0,29,220,411,177,0,217,129,0,1,437,213,0,0,0,6679,161,270,0,4,0,0,453,15,467,6,0,229,0,0,0,262,0,238,1265,79,0,0,270,0,0,432,0,604,78,1,60,0,0,0,0,715,0,0,0,11,48,257,36,290,1209,229,1178,739,227,3530,0,3,338,373,284,9,583,0,0,91,157,0,20,0,0,417,12422,0,417,312,0,11,484,0,31,0,312,10,613,222,1,0,982,0,140,83,0,0,39,0,0,0,0,237,16,423,0,828,180,618,0,607,0,0,422,323,2115,0,0,258,0,214,117,40,168,0,0,0,256,0,270,239,0,773,3,84,4760,652,0,89,297,0,0,5,346,1474,0,1995,673,0,0,13,1142,0,0,613,1800,0,348,0,440,0,0,1661,254,1,209,312,0,0,422,0,0,0,264,0,170,0,0,0,0,0,387,96,297,535,271,0,0,258,0,0,149,272,321,97,0,705,1448,0,9,276,487,285,0,186,663,0,9,191,0,0,939,134,500,0,255,121,23,0,0,180,224,138,214,253,222,0,130,0,316,10247,271,2443,0,59,0,207,289,1,96,1030,104,430,166,456,44169,0,0,9,78,289,124,18,0,140,178,0,287,4,0,0,124,0,0,0,0,508,163,0,197,0,0,126,0,0,0,4925,0,311,394,0,163,259,0,2025,0,0,0,0,6,0,607,0,39,206,6842,284,225,213,116,0,364,0,238,28,0,0,2197,803,2,0,0,0,38,131,0,0,0,17,0,0,0,2514,249,13,0,233,21,404,105,0,0,0,20,201,191,6,0,29,158,0,0,0,0,0,0,21233,0,0,672,413,0,0,96,102,736,441,264,0,0,0,114,3,0,0,0,319,0,343,0,14,748,0,0,108,0,0,647,0,8159,0,0,0,77,0,162,326,32,0,284,0,324,0,157,150,408,0,260,9742,347,20,0,0,74,7235,57,69,96,0,0,0,0,0,114,0,527,4,0,92,184,934,28897,159,84,636,62,0,81,23,0,232,70,0,0,93,3020,0,172,205,0,0,10647,368,1848,0,1848,50,0,0,805,0,466,0,0,604,1,0,513,48,0,0,29,317,0,0,0,27,0,0,0,224,364,0,181,53,0,53,278,0,204,0,237,0,0,400,1,0,0,0,0,76,0,0,0,74,0,12,0,0,334,22,499,0,188,71,0,638,0,35,279,0,223,392,0,0,539,9,305,2,36,0,284,0,0,236,85,141,943,0,749,64,0,240,0,138,1277,0,125,1102,0,0,0,0,264,376,0,145,1024,220,186,478,0,20,260,0,87,327,443,307,0,14,0,296,1,0,0,5598,1351,210,810,0,213,0,63,131,13,285,25,0,1108,0,0,0,0,434,502,331,316,1905,0,0,237,0,0,479,1045,0,0,0,261,0,22,555,0,192,0,36,136,255,0,20,892,361,390,42,0,240,0,0,3,563,0,121,0,5263,0,0,127,7131,235,273,189,1399,113,20,746,0,398,0,0,365,656,0,326,0,438,0,241,0,90,0,0,0,14,275,23,0,769,0,7,0,237,103,1922,267,3,0,0,24,298,554,27,131,0,102,252,0,0,0,0,179,0,143,428,320,0,0,182,2990,203,23944,0,1037,0,198,0,0,1614,12,17,0,409,283,395,0,0,449,0,0,0,125,0,126,0,0,0,18,0,0,360,0,0,22,674,0,31,0,0,0,228,0,254,187,306,0,46,0,127,478,0,211,0,165,326,190625,232,195,272,0,229,0,4367,1,389,203,0,344,189,72,372,133,57,384,4,0,38,248,0,0,485,0,0,1061,355,0,0,0,0,0,127,0,0,115,330,0,346,236,0,0,873,0,0,2953,168,262,486,151,24,1709,0,0,92,137,229,353,8,404,0,0,0,639,288,0,137,0,0,992,49,0,0,283,0,0,0,2832,11,0,0,0,283,2,277,613,0,713,182,363,10,0,0,0,295,0,0,2902,0,524,12,2,432,127,2343,0,340,91,14,86,134,262,91,0,489,0,0,153,0,0,170,488,0,0,35,324,0,1564,1159,0,87,0,0,83,128,887,0,294,411,49,103,299,0,0,107,97,309,0,117,0,319,373,0,325,0,0,24,57,0,129,133,0,306,0,0,0,249,0,149,191,0,1455,3,0,0,0,6,324,0,0,242,680,0,0,0,461,102,0,1163,10,0,0,477,255,0,122,0,123,0,991,163,11,218,243,19,0,301,11,0,0,19,0,0,17,0,94,0,3865,0,0,322,0,231,12,257,85,0,0,0,257,337,125,0,0,0,0,319,29,0,0,388,183,0,0,6,0,27,91,266,78,219,0,279,8,0,97,0,216,0,248,0,195,186,0,3315,0,0,151,0,0,0,0,0,0,116,0,0,87,0,0,0,0,192,408,1046,0,17,0,270,139,20,1,7,432,0,0,119,43,1355,335,0,344,146,622,1470,0,0,337,2672,199,0,363,0,0,0,1441,1818,0,0,0,0,0,1,0,0,0,77,803,853,0,0,29,69,0,148,0,0,0,0,0,777,0,503,198,237,369,0,2860,0,0,765,0,296,423,0,1047,342,0,0,0,226,0,0,0,0,317,189,233,0,0,272,34,0,0,84,120,0,0,140,0,353,12,61,477,0,0,0,414,0,0,0,308,121,8,0,80,11,0,0,0,0,0,108,0,2112,0,0,773,0,1993,126,231,155,76,0,96,169,203,0,192,621,0,0,425,120,9848,346,228,0,35,231,0,352,22,716,109,0,0,0,0,2741,0,206,0,0,879,72,0,213,424,0,1,0,0,20,0,2,8,863,0,30,1500,0,22,0,327,0,0,0,2,0,228,289,308,292,51,279,0,0,0,200,0,252,371,0,0,72,146,16,306,5,278,155,0,0,0,0,533,285,151,169,4,366,0,37,0,0,0,0,0,0,452,0,1397,543,0,121,0,2,37,4289,0,99,9,154,0,683,0,760,0,301,0,124,185,0,0,0,0,220,0,691,290,0,0,0,15,0,0,0,0,0,0,0,418,0,307,0,0,0,0,0,0,34,0,0,0,238,0,126,0,1,6,2485,0,0,0,630,193,0,4942,419,0,0,0,0,21,0,0,25,166,0,262,176,210,249,270,272,0,0,736,0,381,21247,82,39,247,0,0,178,0,0,408,216,0,0,0,644,22,186,275,0,0,222,0,0,283,0,0,4431,138,246,321,0,0,0,1,48,227,0,0,760,0,338,2,162,112,244,87,28,5,0,0,23,0,0,232,31,0,10087,0,0,0,2951,4,0,0,67,0,73,10,0,214,316,184,0,22,7,0,604,0,162,11,0,168,209,0,370,222,954,0,6,0,826,0,0,0,77,56,807,0,882,261,148,0,0,14,0,0,0,200,16,0,421,612,407,208,0,67,8,0,394,57,0,0,0,969,0,0,0,404,1904,115,0,675,0,8495,3068,469,0,0,0,0,0,0,564,0,656,0,0,53,80,8,0,819,0,0,3975,0,182,68,75,0,1326,648,0,639,47,2735,234,527,8,0,0,1623,0,0,341,686,0,1111,0,453,232,285,0,381,253,0,252,0,0,529,0,239,0,69,160,0,108,0,1154,0,0,0,3,121,1394,0,182,217,0,0,836,364,322,0,236,22,0,270,21,68,0,236,0,68,0,0,15961,0,0,550,0,46,856,281,0,0,294,46,0,301,0,69,754,0,281,118,211,0,507,76,0,0,223,0,778,142,0,0,107,0,222,324,0,3,232,0,0,1251,159,0,121,17,0,443,0,0,0,0,277,244,0,351,347,0,396,6,0,274,0,27,0,260,96,0,107,0,455,0,0,0,69,0,5046,629,258,0,164,51,0,168,0,0,73,0,0,237,0,0,75,0,0,0,0,260,1602,0,380,0,0,0,0,0,0,1231,0,283,248,0,307,0,0,31,932,1752,0,0,0,3,307,0,288,0,26,0,1302,0,1244,4822,0,0,202,0,327,199,0,0,86,0,170,333,5647,614,121,105,155,19,0,0,47,94,0,0,181,250,142,0,152,0,2583,0,2938,232,0,0,386,1373,0,401,0,118,43,0,137,0,658,0,0,0,0,325,36,0,214,0,0,238,1070,156,0,11,0,0,73,16,0,0,0,1121,2550,257,0,0,0,5237,0,122,0,0,173,0,39,83,14,197,0,10,0,0,322,0,256,148,4200,0,0,74,0,334,228,435,1055,219,100,0,232,0,147,0,137,48,0,333,1108,0,0,0,33,20,0,17,125,23,0,0,0,50,0,0,1070,0,0,5585,198,221,13,0,2119,0,129,0,15,0,0,188,724,0,17,1204,0,0,724,18,271,286,0,524,370,188,0,50,264,0,113,146,1,0,207,172,0,0,315,23,0,0,0,0,14,195,3835,46,314,476,1201,189,196,0,8,149,0,0,984,1448,0,0,805,12,0,133,192,0,90,242,0,890,0,0,434,0,215,1240,0,0,126,268,1180,0,280,0,231,0,0,277,0,712,0,2908,0,0,161,0,0,0,105,1062,8138,196,0,170,0,0,0,0,723,31,61,1107,9,174,570,99,128,183,0,0,0,222,300,1871,3,0,0,46,1,1559,172,0,0,1,10,12927,89,0,0,826,363,277,1264,140,0,290,242,335,448,1281,1,180,0,0,0,0,445,0,105,0,0,19,902,0,0,132,47,0,147,751,2029,0,7,0,183,0,0,0,0,0,0,0,332,215,218,123,0,0,135,37,4,0,1064,222,14,0,214,0,0,0,0,1987,8,0,143,365,0,19,6,1518,11,0,0,24,0,0,187,52,0,151,49,0,0,115,0,0,37,0,231,185,0,568,0,130,0,0,13,487,313,0,222,0,4,0,0,0,361,0,1615,0,191,5904,38,849,0,4,0,43632,0,1846,0,0,0,271,3,256,0,0,22,1294,34,34,497,63,10,1642,185,0,0,250,224,216,308,337,342,337,105,0,43,290,54,1,574,0,77,57,0,0,1970,374,303,275,14,0,0,0,0,34,411,0,0,73,0,0,267,0,533,0,90,179,0,0,0,669,0,0,454,166,1266,251,0,0,5,188,41,7,291,143,666,1270,1087,0,0,0,0,0,212,864,2106,454,382,336,0,85,7,86,496,210,175,0,686,58,140,0,0,28,0,15,0,0,7194,0,13,0,557,470,50,0,38,0,22,184,0,0,0,0,0,0,750,127,0,871,0,0,0,0,0,6,1016,28,58,90,0,0,0,0,0,198,58,505,342,0,0,0,0,585,0,316,3,1,0,430,0,0,39,382,0,15924,0,0,0,0,227,284,262,0,258,0,254,46,467,6,518,23,0,0,29,0,187,0,0,351,707,189,106,0,763,0,422,80,259,0,0,0,0,252,0,0,46,271,257,0,723,0,32,41,0,0,240,0,154,339,101,55204,84,282,0,0,1835,100,5,255,0,58,276,0,0,0,0,206,0,59,174,0,0,0,0,17,335,0,0,580,0,354,54,145,78,0,0,372,603,332,171,266,272,5,0,108,0,12,0,338,194,73,0,203,0,0,147,0,280,0,0,6,73,0,0,0,501,0,193,547,0,0,0,586,184,243,0,9,0,0,0,0,195,658,434,223,494,329,27,0,1073,740,188,0,0,1909,93,0,30,0,491,568,0,0,9413,256,0,0,0,10,152,0,815,1051,329,0,636,10,201,65,0,75,851,86,12,0,63481,3,250,662,0,131,506,4,0,341,0,184,0,3,0,81,0,432,2,215,108,348,241,244,15,0,18,142,0,0,123,227,0,149,0,2713,377,0,1336,183,11,0,0,0,0,0,0,178,2021,280,0,166,7,934,0,784,150,4672,163,0,7,0,0,0,1433,241,84,152,153,0,0,0,0,1,0,27,317,17,1497,0,246,101,297,132,0,879,0,13,0,100,0,0,273,141,363,380,46,82,235,13,199,0,991,0,0,0,722,217,0,212,0,0,365,798,213,0,0,613,280,0,112,0,129,288,0,1109,3,0,0,115,0,683,1094,65,0,213,0,178,0,237,3651,207,512,392,0,121,0,387,16,0,0,0,0,0,57,140,0,0,0,0,0,69,260,540,796,726,210,1241,105,0,0,0,0,0,242,0,518,180,0,2061,0,0,1330,61,0,0,0,139,547,1891,378,221,0,0,523,951,61,0,0,226,219,8,2616,0,0,223,1492,1,254,73,169,2,117,0,0,0,239,27,15,0,508,482,0,141,258,0,0,98,796,193,0,0,309,276,29,129,648,0,220,0,212,18,17,68,0,464,0,90,301,0,11,91,3,0,0,0,66,2086,13,0,48,0,206,35,330,11,0,0,102,0,2201,0,241,0,235,508,214,172,0,176,0,617,568,0,913,183,0,1,7,1195,1069,0,0,0,664,0,0,1937,431,19,392,0,86,0,0,0,245,0,52,196,0,1469,167,396,1508,0,73,277,288,232,221,68,10,0,0,112,297,0,225,264,239,0,932,0,306,457,0,352,9,0,2225,106,0,530,371,46,0,0,0,103,102,257,211,0,0,225,128,0,291,0,0,1,245,297,6,0,67,135,0,0,177,283,0,0,279,418,110,387,204,1203,926,169,4,313,32,648,0,175,0,67,324,0,169,1423,0,230,947,55,520,42,223,0,1,0,210,0,1,3,272,0,0,44,2901,237,435,62,25,14,1166,654,0,112,0,0,0,12787,0,346,55,0,407,0,365,428,190,0,162,657,2377,145,52,325,3610,76,0,0,0,0,2098,2075,618,716,273,391,0,97,0,0,44,0,3142,715,93,381,0,133,15,458,767,3,3531,273,0,0,0,1,0,3107,104,0,0,0,0,239,448,64,0,0,216,0,3079,199,224,0,0,1641,269,0,12,0,21,1,18,76,11517,0,0,789,182,0,85,714,188,313,0,384,600,0,257,0,1096,0,292,0,2129,0,194,49,70,214,0,0,190,0,58,528,82,21,83,0,0,9,0,227,0,834,0,412,567,435,1812,374,177,0,116,0,70,0,0,0,296,250,0,42,0,326,0,4774,63,27,112,162,0,0,194,0,188,3,137,0,0,0,864,20,0,0,274,173,0,54,0,175,212,0,0,0,343,462,170,0,1,48,0,382,0,52,0,0,28,333,1221,0,1117,0,0,125,43,1349,0,17,1054,293,282,0,693,601,54,357,27,0,67,0,0,0,0,0,0,276,2287,72,586,0,2004,249,0,47,351,207,331,0,0,2,0,1225,0,345,218,8,0,93,451,0,0,1969,0,0,11,0,230,42,9,0,168,53,105,84,7,21,0,0,0,236,0,0,298,350,112,0,264,288,259,171,43,1587,0,0,0,0,0,1,247,0,110,152,0,0,245,0,53,54,0,0,42,224,0,202,0,0,0,184,235,312,2,0,258,42,0,278,490,0,0,216,247,0,1,0,0,277,0,0,56,67,23,0,0,0,0,0,72,129,0,0,0,0,0,243,14,0,5,0,0,268,0,101,7,29,143,0,81,2417,238,38,0,0,30,194,0,544,0,0,450,5,0,260,0,679,0,129,8368,319,377,0,15,0,170,0,583,11,0,0,5,32,221,25,12,0,211,139,130,176,644,0,0,195,0,0,0,438,1454,316,201,38805,12,0,0,0,9,19,16710,0,0,78,0,360,140,4377,0,0,7919,0,80,0,0,1797,42,2473,63,0,196,0,263,280,0,22,0,0,0,219,0,0,1425,20,0,0,0,0,16,310,0,592,0,0,0,0,24,0,210,211,80,75,0,0,2938,71,0,16,0,260,206,0,0,145,0,276,0,128,1160,0,114,270,243,366,509,16,0,0,0,0,2365,17,0,200,7,2022,0,0,0,0,254,7999,0,0,289,326,320,3456,0,204,15,0,0,0,0,0,167,183,87,0,314,935,212,212,0,0,0,0,0,9,10,8,305,0,0,7,0,97,226,293,0,0,50,0,51,0,0,672,0,0,0,693,0,0,55,2628,0,227,342,206,553,0,0,18,2162,571,1,0,271,286,21,54,0,489,0,153,757,527,0,218,0,176,0,0,136,0,337,75,108,41,0,0,0,0,319,0,83,0,0,254,294,0,256,0,0,0,0,0,0,0,507,88,168,0,0,331,0,0,0,147,0,1278,0,0,1849,771,280,140,0,69,0,291,236,143,322,801,704,126,129,14,145,215,89,525,0,246,0,0,149,139,205,14,9,432,256,99,1296,384,0,0,285,521,241,0,408,79,254,253,449,323,226,777,0,267,269,0,441,0,0,290,232,0,0,188,0,0,0,236,0,45,0,340,239,5,0,0,0,341,326,0,199,0,306,189,0,189,0,0,679,194,0,0,6,0,816,463,275,174,0,297,584,0,0,0,141,0,0,0,309,0,28,2908,0,0,0,243,2729,306,377,5,194,206,0,9,0,0,0,4975,0,0,46,0,0,0,31,0,0,0,357,0,157,156,220,250,10,144,239,0,0,64,0,0,0,134,413,376,2,0,1902,990,0,9,1,0,70,0,0,14,379,5,591,0,271,0,0,72,2747,0,0,0,264,1345,1667,0,0,0,751,79,5825,0,0,67,0,37,0,196,10575,242,0,182,267,437,1029,1,261,0,154,233,212,0,0,1475,238,0,4623,208,28,49,153,144,260,771,0,299,0,0,0,0,41,0,465,4,245,190,0,967,435,6,234,241,19,0,4545,0,17,1536,86,868,0,0,28,0,0,0,396,257,0,243,418,0,220,1307,297,22,29,0,292,179,218,880,0,49,0,5,484,278,0,214,257,0,3194,120,209,0,0,0,1062,317,0,0,1472,660,0,211,106,53,380,247,258,1649,1244,0,1069,69,6569,71,151,131,0,0,84,0,266,141,3350,280,132,276,114,0,4,637,0,4277,193,101,0,5852,0,2398,0,0,243,367,279,0,40,231,351,355,0,12173,9,25,232,0,276,277,0,0,354,3,0,104,50,0,239,0,0,33,266,245,1595,0,271,170,0,0,1388,5402,497,282,0,0,272,0,0,0,107,46,211,593,0,0,8,480,0,0,213,0,5,23,0,150,0,0,0,0,54,0,0,0,21,0,275,112,0,341,0,0,0,0,0,42,54618,0,0,450,4,205,65,174,0,0,75],\"xaxis\":\"x\",\"y\":[3914,10728,635792,253864,49818,11966,1497694,12532,3914,49837,27176,93694,52572,62764,101824,134416,26544,16182,16211,4816,12896,70200,78884,22344,15326,702956,57460,17732,176540,14896,8643,10507,10008,57784,6758,29541,44020,8424,8604,350997,9362,34918,4294,5676,34216,6106,79711,40486,78964,225624,14144,157914,16568,39312,11594,936900,3631584,6240,6042,18012,9568,137643,16297,6262,1293336,155918,14040,6364,47424,6696,72936,236500,3924,4028,5246,24024,511841,20304,6084,12245,5246,14319,18876,41648,8428,42952,27924,198369,43004,13032,11448,4320,4750,27156,70176,15748,14018,12482,7254,6968,6063,10406,42966,48982,4859,4248,6386,4524172,30573,40092,5304,76836,10664,6278,18791,29388,7668,14756,6262,116356,15084,5805,109512,24128,57474,14446,98540,16776,13416,75672,26208,778545,72680,4446,101308,40964,6324,132870,5824,130500,14248,147098,10912,363084,7502,13020,13373,9196,885422,9724,12943,9559,8246,30524,18802,24095,21804,607724,12403,4066,61628,20398,41065,148441,10712,6344,282948,8664,33440,99634,6372,4134544,31261,147651,49612,48880,11524,4687,31868,14544,5510,12064,69678,7525,80484,53692,3990,153418,15247,1279326,19656,74046,11020,54720,11128,285200,37658,4066,52344,4636,451422,3838,6188,117676,861032,229416,872318,30702,4945,28260,6880,195768,8556,28086,50165,100835,195156,25844,14516,654192,33488,27413,41184,3744,7353,39832,5130,4218,22828,12324,306590,18824,4788,5824,18920,559152,19396,5876,97632,4332,8684,20167,11718,12636,6552,37696,28462,44978,19836,7998,4343,143052,334366,5408,50955,45792,4104,11692,470808,19440,223028,23564,22458,109148,10354,52668,262438,10922,6149,11137,5724,48418,7790,121892,189504,72432,98280,35234,19448,17568,15696,201172,20160,229892,47716,3636,64464,11818,12744,22204,121458,13680,68536,160528,56268,13934408,7900,35313,78289,18658,6292,6498,26728,14405,23858,10816,13144,38710,13702,10981,15394,24804,11804,42897,4560,50220,164260,6916,52030,24056,10816,12772,14446,1195744,698400,5203,24928,5054,39384,117676,151446,19968,24264,126880,20540,15300,18356,10712,17004,6084,19344,1418688,8640,263149,18576,10244,166216,11438,8216,37232,36103,32472,11376,1039492,60528,8496,338840,251136,166032,177460,450379,20066,5356,26149,55068,95906,51088,39216,29488,11248,14664,27612,6384,7697,9610,17696,12096,31304,7344,32916,224992,22594,4066,11818,7998,38528,9216,140920,76322,3996,7936,9204,8684,39096,140976,31806,26164,12428,10656,15824,90534,54954,234732,28892,128804,132408,373591,18000,17784,11904,19096,24984,872784,34162,212836,355579,26064,10191,53234,37368,8320,12168,9030,192918,34844,37539,15958,45198,649472,11880,78192,27456,59768,9287082,11448,6968,560652,37656,53878,180804,44161,393908,204048,6012,8436,6696,15562,43920,312998,23760,15168,13520,6634,59148,14964,8901,13392,4522,26424,19197,11051,21476,29588,23472,13104,5332,149136,19368,24964,601016,4408,4515,5436,12384,20646,14782,21142,5504,11448,7560,49104,121518,10224,1951813,4140,19522,13454,47386,8060,5358,8184,231154,10586,16802,18060,33891,9724,7488,4343,94068,134628,94428,158237,75445,134142,15934,162136,91542,95728,11284,16872,40394,13373,34529,17628,168428,154960,144216,480952,93912,5890,338436,6448,12152,18144,287370,55853,16530,5700,68809,2691358,34424,9620,24727,4104,23940,185938,11997,10602,19080,10664,692744,10716,19684,750421,7992,7182,14136,11664,20769,218400,85162,696299,6200,6604,5652,104201,10368,19197,10540,48856,24332,7704,9620,16297,32040,8385,5564,9202,7072,16454,7592,53483,335952,11016,11222,50616,5980,8892,25012,16068,2747784,7748,10080,119536,857956,4279114,311116,28348,17856,187200,83898,501642,5461,5805,192049,45346,473817,6342856,7904,20482,454248,47196,38236,10944,115577,11266,13114,56072,15190,14018,9238,23472,58320,24885,6063,12692,476397,321382,18060,15444,8769,11248,68510,219085,17992,11904,15428,4262856,77376,70626,40032,54194,9796,16120,280800,12350,9504,55695,5512,533696,17628,17673,22308,31442,9672,6344,273600,718189,176802,155746,3876,140620,29154,10277,5564,151048,35464,9006,19908,15872,8112,20644,10008,12482,8712,289140,200592,405954,12324,52390,28424,19722,67071,15523,71416,20880,220410,19908,2108510,96301,5564,17459,40104,6136,6324,51688,28704,918788,4343,16641,8295,41400,5976,4472,9072,21638,49724,9216,130260,18616,75551,7632,337156,20212,8856,5160,858572,14328,28334,475106,21543,306362,20026,5966,9486,859125,6688,10816,327455,49375,36378,4332,20488,152312,178144,8684,9360,9300,8122,10800,213409,4294,98568,8996,44772,15548,55796,13676,66992,96933,1665162,4452361,17108,75981,11346,17680,6292,115541,21018,28582,37841,12152,18723,5200,889632,9734,343097,8996,4320,1315113,18662,18328,17673,45662,21888,21962,27590,11594,261934,62372,26531,16899,9932,9234,19902,6552,4464,11613,16432,40536,154284,10908,13206,70784,7748,9766,8684,754134,413170,1071288,23750,9308,25438,35155,6536,75168,13826,5928,25128,8804,28835,20026,105710,6968,78819,7030,17352,76946,20088,19032,22704,92132,1066464,12584,265440,5720,382044,5976,64688,15190,4176,221760,25482,13392,7540,51342,14174,22575,4032,571814,11524,9006,7192,1033075,20640,2555424,9360,48450,9144,14402,25200,7866,10602,98784,6572,78605,11532,32612,280618,123264,299568,39579,6751,1309252,16796,16484,200668,880771,103806,34844,37080,9847,155304,7697,7052,7296,317896,63898,6042,22360,52762,29146,3952,5332,51350,259064,23296,6080,9100,16120,917111,32390,19671,18565,29283,13826,20448,11780,10504,65188,32262,22104,757136,5590,13186,34200,177987,22680,6460,6136,165044,10234,178452,13889,18447,528984,7696,121888,60888,35352,6552,20368,20832,32723,6324,16112,12046,3952,216638,15552,62062,7482,102621,5168,10088,390290,12087,6192,77896,4572,11016,8788,2152750,107543,74218,6688,48568,5719,32544,14560,37202,66508,17415,11218,37076,57304,398908,201213,195676,12642,10728,5408,9734,16856,53884,48360,15840,10184,17670,35313,26445,61383,115754,727669,39596,49538,31679,12024,4066,5928,18091,9932,4472,32548,40456,203164,325006,1473802,5876,14384,5246,37752,133431,5332,115026,24358,11309,44878,12768,65333,23560,28124,6292,48111,13728,35030,10292,162582,12245,293968,23384,11752,151580,5624,918375,7130,30889,13454,7600,96064,7224,5230816,21736,3248336,4598,24804,3780,6696,227582,39308,167164,5966,124776,12482,15652,8604,81792,27492,6572,4816,41317,36577,18460,43272,1451704,38950,7956,9348,19608,5356,72759,20800,27404,16692,8778,103272,6572,13104,860976,11297,17784,6278,11128,1086488,7124,139176,12586,30616,26520,47400,49556,6572,17243,10449,125689,75528,6760,403056,39263,55774,27396,9880,16037,13889,12561,7697,262694,10507,17964,7280,19592,71337,7334,38184,3785601,5289,17160,61383,11481,9610,179181,27504,13832,10556,13104,5460,13536,28595,21372,60202,17112,33332,64844,55986,124930,32904,4386,12688,86742,13509,7372,54288,19500,23244,10348,31304,10664,15136,7812,10044,181718,7310,51745,891820,164880,10912,35647,30628,592844,155420,30876,53957,37324,44856,25948,4859,2491660,85570,3439502,32508,8127,164715,15800,119527,21684,28348,10540,51745,37296,6407,17544,4261023,4386,5203,9374,58708,21584,26875,11492,9717,43206,4446,26486,23250,60320,470208,4472,16560,26474,9417,7316,15438,178312,597896,53641,13640,39816,10368,8684,236447,126666,17696,21112,16560,16848,13244,726089,56287,21156,5184,5824,13072,579120,1886836,97802,692128,7296,6696,43524,150653,21758,40976,1810042,18407,1348925,26860,11139,4864,17064,21700,38141,20026,34271,150722,46384,8892,16037,30816,961362,100168,14256,38664,78416,1152531,20232,16848,25704,11552,15128,5805,4028,148678,67756,1246304,8736,13516,4816,4142,55490,13072,5246,11476,29512,55774,62173,183481,153260,75816,9776,43416,10608,36972,21762,9085,5016,11088,1216800,19114,12255,2275911,59112,69368,363874,38448,14196,39888,15496,205321,741960,19840,82560,15879,10244,5848,20020,42423,111241,15340,16488,54498,7332,146010,12654,27590,7750,49794,5289,970416,27962,8246,755793,16168,525587,20894,10608,7095,164304,9890,51116,8112,872526,1931392,53784,4446,145992,18644,20088,26228,29025,16226,7488,129580,55512,20016,13826,9216,10974,38786,30240,4028,9362,15264,4750,5934,8360,14858,24232,23932,8170,21840,290641,17244,205632,216980,506602,34732,556416,20736,20592,25992,5375,9761,4978,7224,31044,13248,30400,73865,56012,5376240,11970,27892,60264,9417,736112,77584,156104,5668,91547,263160,12384,5252,6136,401076,10972,27352,33228,41610,105696,211562,45714,44252,4104,14276,24358,22833,17160,69254,24940,13248,14570,4902,38626,10664,9216,18050,8712,376154,15704,227599,18146,6156,4558,21892,13452,10578,19604,877084,155880,291462,37656,14256,6321,122832,30384,4902,31680,11739,15120,16920,5980,5676,29842,20664,11016,34344,63990,5289,37354,18582,20770,13032,6751,70432,967460,42280180,16906,9576,16344,25359,10108,31916,93353,147146,13932,87216,504099,6510,38532,30600,36270,8742,70704,5031,22176,7540,49059,6572,5548,16120,13312,4078274,4218,9638,153748,27821,53072,40132,16120,6188,60624,82950,449136,59724,14060,90250,14248,7912,11284,7611,5890,45144,4522,5719,250952,7130,93930,17632,15010,12740,24806,144612,24037,12816,281294,22176,15872,13788,538222,34365,19158,4730,23400,14615,4294,16426,5244,51264,206568,29038878,34684,36464,12428,11352,21762,142201,12168,7072,14196,191208,5633,15552,33384,109908,354394,8987,13608,46624,131112,18316,18091,30784,100738,211668,282978,181779,12888,66248,178966,119392,3501504,145281,3952,170956,17544,128016,7502,10540,13520,319160,22910,9424,33136,5375,3577673,3914,7904,7254,160128,982338,4787921,9576,72443,124504,742392,14328,10944,216934,5624,22464,10191,102180,16834,8172,100152,5548,12084,34602,5130,8094,10230,8320,143069,16380,13676,13338,253440,81282,48418,135098,1190276,7353,397606,6192,11856,10088,12028,18720,63550,9300,949240,8784,53300,31679,159692,1229240,11534,80659,1457682,9724,20748,346476,54994,6574,20540,726657,50112,11352,57190,12482,76393,8927,13888,3600,10744,17459,11476,13780,23932,9576,122450,11929,38520,144965,95542,45448,25194,14630,321451,18404,17775,5184,66528,299160,5244,14536,47795,80414,38502,14880,124668,7182,82056,16802,6916,5472,13780,12400,10368,17775,10296,41949,2154014,38076,53621,63752,188889,32422,10070,7228,20862,9576,92035,9954,47684,31464,65246,5130,15184,9864,7800,122544,63498,10415002,8901,36498,19866,16276,5848,44764,1875376,12599,354710,75888,10222,9176,212115,40291,30616,8618,13932,7224,16669,400192,14976,5848,13392,10850,6136,182676,76824,956332,8580,26524,61938,15132,9500,7711348,10192,82713,6500,9675,3952,406297,29016,76235,24467,24411,6916,28132,13392,5928,14364,13896,5976,179883,19902,24253,16864,6080,38868,19500,10556,596711,79484,9954,8094,9766,81528,4472,45030,131924,4343,16306,46512,8372,1071161,85020,3838,218922,26070,891041,14198,27144,73268,19092,5805,19654,15958,12276,42344,55670,42532,137206,7998,9828,36182,9176,14288,16952,40774,44200,58464,32943,22248,6450,38270,5460,7936,11970,24244,4902,58178,30889,40608,18720,4218,11139,59400,7144,19269476,287496,443269,33338,3960,6156,72488,360158,25792,8320,16692,39263,17316,33048,386136,16380,8170,395604,25517,14615,28614,6156,5848,4773,10191,19928066,9100,166752,10478,5418,12648,5461,18864,335916,18772,4522,11552,66994,46784,10836,17628,12008,16272,550185,51034,5512,30573,6232,5117,85696,23478,10504,5976,265734,6696,129704,14322,114939,251292,225792,31320,6966,811172,31096,8268,7783,23832,271918,13110,165505,24048,66248,4988,12152,112060,9412,8690,13000,84925,19874,4598,10712,279186,302188,6574,4988,29388,14773,28638,76153,139040,15872,16016,18648,7440,30628,46698,25413,6235,5396,1356212,5633,9516,5408,434668,947376,7525,5206,36656,11376,6080,32224,6708,11376,73530,21027,53246,102856,12096,1408752,1861184,32566,46398,9114,7344,16992,67624,13364,11352,17594,19708,7416,30628,15934,25346,26600,15184,5092,49928,29520,12152,15984,73584,8990,43645,4687,49920,21424,11592,108252,58144,460096,297960,16058,63279,131219,56992,4066,62805,79608,798769,10608,5054,13536,2141136,46314,5332,12096,6032,123324,17028,1493021,5720,24804,15563,24700,20160,34128,14560,7592,12896,13889,32736,4386,19355,7448,10868,4687,21514,50560,23068,6536,20016,16302,16195,19656,34049,7396,90516,5977,21008,39364,7525,7790,14104,3395520,12400,31218,33136,23068,73910,20880,42344,74214,8496,6384,11180,27360,5977,262596,5652,22824,24381,122140,31540,36890,134230,6020,804615,5772,16120,1989704,11966,350207,9504,124754,163866,4750,8928,92579,43134,22420,5676,53496,656885,3914,32034,3744,27864,9216,7280,19197,127286,6837,7696,288917,7439,34916,14694,8643,4788,9048,17784,174580,117728,13244,16254,10965,217672,10535,13208,93252,13115,3876,12900,181068,18166,99303,6880,142168,4712,7440,20808,6450,67392,5252,20145,209932,8460,4788,46170,5624,40362,9272,16985,10922,126100,73584,37128,12298,6500,9776,4104,7384,8987,11648,14456,19152,12685,16590,115656,7095,468884,113602,53630,11856,30008,550393,6764,119784,177750,161476,5396,37920,15066,4859,71982,423708,94886,8996,12212,8256,32832,23736,145584,947842,29713,13502,13578,5662,786780,6878,14768,411985,192386,7410,7800,56564,55800,15872,252168,4558,52706,44304,18648,640212,6118,200564,10602,481954,25675,31540,151443,4560,9864,13020,42840,38710,136697,27413,70980,25344,4332,18662,19995,30168,119952,3744,10108,25420,6880,749552,171120,118598,15028,20425,301306,48190,73573,8618,35880,5244,9804,11088,114550,158328,22989,6572,16432,35984,78884,8280,6344,8184,10836,113760,3838,4896,101804,3996,5738,9724,8632,464318,55872,30020,10184,118664,349259,1742317,34906,80352,8436,4256,7790,35392,28196,11804,6878,14446,13588,4598,21476,25704,11352,46956,397008,45899,46368,8084,18848,42011,64930,23328,48891,20904,46488,480240,6278,7812,535651,346652,62124,11592,4429,121368,10036,5928,4408,7828,193128,30312,5418,403374,7998,49217,86387,191654,60198,17243,70408,26273,122740,23972,886854,177568,214848,19522,14694,132088,7525,70942,30315,5130,128592,58996,6923,36480,6240,29808,5092,4864,12532,26000,23976,22032,20224,19190,8626,22116,18240,9052,52576,5504,6882,9196,1177848,11340,49324,7334,146880,4484,326823,23688,64414,81449,5168,494326,21166,19136,96222,11952,29467,6758,298034,64844,66664,19694,117154,79670,13320,127368,87516,119536,5590,37200,30600,61462,80969,16120,6820,559320,436852,13224,195672,18414,171950,12616,94385,53404,43946,49556,239904,963802,7852,4680,15800,42696,3378752,38270,380376,15879,424625,17143,112891,995665,138566,393016,661072,14580,6149,235152,22594,24336,21576,7750,7904,33060,22932,44194,12688,100172,23521,52693,14092,6820,154584,279000,14098,9920,53010,217208,6240,30004,16492,27000,99944,43766,13640,31320,9486,17480,118336,143312,6063,28598,5616,64440,10868,8840,10368,62884,26860,15247,14688,162029,95288,25327,10348,153338,117552,33934,10354,10412,291589,30336,194256,7540,1227976,32344,10348,5934,48348,60164,24648,3914,19497911,10234,5760,27576,47558,22724,237460,49290,8372,57190,19512,6448,80106,8424,8424,6536,38304,43834,17632,85952,6916,81840,74808,8295,15563,19039,24862,71416,12636,226610,4028,10400,11594,13244,44082,23134,71208,40680,3720312,11096,22516,7790,4484,90948,16856,53612,5160,325884,5160,8928,46664,6665,11908,6696,12274,67500,8532,241034,6574,10088,14560,9776,25116,5460,18648,7502,4902,13020,9734,5662,37202,30336,262260,67906,103392,71939,83018,66766,116774,11297,33418,1062014,21268,3708,23263,8686,19916,9880,31920,102114,55432,5564,885794,12728,186319,7176,9796,188928,2703014,28234,7020,37762,14456,34602,10354,256987,15048,2912493,7072,14018,32968,10088,26524,56916,53444,14457,12844,43529,9417,1932696,461088,29232,8320,9108,68414,26136,14560,24332,34920,271128,8927,169594,8474,684140,598345,11455,35064,7164,77328,965808,9880,4598,9100434,15996,46228,32760,5928,12084,8690,5776,9000,2987504,13072,106652,5564,3602092,123635,235894,5460,247052,53754,13193,19646,28086,106887,745920,9546,5074,12896,59976,21684,18460,141963,71188,67526,11700,16952,12744,149872,28644,777712,120317,7540,13104,22392,14319,5700,66994,27097,89544,5977,42120,7006,6634,76464,4902,11180,93654,16416,14190,4386,5662,11352,71362,21600,16555,779730,26781,172694,4256,478503,45899,93299,5928,32452,59128,225990,216562,16678,17794,10348,36144,4068,5472,7095,11856,23305,7181,39263,76756,201514,81449,25916,19158,49348,47479,10602,6149,5054,35155,70992,19584,241552,8471,26208,117046,29625,338910,92235,4284,132096,5805,13454,7942,125517,86060,44352,61704,326244,1054614,20026,44460,25978,33583,93000,415423,36704,163176,16039,54747,410332,4142,222480,48384,402268,8772,16640,4408,14144,27492,84604,575172,494145,754992,28656,1210356,515317,58104,4142,388864,12024,10277,7828,56886,130591,13186,17316,67704,5590,149389,11137,25848,64372,9900,597528,45980,8514,80969,14326,40824,222490,11098,8476,31284,68940,973517,149358,168302,10191,100409,1756723,5668,15480,15552,126716,22199,286936,399024,20592,7912,73628,13702,14716,35774,18044,19964,6384,7124,22306,9766,29736,348074,911090,5016,20066,56327,28024,488299,8772,127111,2482046,9576,14060,142386,132440,20384,69502,4294,19552,28756,939238,218096,5564,81270,4484,424908,23700,50639,11514,6292,4256,13490,7697,17822,88198,6020,8164,5460,61857,13029,9464,12888,9548,24984,33232,1918831,18565,212668,20026,67466,4674,2289815,8927,143464,17518,9559,29488,28800,17856,110916,11309,59469,27300,131688,8213,6232,14632,101093,7338600,19584,19760,1379040,9720,33669,8987,62173,4902,117864,22747,449565,49248,186519,23832,14508,76712,13052,14256,6992,13680,23005,9114,10296,172328,47953,6552,80724,6882,6510,10640,12636,17100,74418,161120,23688,47736,60216,117648,12220,45267,8788,54036,23218,9540,41292,44640,4558,8816,4446,5700,9360,10504,5824,11180,119606,67642,167717,12888,4300,7439,39026,46728,30168,7396,2417163,104594,13468,5289,61778,830717,456404,11016,8618,5160,89156,4674,1106237,9568,25517,1094071,120776,31205,21567,9690,230601,199008,26496,633256,12532,15132,1934473,5436,60435,22489,18936,46311,6084,26273,17174,8927,7144,146415,934648,28519,26102,1520640,12090,15132,140146,23940,1001088,13825,145578,210900,38736,19476,31679,293472,20150,21576,7439,243568,10354,8476,45714,163852,42904,4680,32976,4332,11020,227240,4446,88504,25675,5200,49770,168259,9245,32550,18000,10452,75603,8008,72106,36024,46764,6042,81133,8736,37288,15265,29704,35100,509787,131021,5112,68472,15964,57252,8996,61304,5762,80848,15437,50998,56520,20748,1289160,8127,7866,14319,381900,15652,4902,298857,6232,7310,17856,61936,137088,9272,140554,8840,6450,8018,10230,45881,182806,17556,37440,7296,8611,8385,66960,15314,37604,7592,4294,41366,147146,5408,1709876,22152,289952,4515,31126,12350,5720,33480,116130,9652,46956,12400,119764,701896,1120220,4750,7562,6500,87668,293959,46500,126432,96876,25740,33332,36894,7344,198328,44333,5320,19592,14976,4644,18600,18881,8729,37754,10152,17933,47652,12083,191338,956004,89856,247884,16340,6292,9462,13268,12350,7344,153813,23036,22403,7562,7272,15336,4212,18834,8424,177630,199836,3922828,41306,186248,220884,3819510,775806,78447,9804,18644,65556,8930,133859,930620,2279545,14544,1019258,9638,6188,17050,13459,106210,124030,44763,29796,233064,7992,31668,325510,16864,149832,6912,40979,34701,14706,237711,14061,9976,7828,70520,93931,20644,28496,7920,346890,37262,26860,36146,18216,51127,21672,6726,5031,245186,25026,48060,52417,740808,7416,9462,157526,16678,745444,5246,1027710,12220,42186,7874,8736,116057,198432,180041,9620,38998,40334,7095,132192,59555,22752,63426,9648,820728,11128,32072,26676,97881,29848,8742,37368,31428,15132,24986,7384,24552,7904,11036,7596,11532,81936,151759,14322,92579,6080,31691,8164,1119588,20511,6880,10222,21070,3952,31668,30020,16827,80640,288350,7410,12771,2937062,196664,10792,72664,13114,37752,54826,16740,27432,45562,23305,15238,3636,593290,198360,47795,32976,24776,88236,24336,228888,220058,5203,15656,18616,35152,14544,30816,9256,20232,574184,9612,35280,16948,140223,5564,24192,49176,4730,4978,41572,12168,84878,5966,9766,7998,19872,32528,30744,41194,5738980,17420,689184,1516958,27072,41044,60946,6032,6262,18668,52030,7280,41600,9072,29448,26568,31205,146808,33840,69574,86060,4773,5418,6751,18506,282899,6084,11929,56412,305809,112654,13832,9976,12896,414355,6321,163846,20777,10981,49538,6020,57600,194814,12245,6650,8295,2359296,4177599,17112,50544,16616,32736,7942,5876,367744,41416,1861704,499658,138503,9672,6764,118121,68284,11532,10660,209324,352160,83886,454646,8213,507936,10106,7228,7750,12792,122450,11596,21514,52832,492881,6510,145080,131193,10112,233366,9030,11068769,28148,18228,33153,20274,57252,34424,19708,20436,10507,7611,4294,9048,34271,55142,8132,4826,74971,11532,8930,8686,59882,38952,13338,25359,108288,20232,32074,13760,6192,37525,405964,4968,9348,26350,13392,17472,18408,223886,4560,82088,72850,10452,44677,7192,12168,61146,132088,7904,15500,12772,6751,134300,36720,6194,313404,6536,35136,7316,882828,12008,234000,36348,18802,88556,2832545,8588,1082830,85557,6820,36244,187941,293485,6063,66439,10168,7488,45267,147992,168020,14756,3600,60496,32908,873496,542160,92588,133300,13888,59328,18960,13490,10728,39780,25438,4663844,222196,22464,9412,15050,71258,32616,7632,26226,7783,31464,63200,62489,15562,19500,582660,23712,142595,268632,18962,6192,40014,20016,58104,87096,19158,9417,19530,4180,10664,22534,23972,12126,21543,77862,12768,17696,21080,62640,7812,4218,11160,11395,292448,49894,14196,73948,14820,4978,9890,119908,16432,16340,12814,68328,6880,9196,7272,5547,7644,7564,8928,65728,23370,3249823,7611,199080,12586,4816,8742,45792,132088,30690,111176,2638363,716196,25284,28008,88350,18538,196352,28598,8094,42744,14508,62890,5548,19152,49296,10621,37336,30836,12688,9766,21567,11492,8680,24814,13946,5332,23976,5364,202635,24800,15010,47214,4859,202844,11248,30600,537753,81158,236220,512856,9052,153037,14668,22317,18600,30336,7124,6500,75287,108624,113839,6422,16128,11718,70942,9672,10504,51460,21744,77443,5408,224755,85083,18920,34996,675936,58136,32860,35724,144566,7852,57888,15652,3852,15624,275394,1997320,8930,81054,17732,81792,154656,10712,163787,48070,4988,42696,9245,7228,74734,41496,1202581,7068,158808,16872,4408,55588,27716,6168715,85464,7704,25978,18928,5168,47728,52000,10868,6696,4978,7560,12376,10656,9204,10602,437502,19468,7181,551973,89225,61070,122608,8532,12642,88776,63284,4284,65884,13115,10974,10707,301320,16016,5700,120652,16306,46136,6020,4940,12160,7228,1298032,8064,200660,14964,5252,9880,71653,318291,68696,6794,48585,154368,1623024,31616,10728,10621,3952,4142,8428,41791,19872,24586,171144,51584,13330,50353,36022,5772,27976,61189,5461,27413,5304,4932,19049,5130,68651,3952,25776,20304,98696,96933,113100,8352,10140,176886,147368,5547,285348,6235,175248,7776,25428,19380,6188,993852,285192,21112,12324,140144,10036,8684,41344,77672,22704,159831,376593,20224,4370,390624,8164,19684,16068,81686,7254,5700,38812,61304,27820,150495,5555359,63042,22458,40092,59882,14749,9994,23560,7740,3800,18504,17898,55584,74932,65304,64410,12040,4816,6612,12744,31916,997770,13764,146946,29716,10754,9006,3914,164448,7525,244872,9648,25048,5738,18724,4212,43608,4180,75504,44346,8385,7372,5004,297228,4788,20520,59508,242208,13728,8769,10879,4356,2513880,9804,11966,13193,88882,50778,23622,21371,201818,153381,8476,81449,9000,9672,295195,12008,11223,22152,34580,6364,118248,6923,120228,28466,8453,9796,4429,16244,14012,28028,25754,60909,3744,28440,45240,6292,176042,71574,438529,20592,12648,3708,362318,8216,8840,64543,16188,158498,13760,25840,36868,70512,14012,11088,29264,31198,30494,54126,5928,107068,13144,862358,31824,59487,25584,6136,12168,195780,1035648,22680,7848,234522,10088,17484,12312,7752,12376,168516,9300,13824,47690,6396,8742,67983,11160,352893,17064,15252,34056,16116,22444,217566,6308,62248,9424,254448,76235,4687,10920,13364,16340,22496,221676,42226,1807204,33540,2408315,15800,148994,977904,6650,8453,22444,59812,63911,14198,22831,6696,135720,173166,174384,8476,26660,40546,16112,17640,8246,21762,12502,50464,164715,15314,44802,53167,153983,46810,39816,5289,11024,7396,10192,4945,9672,8815,11160,26728,14577,16827,5891,7525,11395,37752,8611,204373,11388,19276,4824,4752,226352,114712,28860,237460,580808,12616,73530,37634,6149,5848,16727,7378,122845,161634,27838,39888,9204,8736,523296,5408,5700,9880,22392,65175,7236,16632,38055,9766,16956,28086,104000,53879,38592,36024,6240,179452,60952,10332,11514,14976,136332,7280,877176,49849,7181,6408,62963,28582,26961,17422,7488,5252,7267,10712,11218,7884,13825,6300,8208,3387308,13186,11470,10788,25482,90139,16016,33970,53768,1978056,113956,5547,602732,31824,144096,51452,11739,86989,69204,212334,9331,140620,12198,4300,66404,29326,15352,70784,7979,12220,5876,30032166,17918,133418,221364,15548,73865,74958,10726,49248,7750,132768,6751,155168,35360,17856,8632,30172,8280,47244,41808,18648,4826,128375,5980,10036,14400,14260,47902,27413,269328,57970,108224,17587,370822,25168,168910,5512,5220,17424,88846,774086,19952,90954,33264,10488,53072,2552885,8640,21166,6708,28677,13312,19916,11438,15953,185887,8632,25116,14062,8788,10633005,477672,22515,17538,24095,9322,19750,4750,45666,120328,11736,48269,101400,16598,7540,69882,1352085,117612,5408,37872,233834,5510,80064,8170,16827,28282,11524,1582920,7228,33575,66220,13000,9804,29230,24120,9120,5200,21488,15500,7228,32328,40204,6572,4558,7611,8164,34400,26307,8686,242996,28954,15010,13520,7436,5824,13946,23920,8580,91010,9538,60610,13364,78520,8856,35720,10660,40053,58500,4601,142911,61699,4066,22506,1044854,19874,23472,14062,49848,6396,11952,58222,1817902,11771,44640,9610,15028,16328,24700,13826,412982,27864,9576,479598,18648,344519,22412,169100,995400,5814,18538,8360,7852,11532,45032,13884,1775556,11856,777852,249302,7688,106468,81720,7568,50718,10062,7254,124109,13870,36328,109512,6262,6696,183528,18620,5396,45562,5016,23332,103106,8424,11780,11904,13156,4068,11960,21014,8736,486008,18644,15128,12212,3683544,7410,537984,149683,21888,43524,508752,11268,1096110,12798,7228,6232,14942,19908,4773,138961,9717,50323,12688,6330823,6448,198843,118792,64440,13728,22360,5074,8804,7900,6552,10292,95532,1364544,4816,4294,4608,5624,17860,87048,53506,8858,13803,32422,22880,7095,10726,792370,14664,60192,5616,11336,41949,17802,13746,6448,7936,6650,28203,124109,250303,45000,10512,26617,306599,16796,14872,4816,8060,6136,25560,252148,4386,16920,91846,14663,16120,4816,19592,18644,113444,19220,53998,24411,13640,53732,48934,33540,10540,7783,7138,29072,5356,68894,17716,18166,11336,40114,6794,11590,19800,27962,25284,20597,61516,12169,25560,5472,63752,5633,34684,31980,5590,67824,16182,14022,182016,15264,214406,49320,92448,11594,9568,2930368,871224,424008,7644,24192,59013,7432952,55480,46436,38220,59760,37656,9675,5472,15048,200294,7272,301731,30960,5168,5203,19908,118800,857880,34944,7783,477660,120080,11395,222552,5054,19282,3990,37999,49286,5074,299304,482790,6916,566825,287481,10602,16492,736632,58344,157508,27664,3688273,14534,8532,5289,441531,9804,322457,10744,46246,63674,51192,4988,5092,40486,7611,23940,107694,173352,8680,6708,12166,8729,39052,82584,7006,48828,514520,8127,13032,72996,23822,42480,18928,28224,6622,6500,34314,9322,32798,13746,16182,12338,4142,6422,23816,122616,62264,14782,8643,43128,11470,24480,4601,27133,11128,9648,1973088,9503,120280,12772,14457,282910,17372,57288,88846,10105,13416,100296,4730,20461,12692,43648,326088,19778,45899,82460,26312,21948,22403,5720,18792,28964,23616,4522,3398975,68472,12341,11222,5772,4978,215498,86490,32311,562875,16568,8474,5418,5590,33022,127152,9234,28458,154682,7654,96459,402480,39816,17301,22176,6572,17316,229732,69564,18476,35712,27032,6235,70735,132652,8740,16900,371108,1253063,5512,21888,7380,6882,92340,101592,7852,94326,15236,37446,5547,288113,6407,6510,9245,18354,527404,185318,95784,9204,189284,32400,53280,248248,6228,4028,8557,2650104,12240,8643,15500,166764,32414,25972,181168,15910,822888,7009,197974,78921,7644,44856,130587,671816,335118,20336,164304,28124,22824,8736,13578,8600,1907424,20938,9500,6820,6139090,30240,7956,32032,604810,10296,119808,22724,117000,140040,40820,657384,6344,118342,13717,9164,31668,49824,10640,268560,10902,162130,47736,9052,15066,4386,13904,9300,21567,99066,1122432,81700,6321,1168410,7192,79128,6536,30968,98197,1440504,37446,22120,26728,7956,21052,13082,324942,108288,143260,4902,110679,6552,9120,20708,11098,13373,36270,10584,23779,1296469,694440,10712,12456,13988,1010568,421290,79441294,14756,2472384,27170,88064,22360,4515,2110999,69125,7638,10404,309601,64896,546838,6708,7030,51557,19823,110050,7052,44304,27404,14276,4864,37683,95073,163530,7714,35932,545495,12524,10981,59803,268836,21312,33800,7800,6048,10224,473688,5762,178932,105196,295802,7482,37446,15264,12152,998675,11532,6760,4218,133036,321516,8736,141015,52200,9984,36432,136710,19708,795801,4408,537911,5980,11309,14456,37512,20596,164016,53784,138675,297830,46748,35640,88848,103806,46080,12008,518328,4712,5940,28704,45360,5700,15912,4142,69998,6321,7848,6612,14835,11455,31744,4515,20696,11008,9728,15340,200298,7783,7568,6132217,32184,33192,537844,45694,47400,16744,22536,16036,54036,21330,291668,384648,6156,17422,7740,21414,18920,284696,15912,5876,45012,4028,7592,495876,8471,4343,34504,54360,23779,44928,92606,163873,10664,17784,21204,192386,186010,9073,11825,213044,89507,219024,274680,2113704,14615,5460,8280,9374,298512,8476,10192,148614,6498,12012,15580,26918,343790,176881,522743,15238,1181998,4343,27413,98434,42581,16616,54994,6696,28423,7200,59976,7020,32448,9052,70434,1247936,4028,14652,87453,520531,11266,13490,136462,28964,9100,9288,5547,97266,178002,162184,19800,31824,137618,66384,46018,9546,5289,4902,150048,104833,96928,18705,50592,13983,12740,65175,7128,13260,23244,3800,41002,224044,10640,6622,52851,23940,7750,42192,16952,6270,133200,7740,280292,27950,5074,679572,5408,11160,10184,100804,6344,205088,9932,14400,38948,562030,7068,8436,7912,1083959,12528,7181,238817,16598,105694,7296,19840,16297,27432,68286,11880,25480,24095,34918,6084,25596,12480,20336,35150,8184,173414,11036,57668,7611,8295,4826,20384,24490,14457,25628,3744,150746,11804,7006,51272,17004,75582,7254,513648,1116648,16770,4294,6136,7258,6235,27248,8632,5824,16058,3960,1591218,118637,17775,10664,6321,191180,50482,13908,33180,11160,14760,41949,1846728,180471,22568,8164,124141,14248,7009,41496,11232,108376,11856,60788,16182,290404,139514,8342,43258,10036,9417,35048,32968,7106,8816,14402,8295,19448,34013,29111,3708,100812,9504,26820,100254,19344,17980,162898,1382500,9920,10191,9159,14147,29070,87360,18096,38190,225288,10192,18288,15132,34944,756288,145813,14508,96965,66024,400536,3057458,13566,16740,142832,1267160,35076,8280,84630,13566,13832,7006,323020,76320,5824,23296,10428,5396,26832,9158,4644,39259,6344,61332,75680,51168,11648,63812,50184,141252,5976,90060,10965,12298,14364,11324,16068,31692,6820,301392,21892,167152,534909,14190,31949,18980,43416,47736,16588,160848,455830,4284,201292,34523,4636,27612,7410,12064,7258,9396,71760,12956,12586,8840,6656,33927,5848,598680,7267,25929,7776,36335,48633,9796,22608,94612,4356,15084,15066,12672,10912,4386,7068,14061,52061,41904,55536,14688,61566,163990,21944,6346,189679,21199,7750,6500,15484,24048,21008,23746,8060,16068,9310,7344,56406,18042,127452,52456,8892,56011,72384,7783,8112,92752,11856,8122,9256,145018,9724,13717,25359,20072,22356,32916,10816,12648,10320,53924,7052,8476,4028,153698,90864,61940,16530,28830,5246,1145264,7638,368136,9858,26496,118658,18354,12116,93496,138320,5358,10449,6156,11160,21973,5246,7900,50402,52632,7912,6688,7224,19952,11440,7192,6708,22648,12688,5668,124558,9982,4945,14534,5719,260463,142792,26226,9761,18328,6422,298699,22672,768196,548018,15428,4370,623626,37804,23091,6864,26752,774832,164808,5580,20770,69472,26220,180594,4730,113688,84778,9164,8804,5320,144096,4484,5168,45899,27056,31200,4392,729926,21758,200148,235578,4066,34959,17980,53009,10222,247832,7488,25201,10764,186835,15624,33356,18936,149530,21024,8060,20020,71712,20770,14694,6760,8804,19221,6364,5891,4978,14773,6708,13201,34352,58460,4472,23750,8424,10707,7740,76880,10008,100316,30456,6510,22230,8968,23370,9462,4864,13716,25929,44793,10296,21660,133194,33170,292932,6622,8213,17264,5522495,9082,7696,6802,408408,9880,7812,14424926,22962,63468,10836,10621,4515,37625,5203,20520,194016,92820,5891,209592,27792,11160,255012,140936,261288,7332,9159,2011606,18216,6968,72000,39895,22059,5418,17524,12403,546285,4636,8702,57660,11388,16524,10036,25840,6020,14061,34839,34164,15089,21251,10664,12948,68888,74464,74256,6020,1200610,27588,26208,108072,8208,3838,4392,80166,96854,844116,4515,3914,2156622,9234,29202,17696,4822192,592658,55252,201025,22536,4945,12728,5564,7176,42441,67680,68688,8436,7688,2529332,10726,14319,26187,56544,150722,19296,4773,38552,63216,31777,94815,42423,40176,26936,109944,7124,87420,11210,7750,432388,24814,114471,34892,7936,52820,840244,10234,13752,56592,13104,68744,7992,8028,150258,4644,10972,5246,86900,121148,2379480,7596,561168,189384,77184,5564,7296,22962,11966,7848,13020,36952,54028,67467,1160068,851067,6032,4300,25992,93444,35787,6240,247379,144017,19158,11096,21930,370584,8736,10270,38502,29025,57828,22831,59598,4932602,17748,43443285,12879136,10244,11932,6660,7904,8804,5738,65592,594828,10665,127920,62135,4066,26536,52488,6278,7254,146984,11908,4484,28849220,14942,404673,230308,70122,88660,324636,4484,7192,407482,83460,427492,9847,18824,36103,10440,21027,128217,30108,18104,6321,12920,73568,3497330,24076,105958,5719,46452,9412,12896,7502,83700,11718,6916,24336,19220,4859,11284,12578,57196,165110,12312,115498,16416,36498,8322,16254,8944,17243,16430,390139,4978,17108,9396,36898,23088,4104287,129636,127660,3888,16200,75578,24016,32798,15236,83187,19342,9374,13896,332272,5772,27612,640646,13968,62662,22464,5460,537437,233116,665575,40896,53424,6880,6032,7072,8060,5074,108864,988011,17546,34286,170976,10140,5206,59171,115752,29760,17056,15953,17420,430160,78572,31648,42269,94800,5016,64440,7776,8471,67580,460728,75384,44826,746313,80659,5977,34997,13984,3952,190368,28386,11248,19038,10374,333301,13459,9880,21584,17316,12708,18228,83876,18275,22940,16920,31096,5358,11492,30324,60822,22968,5054,270180,10974,5720,15910,17280,48906,1042964,109951,1067454,4066,783432,54548,9234,23126,6760,23328,12768,5220,17280,422097,8740,10965,8164,6120,11180,10621,17974,1597459,1465213,14632,3714580,16353,5356,6200,4978,8680,14292,1366092,8690,90720,20520,15810,184544,39618,8928,68098,1280088,394108,12806,20522,11137,46768,37200,3876,446982,7564,20634,15124,69746,253270,90472,9656686,10788,45648,17836,7920,403295,26846,28334,16120,14260,7436,37224,21801,120270,6579752,255291,30286,8512,23712,27968,14782,12341,42718,4712,26784,7524,1567296,12578,16112,379756,4752,7697,16796,47601,5928,12642,22692,48152,87984,6292,76000,13035,26728,65728,4636,222859,9672,29016,8184,4601,4386,4945,52018,53799,7334,15392,6020,12169,7912,83029,253448,6820,194814,19188,19228,65145,83503,10412,5031,13826,2510820,301378,204594,10578,7502,8557,28086,6136,90432,37152,4750,21008,10728,18848,7752,64464,29484,7224,9880,16125,149864,858676,34808,9464,231480,8375422,98857,8424,104359,4522,81468,233616,35880,877982,106912,24118,5928,5356,3838,17538,16306,345228,25416,10044,41688,327218,15192,5876,16211,15089,8213,9196,23134,279032,47842,7396,14632,16856,11818,40560,8928,5865964,30420,61560,20808363,387810,75354,33022,15192,791440,5252,10556,6948,6992,22176,56160,116525,522106,5966,77710,451440,51532,18460,541060,226486,116784,26928,4636,1082520,1239431,13312,16368,12692,35030,7697,85699,6764,16432,11376,94213,442479,67639,70566,24490,11534,244556,15089,5203,16430,13578,52824,2512753,398634,8640,9464,527592,15444,36214,26970,7688,11346,4343,6188,403992,8474,19909,22420,114088,8990,7448,361741,33912,16802,213221,22680,5246,30616,5004,8680,23712,79236,10088,328290,11266,70784,4332,6407,16848,4104,32250,14478,23760,9766,6820,17484,7488,856755,13268,16128,6386,7812,342237,4248,13604,17316,133984,1571184,3839400,7697,5720,2716336,70308,16988,9724,13728,505293,27280,11395,30020,13846,21886,199004,98671,79790,65782,5200,7436,15562,8213,102410,146604,8626,21962,91640,38947,14931,731724,51116,8712,117390,44824,16748,456878,43416,7482,27404,809782,39990,531179,139032,27097,12236,8060,26860,17918,122360,27288,32469,84846,15093,12600,6106,8018,364032,35048,23446,73512,27664,94326,750184,5460,5396,13676,10793,29698,89139,17544,301948,9116,34444,6802,21112,6235,5200,19276,8164,32328,5418,9792,34038,24840,7488,21762,11218,15548,11196,54481,12272,5396,170810,12744,15563,117312,20708,9432,9044,8568,74261,1569113,79636,41396,5848,38880,33604,10584,10512,59272,11596,17856,37758,9417,5054,9842,109800,16632,6966,8580,259992,6552,18565,14612,21164,6300,17222,16678,435240,341833,18126,16150,9331,100434,5814,8580,75516,28028,168646,6536,6916,10792,7998,23312,7440,8740,112812,10192,20556353,19264,64543,9656712,13248,295568,16985,7904,8840,21584,12599,3522294,54872,7006,5510,21142,59020,7654,21840,7254,14536,24244,184202,44635,122335,30336,48348,322582,11656,11718,18662,56576,8684,22878,7626,42532,135876,163080,12956,6240,25585,63270,68241,8729,24614,262446,6708,34788,22828,22199,11954,9030,121432,1490572,4712,5203,6948,27735,13702,9920,44240,11076,89784,148986,76536,9568,26040,8643,122976,10062,3952,26101,5504,63550,275157,4515,26149,85320,9460,288143,2858324,423398,24016,6572,31558,232066,314352,64656,116604,14664,38844,768018,886143,10868,18476,8041,7228,19292,11997,798424,1494578,34782,15996,70742,11804,92983,29941,401241,16378,10140,14835,11596,753186,64220,1612627,14924,8216,30744,13545,7224,20145,11008,27300,10868,6232,23180,190706,40248,21725,17236,61857,18360,8060,10440,27792,4218,9994,11438,18430,26638,210930,48724,101136,40796,14554,5168,8848,7144,36577,20808,17458,18000,75960,367564,41882,37656,23472,5332,7181,333372,31521,279792,48724,5203,14835,7384,8632,1118000,11098,5289,15824,14012,11336,39744,23296,27248,81406,6794,21700,427320,21172,12648,4370,11058,80422,71337,7688,14400,142012,16195,123552,54720,23126,22754,332444,33904,26156,54560,32414,11139,39600,7568,18146,175392,47637,68651,166656,44044,61814,14782,10816,60610,6916,9559,13884,31752,14174,5590,13764,7955,97774,19512,3012665,6240,575989,19866,31720,138456,14536,4826,19264,11868,22968,8788,19750,62282,193544,90396,12341,8600,1925368,273208,10296,7228,4429,57722,860705,35092,4644,6665,4598,6794,11052,128098,524016,5356,34224,9362,4940,23580,8600,9576,21508,29016,7568,1153242,12640,68848,170877,31519,66774,6235,57164,90688,59400,128217,246844,34736,10507,22320,13680,58102,9362,125316,291668,10540,7654,63468,12152,15168,116920,5548,166611,9864,7776,235973,48152,110983,7688,5805,695952,24552,114076,255456,14144,82512,15912,463268,139384,393696,9792,164424,8432,8008,5719,66123,87880,1570441,214458,30816,375092,592105,10526,3924,967104,70128,12958,9589,5092,250900,92588,45741,150822,53072,50052,163956,12771,7502,2078024,15028,6732,7956,15964,18616,80352,10354,13780,3453959,13020,6063,1255176,10621,19656,34884,4687,13680,677730,6878,49880,13114,230412,29450,17928,8494,6156,16948,265124,44454,26312,561279,36792,61828,25359,8424,5460,63516,5616,31248,9360,16692,54696,1614548,5928,18000,33402,17888,37130,52772,227664,8018,112812,12948,4750,58867,7525,114504,36608,6552,20824,630894,14749,11024,4940,8640,28656,50592,16813,35412,264168,12376,11613,291408,7956,675614,3990,215928,422650,428792,106578,11160,9216,14612,10260,10602,408667,191575,20253,68019,67166,33418,5633,148738,11739,13932,29108,75998,34596,64666,704520,4386,296092,73075,164320,28122,7592,737781,6422,15314,6916,10507,6032,7439,50353,43896,8712,14706,472750,198120,6084,20488,209664,4068,802152,14074,5200,7626,13984,155472,14716,9288,10400,5117,55728,1215084,30992,7488,13082,596068,45448,6192,87152,13824,469339,13490,8208,134106,40144,4636,10586,397277,6552,469023,99386,47272,24885,290108,6278,34830,8690,321152,1529320,27072,3587688,34560,7704,6278,4902,482804,122512,7416,32178,5876,10140,6188,82440,106742,14706,9486,8580,8928,18772,29541,35424,161856,451152,7688,5633,574824,15010,4370,14322,10044,28548,7280,52920,9243,7138,257688,5160,527325,121024,10192,38157,35733,4644,22278,16416,25776,223820,570960,1386529,197972,7482,4300,60268,2610530,6878,4256,5928,9724,185115,49059,30780,60912,14248,43628,298566,18791,17160,35836,25110,6665,199001,14260,67104,8360,24209,17680,6235,8424,315456,46696,5616,25596,121660,13260,33552,431972,75140,36784,10088,7138,23250,10707,25201,26939,15010,12428,11596,4558,3990,18202,31104,21926,6820,2050445,12384,198606,8170,9158,76128,31248,6622,5624,7592,4968,117990,1425424,33101,5586,36576,23674,6292,70618,77976,44252,76669,14760,97696,17424,239295,7812,128180,5356,7488,690934,19654,32760,40536,16172,11782,52056,36244,5548,25194,14092,15696,9272,4988,50902,1291264,14276,17050,18290,17759,8352,12958,11481,1055440,107045,5200,16120,84882,7884,17372,16848,5375,5852,8094,107414,8550,25069,158711,9073,102960,5472,18723,312129,811014,417487,32860,9516,45942,13459,4256,15721,77748,11268,51840,12168,35402,12996,294851,4408,250667,12168,3838,81096,14457,10974,312481,40280,11309,8164,45012,78289,29484,4028,25740,198273,73216,555449,63612,5092,49348,8216,21964,88288,7344,4343,5512,33812,28340,1070888,24388,13373,142200,63437,21199,12744,542098,18275,24624,11088,226670,38750,8901,251299,34944,926484,30566,61152,9417,9048,27648,609768,15066,61048,5934,21166,4773,12513,85241,76700,6063,114638,1127883,112892,333640,53320,122044,17286,27056,12806,9256,16454,58344,6840,7874,5652,12084,415079,424574,23296,12480,102297,96668,13148,235657,57433,7334,21672,4370,4066,35948,388296,7920,49063,51116,7006,695968,8132,218088,12958,26445,4750,12400,1016280,2434104,42470,12502,162316,2064608,29625,32968,9256,5436,41791,25413,38088,2494346,323280,31564,7783,11058,33101,6084,10412,6688,70866,7717724,936944,12083,81528,17587,58368,18920,28124,1081184,9202,2223218,6136,33259,6812,8901,28912,6262,1268208,28830,6324,6324,7396,5244,43416,320952,107224,5246,11139,161772,8840,1886544,492404,110448,4515,4256,425258,5547,4945,20296,5160,6726,67704,71796,35774,285758,17264,6536,139356,11160,5117,55771,150021,12960,187467,5504,32034,600795,8626,10972,7332,86903,6448,41882,308396,10191,15264,97344,120317,19307,9516,20664,4370,13452,11804,179409,9331,61978,55063,324360,9331,7228,9796,15376,122766,122450,23392,21508,7634060,13201,139277,116288,8112,23504,7998,12943,7564,6923,19479,7956,5112,7626,675800,14074,13578,7525,64232,5016,80422,140146,53246,12986,19512,10152,8028,53167,9424,39960,11856,124920,8424,38952,21024,452876,79050,14760,7448,9216,32656,19152,871607,55728,33046,480624,19188,10222,19396,5282,152134,840086,17222,16120,23435,11440,155808,12040,256824,35561,6136,31758,1131552,54352,20640,15394,5130,5824,54264,23036,240002,8854,17992,39579,456699,25280,15168,149081,552064,32078,11514,198328,28124,16900,10404,76456,8496,9216,7332,8901,35561,59688,124583,19080,12168,6236464,832581,8496,19434,115111,18538,165416,6634,24490,6634,10070,56340,11058,30992,131298,13788,14384,472812,382123,45425,6579,840718,17062,6665,20210,25896,6916,45408,12556,9204,42739,51858,14400,437684,39494,13624,93783,7353,4826,29536,6696,6063,20708,193180,159264,13110,17174,63792,267264,192608,84538,1094178,8060,24966,16380,47994,28132,7869,335671,12920,33356,25064,7334,6760,197856,4598,68335,14896,7332,3952,10296,207762,7488,15438,15808,6552,7267,99424,136276,22464,87768,9976,11594,216697,37281,15652,102068,14688,4940,35256,66716,3914,4940,5289,6840,17174,15484,7644,95666,107440,30058,20640,5616,17538,8320,10707,27334,108432,5772,4180,3914,24624,5356,43524,40320,11932,79128,6536,11692,720502,31564,110542,23384,12502,105552,11324,156302,4534958,35672,485857,10902,11952,42581,51398,9776,36034,5738,10292,462528,38532,19656,79128,6923,20448,75096,51794,48980,56373,202802,4730,28086,13588,133510,14300,5252,311240,13794,4142,5289,64030,278720,11060,29068,5676,32379,425010,15089,126953,1689128,19604,6760,16328,14362,6408,42120,16328,118924,46689,6278,43316,378138,8816,8385,8374,4644,54684,50869,7144,4218,10902,10152,44268,121520,636272,10348,4212,13832,26496,112902,7980,13728,776644,62568,21328,69230,4515,56674,9048,2339585,9516,8784,12312,15336,13020,16560,10416,17784,10836,638058,56760,15192,6396,9308,24467,55728,582941,8742,7676,17160,20212,11567,30780,110032,7956,8060,155272,170196,91246,19592,26574,2004187,421860,10449,14760,18662,250704,59436,82947,9085,45583,7448,28272,4142,309776,210444,76235,34128,44714,7776,445176,402628,35776,15704,32153,56012,5928,198290,10270,3672,28768,62816,2098443,21576,7800,13764,8094,7998,278080,7904,22204,48484,19513,70876,537887,28810,62186,86040,8058,9116,12900,8892,13144,20232,30312,49928,5396,370352,19522,841745,5934,4142,4560,19872,7009,5054,8360,14184,13728,406348,10191,36332,110304,221052,12087,24054,2762946,4788,13644,17174,7482,9464,10044,6968,130884,23978,29172,5805,44136,6292,3708,71592,304200,32500,187302,109415,6760,66464,7384,8041,158474,115596,9724,117360,7740,4386,86490,93931,190112,10504,9072,15998,224992,8600,47874,10868,11076,42978,1014676,20336,8136,122845,30968,146232,25848,19292,89642,31600,16016,11088,7688,20336,8428,7095,15768,6200,106255,9073,4472,9890,19393,29952,12524,22356,35308,19866,21488,738966,16802,240864,17759,13224,20708,45074,4212,9300,21096,16056,436321,9030,4472,3566850,28598,13104,37969,7600,146940,6080,81432,102672,35392,59830,49770,650547,13320,17222,6536,62252,5616,139464,23908,7564,13156,5966,4320,1039464,84940,16469,93384,18619,48960,4601,50046,21164,6194,13870,7410,74304,6820,5160,10296,12524,14260,23746,16536,337156,18506,10764,194145,7696,7956,49680,9828,104036,5719,6574,12376,17420,6656,18318,248534,5662,4028,7852,28954,11908,41236,11232,55536,9401,13825,6080,9460,16416,8626,68944,8740,361267,8856,14136,6188,26149,29016,7750,27477,6344336,8928,4464,4522,13373,27056,42104,62479,18166,5117,6966,15964,1188606,6188,10726,39246,64414,31521,6864,9052,818763,26714,20461,1618993,5289,5676,11970,19080,2358876,70704,13052,71208,77584,25542,14744,53618,11139,17160,9648,13825,28210,21251,28203,5934,85952,12338,71574,5966,9386,43632,181896,5876,12462,80580,15562,13676,4028,913951,117473,7378,7254,4644,6396,6579,27512,16536,8170,1452204,8372,10492,812520,712975,11232,19096,8432,18724,39780,9546,28656,44424,9548,187426,6321,8664,5876,9308,15405,131254,2437034,15652,6448,23112,8476,159912,120120,15028,5548,7200,166152,116762,16391374,16616,12168,5891,7848,110916,7378,363320,56628,45537,59706,141768,307942,5547,2630700,10823,54622,38916,32240,478345,15132,6882,18810,222227,5668,9620,903997,18091,82713,5928,238248,77634,12896,2306484,6240,5460,6510,4408,4104,14668,17422,34918,19912,44578,340318,10478,47400,46136,22776,25628,22360,9880,23244,34162,2303238,19656,83898,267592,190008,91846,118800,7998,56169,9717,3852,3708,460917,1268856,6660,12688,493064,20862,37584,1157587,10764,118248,13208,9006,7176,16039,62496,38829,32184,4066,13330,5772,293169,893234,5112,8772,1062234,12814,625352,919274,113088,44556,22436,12719,368037,7440,30336,10478,2106326,1039561,28196,68112,165663,57350,28519,29704,365456,130910,39658,6032,291826,16692,1204412,400214,105768,49665,19722,44763,4066,15428,185966,86268,421496,17856,103329,218808,95202,5206,7904,40166,33748,8122,25438,61017,20736,722736,9933,342409,4560,12240,124682,22256,72842,12245,130312,67464,244110,44793,32627,23932,21488,5772,10452,13832,234422,8686,7848,72360,100152,91728,20376,10750,46624,18936,17212,32798,12255,10406,34996,7130,7675506,12502,459000,48111,4294,19522,20683,7280,20952,374539,18565,9503,118512,15552,4773,21844,9030,34048,15496,69757,10922,10902,17280,1191636,4687,5160,53878,4859,49849,34684,16432,49400,11180,82646,6758,40053,13752,9620,18490,64368,9159,7410,49770,218178,10080,210485,5418,8632,14554,42294,4142,9672,79116,8996,55214,252864,11696,37446,24130,550368,10906,18876,29625],\"yaxis\":\"y\",\"type\":\"scattergl\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"average_playtime\"},\"type\":\"log\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"estimated_sells\"},\"type\":\"log\"},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Scatter plot: estimated_sells vs average_playtime\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('8c9c6571-8ca9-43de-9a85-7d857207a770');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Las 2 últimas variables numéricas muestran una dispersión en lugar de algún tipo de relación con la cantidad de ventas estimadas. Se cree que estas variables no serán de utilidad para este problema."
      ],
      "metadata": {
        "id": "9Xo5bXW18i7Z"
      },
      "id": "9Xo5bXW18i7Z"
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.scatter(df_train, y=\"estimated_sells\", x=\"price\", log_y=True)\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "P0cXxJqt-hBT",
        "outputId": "d3fb2915-747a-4309-edcb-7b28ea926cf1"
      },
      "id": "P0cXxJqt-hBT",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.16.1.min.js\"></script>                <div id=\"eaac4908-9d05-49c5-9fa7-c8191c10a3c5\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"eaac4908-9d05-49c5-9fa7-c8191c10a3c5\")) {                    Plotly.newPlot(                        \"eaac4908-9d05-49c5-9fa7-c8191c10a3c5\",                        [{\"hovertemplate\":\"price=%{x}<br>estimated_sells=%{y}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"\",\"showlegend\":false,\"x\":[0.0,10.99,6.99,0.0,7.99,0.75,27.79,1.99,19.49,0.0,13.99,3.99,0.0,0.0,29.99,0.0,4.99,3.99,3.99,0.0,6.99,0.0,6.99,15.49,4.99,23.39,0.0,6.99,0.0,6.99,7.19,6.99,10.99,6.99,1.69,5.99,0.0,14.99,17.99,8.49,9.99,2.99,22.99,6.99,0.0,10.99,7.19,3.99,3.99,4.99,0.79,1.99,14.99,2.09,18.99,44.99,19.49,14.99,11.39,34.99,10.99,34.99,0.0,14.99,3.99,15.49,18.99,10.99,14.99,2.79,22.99,10.99,19.49,1.69,1.69,6.99,14.99,10.99,2.79,0.0,3.99,8.99,0.0,15.49,0.79,0.0,14.99,10.99,4.79,15.49,3.99,0.0,0.0,14.99,29.99,2.79,5.79,6.99,3.99,4.99,0.79,7.19,0.0,10.99,6.99,0.0,6.99,14.99,5.59,0.79,3.99,34.99,0.79,3.99,0.79,1.99,19.99,0.0,14.99,9.29,5.99,3.99,10.99,7.19,14.99,3.99,1.99,0.0,14.99,7.19,1.99,9.99,4.99,12.39,6.99,0.0,1.99,15.99,2.79,34.99,9.99,4.99,7.19,0.0,3.99,4.99,6.99,11.99,31.99,4.99,10.29,10.99,3.99,9.99,6.99,6.99,10.99,29.99,14.99,34.99,14.99,6.99,10.99,16.99,14.99,2.09,29.99,11.39,19.49,14.99,6.99,9.99,11.99,9.99,4.79,8.99,1.69,10.29,1.99,8.29,0.0,1.59,4.29,7.99,11.39,0.79,10.29,6.99,4.99,0.0,6.99,11.39,0.0,8.99,6.99,10.99,15.49,0.0,2.09,1.99,3.99,3.99,2.79,8.99,19.99,0.0,0.0,22.99,0.79,12.99,0.0,26.99,7.19,15.49,3.99,19.99,0.0,0.79,0.79,24.99,0.79,6.99,3.99,0.79,0.0,12.99,0.0,11.39,0.0,5.19,0.0,0.9,10.99,2.09,9.99,14.99,0.79,2.79,6.99,1.69,3.99,1.59,9.99,6.99,0.79,0.0,7.19,0.0,15.49,3.99,6.99,34.99,4.99,6.99,2.99,0.79,8.29,3.99,14.99,4.49,3.99,14.99,0.0,1.99,0.0,27.99,3.99,5.19,10.99,30.99,0.0,0.0,7.19,0.79,6.99,1.59,14.99,2.99,6.99,6.99,6.99,5.19,2.09,14.99,10.99,11.0,2.89,14.99,4.49,0.79,14.99,4.99,0.79,2.49,19.49,0.0,6.99,6.99,7.99,2.99,10.99,11.99,12.39,0.0,4.99,12.99,1.59,4.99,7.19,0.0,14.99,0.79,3.99,4.99,11.99,14.99,14.99,7.19,14.99,0.0,15.49,6.99,6.99,6.99,14.99,11.49,0.0,7.99,10.99,13.37,10.99,12.99,0.0,0.0,1.99,15.99,6.99,1.99,7.99,12.39,6.99,25.99,4.99,12.49,15.49,13.59,18.99,1.69,6.99,0.79,4.99,4.99,3.49,29.99,0.0,3.99,6.99,1.99,2.09,44.99,7.99,6.99,8.99,7.99,8.59,8.59,3.99,12.99,0.0,5.79,6.99,14.99,4.79,19.99,4.79,4.99,13.5,0.0,5.19,0.0,6.99,6.99,0.79,14.99,0.79,1.99,36.99,0.0,14.99,10.29,6.99,3.99,1.99,22.99,37.99,10.99,5.59,2.79,10.29,0.0,9.99,15.49,0.0,0.79,10.99,4.49,14.99,3.99,11.39,2.79,5.59,4.99,22.99,3.99,27.99,6.99,29.99,2.99,11.99,5.79,6.99,0.0,10.29,14.99,10.99,0.0,5.99,29.99,0.0,3.99,14.99,6.99,0.0,29.99,0.0,6.99,14.99,1.69,5.59,29.99,4.99,14.99,18.99,11.39,15.49,7.19,4.79,2.79,3.99,5.59,3.99,0.9,5.59,0.0,0.0,1.69,6.99,5.19,22.99,5.59,0.79,2.79,7.99,6.99,10.99,1.69,12.99,10.99,4.99,34.99,0.0,5.59,11.39,6.99,1.59,1.59,7.19,7.19,13.99,1.59,3.19,39.99,5.99,14.99,5.99,11.39,6.99,11.39,0.0,15.49,2.89,18.99,5.59,7.19,3.19,4.99,1.99,3.19,0.79,0.0,15.99,0.0,14.99,3.99,6.99,13.99,7.19,7.19,11.39,3.99,15.49,17.99,11.99,10.99,1.69,9.99,49.99,3.99,18.99,10.99,4.79,8.99,2.79,10.99,60.99,1.99,6.99,1.69,0.0,0.99,0.0,0.79,0.0,6.99,3.99,1.69,14.99,6.99,1.59,9.99,3.99,6.99,0.79,0.0,6.99,4.79,7.19,19.99,13.49,34.99,15.99,6.99,39.99,4.99,1.99,19.49,6.99,4.79,22.99,3.99,6.99,4.49,13.99,0.0,3.99,27.99,0.0,0.0,29.99,3.99,19.49,12.49,13.99,0.0,15.49,0.99,3.99,14.99,6.99,0.0,14.99,39.99,7.99,10.99,10.99,14.99,19.99,9.99,32.99,0.0,10.99,12.99,0.0,0.99,5.19,6.99,7.99,0.0,10.99,1.99,7.19,2.79,15.49,6.99,0.0,4.99,6.99,2.09,1.99,14.99,2.89,14.99,1.59,6.99,7.99,0.0,0.0,14.99,1.59,9.99,0.0,2.99,0.0,3.99,14.99,29.99,3.99,11.5,11.99,5.59,7.19,6.99,3.99,4.49,0.0,10.99,11.39,17.49,3.99,0.79,0.0,5.99,2.09,6.99,3.99,1.59,2.79,0.0,14.99,0.0,0.0,0.0,0.79,18.99,3.19,0.79,6.99,3.99,4.29,14.99,0.79,10.99,14.99,29.99,8.99,3.99,7.99,14.99,22.99,0.79,0.0,15.49,5.99,11.99,12.99,6.99,3.99,10.99,10.99,6.99,7.99,4.79,14.99,1.69,14.99,11.39,0.0,0.0,4.79,23.79,14.99,6.99,3.99,2.09,2.79,16.99,1.69,0.79,10.99,6.99,5.99,13.49,2.79,15.49,6.99,6.99,19.99,13.99,0.0,6.99,7.19,14.99,7.99,9.99,14.99,5.99,0.0,34.99,10.99,0.99,6.99,10.99,0.0,7.19,11.99,13.99,6.99,6.99,3.99,6.99,7.19,15.49,11.39,0.0,0.0,10.99,4.99,1.59,0.79,6.99,8.99,19.99,14.99,0.0,18.99,10.99,4.79,2.79,14.99,1.99,4.79,6.99,1.59,3.99,0.79,23.79,5.59,11.39,1.69,0.0,19.99,10.99,11.39,46.49,1.59,14.99,4.79,6.99,3.99,0.0,10.99,2.09,10.99,0.79,3.99,6.99,1.99,23.79,4.49,0.0,3.99,13.59,7.7,2.09,4.99,1.99,23.79,7.19,19.99,12.99,19.99,15.49,10.99,3.99,15.49,5.19,16.99,6.99,1.69,3.99,0.0,3.99,4.79,6.99,0.0,23.79,4.79,6.99,11.99,9.99,0.0,15.49,0.79,19.99,1.59,3.99,8.99,14.99,1.69,0.0,14.99,11.39,10.99,1.59,5.99,3.99,14.99,11.39,4.79,0.0,19.49,1.69,6.99,7.99,0.0,0.0,14.99,0.79,0.0,8.99,14.99,4.99,0.0,0.0,1.99,4.99,11.39,1.59,3.99,0.0,7.99,6.99,6.99,0.0,49.99,6.99,10.99,4.99,0.0,7.99,24.99,22.99,18.99,19.99,6.99,0.0,15.49,6.99,32.99,14.99,22.49,0.0,6.99,2.89,11.39,6.99,10.99,9.99,2.09,1.59,0.79,9.99,0.79,5.99,4.79,39.99,11.99,1.99,2.79,0.79,1.69,15.49,6.99,14.99,19.49,11.39,39.99,4.99,0.79,0.0,1.49,12.99,0.0,23.79,6.99,11.99,10.99,0.0,0.59,14.99,6.99,13.99,0.79,10.29,24.99,3.99,0.0,14.99,6.99,19.99,5.99,6.99,4.79,3.99,4.79,14.99,19.49,6.99,0.99,0.0,11.39,3.99,0.0,14.99,9.99,4.79,10.29,6.49,9.29,6.99,0.79,0.0,4.99,11.39,3.99,1.99,0.0,13.99,6.99,10.99,0.0,4.49,0.79,14.99,0.79,10.99,14.99,1.99,12.39,8.99,3.99,2.79,2.99,0.0,0.0,19.49,4.99,3.99,4.99,2.89,10.99,3.99,6.99,0.72,2.09,3.99,0.0,3.49,11.99,7.19,6.99,4.79,6.99,0.0,1.99,15.8,7.19,10.99,0.0,11.39,9.99,0.32,4.29,6.99,3.99,15.99,10.99,2.89,6.99,6.99,34.99,11.39,0.79,29.99,0.0,9.99,1.69,3.99,2.89,0.79,10.99,15.49,24.99,11.39,29.99,7.19,5.99,9.29,6.99,14.49,1.99,6.99,7.19,7.19,2.49,29.99,15.99,6.99,9.99,0.0,0.79,6.99,4.25,0.79,0.79,0.0,0.0,9.99,3.99,14.21,0.79,8.59,6.99,11.99,9.99,11.39,16.99,3.99,4.79,0.0,7.99,3.99,4.79,0.79,9.99,6.99,10.99,2.09,9.99,11.39,11.99,0.0,0.79,11.99,3.99,0.0,11.99,0.79,14.99,3.99,6.99,5.79,2.09,5.59,6.99,4.29,0.0,6.69,3.99,23.79,3.99,4.99,18.99,2.89,0.0,15.49,5.19,6.99,15.99,0.0,9.29,11.39,3.99,11.99,1.99,1.99,7.19,14.99,14.99,0.0,3.99,3.99,1.59,34.99,2.79,3.99,7.49,3.99,1.99,14.99,2.99,11.39,3.99,3.99,0.79,3.19,0.0,7.99,10.99,5.59,5.59,10.99,0.72,14.99,19.99,17.99,14.99,3.99,0.0,15.49,15.49,5.99,6.99,18.99,10.99,8.99,0.0,2.79,10.99,6.99,3.99,6.99,7.99,4.99,5.59,10.99,15.49,1.99,3.99,11.39,7.19,14.99,0.0,1.99,1.49,0.0,14.99,15.49,15.49,3.99,6.99,4.79,6.19,39.99,7.19,11.99,0.0,4.99,0.0,6.99,3.99,4.79,0.0,1.69,24.99,6.99,3.99,3.99,10.99,1.99,14.99,14.99,2.79,10.99,9.99,5.79,29.99,14.99,0.0,0.0,0.79,6.99,0.0,44.99,0.0,3.99,7.99,0.0,6.19,6.99,7.99,6.99,39.99,10.99,6.99,13.99,3.99,5.99,11.39,6.99,3.99,2.79,0.0,18.99,1.59,3.99,0.79,22.99,15.49,49.99,27.79,1.99,15.49,0.79,6.99,15.49,0.79,0.79,7.19,3.99,11.39,24.99,7.99,1.99,23.99,5.59,0.0,1.69,4.79,10.29,24.99,6.99,0.0,6.99,3.99,6.99,34.99,6.99,2.79,2.09,6.99,0.0,0.0,3.99,6.99,0.79,5.19,6.99,19.49,3.99,6.99,0.0,0.0,14.99,0.0,14.99,3.99,2.79,19.99,19.99,10.99,34.99,7.19,0.0,7.19,4.99,1.69,0.0,29.99,4.99,39.99,3.99,6.99,44.99,3.99,3.99,2.79,4.99,0.0,3.99,6.99,12.49,0.0,0.0,5.19,3.99,0.79,0.0,3.99,6.99,4.99,7.19,0.0,6.99,5.19,18.99,3.99,0.0,6.99,10.99,10.29,13.49,4.49,2.99,6.19,0.0,18.99,0.0,24.99,22.99,0.79,14.99,2.79,1.69,2.28,12.99,0.99,22.99,6.99,4.99,11.39,14.99,7.19,0.0,15.49,0.0,6.99,0.0,9.29,0.79,5.59,0.79,3.99,0.79,0.99,7.19,15.49,10.29,5.99,0.0,10.99,15.49,29.99,39.99,14.99,10.99,3.99,7.19,3.99,7.19,8.99,0.79,2.89,6.99,0.0,2.89,0.79,13.59,11.39,6.99,5.99,0.0,6.99,0.0,1.69,15.49,14.99,18.99,5.59,22.99,5.59,7.19,2.89,2.89,29.99,12.99,0.79,4.99,0.0,0.0,4.99,7.19,0.79,29.99,10.99,11.99,23.79,0.79,14.99,10.99,22.99,3.99,0.0,1.69,10.99,5.59,0.0,1.99,1.59,6.99,6.99,0.79,10.99,0.79,1.69,4.99,29.99,8.59,7.19,29.99,12.39,10.99,3.49,1.99,3.99,8.99,26.99,6.99,5.59,0.0,0.0,5.79,1.69,23.79,10.99,0.79,3.99,14.99,9.99,0.79,10.99,1.59,8.99,10.99,19.99,4.79,1.99,11.99,0.0,9.29,2.79,7.19,49.99,1.69,6.99,19.49,15.49,10.99,5.99,25.99,3.99,1.99,6.99,6.99,6.99,1.69,9.29,1.99,0.79,1.69,8.99,10.29,0.0,14.99,5.79,0.0,10.99,0.49,0.0,4.99,0.79,6.99,10.99,8.99,15.49,10.99,0.0,10.99,5.19,0.79,7.99,5.99,3.99,2.79,6.99,1.69,4.99,15.49,3.99,24.99,24.99,6.99,13.99,1.99,7.99,22.99,6.99,7.19,6.99,3.99,3.19,10.99,3.99,10.99,14.99,6.99,29.99,1.99,1.99,9.29,15.49,12.99,6.99,0.0,6.99,52.99,2.99,34.99,10.29,11.39,14.99,10.99,6.99,0.0,6.99,15.49,14.49,3.99,10.99,0.79,1.79,3.99,11.9,5.79,0.0,29.99,7.19,7.99,4.79,39.99,3.99,0.0,3.99,17.99,4.99,24.99,1.99,10.99,3.99,3.99,4.99,7.99,0.0,0.0,11.39,0.0,11.39,10.29,7.99,0.0,11.39,5.99,6.99,9.99,3.99,6.99,1.69,15.99,14.99,0.79,0.79,6.99,6.99,3.99,0.0,0.0,2.09,6.99,0.79,9.99,7.19,23.79,5.79,0.79,7.99,0.0,29.99,1.99,6.99,0.0,0.0,11.39,13.59,7.99,0.79,3.99,39.99,0.0,7.19,39.99,22.99,0.0,3.49,3.99,49.99,7.99,15.49,4.49,26.99,6.99,6.99,14.99,6.99,2.09,0.0,6.99,10.29,0.0,10.99,9.99,15.49,6.19,0.0,15.49,6.99,14.49,5.59,6.99,5.59,10.99,1.59,19.49,14.49,5.99,5.99,6.99,19.49,2.79,3.99,2.79,6.99,9.99,5.79,16.99,2.89,12.49,9.99,6.99,0.0,0.0,14.99,15.49,4.99,0.0,6.99,0.0,7.99,39.99,0.0,11.39,4.99,3.19,11.39,30.99,27.79,6.99,3.99,0.79,2.79,0.0,9.99,29.99,4.79,3.99,0.0,2.09,0.79,7.99,6.99,10.99,3.99,4.79,2.79,7.99,7.19,2.49,5.19,2.99,3.99,3.99,6.99,3.99,39.99,3.19,34.99,0.79,10.99,11.39,14.99,10.99,3.99,6.99,15.99,5.99,8.99,7.5,15.49,2.09,4.99,9.99,0.0,3.99,1.59,14.99,3.99,15.49,8.99,18.99,10.99,10.99,0.0,6.99,1.69,3.99,5.79,0.0,4.99,12.39,7.19,6.99,0.0,3.99,1.59,0.0,4.99,15.99,2.09,7.19,0.0,11.39,3.99,4.99,9.99,0.0,10.99,27.79,23.79,0.0,3.99,2.79,3.99,6.99,11.39,6.99,1.99,0.0,10.59,0.0,7.19,19.49,0.0,0.0,0.0,1.59,2.99,6.99,1.59,14.99,22.99,4.99,7.19,32.99,1.69,23.79,3.99,6.99,0.79,0.0,15.49,3.99,0.79,16.99,6.99,0.0,3.99,11.39,15.49,0.0,7.19,11.99,0.0,6.99,1.99,0.79,29.99,0.0,0.0,6.19,0.0,7.19,9.99,5.99,34.99,0.0,0.79,3.49,9.99,1.59,8.99,9.99,26.99,6.99,0.79,3.99,31.99,7.19,11.39,7.99,23.79,4.99,18.99,3.99,11.99,3.99,39.99,5.59,16.99,5.99,34.99,0.0,14.99,2.09,14.99,9.99,0.0,3.99,11.39,19.99,14.99,14.99,0.0,6.99,22.99,9.99,4.99,0.79,0.0,7.19,3.99,19.49,1.69,3.99,10.99,0.0,6.99,0.0,1.99,6.99,0.0,14.99,23.79,1.69,2.89,8.99,0.0,0.0,0.79,4.99,9.99,18.99,10.99,19.49,3.99,1.69,2.79,0.0,10.29,0.79,13.59,0.0,11.39,29.99,0.79,2.89,3.1,10.99,24.99,0.79,7.19,3.99,5.99,23.79,0.0,3.99,4.99,0.0,11.39,6.99,11.39,6.99,9.99,34.99,19.49,2.79,13.49,14.99,3.99,5.99,8.99,23.79,19.99,6.99,4.79,0.0,18.99,0.0,7.19,8.99,7.19,5.59,4.79,0.0,0.79,9.99,0.79,15.49,3.99,15.99,4.79,0.79,3.99,3.99,0.0,14.99,3.99,10.99,10.99,22.99,1.69,3.99,25.79,12.99,15.99,0.0,3.99,14.99,1.59,6.99,6.99,5.99,22.99,15.49,7.19,1.59,0.79,3.99,0.0,15.49,10.99,0.79,3.99,15.49,0.79,0.79,0.0,3.99,15.49,19.49,2.79,19.49,3.99,3.99,10.99,3.99,30.99,7.19,2.79,7.19,0.79,15.49,10.99,10.59,14.99,0.0,0.0,5.79,0.0,4.99,15.99,0.0,6.99,0.0,1.69,5.59,0.79,3.99,0.79,10.99,29.99,0.79,6.99,6.19,1.99,39.99,0.0,0.0,2.99,23.99,11.99,14.99,2.89,14.99,11.99,10.99,7.99,4.79,15.49,10.99,7.19,3.99,4.99,3.99,0.0,5.59,6.99,0.0,15.49,1.69,10.29,12.99,3.99,1.99,3.99,22.99,6.99,13.99,0.0,7.99,18.99,8.99,3.99,7.19,4.99,3.99,44.99,15.49,0.0,0.0,3.19,0.0,0.0,0.79,13.99,4.99,9.29,24.99,6.99,10.99,7.19,6.99,1.59,15.49,1.59,4.79,6.99,10.99,24.99,3.99,33.99,7.19,0.79,10.29,7.19,6.99,11.99,0.79,11.39,0.79,0.0,14.99,0.79,0.79,0.0,14.99,9.99,14.99,10.99,14.99,23.79,6.99,13.99,9.99,8.99,25.99,9.99,10.99,0.72,0.0,12.49,23.79,0.0,22.99,14.99,13.49,6.99,13.59,3.49,0.0,12.49,24.99,12.99,14.99,10.99,6.99,7.19,10.99,16.99,6.99,0.0,6.99,10.99,4.99,1.69,3.99,3.99,0.0,0.0,3.99,3.99,13.99,0.79,19.99,6.99,0.79,12.99,5.49,14.99,2.09,14.99,6.99,34.99,3.99,0.0,8.59,14.99,4.99,10.99,4.59,7.19,0.0,3.99,14.99,0.0,0.79,0.79,0.0,4.79,4.79,19.49,23.79,1.99,6.99,14.99,0.0,44.99,15.49,0.79,3.99,14.99,0.0,7.19,0.0,6.99,0.79,4.79,8.59,14.99,3.99,1.59,3.19,10.99,8.99,8.99,6.99,7.19,4.99,3.99,3.19,3.99,16.99,10.29,4.79,4.24,0.79,14.99,1.99,1.99,0.79,24.99,0.0,14.99,0.79,0.79,15.49,11.99,7.19,4.49,10.99,10.99,0.0,1.99,9.99,0.79,1.59,6.99,4.79,0.79,3.99,8.59,4.99,3.99,3.99,22.99,20.99,6.99,8.99,3.99,6.99,10.99,0.0,1.69,1.59,6.99,0.0,14.99,3.19,7.19,3.99,23.79,15.49,2.99,29.99,6.99,0.79,0.0,46.49,12.39,14.99,8.99,1.99,29.99,14.99,6.99,8.29,1.99,9.99,0.0,6.99,11.39,9.99,14.99,4.79,6.99,6.99,14.99,5.99,0.79,5.19,0.0,1.99,6.99,16.99,1.69,8.99,1.59,11.0,2.09,6.99,0.0,7.19,15.99,11.39,6.99,12.99,0.0,9.29,0.79,12.49,0.0,19.49,30.99,0.0,9.29,3.49,6.99,7.99,2.79,10.29,0.0,11.99,3.99,9.99,4.79,6.99,0.0,6.99,0.0,0.79,0.79,2.89,7.19,4.49,4.79,10.99,15.49,4.79,3.99,6.99,0.0,11.49,14.99,3.99,0.0,10.99,0.0,10.99,3.99,12.39,39.99,6.99,0.0,0.0,14.99,0.0,39.99,0.0,0.0,2.99,4.99,29.99,0.79,6.99,0.0,14.99,11.99,4.99,0.0,6.99,3.99,8.99,39.99,0.0,11.39,6.99,6.99,7.19,1.99,7.19,0.0,0.79,44.99,14.99,25.99,0.0,4.99,0.79,4.99,14.99,6.99,15.49,10.99,1.59,29.99,1.59,6.99,15.49,3.99,19.99,7.19,10.99,3.99,2.09,0.0,22.99,15.99,1.69,8.59,1.59,0.0,0.0,5.19,9.99,7.99,8.99,3.99,5.59,1.69,0.0,0.0,2.89,0.0,26.99,5.79,0.79,25.99,9.99,3.99,0.79,52.99,10.99,3.99,1.69,18.99,4.79,0.0,6.99,10.29,0.0,39.99,14.99,4.99,24.99,1.99,14.99,6.99,6.99,2.79,0.0,4.79,6.99,10.99,1.59,7.99,10.99,6.99,9.29,17.99,4.99,2.09,2.09,1.59,4.99,10.99,7.19,10.99,6.99,0.0,19.49,23.79,2.09,1.99,2.09,0.0,3.99,10.99,7.19,0.0,6.99,0.0,0.79,1.59,0.0,5.59,2.09,6.99,2.09,0.79,1.69,23.79,1.59,1.99,2.09,14.99,5.99,15.49,0.0,15.99,1.59,3.99,0.79,6.99,3.99,6.99,11.39,5.99,6.99,15.99,15.49,8.59,0.0,0.0,14.99,0.0,14.99,9.29,23.39,3.99,0.0,0.0,6.99,49.99,1.69,19.49,0.79,4.79,0.0,29.99,4.12,10.99,15.99,3.99,24.99,1.69,10.99,10.99,24.99,9.99,5.99,3.99,10.99,7.49,4.99,6.99,0.0,9.99,6.99,5.79,6.99,2.89,10.99,0.0,0.9,6.99,0.0,10.99,5.19,0.0,14.99,4.99,6.99,5.79,4.29,7.99,5.19,4.79,4.99,9.99,10.99,44.99,7.99,6.99,0.0,4.49,5.59,0.79,3.99,19.99,22.99,23.79,44.99,1.69,13.99,0.0,4.79,10.29,6.99,39.99,4.99,49.99,19.49,6.99,6.99,19.99,3.99,6.99,1.59,14.99,1.59,1.99,10.99,6.99,8.59,14.99,10.99,23.79,5.79,14.99,14.99,0.0,4.99,0.0,10.29,6.99,6.99,3.99,39.99,10.99,0.0,3.99,0.79,0.0,3.99,5.69,7.19,0.0,5.59,14.99,7.19,0.79,6.99,3.99,6.99,32.99,18.99,9.29,15.49,1.49,3.19,11.39,4.99,0.0,0.0,0.0,6.99,3.99,9.99,4.79,10.99,8.99,0.0,14.99,7.19,3.99,0.0,6.49,6.99,7.19,1.59,60.99,24.99,6.99,14.49,8.99,3.99,14.99,3.99,6.99,33.99,5.99,14.99,0.79,0.0,7.19,4.79,0.0,2.09,4.99,14.99,4.99,10.99,0.79,14.99,12.39,3.99,7.99,0.79,11.95,26.99,0.0,10.29,0.0,10.99,0.0,4.99,17.99,9.99,25.99,0.79,23.79,10.99,8.99,3.99,39.99,1.59,18.99,0.79,9.99,0.0,0.0,14.99,10.99,0.0,0.0,5.59,4.79,0.0,4.99,3.99,41.99,9.29,3.99,1.99,23.79,14.99,1.59,0.0,39.99,1.99,10.99,2.89,11.99,29.99,27.79,1.99,0.79,0.79,3.99,6.99,1.59,14.49,0.0,0.0,23.79,2.79,29.99,15.49,10.99,44.99,7.19,0.79,10.99,14.99,9.99,14.99,15.49,5.99,0.0,14.99,9.99,11.39,10.99,6.99,4.79,1.99,9.99,0.0,13.99,7.99,0.79,14.99,5.99,5.79,7.19,0.79,1.99,11.39,0.0,14.99,6.99,10.99,0.79,5.99,6.99,1.99,0.0,3.19,5.59,15.99,3.99,0.0,0.0,5.59,15.49,6.99,0.0,0.0,6.99,0.0,18.99,2.79,7.19,1.69,24.99,9.99,6.99,14.49,3.99,15.49,19.49,3.99,22.99,14.99,3.99,3.19,2.79,4.99,6.99,10.99,3.99,4.79,22.99,0.0,6.99,14.99,13.99,15.49,1.99,10.29,11.39,7.99,18.99,10.99,6.99,15.49,1.99,3.99,3.99,4.99,14.95,10.99,19.99,6.99,0.0,3.99,6.99,6.99,2.79,14.99,10.99,1.99,14.99,0.0,4.99,15.49,13.99,5.59,0.0,4.99,16.99,29.99,5.99,6.99,6.99,4.99,3.99,0.0,3.99,2.09,3.99,39.99,9.99,0.79,0.0,5.19,3.99,1.69,16.99,23.79,4.79,2.09,12.99,11.39,29.99,12.39,10.99,5.99,5.79,3.99,10.99,19.49,0.0,6.99,0.0,0.0,5.19,0.0,3.99,4.99,3.19,14.99,7.99,10.99,0.79,2.09,0.0,7.19,6.99,3.99,7.19,15.99,6.99,14.99,7.19,6.99,9.99,14.99,0.79,6.99,4.99,0.0,1.99,3.99,11.99,0.79,6.99,6.99,10.99,4.99,7.19,11.39,17.99,14.99,5.19,29.99,3.19,5.59,0.0,1.69,0.0,1.59,44.99,14.99,7.19,0.0,9.99,1.99,18.99,19.99,14.99,7.19,10.99,0.0,6.99,1.59,3.99,0.79,6.99,6.49,19.49,26.99,3.99,0.79,7.19,4.99,10.59,0.0,7.19,3.99,4.99,12.99,0.0,14.99,0.0,7.19,6.99,2.89,25.99,23.79,19.49,10.99,0.79,0.0,7.19,10.99,0.0,6.99,6.99,3.19,11.99,13.99,14.99,10.99,15.49,19.99,6.99,0.79,5.99,22.99,7.19,7.99,7.99,34.99,0.0,0.0,0.0,19.49,1.99,5.59,3.99,0.0,2.09,0.79,2.09,1.59,11.99,0.79,1.69,27.79,0.0,6.99,9.29,9.99,23.79,15.49,6.99,14.99,4.99,3.99,6.99,0.79,18.99,1.69,6.99,44.99,1.99,0.0,10.99,19.49,6.99,7.99,14.99,3.99,3.49,7.19,23.79,17.99,9.9,0.79,11.99,5.99,7.19,0.79,6.99,7.19,3.19,6.99,14.99,5.59,18.99,2.79,9.99,3.99,14.99,0.0,0.0,10.99,14.99,11.99,1.69,16.99,0.0,0.79,18.99,4.99,15.49,0.0,2.79,30.99,5.49,6.99,0.0,12.99,3.99,14.69,14.99,6.99,6.99,4.99,9.99,6.99,19.49,11.99,10.99,13.99,6.99,5.99,3.99,19.99,6.99,4.99,0.79,10.99,7.18,4.99,4.79,19.99,10.99,5.59,1.99,10.99,41.99,15.49,0.0,4.25,0.0,1.99,9.99,6.99,3.99,34.99,19.49,8.29,15.49,7.19,2.79,11.39,4.99,8.99,3.99,3.29,0.0,6.99,3.19,6.99,7.19,3.99,10.99,1.59,1.99,11.39,2.89,14.99,3.99,3.99,0.0,6.99,11.39,11.39,11.99,10.99,1.59,0.0,4.79,5.79,1.99,9.99,6.99,2.99,49.99,0.79,7.19,4.79,44.99,0.0,0.0,1.59,0.0,2.79,15.49,10.99,5.59,14.99,0.79,0.0,15.49,6.99,29.99,3.99,29.99,9.99,10.99,1.99,14.99,0.0,0.0,3.99,0.0,3.99,4.79,3.99,4.99,0.0,11.39,0.79,4.99,14.99,5.59,3.99,11.39,0.79,10.99,3.99,11.39,0.0,3.99,13.99,1.99,10.99,3.99,3.99,1.59,0.0,17.99,10.99,24.99,9.99,3.99,6.99,11.39,0.0,10.99,10.99,2.89,0.0,10.99,23.79,1.59,10.99,14.99,0.0,9.99,7.99,11.39,6.99,15.49,3.99,0.0,9.99,19.49,0.0,0.0,5.19,7.19,6.99,5.19,10.99,0.0,3.99,19.99,3.99,0.0,3.99,18.99,3.99,2.09,10.99,14.99,6.99,24.99,6.99,0.0,3.99,3.99,1.99,2.09,4.99,0.0,39.99,8.29,18.99,0.0,0.79,3.99,5.99,7.19,5.79,29.99,39.99,7.99,44.99,11.99,4.99,4.99,0.79,1.99,0.0,9.99,0.0,6.99,19.99,11.39,2.09,6.99,9.99,3.99,3.99,29.99,2.99,0.0,10.99,0.0,7.19,2.99,3.99,6.99,4.79,5.99,6.99,0.79,0.0,0.0,9.99,9.99,4.99,6.99,12.99,0.0,18.99,6.99,3.99,9.99,7.19,3.99,0.0,7.19,7.19,5.59,0.0,6.99,7.19,4.79,0.0,10.99,14.99,0.0,18.99,0.79,1.69,13.0,0.0,3.99,1.59,11.39,0.0,10.99,9.99,16.99,3.99,7.19,1.99,3.99,10.99,10.99,4.99,9.99,0.0,8.99,2.09,3.99,22.99,2.09,19.99,6.99,7.19,29.99,0.0,6.99,11.39,0.79,9.99,3.19,6.99,6.99,0.0,23.79,0.79,19.49,6.99,0.0,30.99,25.99,0.0,0.0,5.79,10.99,9.99,14.99,6.99,0.0,1.59,7.19,13.99,4.99,3.99,13.59,0.0,3.99,1.99,3.99,10.99,3.19,5.99,1.69,7.19,18.99,9.29,0.0,0.0,8.29,8.59,4.79,0.0,3.99,14.99,3.99,19.99,22.99,3.99,0.0,0.79,4.79,14.99,49.9,6.99,0.0,10.99,3.99,12.99,29.99,4.79,22.99,6.99,8.99,19.49,14.99,3.49,22.99,6.99,3.99,6.99,3.99,0.0,19.49,10.99,7.19,11.39,11.99,15.99,23.79,4.25,22.49,11.99,6.99,4.99,15.99,5.2,7.19,3.99,10.99,14.99,7.99,3.99,3.99,3.99,9.99,29.99,0.79,15.49,0.0,0.0,7.99,10.99,3.99,6.99,14.99,16.99,12.99,0.0,8.29,22.99,11.39,26.99,19.49,0.0,1.59,4.99,2.09,4.99,15.49,14.99,2.79,0.0,0.0,7.19,7.19,18.99,9.99,11.39,0.79,1.99,14.99,24.99,7.19,9.99,15.49,0.0,0.79,0.0,9.29,14.99,10.99,0.0,6.99,6.99,0.0,1.59,7.99,1.99,3.99,6.99,6.99,11.39,14.99,6.99,3.99,3.99,2.89,7.19,12.99,10.99,8.99,14.99,10.99,9.99,3.99,10.99,0.79,14.99,0.0,16.99,17.99,14.99,19.49,32.99,0.0,6.99,0.79,6.99,0.0,0.79,0.0,4.79,15.49,10.99,29.99,11.39,0.0,5.99,6.99,0.0,10.99,6.99,8.02,6.99,2.09,15.49,34.99,3.99,3.99,6.99,22.99,1.99,3.99,0.0,49.99,0.0,3.99,3.99,1.99,5.19,8.59,1.99,8.59,0.0,3.99,0.79,6.99,13.49,6.99,7.49,4.99,6.99,5.99,6.99,11.99,0.0,0.79,22.99,19.99,6.99,6.99,24.99,0.0,6.99,4.99,0.0,3.99,8.59,14.99,4.79,54.99,0.79,6.99,14.99,3.99,39.99,10.99,29.99,3.99,13.99,10.99,6.99,11.49,15.49,3.99,3.99,14.99,2.09,0.0,0.79,14.99,11.39,6.99,12.39,9.99,9.29,11.39,0.0,14.99,15.49,0.79,1.59,10.99,9.99,5.19,3.99,3.99,22.99,9.99,3.99,14.99,6.99,0.0,11.39,0.0,15.49,16.99,32.99,0.0,0.0,0.0,0.79,3.99,1.99,0.0,0.0,6.99,4.39,8.99,12.39,0.0,22.99,19.49,6.99,4.99,11.39,1.99,0.0,3.99,5.59,10.99,10.99,11.99,6.99,25.99,6.99,2.89,5.99,0.0,11.49,9.99,5.59,7.99,0.0,1.99,10.29,7.19,1.59,6.99,6.99,0.79,18.49,0.79,6.99,6.99,0.0,0.0,0.79,6.99,0.0,14.99,10.99,11.39,3.99,0.0,3.99,1.59,11.39,0.0,1.49,14.99,0.79,11.39,11.39,14.99,11.39,0.79,24.99,5.19,0.0,0.79,15.0,0.79,5.79,0.79,22.99,14.99,19.49,1.59,6.99,0.0,11.99,2.89,29.99,8.99,3.99,2.09,0.0,6.99,7.19,2.79,15.99,7.19,4.29,1.69,0.79,8.59,3.1,2.09,9.99,10.99,34.99,6.99,14.49,3.99,0.79,9.99,24.99,7.19,1.99,6.99,22.99,6.99,7.99,1.99,0.0,0.79,10.29,6.99,2.89,15.49,0.79,0.0,2.79,6.99,15.49,14.99,0.0,6.99,0.0,0.0,24.99,14.99,19.99,15.49,0.0,0.0,4.99,0.79,0.0,3.99,2.09,3.99,19.49,15.49,2.49,1.99,7.99,10.99,0.79,4.99,0.0,32.99,39.99,7.99,4.79,4.99,9.99,37.99,0.0,14.99,22.99,7.19,14.99,20.51,29.99,10.99,2.79,3.99,3.99,0.79,4.99,0.0,0.0,6.99,0.0,5.19,3.99,0.0,0.79,11.99,0.79,7.99,0.79,1.99,15.49,0.0,6.99,1.99,0.0,7.5,39.99,0.0,0.0,6.99,9.99,8.99,7.19,3.19,15.99,3.99,1.59,3.99,0.0,6.99,34.99,14.99,5.99,8.99,6.19,5.59,0.0,18.99,2.09,6.99,0.0,6.99,2.79,6.99,15.49,7.19,1.99,4.99,29.99,0.0,0.0,3.99,6.99,2.79,6.99,0.0,3.99,14.99,7.19,3.99,3.99,0.0,7.19,6.99,0.0,2.99,5.99,7.19,3.99,0.0,15.49,0.0,0.0,7.99,2.79,39.99,6.99,3.99,19.49,2.09,7.99,4.99,11.39,3.99,6.99,6.99,6.99,3.99,0.0,6.99,0.79,6.99,2.89,9.29,3.99,0.0,1.99,0.0,1.69,6.99,39.99,10.29,10.99,19.49,9.99,1.99,14.99,10.99,0.0,1.99,0.79,0.0,1.69,6.99,15.49,4.79,1.99,6.99,10.99,6.99,0.79,6.99,9.99,3.99,3.99,0.0,9.99,1.59,14.99,14.99,14.99,9.99,14.99,14.99,1.99,10.29,8.99,4.99,4.79,10.99,17.99,0.79,29.99,7.19,0.0,6.99,2.09,10.29,30.99,6.99,8.59,10.99,10.99,14.99,0.0,0.0,4.79,39.99,10.99,6.99,4.79,1.69,10.99,49.99,24.99,9.29,4.99,0.0,0.79,6.99,9.99,15.49,15.49,9.99,10.99,8.99,5.19,6.99,1.59,0.0,0.0,7.99,2.89,6.99,11.39,15.99,0.0,44.99,5.79,3.99,0.0,6.99,0.79,3.99,10.99,14.99,1.99,21.99,17.99,0.79,34.99,27.79,0.0,0.79,6.99,8.59,0.79,10.99,9.99,0.79,4.99,11.99,8.99,6.49,3.99,10.99,0.0,6.99,17.99,39.99,22.99,11.99,5.59,0.0,1.99,1.59,0.0,10.99,14.99,10.99,0.79,3.99,3.99,14.99,5.59,3.99,10.99,0.0,7.99,4.79,11.99,5.19,17.99,1.59,0.79,2.99,0.0,14.99,22.49,24.99,14.99,11.39,24.5,8.99,7.19,1.99,1.99,18.99,0.0,14.99,1.69,0.0,3.19,6.99,10.99,30.99,0.79,3.99,15.49,3.99,3.99,6.99,6.99,0.0,2.79,14.99,1.59,19.99,0.0,0.0,6.99,3.99,6.99,3.99,0.79,3.59,22.99,3.99,4.99,1.99,0.0,3.99,0.79,14.99,0.0,2.89,3.99,23.79,10.99,6.99,14.99,5.59,11.99,11.39,29.99,0.79,9.99,0.0,10.99,0.0,1.59,3.99,14.99,6.99,3.99,3.99,10.99,4.99,14.99,3.99,0.79,3.99,8.29,0.0,7.99,1.59,14.99,3.99,3.99,1.59,3.19,0.79,11.39,6.99,1.99,0.0,4.79,15.49,11.99,15.49,6.99,0.0,3.19,1.59,0.0,0.79,14.99,2.09,10.99,0.0,19.99,7.19,14.99,3.99,2.99,0.79,5.59,14.99,0.0,2.99,4.79,29.99,2.79,1.99,0.75,6.99,3.99,7.19,6.99,0.0,13.59,5.99,0.0,0.0,9.99,6.99,0.79,3.99,0.79,5.19,0.0,3.99,15.99,0.79,1.99,9.99,3.99,54.99,3.99,3.99,4.99,0.79,5.99,14.99,12.39,10.99,1.99,1.59,11.39,0.0,0.0,19.99,23.79,10.99,19.49,5.99,0.79,39.99,3.99,0.79,0.0,3.99,0.0,6.99,1.99,2.49,5.59,5.59,44.99,0.79,6.99,14.99,21.99,10.99,24.99,6.99,23.79,25.99,0.0,8.99,2.79,4.99,1.59,6.99,3.99,8.99,4.79,7.19,1.69,6.99,0.79,3.99,6.99,5.99,2.89,2.09,8.99,0.0,0.0,23.79,6.99,0.0,0.0,0.0,0.79,1.99,14.99,0.0,0.0,26.99,10.99,6.99,2.09,4.99,0.0,4.79,14.99,0.0,3.19,6.99,9.29,14.99,6.39,5.79,10.29,6.99,3.99,14.99,4.79,4.99,0.0,9.99,4.99,0.0,5.99,6.99,6.99,2.89,0.0,6.99,6.99,8.29,0.79,1.59,11.39,6.99,7.99,9.99,7.19,19.49,3.99,3.99,25.99,24.99,0.0,3.99,3.99,18.99,5.99,1.99,17.99,7.19,0.0,4.99,10.99,5.59,23.79,9.99,1.99,0.0,5.59,33.99,15.49,7.19,1.69,0.0,8.99,10.99,2.79,10.99,1.99,7.19,23.79,11.99,11.39,3.99,1.59,24.99,0.0,3.99,0.0,0.0,0.0,3.99,6.99,9.99,33.99,1.69,30.99,0.0,7.19,10.99,13.99,11.39,6.99,10.99,11.39,19.99,2.09,0.79,6.99,6.99,16.99,9.99,3.99,3.99,44.99,17.99,7.19,7.99,7.19,1.99,1.99,2.79,17.49,18.99,0.0,44.99,0.0,6.99,3.99,11.39,6.99,0.0,3.19,0.0,19.49,6.99,18.99,6.99,15.49,5.99,7.19,6.99,3.99,18.99,6.99,14.99,6.19,15.49,0.0,0.0,10.99,9.99,10.59,1.0,13.59,4.25,0.0,0.0,14.99,3.99,0.79,24.0,19.49,5.59,6.99,3.99,0.0,4.79,22.99,0.79,1.59,8.59,0.0,4.79,6.99,7.19,18.99,0.79,0.0,0.0,0.0,34.99,15.99,22.99,1.59,3.99,0.0,0.0,14.99,1.59,3.99,0.0,14.99,29.99,6.99,6.99,14.99,29.99,0.0,4.79,39.99,9.99,1.99,14.99,10.99,29.99,0.0,10.99,0.0,3.99,3.99,2.89,4.79,18.99,0.79,1.59,3.99,14.99,7.19,7.99,5.59,14.99,3.99,0.0,2.79,11.39,6.99,3.99,0.0,19.49,31.99,10.29,6.99,0.79,10.59,10.99,3.99,14.99,3.99,3.99,6.99,3.99,1.69,4.99,10.99,0.0,14.99,0.79,3.99,15.49,6.99,14.99,6.99,0.0,8.29,5.79,0.0,0.0,3.99,15.49,0.0,2.79,24.99,6.99,0.79,14.99,0.79,4.99,6.19,14.99,13.99,4.79,4.99,5.79,14.99,15.99,18.74,2.09,9.99,6.99,4.99,0.79,0.0,0.79,15.99,25.99,29.99,16.66,60.99,10.99,0.0,10.99,10.99,3.99,0.0,2.79,6.99,6.99,3.19,12.99,3.99,0.0,3.99,5.59,0.0,3.99,2.09,7.19,1.59,0.0,29.99,22.99,10.99,3.99,0.0,34.99,3.99,0.72,0.0,1.69,13.49,5.99,24.99,2.79,11.99,10.99,13.0,17.99,2.79,4.25,11.39,4.99,24.99,26.99,14.99,14.99,13.59,1.99,1.99,3.99,14.99,3.99,7.99,5.99,3.99,0.0,3.99,10.99,4.79,1.99,19.99,4.25,10.99,9.99,4.25,6.99,7.19,14.99,10.99,4.79,11.39,7.99,1.59,1.69,6.99,4.79,5.19,1.99,4.79,7.19,2.79,6.99,1.69,19.99,16.99,0.0,3.99,3.99,0.0,11.39,0.0,1.59,14.99,15.49,10.99,10.99,5.79,0.0,0.0,7.19,7.19,0.0,10.99,15.49,14.99,0.0,10.99,13.49,6.99,0.79,14.99,29.99,13.59,15.99,8.59,22.99,9.99,12.99,14.99,8.59,3.99,6.99,5.99,19.99,1.59,0.0,8.99,11.39,4.99,24.99,9.99,3.99,23.79,15.99,2.79,0.79,15.49,7.99,13.99,6.99,0.79,5.79,5.99,19.99,0.0,3.99,6.99,6.99,26.99,15.49,5.99,34.99,0.0,35.96,2.09,15.9,0.79,1.99,0.0,4.99,10.99,34.99,0.0,0.0,6.99,14.99,6.99,14.99,0.0,0.0,15.49,15.99,0.0,14.99,1.69,0.0,10.99,7.99,0.0,5.99,11.39,5.59,4.99,1.99,7.19,0.0,3.19,0.79,3.99,39.99,10.99,7.19,18.99,10.99,2.79,1.59,11.49,11.99,0.79,5.79,15.99,6.99,4.99,7.19,26.99,0.0,11.99,4.69,49.99,49.99,15.99,4.79,6.99,1.59,10.99,22.99,24.99,0.79,6.99,29.99,4.49,6.99,6.99,39.99,30.99,1.99,14.99,1.59,33.99,10.99,10.29,0.99,18.99,2.99,12.99,10.99,14.99,1.69,5.79,13.99,1.69,6.99,0.79,5.59,9.99,11.99,10.99,3.99,0.0,19.99,7.19,0.0,1.69,19.98,0.79,4.79,2.79,4.99,2.79,0.0,2.79,14.99,10.99,6.99,6.99,6.99,5.19,0.79,24.99,15.49,27.79,7.49,4.99,0.0,0.0,19.49,1.59,1.99,29.99,2.89,1.59,0.0,19.49,3.99,3.99,8.99,0.0,15.49,15.49,7.19,1.3,1.59,6.99,14.99,75.99,0.79,13.99,1.59,3.99,5.19,0.9,0.0,0.0,0.0,10.99,29.99,0.79,4.99,19.49,3.99,29.99,17.99,2.09,11.49,11.39,6.99,0.0,14.99,14.99,0.0,2.89,15.99,22.99,0.0,0.0,6.99,14.99,3.99,14.99,10.99,1.69,3.99,10.99,14.99,0.0,14.99,0.0,26.99,15.49,1.99,0.79,6.19,8.99,0.0,3.99,9.99,7.99,1.69,5.59,9.99,3.19,17.98,6.99,14.99,0.0,14.99,1.69,8.59,14.99,6.99,7.19,6.99,4.79,17.99,37.99,14.99,3.99,10.99,10.99,14.99,3.99,2.79,0.0,49.99,0.0,3.99,5.19,3.19,14.99,3.99,1.69,6.99,0.0,29.99,0.0,4.99,6.99,6.99,18.99,8.99,23.79,7.99,15.49,8.99,6.99,39.99,1.59,7.19,9.29,1.69,0.0,0.0,0.0,0.0,9.99,6.99,15.49,10.99,15.49,9.99,22.99,49.99,5.79,49.99,3.19,0.0,3.99,0.79,11.39,14.99,11.99,6.99,23.79,11.39,7.19,2.79,1.69,10.99,3.99,2.09,12.49,8.59,0.0,3.99,1.59,5.59,7.19,1.59,0.0,0.0,6.99,10.99,6.99,11.99,6.99,23.99,18.99,4.99,6.99,6.99,6.99,14.99,0.0,11.99,6.99,29.99,3.99,6.99,10.29,0.79,7.19,0.79,29.99,10.99,8.29,24.99,6.99,8.29,3.99,0.0,0.0,14.99,0.0,0.0,14.99,10.99,2.79,13.49,0.0,3.99,11.39,4.99,2.79,2.09,0.0,0.0,26.99,18.74,4.79,0.0,14.99,14.99,7.19,29.99,0.0,4.99,14.99,7.19,10.99,6.99,5.59,7.19,5.19,4.99,3.99,10.99,0.79,1.99,10.99,0.79,14.99,6.99,3.99,4.99,3.19,22.99,3.99,0.79,8.99,14.99,6.99,12.99,4.79,5.59,3.99,10.99,14.99,3.99,0.0,10.99,1.99,6.99,22.99,6.99,14.99,7.19,14.99,6.99,9.99,8.99,4.79,8.49,7.19,0.0,3.99,5.99,22.99,7.19,5.59,0.0,10.99,0.79,11.99,3.99,6.99,0.0,24.99,6.99,3.19,10.99,4.79,10.29,14.99,3.99,1.69,5.79,6.99,6.99,6.99,1.99,6.99,2.79,34.99,0.79,0.79,22.99,3.99,6.99,0.79,3.99,15.99,10.99,5.59,24.99,14.99,13.99,19.99,6.99,15.49,0.79,5.59,2.79,12.99,19.99,10.99,1.59,19.99,2.09,0.0,15.99,6.99,6.99,10.99,3.99,5.59,15.99,10.99,9.99,22.99,14.99,10.99,4.79,4.99,9.99,1.69,2.79,0.0,6.99,11.39,0.79,1.99,7.19,1.99,3.99,16.99,3.99,0.79,7.99,2.5,19.99,14.99,7.19,5.99,5.99,1.59,0.0,3.99,11.39,10.99,6.99,30.99,6.99,26.99,3.99,18.99,0.79,6.99,2.79,9.99,6.99,0.0,0.0,11.39,4.99,3.99,15.49,9.99,1.65,4.99,0.0,39.99,9.99,0.0,10.99,6.99,15.99,6.99,24.99,13.99,3.99,0.0,1.79,6.99,1.99,11.39,11.29,18.99,3.99,0.0,6.99,3.99,14.99,4.99,3.99,6.99,0.79,14.99,9.99,4.79,0.0,0.0,11.39,6.49,5.59,15.49,4.99,0.0,0.79,6.99,6.99,11.99,17.49,3.99,6.99,13.49,0.0,11.39,0.0,13.49,0.0,3.99,0.0,0.79,3.99,4.79,8.59,11.39,3.99,0.0,7.99,0.79,17.99,0.79,29.99,3.19,2.09,14.99,10.99,1.69,14.99,0.79,12.39,0.0,4.79,22.99,0.0,15.99,0.0,25.99,3.99,0.79,15.49,2.09,0.0,0.0,9.99,0.0,0.0,24.99,0.0,2.99,19.49,0.79,10.99,6.99,10.99,0.0,15.99,6.99,1.99,0.0,1.59,0.0,15.49,3.99,5.59,3.19,14.99,6.99,3.99,11.99,24.99,6.99,41.99,0.0,33.99,3.99,0.79,6.19,10.99,15.49,49.99,0.0,0.0,14.99,22.99,0.0,23.79,7.19,5.99,3.99,0.0,6.95,29.99,5.99,6.99,3.99,22.99,10.99,0.79,15.49,16.99,6.99,5.79,14.99,21.0,1.99,0.0,10.99,9.29,11.39,2.09,3.99,6.99,4.79,0.0,0.0,6.99,9.99,14.99,6.99,1.59,0.0,0.0,6.99,15.99,0.0,6.99,0.0,4.99,14.99,5.99,5.59,10.99,3.99,4.99,18.99,3.99,14.99,12.99,9.99,7.99,3.99,4.99,0.0,9.99,0.0,6.99,0.0,3.99,0.0,15.49,14.99,17.99,11.39,2.79,0.79,10.99,22.99,10.99,7.99,6.99,0.79,18.99,23.99,1.99,5.99,10.99,3.99,7.19,13.49,6.99,19.99,1.59,1.99,19.49,6.99,14.99,5.59,11.99,18.99,44.99,0.0,24.99,1.99,0.0,5.99,0.0,7.99,7.19,10.99,33.99,4.99,23.79,6.99,4.79,6.99,33.99,11.99,14.99,15.49,22.99,12.39,7.49,11.49,0.0,0.0,14.99,10.99,10.99,10.29,10.99,9.99,29.99,0.0,3.99,14.99,4.79,2.09,4.99,14.99,14.99,0.79,0.79,0.0,15.49,6.99,14.99,5.59,0.79,5.99,6.99,2.79,1.69,10.99,26.99,2.79,9.99,9.99,5.19,6.99,0.79,4.29,9.99,0.0,5.99,3.99,6.99,8.29,16.3,0.79,14.99,0.79,19.99,0.0,0.79,10.29,7.19,8.59,16.99,6.99,3.99,1.69,2.79,0.0,6.99,0.79,7.19,2.79,11.39,1.99,3.99,0.0,19.99,0.0,0.0,2.09,15.49,0.0,1.99,0.0,24.99,5.79,10.99,3.49,6.99,6.99,6.95,1.99,7.19,6.99,0.0,1.59,4.99,7.99,0.79,7.19,16.99,0.0,6.99,1.59,6.99,26.99,38.99,4.79,11.39,3.99,0.0,0.79,1.99,1.99,0.79,0.0,11.99,1.99,10.99,0.0,5.59,1.59,7.19,15.49,21.99,19.99,15.49,2.09,27.0,7.19,10.99,0.0,0.0,15.49,7.19,39.99,7.99,0.0,24.99,2.79,1.99,6.19,0.79,7.99,0.0,10.99,6.99,11.99,6.99,4.99,2.79,6.99,10.99,19.49,0.0,11.99,22.99,7.19,18.74,0.0,0.79,14.99,14.99,6.99,0.0,0.0,6.99,6.99,0.79,10.99,0.0,0.0,14.99,19.99,2.09,9.99,19.99,3.99,6.99,3.99,6.99,7.19,14.99,3.99,0.0,49.99,10.59,6.99,6.99,26.99,6.99,4.79,1.99,7.19,29.99,0.0,0.79,4.99,15.49,3.99,1.99,8.99,6.99,1.99,15.49,29.99,23.79,22.99,14.99,19.99,5.79,9.99,4.99,18.99,14.99,1.69,49.99,3.99,2.79,10.99,4.99,15.99,0.0,19.99,44.99,24.99,15.49,2.89,0.0,7.19,0.79,6.99,2.09,6.99,0.0,39.99,19.49,23.99,12.99,11.39,45.0,0.79,8.99,1.59,14.99,5.59,6.99,39.99,11.99,23.79,9.99,4.99,6.99,0.0,1.49,6.99,0.79,10.99,2.09,6.99,2.79,1.99,6.99,0.0,0.79,0.0,5.99,0.79,6.99,10.29,3.99,7.99,10.99,7.19,10.99,7.99,0.0,1.1,4.79,18.99,0.0,15.49,3.99,2.09,0.0,0.0,9.99,11.39,11.99,0.0,0.79,6.99,6.99,0.0,6.99,0.99,0.79,1.99,0.79,27.1,14.99,14.99,3.19,10.99,0.0,13.59,6.99,26.99,6.19,5.79,6.99,6.99,0.0,6.99,4.79,14.99,1.69,12.99,4.79,29.99,0.79,6.99,2.09,2.79,10.99,0.0,3.99,11.39,8.59,0.79,11.39,7.19,0.79,5.79,6.99,0.79,11.39,0.0,15.49,6.99,10.99,22.99,6.99,6.99,10.99,34.99,6.99,3.99,0.0,0.0,9.99,0.0,1.69,6.99,3.99,0.0,14.99,0.0,0.0,15.49,0.0,4.79,25.99,1.99,2.09,6.99,7.19,11.99,11.99,1.69,1.69,1.69,18.99,9.99,10.99,10.99,15.49,14.99,0.0,6.99,5.59,10.99,1.69,2.79,49.99,0.0,3.99,6.99,2.79,14.99,0.0,6.99,3.99,5.59,34.99,6.99,23.79,9.99,0.0,0.0,2.09,5.59,22.99,0.0,49.99,3.99,22.99,10.99,24.99,14.99,3.99,8.99,3.99,12.99,4.99,5.99,15.49,3.99,1.69,15.49,0.79,16.99,10.99,10.99,12.49,0.79,3.99,8.99,11.39,2.89,9.99,0.0,3.99,5.99,3.99,19.99,9.99,3.99,5.79,0.0,0.0,0.0,11.39,0.0,6.99,25.99,34.99,0.79,6.99,9.99,22.99,22.99,14.99,6.99,24.99,29.99,11.39,6.99,0.0,10.99,11.99,5.99,6.99,0.79,6.99,14.99,3.99,2.79,14.99,49.99,0.0,5.59,11.99,1.79,5.99,29.99,9.99,5.59,44.8,0.0,2.99,0.0,14.99,34.99,10.99,12.99,8.99,23.79,14.99,3.99,1.69,0.79,0.79,6.99,0.0,20.99,6.99,6.99,1.59,8.99,0.79,0.0,10.99,26.99,15.99,10.99,18.99,0.0,0.0,10.99,23.79,0.0,0.0,2.79,14.99,7.19,49.99,10.99,5.99,10.99,4.99,0.0,5.19,4.79,4.79,17.99,24.99,5.19,4.99,1.99,1.99,2.79,4.99,5.19,15.49,24.99,2.79,3.99,6.99,5.99,8.99,23.99,2.09,6.99,15.49,3.99,15.49,41.99,6.99,7.19,0.79,2.79,3.99,3.99,0.79,6.99,0.0,3.99,24.99,0.0,6.0,5.79,29.99,3.99,11.99,0.79,1.99,8.99,3.99,14.99,10.99,0.0,6.99,8.99,6.99,14.99,11.39,6.19,12.99,0.0,1.69,3.99,0.0,5.59,10.99,0.0,0.79,15.49,6.99,11.39,3.99,13.49,5.59,3.19,7.19,1.99,3.99,14.99,3.99,26.99,14.99,7.99,6.99,2.89,24.99,14.99,13.5,6.99,9.29,0.79,0.0,7.19,7.19,14.99,6.99,1.69,6.99,4.99,15.99,1.99,2.99,34.99,3.99,1.69,3.99,3.99,3.99,1.59,1.69,6.99,6.99,0.79,7.19,4.99,1.59,7.19,19.99,0.79,0.79,0.0,10.99,10.99,14.99,0.0,0.0,7.99,23.79,0.0,0.0,3.99,10.99,2.99,2.09,2.09,10.99,0.99,5.59,19.99,14.99,5.99,9.99,0.0,5.59,10.99,11.39,11.99,0.79,24.99,11.99,0.78,7.19,5.19,0.79,6.99,15.99,0.79,9.29,15.49,0.0,0.0,0.0,0.79,3.99,0.0,14.99,15.49,19.99,7.19,6.99,14.99,2.79,2.79,15.99,0.0,29.99,6.99,3.99,6.99,6.99,6.49,0.0,7.99,7.19,0.79,18.1,0.0,19.99,0.0,1.99,0.0,10.99,0.0,5.59,0.0,1.99,5.79,0.0,16.99,0.0,7.19,0.0,22.99,2.99,3.99,14.99,14.99,3.99,3.99,10.99,1.69,9.29,10.99,2.89,30.99,14.99,1.99,1.99,10.99,6.19,11.99,3.99,19.99,3.99,6.99,6.99,8.99,3.99,15.99,23.79,10.99,13.5,6.99,19.99,13.99,6.99,10.99,11.99,3.99,13.49,5.59,9.99,11.99,14.99,4.79,0.79,2.89,0.0,9.99,0.0,0.0,0.0,3.99,12.99,0.0,9.99,4.79,1.69,0.0,9.99,7.99,6.99,3.99,1.99,6.99,0.0,9.99,3.99,10.99,7.19,0.79,29.99,3.99,0.0,4.49,3.99,19.49,0.79,7.19,3.99,7.19,0.0,3.99,9.99,15.49,6.99,4.79,0.79,6.99,10.99,2.79,0.0,0.99,0.0,0.0,0.0,2.79,6.99,1.69,7.99,7.19,0.0,0.0,22.99,0.0,0.79,9.29,10.29,3.99,4.79,32.99,0.79,4.79,13.59,24.99,0.0,5.79,4.79,3.19,0.0,5.99,22.99,1.99,5.79,29.99,0.0,1.99,0.0,30.99,11.99,0.79,1.99,14.99,39.99,0.0,0.79,3.99,3.19,14.99,2.89,5.79,7.19,7.99,4.99,10.99,6.99,0.79,3.99,10.99,14.99,8.59,10.99,0.0,10.99,4.99,7.49,15.49,3.99,49.99,6.99,5.79,15.49,29.99,3.99,0.0,9.99,0.79,10.99,14.99,10.99,0.0,0.0,24.99,10.99,4.79,18.99,2.89,6.99,2.29,3.99,12.49,7.19,6.99,49.99,24.99,3.99,0.0,4.99,3.99,7.19,4.49,1.59,9.99,22.99,2.99,6.99,0.0,7.19,7.19,14.99,10.99,0.79,1.59,8.99,14.99,11.39,6.99,0.0,6.99,0.79,14.99,3.99,10.99,34.99,3.99,5.79,4.79,3.99,0.0,3.99,1.59,14.99,0.0,1.99,23.79,19.99,4.79,0.79,0.79,3.99,3.99,34.99,0.79,12.99,3.99,0.0,0.0,2.89,14.99,3.99,0.0,0.0,5.99,10.99,0.0,6.99,11.99,6.99,0.0,2.89,19.99,0.0,0.79,7.19,0.79,1.99,11.99,1.59,6.99,0.0,0.0,2.99,3.99,10.99,3.49,12.99,1.99,1.69,10.99,7.19,6.99,1.99,14.99,30.99,10.99,0.0,6.99,0.0,2.79,6.99,14.99,7.19,0.79,14.99,6.99,3.49,13.99,3.99,0.0,11.39,10.99,10.99,39.99,0.0,17.99,3.99,0.0,10.29,3.99,9.99,10.99,15.49,0.0,9.99,4.79,0.0,9.99,4.99,0.0,11.39,6.99,3.99,0.0,10.99,1.59,10.99,3.99,7.19,22.99,14.99,16.99,5.79,6.99,3.99,4.79,14.99,15.49,3.19,0.0,6.99,5.19,5.79,10.59,1.99,0.0,10.99,39.99,19.99,14.99,1.99,4.79,14.99,9.99,7.19,0.99,0.0,0.79,2.09,19.99,1.99,10.99,14.99,19.49,3.99,0.0,1.99,2.09,11.99,7.19,49.99,14.99,0.0,5.19,7.99,0.0,0.0,23.99,18.99,15.49,6.99,6.99,0.79,0.79,5.79,0.79,19.99,5.59,14.99,14.99,10.99,2.09,0.0,8.99,0.0,6.99,1.69,1.59,10.99,0.0,54.99,39.99,4.99,7.99,0.79,6.99,11.39,27.99,5.59,10.99,0.0,12.39,2.79,14.99,6.99,10.29,14.99,0.0,6.99,6.99,6.99,6.99,11.39,3.99,1.69,14.99,10.99,0.0,4.99,7.99,3.1,9.99,3.99,7.99,10.99,13.99,29.99,7.19,7.99,0.0,18.1,12.49,0.0,0.0,6.99,0.79,14.99,6.99,0.0,14.99,14.99,1.59,0.0,6.99,0.79,12.99,0.79,7.19,8.99,7.19,10.99,15.49,1.69,9.99,10.99,4.79,10.99,4.99,7.19,3.99,3.99,5.59,6.99,5.99,1.99,0.79,4.79,14.99,0.79,0.79,4.29,0.79,3.49,0.0,3.99,6.99,4.79,0.79,7.19,23.79,5.99,14.99,2.09,15.99,3.99,24.99,9.99,3.99,11.39,5.19,7.19,15.49,0.0,14.99,7.99,12.99,6.99,0.0,0.79,14.99,6.99,0.0,11.99,4.99,18.99,6.99,18.99,3.99,3.99,6.99,3.19,14.99,3.99,4.79,2.99,3.99,22.49,0.0,22.99,7.19,19.99,1.99,3.99,0.0,0.0,14.99,29.99,0.0,3.99,49.99,0.0,1.99,34.99,15.49,0.0,7.49,0.79,5.99,0.0,17.99,1.99,4.99,3.99,0.0,19.99,6.99,30.99,3.99,7.19,0.0,19.99,14.99,3.99,3.99,14.99,14.99,0.79,49.99,0.0,11.99,6.99,2.99,0.79,27.79,22.99,0.79,5.59,9.29,49.99,15.49,4.79,9.99,11.39,10.99,3.99,6.99,0.0,0.0,3.99,14.99,3.99,8.59,6.99,0.0,14.99,39.99,15.49,8.59,11.39,7.19,0.0,8.99,2.99,6.99,13.99,0.0,7.19,4.49,1.59,14.99,0.79,10.99,10.99,6.99,14.99,3.99,6.99,10.99,3.99,5.59,29.99,10.99,0.79,1.99,0.79,0.79,14.99,0.0,0.0,4.79,2.09,8.99,10.99,0.0,10.99,12.99,6.99,14.99,3.99,4.79,15.49,4.79,12.99,0.0,15.49,14.99,14.99,18.99,1.69,0.0,1.99,3.99,14.99,0.0,7.19,39.99,3.99,14.99,39.99,14.99,4.79,0.0,0.0,6.19,2.99,6.99,0.0,4.79,2.89,2.89,15.49,0.0,0.0,3.99,14.99,6.99,0.0,2.09,2.09,0.79,0.0,3.99,1.59,25.99,29.99,9.99,15.49,4.99,39.99,14.99,5.99,0.0,15.49,7.19,0.79,6.99,7.19,11.39,4.79,1.59,10.29,1.99,0.0,0.0,11.39,10.99,0.0,14.99,10.99,44.99,0.79,34.99,6.99,6.99,24.99,7.19,0.0,4.99,13.99,2.79,0.79,14.99,0.0,15.49,6.99,2.09,3.99,1.49,10.29,2.99,0.0,0.0,0.0,2.99,29.99,2.79,0.0,23.79,14.99,11.99,6.19,34.99,0.79,5.79,0.0,4.99,0.0,10.99,0.0,14.99,12.99,4.99,11.39,15.99,5.59,0.79,39.99,4.99,3.99,6.99,8.99,0.0,12.49,9.29,2.79,0.0,15.49,10.99,22.99,14.99,2.89,3.99,3.99,9.99,10.99,6.99,3.99,0.0,10.0,7.19,7.19,0.0,0.0,10.99,13.49,19.49,7.19,3.99,0.0,15.99,3.99,3.99,7.19,0.0,14.99,14.99,8.69,3.19,1.59,1.49,6.99,4.99,10.99,6.99,9.99,0.0,14.99,3.99,8.99,5.99,10.99,6.99,0.0,25.99,8.29,12.99,0.79,4.99,6.99,15.49,3.99,1.59,3.99,0.0,0.0,6.19,15.49,14.99,0.0,0.79,11.39,2.09,3.99,1.59,24.99,0.0,19.99,1.59,6.99,0.79,15.49,2.09,1.69,0.0,9.99,5.99,0.0,0.0,7.19,0.0,12.99,4.79,14.99,6.99,4.49,10.99,23.79,24.99,3.99,12.99,2.09,24.99,6.99,8.59,5.79,0.0,8.99,5.99,3.99,3.99,10.99,23.79,0.0,5.99,22.99,6.99,10.99,5.19,22.99,2.79,2.89,3.99,1.59,0.0,4.99,6.99,14.99,5.19,39.99,12.49,6.99,7.19,0.0,2.09,60.99,5.19,6.99,2.09,7.99,14.99,3.99,26.99,6.99,9.99,2.89,7.99,14.99,6.99,0.0,12.99,14.99,10.99,10.99,10.99,2.09,0.0,0.0,0.0,4.99,0.0,4.99,0.0,0.0,0.79,6.99,1.69,0.0,0.79,5.79,18.99,5.79,0.79,7.99,0.0,1.59,10.99,10.99,1.59,0.0,34.99,1.59,24.99,6.99,19.49,7.19,0.0,7.49,7.19,7.19,3.99,11.39,0.0,3.99,0.79,3.99,5.19,10.29,0.79,5.59,0.79,3.99,1.99,0.0,0.0,2.09,10.29,0.0,1.59,0.0,8.29,2.89,7.99,1.49,0.79,14.99,6.99,13.49,0.79,0.79,0.0,7.77,0.0,11.39,6.99,3.99,6.99,14.99,5.99,15.49,10.99,3.99,5.99,4.79,10.99,7.99,14.99,12.99,0.0,0.0,7.19,6.99,0.79,3.99,13.49,4.99,2.09,0.0,0.0,1.59,11.39,0.0,14.99,3.99,23.79,19.49,15.49,0.79,15.49,6.99,4.99,11.99,3.19,6.99,29.99,23.79,2.79,7.19,14.99,7.19,3.99,15.49,6.99,10.99,0.0,14.99,5.99,14.99,2.09,0.0,6.99,8.99,15.49,3.99,6.99,19.99,2.09,3.99,0.0,10.99,3.99,3.99,0.79,3.19,5.79,6.99,3.99,6.99,6.99,1.59,5.59,10.99,10.99,6.99,1.69,5.79,6.99,0.79,10.99,0.0,39.99,10.99,2.99,0.0,0.0,0.0,15.49,11.39,2.79,4.99,15.49,0.79,15.99,10.99,0.0,1.99,0.79,6.99,15.49,0.0,15.99,10.99,0.0,13.0,15.49,0.0,6.99,0.79,0.79,6.99,0.0,11.39,13.99,23.79,4.99,4.79,0.0,25.99,0.0,6.99,14.99,0.0,14.99,0.0,12.99,3.99,15.99,0.0,6.99,15.99,49.99,15.99,0.0,1.69,5.99,0.0,29.99,18.99,0.0,29.99,0.0,7.99,6.19,11.99,6.99,6.99,24.99,5.79,15.49,11.39,0.79,11.39,0.0,4.79,11.99,14.99,4.49,2.79,14.99,14.99,10.99,2.69,14.99,14.99,5.99,9.99,0.79,1.69,3.99,0.0,29.99,22.99,10.99,2.79,7.19,18.99,27.11,7.19,26.99,6.99,4.99,0.79,39.99,22.99,0.79,8.29,4.79,5.19,7.19,7.19,10.29,3.99,5.99,11.49,2.09,10.99,6.99,6.0,1.99,0.0,2.09,6.99,14.99,0.0,0.0,0.0,0.0,29.99,24.99,8.99,0.0,22.99,4.79,10.29,19.99,29.99,2.89,3.99,15.99,10.99,6.99,25.99,10.99,0.0,34.99,15.49,14.99,0.79,2.09,0.0,23.99,15.99,0.79,11.99,0.79,5.59,0.0,7.19,7.99,14.99,3.19,0.0,0.79,0.79,11.39,3.99,0.0,1.69,7.19,19.49,7.19,0.79,6.99,2.09,7.19,7.5,14.99,4.99,2.79,22.99,15.49,10.99,6.99,6.99,0.0,5.59,2.79,8.99,3.99,0.0,8.99,11.39,2.09,6.99,6.99,14.99,2.79,0.79,16.99,6.99,6.99,15.49,0.0,6.99,0.0,30.99,0.0,7.19,14.99,0.0,3.99,0.0,15.49,6.99,6.99,0.79,34.99,11.39,6.99,3.99,6.99,14.99,0.79,9.99,2.99,15.49,1.99,0.79,6.49,6.99,4.79,29.99,18.99,2.49,0.0,2.99,0.79,0.0,30.99,3.99,0.79,0.0,0.0,3.99,11.99,1.99,0.0,0.0,10.99,3.99,14.99,6.99,23.79,34.99,10.99,2.09,5.19,0.79,4.79,3.99,6.99,1.99,3.19,15.99,15.49,0.0,22.99,0.0,5.19,14.99,6.99,9.99,0.0,7.19,4.79,0.79,7.99,1.59,9.99,0.0,3.99,1.99,0.79,6.99,0.0,5.59,10.99,3.99,2.79,11.39,2.89,0.79,19.49,14.99,11.39,14.99,3.99,4.99,3.99,6.99,7.99,3.99,19.99,6.99,9.99,0.0,7.19,0.0,15.49,7.19,3.99,0.79,0.79,0.79,0.79,3.99,4.99,3.99,9.99,33.99,7.99,5.59,6.99,44.99,0.79,3.99,49.99,1.59,0.79,3.99,3.99,34.99,6.99,3.99,9.99,0.79,10.99,15.49,0.0,6.99,4.99,3.99,7.99,6.99,2.99,7.99,1.69,8.99,14.99,1.99,2.09,11.99,7.99,14.99,4.79,14.99,10.99,3.99,2.09,0.0,6.99,16.99,15.49,0.0,29.99,2.49,0.0,54.99,6.99,0.79,0.0,6.99,0.0,15.49,7.19,5.59,7.19,0.0,6.19,0.0,10.99,4.79,0.0,2.79,0.0,1.59,0.79,4.79,6.99,1.99,8.59,0.0,15.49,6.99,0.0,3.19,39.99,0.0,5.99,0.0,3.99,0.0,4.99,14.99,6.99,6.99,6.99,0.79,0.0,5.99,10.99,0.0,15.49,6.99,6.99,9.99,0.79,19.99,4.79,6.99,39.99,0.79,6.99,1.59,6.99,15.49,0.0,1.59,23.79,0.0,9.99,4.29,0.0,0.0,15.49,1.69,14.99,1.59,0.79,1.59,9.29,0.0,0.0,9.99,6.99,10.99,10.99,0.79,3.99,9.99,14.99,0.79,10.99,0.79,1.59,10.99,0.0,19.99,4.99,6.99,29.99,0.79,10.99,8.99,9.99,3.99,6.99,3.99,11.99,14.99,6.99,11.39,0.99,18.99,0.0,4.99,12.99,3.19,0.0,1.69,3.99,0.79,3.99,0.79,7.99,6.99,0.0,0.0,0.0,6.99,7.19,8.99,0.79,0.79,17.99,39.99,6.99,22.99,6.99,2.99,3.99,13.99,3.99,2.79,15.99,23.79,7.19,15.49,11.39,3.99,5.19,6.99,7.19,14.99,34.99,2.99,1.59,14.99,5.99,0.0,6.19,0.79,7.19,15.49,14.99,11.39,29.99,6.99,4.79,24.99,0.79,14.99,3.99,3.99,0.0,0.0,14.99,2.79,5.99,3.99,26.99,78.99,0.0,3.99,39.99,0.0,10.99,7.19,0.79,15.49,7.99,14.99,0.79,0.0,6.99,8.59,14.99,7.99,9.99,3.19,29.99,14.99,18.99,2.79,6.99,5.59,0.0,10.99,0.0,3.99,0.79,2.09,18.99,0.79,0.0,3.19,2.89,0.0,11.39,11.39,6.99,0.0,14.99,24.99,0.79,0.0,7.99,6.99,14.99,10.99,8.99,22.99,5.54,29.99,0.0,0.79,6.99,0.0,6.99,3.99,4.25,10.99,6.99,9.99,0.79,6.99,0.0,4.49,0.0,3.99,39.99,0.79,3.99,15.49,6.99,6.99,6.99,0.79,0.0,11.99,0.0,1.99,6.99,0.0,11.99,19.49,15.49,9.99,10.99,0.0,6.99,7.19,15.49,0.0,8.59,0.0,0.79,2.89,10.99,6.99],\"xaxis\":\"x\",\"y\":[3914,10728,635792,253864,49818,11966,1497694,12532,3914,49837,27176,93694,52572,62764,101824,134416,26544,16182,16211,4816,12896,70200,78884,22344,15326,702956,57460,17732,176540,14896,8643,10507,10008,57784,6758,29541,44020,8424,8604,350997,9362,34918,4294,5676,34216,6106,79711,40486,78964,225624,14144,157914,16568,39312,11594,936900,3631584,6240,6042,18012,9568,137643,16297,6262,1293336,155918,14040,6364,47424,6696,72936,236500,3924,4028,5246,24024,511841,20304,6084,12245,5246,14319,18876,41648,8428,42952,27924,198369,43004,13032,11448,4320,4750,27156,70176,15748,14018,12482,7254,6968,6063,10406,42966,48982,4859,4248,6386,4524172,30573,40092,5304,76836,10664,6278,18791,29388,7668,14756,6262,116356,15084,5805,109512,24128,57474,14446,98540,16776,13416,75672,26208,778545,72680,4446,101308,40964,6324,132870,5824,130500,14248,147098,10912,363084,7502,13020,13373,9196,885422,9724,12943,9559,8246,30524,18802,24095,21804,607724,12403,4066,61628,20398,41065,148441,10712,6344,282948,8664,33440,99634,6372,4134544,31261,147651,49612,48880,11524,4687,31868,14544,5510,12064,69678,7525,80484,53692,3990,153418,15247,1279326,19656,74046,11020,54720,11128,285200,37658,4066,52344,4636,451422,3838,6188,117676,861032,229416,872318,30702,4945,28260,6880,195768,8556,28086,50165,100835,195156,25844,14516,654192,33488,27413,41184,3744,7353,39832,5130,4218,22828,12324,306590,18824,4788,5824,18920,559152,19396,5876,97632,4332,8684,20167,11718,12636,6552,37696,28462,44978,19836,7998,4343,143052,334366,5408,50955,45792,4104,11692,470808,19440,223028,23564,22458,109148,10354,52668,262438,10922,6149,11137,5724,48418,7790,121892,189504,72432,98280,35234,19448,17568,15696,201172,20160,229892,47716,3636,64464,11818,12744,22204,121458,13680,68536,160528,56268,13934408,7900,35313,78289,18658,6292,6498,26728,14405,23858,10816,13144,38710,13702,10981,15394,24804,11804,42897,4560,50220,164260,6916,52030,24056,10816,12772,14446,1195744,698400,5203,24928,5054,39384,117676,151446,19968,24264,126880,20540,15300,18356,10712,17004,6084,19344,1418688,8640,263149,18576,10244,166216,11438,8216,37232,36103,32472,11376,1039492,60528,8496,338840,251136,166032,177460,450379,20066,5356,26149,55068,95906,51088,39216,29488,11248,14664,27612,6384,7697,9610,17696,12096,31304,7344,32916,224992,22594,4066,11818,7998,38528,9216,140920,76322,3996,7936,9204,8684,39096,140976,31806,26164,12428,10656,15824,90534,54954,234732,28892,128804,132408,373591,18000,17784,11904,19096,24984,872784,34162,212836,355579,26064,10191,53234,37368,8320,12168,9030,192918,34844,37539,15958,45198,649472,11880,78192,27456,59768,9287082,11448,6968,560652,37656,53878,180804,44161,393908,204048,6012,8436,6696,15562,43920,312998,23760,15168,13520,6634,59148,14964,8901,13392,4522,26424,19197,11051,21476,29588,23472,13104,5332,149136,19368,24964,601016,4408,4515,5436,12384,20646,14782,21142,5504,11448,7560,49104,121518,10224,1951813,4140,19522,13454,47386,8060,5358,8184,231154,10586,16802,18060,33891,9724,7488,4343,94068,134628,94428,158237,75445,134142,15934,162136,91542,95728,11284,16872,40394,13373,34529,17628,168428,154960,144216,480952,93912,5890,338436,6448,12152,18144,287370,55853,16530,5700,68809,2691358,34424,9620,24727,4104,23940,185938,11997,10602,19080,10664,692744,10716,19684,750421,7992,7182,14136,11664,20769,218400,85162,696299,6200,6604,5652,104201,10368,19197,10540,48856,24332,7704,9620,16297,32040,8385,5564,9202,7072,16454,7592,53483,335952,11016,11222,50616,5980,8892,25012,16068,2747784,7748,10080,119536,857956,4279114,311116,28348,17856,187200,83898,501642,5461,5805,192049,45346,473817,6342856,7904,20482,454248,47196,38236,10944,115577,11266,13114,56072,15190,14018,9238,23472,58320,24885,6063,12692,476397,321382,18060,15444,8769,11248,68510,219085,17992,11904,15428,4262856,77376,70626,40032,54194,9796,16120,280800,12350,9504,55695,5512,533696,17628,17673,22308,31442,9672,6344,273600,718189,176802,155746,3876,140620,29154,10277,5564,151048,35464,9006,19908,15872,8112,20644,10008,12482,8712,289140,200592,405954,12324,52390,28424,19722,67071,15523,71416,20880,220410,19908,2108510,96301,5564,17459,40104,6136,6324,51688,28704,918788,4343,16641,8295,41400,5976,4472,9072,21638,49724,9216,130260,18616,75551,7632,337156,20212,8856,5160,858572,14328,28334,475106,21543,306362,20026,5966,9486,859125,6688,10816,327455,49375,36378,4332,20488,152312,178144,8684,9360,9300,8122,10800,213409,4294,98568,8996,44772,15548,55796,13676,66992,96933,1665162,4452361,17108,75981,11346,17680,6292,115541,21018,28582,37841,12152,18723,5200,889632,9734,343097,8996,4320,1315113,18662,18328,17673,45662,21888,21962,27590,11594,261934,62372,26531,16899,9932,9234,19902,6552,4464,11613,16432,40536,154284,10908,13206,70784,7748,9766,8684,754134,413170,1071288,23750,9308,25438,35155,6536,75168,13826,5928,25128,8804,28835,20026,105710,6968,78819,7030,17352,76946,20088,19032,22704,92132,1066464,12584,265440,5720,382044,5976,64688,15190,4176,221760,25482,13392,7540,51342,14174,22575,4032,571814,11524,9006,7192,1033075,20640,2555424,9360,48450,9144,14402,25200,7866,10602,98784,6572,78605,11532,32612,280618,123264,299568,39579,6751,1309252,16796,16484,200668,880771,103806,34844,37080,9847,155304,7697,7052,7296,317896,63898,6042,22360,52762,29146,3952,5332,51350,259064,23296,6080,9100,16120,917111,32390,19671,18565,29283,13826,20448,11780,10504,65188,32262,22104,757136,5590,13186,34200,177987,22680,6460,6136,165044,10234,178452,13889,18447,528984,7696,121888,60888,35352,6552,20368,20832,32723,6324,16112,12046,3952,216638,15552,62062,7482,102621,5168,10088,390290,12087,6192,77896,4572,11016,8788,2152750,107543,74218,6688,48568,5719,32544,14560,37202,66508,17415,11218,37076,57304,398908,201213,195676,12642,10728,5408,9734,16856,53884,48360,15840,10184,17670,35313,26445,61383,115754,727669,39596,49538,31679,12024,4066,5928,18091,9932,4472,32548,40456,203164,325006,1473802,5876,14384,5246,37752,133431,5332,115026,24358,11309,44878,12768,65333,23560,28124,6292,48111,13728,35030,10292,162582,12245,293968,23384,11752,151580,5624,918375,7130,30889,13454,7600,96064,7224,5230816,21736,3248336,4598,24804,3780,6696,227582,39308,167164,5966,124776,12482,15652,8604,81792,27492,6572,4816,41317,36577,18460,43272,1451704,38950,7956,9348,19608,5356,72759,20800,27404,16692,8778,103272,6572,13104,860976,11297,17784,6278,11128,1086488,7124,139176,12586,30616,26520,47400,49556,6572,17243,10449,125689,75528,6760,403056,39263,55774,27396,9880,16037,13889,12561,7697,262694,10507,17964,7280,19592,71337,7334,38184,3785601,5289,17160,61383,11481,9610,179181,27504,13832,10556,13104,5460,13536,28595,21372,60202,17112,33332,64844,55986,124930,32904,4386,12688,86742,13509,7372,54288,19500,23244,10348,31304,10664,15136,7812,10044,181718,7310,51745,891820,164880,10912,35647,30628,592844,155420,30876,53957,37324,44856,25948,4859,2491660,85570,3439502,32508,8127,164715,15800,119527,21684,28348,10540,51745,37296,6407,17544,4261023,4386,5203,9374,58708,21584,26875,11492,9717,43206,4446,26486,23250,60320,470208,4472,16560,26474,9417,7316,15438,178312,597896,53641,13640,39816,10368,8684,236447,126666,17696,21112,16560,16848,13244,726089,56287,21156,5184,5824,13072,579120,1886836,97802,692128,7296,6696,43524,150653,21758,40976,1810042,18407,1348925,26860,11139,4864,17064,21700,38141,20026,34271,150722,46384,8892,16037,30816,961362,100168,14256,38664,78416,1152531,20232,16848,25704,11552,15128,5805,4028,148678,67756,1246304,8736,13516,4816,4142,55490,13072,5246,11476,29512,55774,62173,183481,153260,75816,9776,43416,10608,36972,21762,9085,5016,11088,1216800,19114,12255,2275911,59112,69368,363874,38448,14196,39888,15496,205321,741960,19840,82560,15879,10244,5848,20020,42423,111241,15340,16488,54498,7332,146010,12654,27590,7750,49794,5289,970416,27962,8246,755793,16168,525587,20894,10608,7095,164304,9890,51116,8112,872526,1931392,53784,4446,145992,18644,20088,26228,29025,16226,7488,129580,55512,20016,13826,9216,10974,38786,30240,4028,9362,15264,4750,5934,8360,14858,24232,23932,8170,21840,290641,17244,205632,216980,506602,34732,556416,20736,20592,25992,5375,9761,4978,7224,31044,13248,30400,73865,56012,5376240,11970,27892,60264,9417,736112,77584,156104,5668,91547,263160,12384,5252,6136,401076,10972,27352,33228,41610,105696,211562,45714,44252,4104,14276,24358,22833,17160,69254,24940,13248,14570,4902,38626,10664,9216,18050,8712,376154,15704,227599,18146,6156,4558,21892,13452,10578,19604,877084,155880,291462,37656,14256,6321,122832,30384,4902,31680,11739,15120,16920,5980,5676,29842,20664,11016,34344,63990,5289,37354,18582,20770,13032,6751,70432,967460,42280180,16906,9576,16344,25359,10108,31916,93353,147146,13932,87216,504099,6510,38532,30600,36270,8742,70704,5031,22176,7540,49059,6572,5548,16120,13312,4078274,4218,9638,153748,27821,53072,40132,16120,6188,60624,82950,449136,59724,14060,90250,14248,7912,11284,7611,5890,45144,4522,5719,250952,7130,93930,17632,15010,12740,24806,144612,24037,12816,281294,22176,15872,13788,538222,34365,19158,4730,23400,14615,4294,16426,5244,51264,206568,29038878,34684,36464,12428,11352,21762,142201,12168,7072,14196,191208,5633,15552,33384,109908,354394,8987,13608,46624,131112,18316,18091,30784,100738,211668,282978,181779,12888,66248,178966,119392,3501504,145281,3952,170956,17544,128016,7502,10540,13520,319160,22910,9424,33136,5375,3577673,3914,7904,7254,160128,982338,4787921,9576,72443,124504,742392,14328,10944,216934,5624,22464,10191,102180,16834,8172,100152,5548,12084,34602,5130,8094,10230,8320,143069,16380,13676,13338,253440,81282,48418,135098,1190276,7353,397606,6192,11856,10088,12028,18720,63550,9300,949240,8784,53300,31679,159692,1229240,11534,80659,1457682,9724,20748,346476,54994,6574,20540,726657,50112,11352,57190,12482,76393,8927,13888,3600,10744,17459,11476,13780,23932,9576,122450,11929,38520,144965,95542,45448,25194,14630,321451,18404,17775,5184,66528,299160,5244,14536,47795,80414,38502,14880,124668,7182,82056,16802,6916,5472,13780,12400,10368,17775,10296,41949,2154014,38076,53621,63752,188889,32422,10070,7228,20862,9576,92035,9954,47684,31464,65246,5130,15184,9864,7800,122544,63498,10415002,8901,36498,19866,16276,5848,44764,1875376,12599,354710,75888,10222,9176,212115,40291,30616,8618,13932,7224,16669,400192,14976,5848,13392,10850,6136,182676,76824,956332,8580,26524,61938,15132,9500,7711348,10192,82713,6500,9675,3952,406297,29016,76235,24467,24411,6916,28132,13392,5928,14364,13896,5976,179883,19902,24253,16864,6080,38868,19500,10556,596711,79484,9954,8094,9766,81528,4472,45030,131924,4343,16306,46512,8372,1071161,85020,3838,218922,26070,891041,14198,27144,73268,19092,5805,19654,15958,12276,42344,55670,42532,137206,7998,9828,36182,9176,14288,16952,40774,44200,58464,32943,22248,6450,38270,5460,7936,11970,24244,4902,58178,30889,40608,18720,4218,11139,59400,7144,19269476,287496,443269,33338,3960,6156,72488,360158,25792,8320,16692,39263,17316,33048,386136,16380,8170,395604,25517,14615,28614,6156,5848,4773,10191,19928066,9100,166752,10478,5418,12648,5461,18864,335916,18772,4522,11552,66994,46784,10836,17628,12008,16272,550185,51034,5512,30573,6232,5117,85696,23478,10504,5976,265734,6696,129704,14322,114939,251292,225792,31320,6966,811172,31096,8268,7783,23832,271918,13110,165505,24048,66248,4988,12152,112060,9412,8690,13000,84925,19874,4598,10712,279186,302188,6574,4988,29388,14773,28638,76153,139040,15872,16016,18648,7440,30628,46698,25413,6235,5396,1356212,5633,9516,5408,434668,947376,7525,5206,36656,11376,6080,32224,6708,11376,73530,21027,53246,102856,12096,1408752,1861184,32566,46398,9114,7344,16992,67624,13364,11352,17594,19708,7416,30628,15934,25346,26600,15184,5092,49928,29520,12152,15984,73584,8990,43645,4687,49920,21424,11592,108252,58144,460096,297960,16058,63279,131219,56992,4066,62805,79608,798769,10608,5054,13536,2141136,46314,5332,12096,6032,123324,17028,1493021,5720,24804,15563,24700,20160,34128,14560,7592,12896,13889,32736,4386,19355,7448,10868,4687,21514,50560,23068,6536,20016,16302,16195,19656,34049,7396,90516,5977,21008,39364,7525,7790,14104,3395520,12400,31218,33136,23068,73910,20880,42344,74214,8496,6384,11180,27360,5977,262596,5652,22824,24381,122140,31540,36890,134230,6020,804615,5772,16120,1989704,11966,350207,9504,124754,163866,4750,8928,92579,43134,22420,5676,53496,656885,3914,32034,3744,27864,9216,7280,19197,127286,6837,7696,288917,7439,34916,14694,8643,4788,9048,17784,174580,117728,13244,16254,10965,217672,10535,13208,93252,13115,3876,12900,181068,18166,99303,6880,142168,4712,7440,20808,6450,67392,5252,20145,209932,8460,4788,46170,5624,40362,9272,16985,10922,126100,73584,37128,12298,6500,9776,4104,7384,8987,11648,14456,19152,12685,16590,115656,7095,468884,113602,53630,11856,30008,550393,6764,119784,177750,161476,5396,37920,15066,4859,71982,423708,94886,8996,12212,8256,32832,23736,145584,947842,29713,13502,13578,5662,786780,6878,14768,411985,192386,7410,7800,56564,55800,15872,252168,4558,52706,44304,18648,640212,6118,200564,10602,481954,25675,31540,151443,4560,9864,13020,42840,38710,136697,27413,70980,25344,4332,18662,19995,30168,119952,3744,10108,25420,6880,749552,171120,118598,15028,20425,301306,48190,73573,8618,35880,5244,9804,11088,114550,158328,22989,6572,16432,35984,78884,8280,6344,8184,10836,113760,3838,4896,101804,3996,5738,9724,8632,464318,55872,30020,10184,118664,349259,1742317,34906,80352,8436,4256,7790,35392,28196,11804,6878,14446,13588,4598,21476,25704,11352,46956,397008,45899,46368,8084,18848,42011,64930,23328,48891,20904,46488,480240,6278,7812,535651,346652,62124,11592,4429,121368,10036,5928,4408,7828,193128,30312,5418,403374,7998,49217,86387,191654,60198,17243,70408,26273,122740,23972,886854,177568,214848,19522,14694,132088,7525,70942,30315,5130,128592,58996,6923,36480,6240,29808,5092,4864,12532,26000,23976,22032,20224,19190,8626,22116,18240,9052,52576,5504,6882,9196,1177848,11340,49324,7334,146880,4484,326823,23688,64414,81449,5168,494326,21166,19136,96222,11952,29467,6758,298034,64844,66664,19694,117154,79670,13320,127368,87516,119536,5590,37200,30600,61462,80969,16120,6820,559320,436852,13224,195672,18414,171950,12616,94385,53404,43946,49556,239904,963802,7852,4680,15800,42696,3378752,38270,380376,15879,424625,17143,112891,995665,138566,393016,661072,14580,6149,235152,22594,24336,21576,7750,7904,33060,22932,44194,12688,100172,23521,52693,14092,6820,154584,279000,14098,9920,53010,217208,6240,30004,16492,27000,99944,43766,13640,31320,9486,17480,118336,143312,6063,28598,5616,64440,10868,8840,10368,62884,26860,15247,14688,162029,95288,25327,10348,153338,117552,33934,10354,10412,291589,30336,194256,7540,1227976,32344,10348,5934,48348,60164,24648,3914,19497911,10234,5760,27576,47558,22724,237460,49290,8372,57190,19512,6448,80106,8424,8424,6536,38304,43834,17632,85952,6916,81840,74808,8295,15563,19039,24862,71416,12636,226610,4028,10400,11594,13244,44082,23134,71208,40680,3720312,11096,22516,7790,4484,90948,16856,53612,5160,325884,5160,8928,46664,6665,11908,6696,12274,67500,8532,241034,6574,10088,14560,9776,25116,5460,18648,7502,4902,13020,9734,5662,37202,30336,262260,67906,103392,71939,83018,66766,116774,11297,33418,1062014,21268,3708,23263,8686,19916,9880,31920,102114,55432,5564,885794,12728,186319,7176,9796,188928,2703014,28234,7020,37762,14456,34602,10354,256987,15048,2912493,7072,14018,32968,10088,26524,56916,53444,14457,12844,43529,9417,1932696,461088,29232,8320,9108,68414,26136,14560,24332,34920,271128,8927,169594,8474,684140,598345,11455,35064,7164,77328,965808,9880,4598,9100434,15996,46228,32760,5928,12084,8690,5776,9000,2987504,13072,106652,5564,3602092,123635,235894,5460,247052,53754,13193,19646,28086,106887,745920,9546,5074,12896,59976,21684,18460,141963,71188,67526,11700,16952,12744,149872,28644,777712,120317,7540,13104,22392,14319,5700,66994,27097,89544,5977,42120,7006,6634,76464,4902,11180,93654,16416,14190,4386,5662,11352,71362,21600,16555,779730,26781,172694,4256,478503,45899,93299,5928,32452,59128,225990,216562,16678,17794,10348,36144,4068,5472,7095,11856,23305,7181,39263,76756,201514,81449,25916,19158,49348,47479,10602,6149,5054,35155,70992,19584,241552,8471,26208,117046,29625,338910,92235,4284,132096,5805,13454,7942,125517,86060,44352,61704,326244,1054614,20026,44460,25978,33583,93000,415423,36704,163176,16039,54747,410332,4142,222480,48384,402268,8772,16640,4408,14144,27492,84604,575172,494145,754992,28656,1210356,515317,58104,4142,388864,12024,10277,7828,56886,130591,13186,17316,67704,5590,149389,11137,25848,64372,9900,597528,45980,8514,80969,14326,40824,222490,11098,8476,31284,68940,973517,149358,168302,10191,100409,1756723,5668,15480,15552,126716,22199,286936,399024,20592,7912,73628,13702,14716,35774,18044,19964,6384,7124,22306,9766,29736,348074,911090,5016,20066,56327,28024,488299,8772,127111,2482046,9576,14060,142386,132440,20384,69502,4294,19552,28756,939238,218096,5564,81270,4484,424908,23700,50639,11514,6292,4256,13490,7697,17822,88198,6020,8164,5460,61857,13029,9464,12888,9548,24984,33232,1918831,18565,212668,20026,67466,4674,2289815,8927,143464,17518,9559,29488,28800,17856,110916,11309,59469,27300,131688,8213,6232,14632,101093,7338600,19584,19760,1379040,9720,33669,8987,62173,4902,117864,22747,449565,49248,186519,23832,14508,76712,13052,14256,6992,13680,23005,9114,10296,172328,47953,6552,80724,6882,6510,10640,12636,17100,74418,161120,23688,47736,60216,117648,12220,45267,8788,54036,23218,9540,41292,44640,4558,8816,4446,5700,9360,10504,5824,11180,119606,67642,167717,12888,4300,7439,39026,46728,30168,7396,2417163,104594,13468,5289,61778,830717,456404,11016,8618,5160,89156,4674,1106237,9568,25517,1094071,120776,31205,21567,9690,230601,199008,26496,633256,12532,15132,1934473,5436,60435,22489,18936,46311,6084,26273,17174,8927,7144,146415,934648,28519,26102,1520640,12090,15132,140146,23940,1001088,13825,145578,210900,38736,19476,31679,293472,20150,21576,7439,243568,10354,8476,45714,163852,42904,4680,32976,4332,11020,227240,4446,88504,25675,5200,49770,168259,9245,32550,18000,10452,75603,8008,72106,36024,46764,6042,81133,8736,37288,15265,29704,35100,509787,131021,5112,68472,15964,57252,8996,61304,5762,80848,15437,50998,56520,20748,1289160,8127,7866,14319,381900,15652,4902,298857,6232,7310,17856,61936,137088,9272,140554,8840,6450,8018,10230,45881,182806,17556,37440,7296,8611,8385,66960,15314,37604,7592,4294,41366,147146,5408,1709876,22152,289952,4515,31126,12350,5720,33480,116130,9652,46956,12400,119764,701896,1120220,4750,7562,6500,87668,293959,46500,126432,96876,25740,33332,36894,7344,198328,44333,5320,19592,14976,4644,18600,18881,8729,37754,10152,17933,47652,12083,191338,956004,89856,247884,16340,6292,9462,13268,12350,7344,153813,23036,22403,7562,7272,15336,4212,18834,8424,177630,199836,3922828,41306,186248,220884,3819510,775806,78447,9804,18644,65556,8930,133859,930620,2279545,14544,1019258,9638,6188,17050,13459,106210,124030,44763,29796,233064,7992,31668,325510,16864,149832,6912,40979,34701,14706,237711,14061,9976,7828,70520,93931,20644,28496,7920,346890,37262,26860,36146,18216,51127,21672,6726,5031,245186,25026,48060,52417,740808,7416,9462,157526,16678,745444,5246,1027710,12220,42186,7874,8736,116057,198432,180041,9620,38998,40334,7095,132192,59555,22752,63426,9648,820728,11128,32072,26676,97881,29848,8742,37368,31428,15132,24986,7384,24552,7904,11036,7596,11532,81936,151759,14322,92579,6080,31691,8164,1119588,20511,6880,10222,21070,3952,31668,30020,16827,80640,288350,7410,12771,2937062,196664,10792,72664,13114,37752,54826,16740,27432,45562,23305,15238,3636,593290,198360,47795,32976,24776,88236,24336,228888,220058,5203,15656,18616,35152,14544,30816,9256,20232,574184,9612,35280,16948,140223,5564,24192,49176,4730,4978,41572,12168,84878,5966,9766,7998,19872,32528,30744,41194,5738980,17420,689184,1516958,27072,41044,60946,6032,6262,18668,52030,7280,41600,9072,29448,26568,31205,146808,33840,69574,86060,4773,5418,6751,18506,282899,6084,11929,56412,305809,112654,13832,9976,12896,414355,6321,163846,20777,10981,49538,6020,57600,194814,12245,6650,8295,2359296,4177599,17112,50544,16616,32736,7942,5876,367744,41416,1861704,499658,138503,9672,6764,118121,68284,11532,10660,209324,352160,83886,454646,8213,507936,10106,7228,7750,12792,122450,11596,21514,52832,492881,6510,145080,131193,10112,233366,9030,11068769,28148,18228,33153,20274,57252,34424,19708,20436,10507,7611,4294,9048,34271,55142,8132,4826,74971,11532,8930,8686,59882,38952,13338,25359,108288,20232,32074,13760,6192,37525,405964,4968,9348,26350,13392,17472,18408,223886,4560,82088,72850,10452,44677,7192,12168,61146,132088,7904,15500,12772,6751,134300,36720,6194,313404,6536,35136,7316,882828,12008,234000,36348,18802,88556,2832545,8588,1082830,85557,6820,36244,187941,293485,6063,66439,10168,7488,45267,147992,168020,14756,3600,60496,32908,873496,542160,92588,133300,13888,59328,18960,13490,10728,39780,25438,4663844,222196,22464,9412,15050,71258,32616,7632,26226,7783,31464,63200,62489,15562,19500,582660,23712,142595,268632,18962,6192,40014,20016,58104,87096,19158,9417,19530,4180,10664,22534,23972,12126,21543,77862,12768,17696,21080,62640,7812,4218,11160,11395,292448,49894,14196,73948,14820,4978,9890,119908,16432,16340,12814,68328,6880,9196,7272,5547,7644,7564,8928,65728,23370,3249823,7611,199080,12586,4816,8742,45792,132088,30690,111176,2638363,716196,25284,28008,88350,18538,196352,28598,8094,42744,14508,62890,5548,19152,49296,10621,37336,30836,12688,9766,21567,11492,8680,24814,13946,5332,23976,5364,202635,24800,15010,47214,4859,202844,11248,30600,537753,81158,236220,512856,9052,153037,14668,22317,18600,30336,7124,6500,75287,108624,113839,6422,16128,11718,70942,9672,10504,51460,21744,77443,5408,224755,85083,18920,34996,675936,58136,32860,35724,144566,7852,57888,15652,3852,15624,275394,1997320,8930,81054,17732,81792,154656,10712,163787,48070,4988,42696,9245,7228,74734,41496,1202581,7068,158808,16872,4408,55588,27716,6168715,85464,7704,25978,18928,5168,47728,52000,10868,6696,4978,7560,12376,10656,9204,10602,437502,19468,7181,551973,89225,61070,122608,8532,12642,88776,63284,4284,65884,13115,10974,10707,301320,16016,5700,120652,16306,46136,6020,4940,12160,7228,1298032,8064,200660,14964,5252,9880,71653,318291,68696,6794,48585,154368,1623024,31616,10728,10621,3952,4142,8428,41791,19872,24586,171144,51584,13330,50353,36022,5772,27976,61189,5461,27413,5304,4932,19049,5130,68651,3952,25776,20304,98696,96933,113100,8352,10140,176886,147368,5547,285348,6235,175248,7776,25428,19380,6188,993852,285192,21112,12324,140144,10036,8684,41344,77672,22704,159831,376593,20224,4370,390624,8164,19684,16068,81686,7254,5700,38812,61304,27820,150495,5555359,63042,22458,40092,59882,14749,9994,23560,7740,3800,18504,17898,55584,74932,65304,64410,12040,4816,6612,12744,31916,997770,13764,146946,29716,10754,9006,3914,164448,7525,244872,9648,25048,5738,18724,4212,43608,4180,75504,44346,8385,7372,5004,297228,4788,20520,59508,242208,13728,8769,10879,4356,2513880,9804,11966,13193,88882,50778,23622,21371,201818,153381,8476,81449,9000,9672,295195,12008,11223,22152,34580,6364,118248,6923,120228,28466,8453,9796,4429,16244,14012,28028,25754,60909,3744,28440,45240,6292,176042,71574,438529,20592,12648,3708,362318,8216,8840,64543,16188,158498,13760,25840,36868,70512,14012,11088,29264,31198,30494,54126,5928,107068,13144,862358,31824,59487,25584,6136,12168,195780,1035648,22680,7848,234522,10088,17484,12312,7752,12376,168516,9300,13824,47690,6396,8742,67983,11160,352893,17064,15252,34056,16116,22444,217566,6308,62248,9424,254448,76235,4687,10920,13364,16340,22496,221676,42226,1807204,33540,2408315,15800,148994,977904,6650,8453,22444,59812,63911,14198,22831,6696,135720,173166,174384,8476,26660,40546,16112,17640,8246,21762,12502,50464,164715,15314,44802,53167,153983,46810,39816,5289,11024,7396,10192,4945,9672,8815,11160,26728,14577,16827,5891,7525,11395,37752,8611,204373,11388,19276,4824,4752,226352,114712,28860,237460,580808,12616,73530,37634,6149,5848,16727,7378,122845,161634,27838,39888,9204,8736,523296,5408,5700,9880,22392,65175,7236,16632,38055,9766,16956,28086,104000,53879,38592,36024,6240,179452,60952,10332,11514,14976,136332,7280,877176,49849,7181,6408,62963,28582,26961,17422,7488,5252,7267,10712,11218,7884,13825,6300,8208,3387308,13186,11470,10788,25482,90139,16016,33970,53768,1978056,113956,5547,602732,31824,144096,51452,11739,86989,69204,212334,9331,140620,12198,4300,66404,29326,15352,70784,7979,12220,5876,30032166,17918,133418,221364,15548,73865,74958,10726,49248,7750,132768,6751,155168,35360,17856,8632,30172,8280,47244,41808,18648,4826,128375,5980,10036,14400,14260,47902,27413,269328,57970,108224,17587,370822,25168,168910,5512,5220,17424,88846,774086,19952,90954,33264,10488,53072,2552885,8640,21166,6708,28677,13312,19916,11438,15953,185887,8632,25116,14062,8788,10633005,477672,22515,17538,24095,9322,19750,4750,45666,120328,11736,48269,101400,16598,7540,69882,1352085,117612,5408,37872,233834,5510,80064,8170,16827,28282,11524,1582920,7228,33575,66220,13000,9804,29230,24120,9120,5200,21488,15500,7228,32328,40204,6572,4558,7611,8164,34400,26307,8686,242996,28954,15010,13520,7436,5824,13946,23920,8580,91010,9538,60610,13364,78520,8856,35720,10660,40053,58500,4601,142911,61699,4066,22506,1044854,19874,23472,14062,49848,6396,11952,58222,1817902,11771,44640,9610,15028,16328,24700,13826,412982,27864,9576,479598,18648,344519,22412,169100,995400,5814,18538,8360,7852,11532,45032,13884,1775556,11856,777852,249302,7688,106468,81720,7568,50718,10062,7254,124109,13870,36328,109512,6262,6696,183528,18620,5396,45562,5016,23332,103106,8424,11780,11904,13156,4068,11960,21014,8736,486008,18644,15128,12212,3683544,7410,537984,149683,21888,43524,508752,11268,1096110,12798,7228,6232,14942,19908,4773,138961,9717,50323,12688,6330823,6448,198843,118792,64440,13728,22360,5074,8804,7900,6552,10292,95532,1364544,4816,4294,4608,5624,17860,87048,53506,8858,13803,32422,22880,7095,10726,792370,14664,60192,5616,11336,41949,17802,13746,6448,7936,6650,28203,124109,250303,45000,10512,26617,306599,16796,14872,4816,8060,6136,25560,252148,4386,16920,91846,14663,16120,4816,19592,18644,113444,19220,53998,24411,13640,53732,48934,33540,10540,7783,7138,29072,5356,68894,17716,18166,11336,40114,6794,11590,19800,27962,25284,20597,61516,12169,25560,5472,63752,5633,34684,31980,5590,67824,16182,14022,182016,15264,214406,49320,92448,11594,9568,2930368,871224,424008,7644,24192,59013,7432952,55480,46436,38220,59760,37656,9675,5472,15048,200294,7272,301731,30960,5168,5203,19908,118800,857880,34944,7783,477660,120080,11395,222552,5054,19282,3990,37999,49286,5074,299304,482790,6916,566825,287481,10602,16492,736632,58344,157508,27664,3688273,14534,8532,5289,441531,9804,322457,10744,46246,63674,51192,4988,5092,40486,7611,23940,107694,173352,8680,6708,12166,8729,39052,82584,7006,48828,514520,8127,13032,72996,23822,42480,18928,28224,6622,6500,34314,9322,32798,13746,16182,12338,4142,6422,23816,122616,62264,14782,8643,43128,11470,24480,4601,27133,11128,9648,1973088,9503,120280,12772,14457,282910,17372,57288,88846,10105,13416,100296,4730,20461,12692,43648,326088,19778,45899,82460,26312,21948,22403,5720,18792,28964,23616,4522,3398975,68472,12341,11222,5772,4978,215498,86490,32311,562875,16568,8474,5418,5590,33022,127152,9234,28458,154682,7654,96459,402480,39816,17301,22176,6572,17316,229732,69564,18476,35712,27032,6235,70735,132652,8740,16900,371108,1253063,5512,21888,7380,6882,92340,101592,7852,94326,15236,37446,5547,288113,6407,6510,9245,18354,527404,185318,95784,9204,189284,32400,53280,248248,6228,4028,8557,2650104,12240,8643,15500,166764,32414,25972,181168,15910,822888,7009,197974,78921,7644,44856,130587,671816,335118,20336,164304,28124,22824,8736,13578,8600,1907424,20938,9500,6820,6139090,30240,7956,32032,604810,10296,119808,22724,117000,140040,40820,657384,6344,118342,13717,9164,31668,49824,10640,268560,10902,162130,47736,9052,15066,4386,13904,9300,21567,99066,1122432,81700,6321,1168410,7192,79128,6536,30968,98197,1440504,37446,22120,26728,7956,21052,13082,324942,108288,143260,4902,110679,6552,9120,20708,11098,13373,36270,10584,23779,1296469,694440,10712,12456,13988,1010568,421290,79441294,14756,2472384,27170,88064,22360,4515,2110999,69125,7638,10404,309601,64896,546838,6708,7030,51557,19823,110050,7052,44304,27404,14276,4864,37683,95073,163530,7714,35932,545495,12524,10981,59803,268836,21312,33800,7800,6048,10224,473688,5762,178932,105196,295802,7482,37446,15264,12152,998675,11532,6760,4218,133036,321516,8736,141015,52200,9984,36432,136710,19708,795801,4408,537911,5980,11309,14456,37512,20596,164016,53784,138675,297830,46748,35640,88848,103806,46080,12008,518328,4712,5940,28704,45360,5700,15912,4142,69998,6321,7848,6612,14835,11455,31744,4515,20696,11008,9728,15340,200298,7783,7568,6132217,32184,33192,537844,45694,47400,16744,22536,16036,54036,21330,291668,384648,6156,17422,7740,21414,18920,284696,15912,5876,45012,4028,7592,495876,8471,4343,34504,54360,23779,44928,92606,163873,10664,17784,21204,192386,186010,9073,11825,213044,89507,219024,274680,2113704,14615,5460,8280,9374,298512,8476,10192,148614,6498,12012,15580,26918,343790,176881,522743,15238,1181998,4343,27413,98434,42581,16616,54994,6696,28423,7200,59976,7020,32448,9052,70434,1247936,4028,14652,87453,520531,11266,13490,136462,28964,9100,9288,5547,97266,178002,162184,19800,31824,137618,66384,46018,9546,5289,4902,150048,104833,96928,18705,50592,13983,12740,65175,7128,13260,23244,3800,41002,224044,10640,6622,52851,23940,7750,42192,16952,6270,133200,7740,280292,27950,5074,679572,5408,11160,10184,100804,6344,205088,9932,14400,38948,562030,7068,8436,7912,1083959,12528,7181,238817,16598,105694,7296,19840,16297,27432,68286,11880,25480,24095,34918,6084,25596,12480,20336,35150,8184,173414,11036,57668,7611,8295,4826,20384,24490,14457,25628,3744,150746,11804,7006,51272,17004,75582,7254,513648,1116648,16770,4294,6136,7258,6235,27248,8632,5824,16058,3960,1591218,118637,17775,10664,6321,191180,50482,13908,33180,11160,14760,41949,1846728,180471,22568,8164,124141,14248,7009,41496,11232,108376,11856,60788,16182,290404,139514,8342,43258,10036,9417,35048,32968,7106,8816,14402,8295,19448,34013,29111,3708,100812,9504,26820,100254,19344,17980,162898,1382500,9920,10191,9159,14147,29070,87360,18096,38190,225288,10192,18288,15132,34944,756288,145813,14508,96965,66024,400536,3057458,13566,16740,142832,1267160,35076,8280,84630,13566,13832,7006,323020,76320,5824,23296,10428,5396,26832,9158,4644,39259,6344,61332,75680,51168,11648,63812,50184,141252,5976,90060,10965,12298,14364,11324,16068,31692,6820,301392,21892,167152,534909,14190,31949,18980,43416,47736,16588,160848,455830,4284,201292,34523,4636,27612,7410,12064,7258,9396,71760,12956,12586,8840,6656,33927,5848,598680,7267,25929,7776,36335,48633,9796,22608,94612,4356,15084,15066,12672,10912,4386,7068,14061,52061,41904,55536,14688,61566,163990,21944,6346,189679,21199,7750,6500,15484,24048,21008,23746,8060,16068,9310,7344,56406,18042,127452,52456,8892,56011,72384,7783,8112,92752,11856,8122,9256,145018,9724,13717,25359,20072,22356,32916,10816,12648,10320,53924,7052,8476,4028,153698,90864,61940,16530,28830,5246,1145264,7638,368136,9858,26496,118658,18354,12116,93496,138320,5358,10449,6156,11160,21973,5246,7900,50402,52632,7912,6688,7224,19952,11440,7192,6708,22648,12688,5668,124558,9982,4945,14534,5719,260463,142792,26226,9761,18328,6422,298699,22672,768196,548018,15428,4370,623626,37804,23091,6864,26752,774832,164808,5580,20770,69472,26220,180594,4730,113688,84778,9164,8804,5320,144096,4484,5168,45899,27056,31200,4392,729926,21758,200148,235578,4066,34959,17980,53009,10222,247832,7488,25201,10764,186835,15624,33356,18936,149530,21024,8060,20020,71712,20770,14694,6760,8804,19221,6364,5891,4978,14773,6708,13201,34352,58460,4472,23750,8424,10707,7740,76880,10008,100316,30456,6510,22230,8968,23370,9462,4864,13716,25929,44793,10296,21660,133194,33170,292932,6622,8213,17264,5522495,9082,7696,6802,408408,9880,7812,14424926,22962,63468,10836,10621,4515,37625,5203,20520,194016,92820,5891,209592,27792,11160,255012,140936,261288,7332,9159,2011606,18216,6968,72000,39895,22059,5418,17524,12403,546285,4636,8702,57660,11388,16524,10036,25840,6020,14061,34839,34164,15089,21251,10664,12948,68888,74464,74256,6020,1200610,27588,26208,108072,8208,3838,4392,80166,96854,844116,4515,3914,2156622,9234,29202,17696,4822192,592658,55252,201025,22536,4945,12728,5564,7176,42441,67680,68688,8436,7688,2529332,10726,14319,26187,56544,150722,19296,4773,38552,63216,31777,94815,42423,40176,26936,109944,7124,87420,11210,7750,432388,24814,114471,34892,7936,52820,840244,10234,13752,56592,13104,68744,7992,8028,150258,4644,10972,5246,86900,121148,2379480,7596,561168,189384,77184,5564,7296,22962,11966,7848,13020,36952,54028,67467,1160068,851067,6032,4300,25992,93444,35787,6240,247379,144017,19158,11096,21930,370584,8736,10270,38502,29025,57828,22831,59598,4932602,17748,43443285,12879136,10244,11932,6660,7904,8804,5738,65592,594828,10665,127920,62135,4066,26536,52488,6278,7254,146984,11908,4484,28849220,14942,404673,230308,70122,88660,324636,4484,7192,407482,83460,427492,9847,18824,36103,10440,21027,128217,30108,18104,6321,12920,73568,3497330,24076,105958,5719,46452,9412,12896,7502,83700,11718,6916,24336,19220,4859,11284,12578,57196,165110,12312,115498,16416,36498,8322,16254,8944,17243,16430,390139,4978,17108,9396,36898,23088,4104287,129636,127660,3888,16200,75578,24016,32798,15236,83187,19342,9374,13896,332272,5772,27612,640646,13968,62662,22464,5460,537437,233116,665575,40896,53424,6880,6032,7072,8060,5074,108864,988011,17546,34286,170976,10140,5206,59171,115752,29760,17056,15953,17420,430160,78572,31648,42269,94800,5016,64440,7776,8471,67580,460728,75384,44826,746313,80659,5977,34997,13984,3952,190368,28386,11248,19038,10374,333301,13459,9880,21584,17316,12708,18228,83876,18275,22940,16920,31096,5358,11492,30324,60822,22968,5054,270180,10974,5720,15910,17280,48906,1042964,109951,1067454,4066,783432,54548,9234,23126,6760,23328,12768,5220,17280,422097,8740,10965,8164,6120,11180,10621,17974,1597459,1465213,14632,3714580,16353,5356,6200,4978,8680,14292,1366092,8690,90720,20520,15810,184544,39618,8928,68098,1280088,394108,12806,20522,11137,46768,37200,3876,446982,7564,20634,15124,69746,253270,90472,9656686,10788,45648,17836,7920,403295,26846,28334,16120,14260,7436,37224,21801,120270,6579752,255291,30286,8512,23712,27968,14782,12341,42718,4712,26784,7524,1567296,12578,16112,379756,4752,7697,16796,47601,5928,12642,22692,48152,87984,6292,76000,13035,26728,65728,4636,222859,9672,29016,8184,4601,4386,4945,52018,53799,7334,15392,6020,12169,7912,83029,253448,6820,194814,19188,19228,65145,83503,10412,5031,13826,2510820,301378,204594,10578,7502,8557,28086,6136,90432,37152,4750,21008,10728,18848,7752,64464,29484,7224,9880,16125,149864,858676,34808,9464,231480,8375422,98857,8424,104359,4522,81468,233616,35880,877982,106912,24118,5928,5356,3838,17538,16306,345228,25416,10044,41688,327218,15192,5876,16211,15089,8213,9196,23134,279032,47842,7396,14632,16856,11818,40560,8928,5865964,30420,61560,20808363,387810,75354,33022,15192,791440,5252,10556,6948,6992,22176,56160,116525,522106,5966,77710,451440,51532,18460,541060,226486,116784,26928,4636,1082520,1239431,13312,16368,12692,35030,7697,85699,6764,16432,11376,94213,442479,67639,70566,24490,11534,244556,15089,5203,16430,13578,52824,2512753,398634,8640,9464,527592,15444,36214,26970,7688,11346,4343,6188,403992,8474,19909,22420,114088,8990,7448,361741,33912,16802,213221,22680,5246,30616,5004,8680,23712,79236,10088,328290,11266,70784,4332,6407,16848,4104,32250,14478,23760,9766,6820,17484,7488,856755,13268,16128,6386,7812,342237,4248,13604,17316,133984,1571184,3839400,7697,5720,2716336,70308,16988,9724,13728,505293,27280,11395,30020,13846,21886,199004,98671,79790,65782,5200,7436,15562,8213,102410,146604,8626,21962,91640,38947,14931,731724,51116,8712,117390,44824,16748,456878,43416,7482,27404,809782,39990,531179,139032,27097,12236,8060,26860,17918,122360,27288,32469,84846,15093,12600,6106,8018,364032,35048,23446,73512,27664,94326,750184,5460,5396,13676,10793,29698,89139,17544,301948,9116,34444,6802,21112,6235,5200,19276,8164,32328,5418,9792,34038,24840,7488,21762,11218,15548,11196,54481,12272,5396,170810,12744,15563,117312,20708,9432,9044,8568,74261,1569113,79636,41396,5848,38880,33604,10584,10512,59272,11596,17856,37758,9417,5054,9842,109800,16632,6966,8580,259992,6552,18565,14612,21164,6300,17222,16678,435240,341833,18126,16150,9331,100434,5814,8580,75516,28028,168646,6536,6916,10792,7998,23312,7440,8740,112812,10192,20556353,19264,64543,9656712,13248,295568,16985,7904,8840,21584,12599,3522294,54872,7006,5510,21142,59020,7654,21840,7254,14536,24244,184202,44635,122335,30336,48348,322582,11656,11718,18662,56576,8684,22878,7626,42532,135876,163080,12956,6240,25585,63270,68241,8729,24614,262446,6708,34788,22828,22199,11954,9030,121432,1490572,4712,5203,6948,27735,13702,9920,44240,11076,89784,148986,76536,9568,26040,8643,122976,10062,3952,26101,5504,63550,275157,4515,26149,85320,9460,288143,2858324,423398,24016,6572,31558,232066,314352,64656,116604,14664,38844,768018,886143,10868,18476,8041,7228,19292,11997,798424,1494578,34782,15996,70742,11804,92983,29941,401241,16378,10140,14835,11596,753186,64220,1612627,14924,8216,30744,13545,7224,20145,11008,27300,10868,6232,23180,190706,40248,21725,17236,61857,18360,8060,10440,27792,4218,9994,11438,18430,26638,210930,48724,101136,40796,14554,5168,8848,7144,36577,20808,17458,18000,75960,367564,41882,37656,23472,5332,7181,333372,31521,279792,48724,5203,14835,7384,8632,1118000,11098,5289,15824,14012,11336,39744,23296,27248,81406,6794,21700,427320,21172,12648,4370,11058,80422,71337,7688,14400,142012,16195,123552,54720,23126,22754,332444,33904,26156,54560,32414,11139,39600,7568,18146,175392,47637,68651,166656,44044,61814,14782,10816,60610,6916,9559,13884,31752,14174,5590,13764,7955,97774,19512,3012665,6240,575989,19866,31720,138456,14536,4826,19264,11868,22968,8788,19750,62282,193544,90396,12341,8600,1925368,273208,10296,7228,4429,57722,860705,35092,4644,6665,4598,6794,11052,128098,524016,5356,34224,9362,4940,23580,8600,9576,21508,29016,7568,1153242,12640,68848,170877,31519,66774,6235,57164,90688,59400,128217,246844,34736,10507,22320,13680,58102,9362,125316,291668,10540,7654,63468,12152,15168,116920,5548,166611,9864,7776,235973,48152,110983,7688,5805,695952,24552,114076,255456,14144,82512,15912,463268,139384,393696,9792,164424,8432,8008,5719,66123,87880,1570441,214458,30816,375092,592105,10526,3924,967104,70128,12958,9589,5092,250900,92588,45741,150822,53072,50052,163956,12771,7502,2078024,15028,6732,7956,15964,18616,80352,10354,13780,3453959,13020,6063,1255176,10621,19656,34884,4687,13680,677730,6878,49880,13114,230412,29450,17928,8494,6156,16948,265124,44454,26312,561279,36792,61828,25359,8424,5460,63516,5616,31248,9360,16692,54696,1614548,5928,18000,33402,17888,37130,52772,227664,8018,112812,12948,4750,58867,7525,114504,36608,6552,20824,630894,14749,11024,4940,8640,28656,50592,16813,35412,264168,12376,11613,291408,7956,675614,3990,215928,422650,428792,106578,11160,9216,14612,10260,10602,408667,191575,20253,68019,67166,33418,5633,148738,11739,13932,29108,75998,34596,64666,704520,4386,296092,73075,164320,28122,7592,737781,6422,15314,6916,10507,6032,7439,50353,43896,8712,14706,472750,198120,6084,20488,209664,4068,802152,14074,5200,7626,13984,155472,14716,9288,10400,5117,55728,1215084,30992,7488,13082,596068,45448,6192,87152,13824,469339,13490,8208,134106,40144,4636,10586,397277,6552,469023,99386,47272,24885,290108,6278,34830,8690,321152,1529320,27072,3587688,34560,7704,6278,4902,482804,122512,7416,32178,5876,10140,6188,82440,106742,14706,9486,8580,8928,18772,29541,35424,161856,451152,7688,5633,574824,15010,4370,14322,10044,28548,7280,52920,9243,7138,257688,5160,527325,121024,10192,38157,35733,4644,22278,16416,25776,223820,570960,1386529,197972,7482,4300,60268,2610530,6878,4256,5928,9724,185115,49059,30780,60912,14248,43628,298566,18791,17160,35836,25110,6665,199001,14260,67104,8360,24209,17680,6235,8424,315456,46696,5616,25596,121660,13260,33552,431972,75140,36784,10088,7138,23250,10707,25201,26939,15010,12428,11596,4558,3990,18202,31104,21926,6820,2050445,12384,198606,8170,9158,76128,31248,6622,5624,7592,4968,117990,1425424,33101,5586,36576,23674,6292,70618,77976,44252,76669,14760,97696,17424,239295,7812,128180,5356,7488,690934,19654,32760,40536,16172,11782,52056,36244,5548,25194,14092,15696,9272,4988,50902,1291264,14276,17050,18290,17759,8352,12958,11481,1055440,107045,5200,16120,84882,7884,17372,16848,5375,5852,8094,107414,8550,25069,158711,9073,102960,5472,18723,312129,811014,417487,32860,9516,45942,13459,4256,15721,77748,11268,51840,12168,35402,12996,294851,4408,250667,12168,3838,81096,14457,10974,312481,40280,11309,8164,45012,78289,29484,4028,25740,198273,73216,555449,63612,5092,49348,8216,21964,88288,7344,4343,5512,33812,28340,1070888,24388,13373,142200,63437,21199,12744,542098,18275,24624,11088,226670,38750,8901,251299,34944,926484,30566,61152,9417,9048,27648,609768,15066,61048,5934,21166,4773,12513,85241,76700,6063,114638,1127883,112892,333640,53320,122044,17286,27056,12806,9256,16454,58344,6840,7874,5652,12084,415079,424574,23296,12480,102297,96668,13148,235657,57433,7334,21672,4370,4066,35948,388296,7920,49063,51116,7006,695968,8132,218088,12958,26445,4750,12400,1016280,2434104,42470,12502,162316,2064608,29625,32968,9256,5436,41791,25413,38088,2494346,323280,31564,7783,11058,33101,6084,10412,6688,70866,7717724,936944,12083,81528,17587,58368,18920,28124,1081184,9202,2223218,6136,33259,6812,8901,28912,6262,1268208,28830,6324,6324,7396,5244,43416,320952,107224,5246,11139,161772,8840,1886544,492404,110448,4515,4256,425258,5547,4945,20296,5160,6726,67704,71796,35774,285758,17264,6536,139356,11160,5117,55771,150021,12960,187467,5504,32034,600795,8626,10972,7332,86903,6448,41882,308396,10191,15264,97344,120317,19307,9516,20664,4370,13452,11804,179409,9331,61978,55063,324360,9331,7228,9796,15376,122766,122450,23392,21508,7634060,13201,139277,116288,8112,23504,7998,12943,7564,6923,19479,7956,5112,7626,675800,14074,13578,7525,64232,5016,80422,140146,53246,12986,19512,10152,8028,53167,9424,39960,11856,124920,8424,38952,21024,452876,79050,14760,7448,9216,32656,19152,871607,55728,33046,480624,19188,10222,19396,5282,152134,840086,17222,16120,23435,11440,155808,12040,256824,35561,6136,31758,1131552,54352,20640,15394,5130,5824,54264,23036,240002,8854,17992,39579,456699,25280,15168,149081,552064,32078,11514,198328,28124,16900,10404,76456,8496,9216,7332,8901,35561,59688,124583,19080,12168,6236464,832581,8496,19434,115111,18538,165416,6634,24490,6634,10070,56340,11058,30992,131298,13788,14384,472812,382123,45425,6579,840718,17062,6665,20210,25896,6916,45408,12556,9204,42739,51858,14400,437684,39494,13624,93783,7353,4826,29536,6696,6063,20708,193180,159264,13110,17174,63792,267264,192608,84538,1094178,8060,24966,16380,47994,28132,7869,335671,12920,33356,25064,7334,6760,197856,4598,68335,14896,7332,3952,10296,207762,7488,15438,15808,6552,7267,99424,136276,22464,87768,9976,11594,216697,37281,15652,102068,14688,4940,35256,66716,3914,4940,5289,6840,17174,15484,7644,95666,107440,30058,20640,5616,17538,8320,10707,27334,108432,5772,4180,3914,24624,5356,43524,40320,11932,79128,6536,11692,720502,31564,110542,23384,12502,105552,11324,156302,4534958,35672,485857,10902,11952,42581,51398,9776,36034,5738,10292,462528,38532,19656,79128,6923,20448,75096,51794,48980,56373,202802,4730,28086,13588,133510,14300,5252,311240,13794,4142,5289,64030,278720,11060,29068,5676,32379,425010,15089,126953,1689128,19604,6760,16328,14362,6408,42120,16328,118924,46689,6278,43316,378138,8816,8385,8374,4644,54684,50869,7144,4218,10902,10152,44268,121520,636272,10348,4212,13832,26496,112902,7980,13728,776644,62568,21328,69230,4515,56674,9048,2339585,9516,8784,12312,15336,13020,16560,10416,17784,10836,638058,56760,15192,6396,9308,24467,55728,582941,8742,7676,17160,20212,11567,30780,110032,7956,8060,155272,170196,91246,19592,26574,2004187,421860,10449,14760,18662,250704,59436,82947,9085,45583,7448,28272,4142,309776,210444,76235,34128,44714,7776,445176,402628,35776,15704,32153,56012,5928,198290,10270,3672,28768,62816,2098443,21576,7800,13764,8094,7998,278080,7904,22204,48484,19513,70876,537887,28810,62186,86040,8058,9116,12900,8892,13144,20232,30312,49928,5396,370352,19522,841745,5934,4142,4560,19872,7009,5054,8360,14184,13728,406348,10191,36332,110304,221052,12087,24054,2762946,4788,13644,17174,7482,9464,10044,6968,130884,23978,29172,5805,44136,6292,3708,71592,304200,32500,187302,109415,6760,66464,7384,8041,158474,115596,9724,117360,7740,4386,86490,93931,190112,10504,9072,15998,224992,8600,47874,10868,11076,42978,1014676,20336,8136,122845,30968,146232,25848,19292,89642,31600,16016,11088,7688,20336,8428,7095,15768,6200,106255,9073,4472,9890,19393,29952,12524,22356,35308,19866,21488,738966,16802,240864,17759,13224,20708,45074,4212,9300,21096,16056,436321,9030,4472,3566850,28598,13104,37969,7600,146940,6080,81432,102672,35392,59830,49770,650547,13320,17222,6536,62252,5616,139464,23908,7564,13156,5966,4320,1039464,84940,16469,93384,18619,48960,4601,50046,21164,6194,13870,7410,74304,6820,5160,10296,12524,14260,23746,16536,337156,18506,10764,194145,7696,7956,49680,9828,104036,5719,6574,12376,17420,6656,18318,248534,5662,4028,7852,28954,11908,41236,11232,55536,9401,13825,6080,9460,16416,8626,68944,8740,361267,8856,14136,6188,26149,29016,7750,27477,6344336,8928,4464,4522,13373,27056,42104,62479,18166,5117,6966,15964,1188606,6188,10726,39246,64414,31521,6864,9052,818763,26714,20461,1618993,5289,5676,11970,19080,2358876,70704,13052,71208,77584,25542,14744,53618,11139,17160,9648,13825,28210,21251,28203,5934,85952,12338,71574,5966,9386,43632,181896,5876,12462,80580,15562,13676,4028,913951,117473,7378,7254,4644,6396,6579,27512,16536,8170,1452204,8372,10492,812520,712975,11232,19096,8432,18724,39780,9546,28656,44424,9548,187426,6321,8664,5876,9308,15405,131254,2437034,15652,6448,23112,8476,159912,120120,15028,5548,7200,166152,116762,16391374,16616,12168,5891,7848,110916,7378,363320,56628,45537,59706,141768,307942,5547,2630700,10823,54622,38916,32240,478345,15132,6882,18810,222227,5668,9620,903997,18091,82713,5928,238248,77634,12896,2306484,6240,5460,6510,4408,4104,14668,17422,34918,19912,44578,340318,10478,47400,46136,22776,25628,22360,9880,23244,34162,2303238,19656,83898,267592,190008,91846,118800,7998,56169,9717,3852,3708,460917,1268856,6660,12688,493064,20862,37584,1157587,10764,118248,13208,9006,7176,16039,62496,38829,32184,4066,13330,5772,293169,893234,5112,8772,1062234,12814,625352,919274,113088,44556,22436,12719,368037,7440,30336,10478,2106326,1039561,28196,68112,165663,57350,28519,29704,365456,130910,39658,6032,291826,16692,1204412,400214,105768,49665,19722,44763,4066,15428,185966,86268,421496,17856,103329,218808,95202,5206,7904,40166,33748,8122,25438,61017,20736,722736,9933,342409,4560,12240,124682,22256,72842,12245,130312,67464,244110,44793,32627,23932,21488,5772,10452,13832,234422,8686,7848,72360,100152,91728,20376,10750,46624,18936,17212,32798,12255,10406,34996,7130,7675506,12502,459000,48111,4294,19522,20683,7280,20952,374539,18565,9503,118512,15552,4773,21844,9030,34048,15496,69757,10922,10902,17280,1191636,4687,5160,53878,4859,49849,34684,16432,49400,11180,82646,6758,40053,13752,9620,18490,64368,9159,7410,49770,218178,10080,210485,5418,8632,14554,42294,4142,9672,79116,8996,55214,252864,11696,37446,24130,550368,10906,18876,29625],\"yaxis\":\"y\",\"type\":\"scattergl\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"price\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"estimated_sells\"},\"type\":\"log\"},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('eaac4908-9d05-49c5-9fa7-c8191c10a3c5');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si bien es cierto las ventas estimadas no tienen un comportamiento tan heterogéneo de acuerdo al precio. Sin embargo, si se puede notar para algunos precios hay una distribución distinta de ventas."
      ],
      "metadata": {
        "id": "76k4b8XZ8-Tl"
      },
      "id": "76k4b8XZ8-Tl"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predicción de críticas"
      ],
      "metadata": {
        "id": "7LiVd1qnEG-8"
      },
      "id": "7LiVd1qnEG-8"
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.histogram(df_train, x=\"rating\", color=\"required_age\", barmode=\"group\", title=\"Cantidad de ratings por cada required_age\")\n",
        "fig.show()\n",
        "fig.write_image(\"age_rating.png\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "uUHBm6mgD7Z8",
        "outputId": "e8d368c2-6ee1-4f8f-a341-ac0df0ffbdd3"
      },
      "id": "uUHBm6mgD7Z8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.16.1.min.js\"></script>                <div id=\"57246412-ad98-422d-a154-9b79056d91fd\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"57246412-ad98-422d-a154-9b79056d91fd\")) {                    Plotly.newPlot(                        \"57246412-ad98-422d-a154-9b79056d91fd\",                        [{\"alignmentgroup\":\"True\",\"bingroup\":\"x\",\"hovertemplate\":\"required_age=0<br>rating=%{x}<br>count=%{y}<extra></extra>\",\"legendgroup\":\"0\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"0\",\"offsetgroup\":\"0\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[\"Mixed\",\"Mixed\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Very Positive\",\"Negative\",\"Mixed\",\"Positive\",\"Negative\",\"Positive\",\"Mixed\",\"Positive\",\"Positive\",\"Positive\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Negative\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Negative\",\"Positive\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Mostly Positive\",\"Very Positive\",\"Mixed\",\"Very Positive\",\"Positive\",\"Very Positive\",\"Mixed\",\"Positive\",\"Negative\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Negative\",\"Mostly Positive\",\"Mixed\",\"Mixed\",\"Positive\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Very Positive\",\"Mixed\",\"Mostly Positive\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Mixed\",\"Very Positive\",\"Positive\",\"Positive\",\"Positive\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Negative\",\"Negative\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Positive\",\"Negative\",\"Mixed\",\"Very Positive\",\"Positive\",\"Positive\",\"Mixed\",\"Positive\",\"Negative\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Very Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Very Positive\",\"Positive\",\"Positive\",\"Very Positive\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Very Positive\",\"Mixed\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Positive\",\"Very Positive\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Mostly Positive\",\"Mixed\",\"Very Positive\",\"Negative\",\"Mostly Positive\",\"Very Positive\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Mixed\",\"Positive\",\"Negative\",\"Very Positive\",\"Positive\",\"Negative\",\"Positive\",\"Positive\",\"Very Positive\",\"Mixed\",\"Very Positive\",\"Very Positive\",\"Mixed\",\"Negative\",\"Very Positive\",\"Mixed\",\"Positive\",\"Very Positive\",\"Negative\",\"Mostly Positive\",\"Very Positive\",\"Very Positive\",\"Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Very Positive\",\"Positive\",\"Mixed\",\"Negative\",\"Mixed\",\"Mixed\",\"Mixed\",\"Mixed\",\"Mixed\",\"Positive\",\"Mixed\",\"Very Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Negative\",\"Mostly Positive\",\"Very Positive\",\"Mixed\",\"Mixed\",\"Positive\",\"Positive\",\"Very Positive\",\"Very Positive\",\"Very Positive\",\"Positive\",\"Mixed\",\"Very Positive\",\"Very Positive\",\"Very Positive\",\"Negative\",\"Negative\",\"Mixed\",\"Very Positive\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Positive\",\"Negative\",\"Very Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Very Positive\",\"Positive\",\"Negative\",\"Mixed\",\"Mostly Positive\",\"Very Positive\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Mostly Positive\",\"Mixed\",\"Very Positive\",\"Very Positive\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Very Positive\",\"Positive\",\"Mixed\",\"Negative\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Positive\",\"Very Positive\",\"Positive\",\"Negative\",\"Negative\",\"Positive\",\"Very Positive\",\"Mostly Positive\",\"Positive\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Positive\",\"Negative\",\"Negative\",\"Mixed\",\"Mostly Positive\",\"Very Positive\",\"Mostly Positive\",\"Very Positive\",\"Mixed\",\"Mostly Positive\",\"Mixed\",\"Very Positive\",\"Negative\",\"Very Positive\",\"Very Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Negative\",\"Positive\",\"Very Positive\",\"Positive\",\"Negative\",\"Negative\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Mixed\",\"Negative\",\"Mixed\",\"Negative\",\"Mixed\",\"Positive\",\"Positive\",\"Mixed\",\"Negative\",\"Negative\",\"Negative\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Negative\",\"Very Positive\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Very Positive\",\"Negative\",\"Negative\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Mixed\",\"Positive\",\"Positive\",\"Very Positive\",\"Mixed\",\"Negative\",\"Mostly Positive\",\"Negative\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Very Positive\",\"Mostly Positive\",\"Very Positive\",\"Mixed\",\"Mixed\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Positive\",\"Mixed\",\"Positive\",\"Mixed\",\"Mixed\",\"Very Positive\",\"Mixed\",\"Negative\",\"Positive\",\"Very Positive\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Mostly Positive\",\"Negative\",\"Negative\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Positive\",\"Mixed\",\"Very Positive\",\"Mixed\",\"Mixed\",\"Positive\",\"Negative\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Negative\",\"Very Positive\",\"Mostly Positive\",\"Very Positive\",\"Mixed\",\"Negative\",\"Very Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Mixed\",\"Very Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Very Positive\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Negative\",\"Negative\",\"Very Positive\",\"Positive\",\"Mostly Positive\",\"Negative\",\"Mixed\",\"Mostly Positive\",\"Negative\",\"Very Positive\",\"Very Positive\",\"Mixed\",\"Mostly Positive\",\"Negative\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Negative\",\"Mixed\",\"Very Positive\",\"Negative\",\"Mixed\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Negative\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Very Positive\",\"Mixed\",\"Negative\",\"Negative\",\"Positive\",\"Very Positive\",\"Positive\",\"Negative\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Mixed\",\"Negative\",\"Positive\",\"Very Positive\",\"Negative\",\"Positive\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Very Positive\",\"Mixed\",\"Very Positive\",\"Mixed\",\"Positive\",\"Positive\",\"Negative\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Mixed\",\"Positive\",\"Negative\",\"Positive\",\"Positive\",\"Very Positive\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Very Positive\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Negative\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Mostly Positive\",\"Negative\",\"Negative\",\"Positive\",\"Mixed\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Positive\",\"Negative\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Negative\",\"Positive\",\"Very Positive\",\"Mixed\",\"Very Positive\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Very Positive\",\"Negative\",\"Positive\",\"Very Positive\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Very Positive\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Mixed\",\"Mixed\",\"Very Positive\",\"Negative\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Very Positive\",\"Negative\",\"Very Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Negative\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Mixed\",\"Very Positive\",\"Mixed\",\"Mixed\",\"Negative\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Positive\",\"Mixed\",\"Very Positive\",\"Positive\",\"Mixed\",\"Mixed\",\"Negative\",\"Mixed\",\"Positive\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Mixed\",\"Mixed\",\"Positive\",\"Mixed\",\"Negative\",\"Mixed\",\"Mixed\",\"Very Positive\",\"Negative\",\"Very Positive\",\"Positive\",\"Mixed\",\"Mixed\",\"Positive\",\"Very Positive\",\"Mixed\",\"Mixed\",\"Negative\",\"Very Positive\",\"Mixed\",\"Positive\",\"Negative\",\"Very Positive\",\"Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Very Positive\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Mixed\",\"Mixed\",\"Negative\",\"Negative\",\"Mostly Positive\",\"Positive\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Mixed\",\"Positive\",\"Negative\",\"Positive\",\"Mixed\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Very Positive\",\"Positive\",\"Negative\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Positive\",\"Negative\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Mostly Positive\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mixed\",\"Very Positive\",\"Mostly Positive\",\"Negative\",\"Mixed\",\"Mixed\",\"Negative\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Positive\",\"Very Positive\",\"Negative\",\"Mostly Positive\",\"Negative\",\"Mixed\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Very Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Negative\",\"Positive\",\"Mixed\",\"Negative\",\"Mixed\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Mixed\",\"Positive\",\"Positive\",\"Positive\",\"Negative\",\"Mixed\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Negative\",\"Very Positive\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Very Positive\",\"Very Positive\",\"Positive\",\"Negative\",\"Negative\",\"Negative\",\"Mostly Positive\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Mixed\",\"Negative\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Mixed\",\"Positive\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Very Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Negative\",\"Positive\",\"Positive\",\"Negative\",\"Positive\",\"Negative\",\"Very Positive\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Very Positive\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Mixed\",\"Mixed\",\"Mixed\",\"Mixed\",\"Positive\",\"Very Positive\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Very Positive\",\"Positive\",\"Mixed\",\"Mixed\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Mixed\",\"Mixed\",\"Very Positive\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Very Positive\",\"Mixed\",\"Positive\",\"Negative\",\"Mostly Positive\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Positive\",\"Mixed\",\"Negative\",\"Mostly Positive\",\"Very Positive\",\"Negative\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Negative\",\"Mostly Positive\",\"Mixed\",\"Very Positive\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Positive\",\"Very Positive\",\"Positive\",\"Negative\",\"Mostly Positive\",\"Mostly Positive\",\"Very Positive\",\"Mostly Positive\",\"Very Positive\",\"Negative\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Negative\",\"Mostly Positive\",\"Very Positive\",\"Very Positive\",\"Positive\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Negative\",\"Positive\",\"Positive\",\"Very Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Mixed\",\"Very Positive\",\"Negative\",\"Negative\",\"Mostly Positive\",\"Negative\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Positive\",\"Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Mixed\",\"Very Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Very Positive\",\"Mixed\",\"Mixed\",\"Mixed\",\"Negative\",\"Negative\",\"Negative\",\"Very Positive\",\"Very Positive\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Mixed\",\"Very Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Negative\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Very Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Negative\",\"Very Positive\",\"Positive\",\"Mixed\",\"Very Positive\",\"Very Positive\",\"Mostly Positive\",\"Negative\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Mostly Positive\",\"Negative\",\"Mixed\",\"Very Positive\",\"Negative\",\"Mostly Positive\",\"Very Positive\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Negative\",\"Mostly Positive\",\"Mostly Positive\",\"Very Positive\",\"Mixed\",\"Positive\",\"Negative\",\"Very Positive\",\"Very Positive\",\"Negative\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Very Positive\",\"Positive\",\"Positive\",\"Negative\",\"Very Positive\",\"Positive\",\"Mixed\",\"Very Positive\",\"Mixed\",\"Negative\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Very Positive\",\"Negative\",\"Mostly Positive\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Very Positive\",\"Negative\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Very Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mixed\",\"Very Positive\",\"Positive\",\"Negative\",\"Very Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mixed\",\"Mixed\",\"Positive\",\"Positive\",\"Negative\",\"Positive\",\"Positive\",\"Positive\",\"Negative\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Positive\",\"Positive\",\"Negative\",\"Positive\",\"Positive\",\"Negative\",\"Mostly Positive\",\"Mixed\",\"Very Positive\",\"Mixed\",\"Mixed\",\"Negative\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Very Positive\",\"Very Positive\",\"Very Positive\",\"Positive\",\"Very Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Very Positive\",\"Mixed\",\"Positive\",\"Mixed\",\"Mixed\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Negative\",\"Very Positive\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Negative\",\"Positive\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Mixed\",\"Mostly Positive\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Negative\",\"Very Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mixed\",\"Mostly Positive\",\"Negative\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Very Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Mixed\",\"Mixed\",\"Mixed\",\"Positive\",\"Positive\",\"Positive\",\"Negative\",\"Very Positive\",\"Mixed\",\"Very Positive\",\"Negative\",\"Mostly Positive\",\"Very Positive\",\"Mostly Positive\",\"Negative\",\"Negative\",\"Positive\",\"Positive\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Negative\",\"Negative\",\"Mixed\",\"Positive\",\"Negative\",\"Very Positive\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Very Positive\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Negative\",\"Mixed\",\"Mixed\",\"Very Positive\",\"Positive\",\"Very Positive\",\"Very Positive\",\"Positive\",\"Very Positive\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Mixed\",\"Positive\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Very Positive\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Mixed\",\"Mixed\",\"Mixed\",\"Very Positive\",\"Mostly Positive\",\"Positive\",\"Negative\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Very Positive\",\"Mixed\",\"Very Positive\",\"Negative\",\"Positive\",\"Positive\",\"Positive\",\"Negative\",\"Mixed\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Positive\",\"Very Positive\",\"Mixed\",\"Mixed\",\"Negative\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Negative\",\"Mixed\",\"Mixed\",\"Very Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Negative\",\"Very Positive\",\"Positive\",\"Very Positive\",\"Negative\",\"Positive\",\"Positive\",\"Very Positive\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Mixed\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Very Positive\",\"Mostly Positive\",\"Mixed\",\"Very Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mixed\",\"Very Positive\",\"Mixed\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Very Positive\",\"Very Positive\",\"Positive\",\"Positive\",\"Very Positive\",\"Positive\",\"Very Positive\",\"Very Positive\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Negative\",\"Mixed\",\"Positive\",\"Very Positive\",\"Positive\",\"Very Positive\",\"Mixed\",\"Negative\",\"Mixed\",\"Mostly Positive\",\"Very Positive\",\"Negative\",\"Very Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Negative\",\"Negative\",\"Mostly Positive\",\"Positive\",\"Very Positive\",\"Very Positive\",\"Positive\",\"Negative\",\"Negative\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Negative\",\"Positive\",\"Mixed\",\"Mixed\",\"Positive\",\"Positive\",\"Positive\",\"Positive\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Mixed\",\"Mixed\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Negative\",\"Positive\",\"Positive\",\"Positive\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Very Positive\",\"Very Positive\",\"Mixed\",\"Negative\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Mixed\",\"Negative\",\"Very Positive\",\"Mostly Positive\",\"Mixed\",\"Very Positive\",\"Positive\",\"Mixed\",\"Negative\",\"Mixed\",\"Positive\",\"Positive\",\"Positive\",\"Negative\",\"Negative\",\"Very Positive\",\"Positive\",\"Negative\",\"Mostly Positive\",\"Mixed\",\"Very Positive\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Negative\",\"Negative\",\"Mixed\",\"Mixed\",\"Positive\",\"Positive\",\"Mixed\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Very Positive\",\"Negative\",\"Very Positive\",\"Very Positive\",\"Very Positive\",\"Positive\",\"Very Positive\",\"Mixed\",\"Very Positive\",\"Positive\",\"Very Positive\",\"Negative\",\"Negative\",\"Mixed\",\"Negative\",\"Mixed\",\"Negative\",\"Positive\",\"Negative\",\"Mixed\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Mixed\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Negative\",\"Negative\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Mixed\",\"Positive\",\"Very Positive\",\"Positive\",\"Positive\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Very Positive\",\"Mixed\",\"Negative\",\"Very Positive\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Positive\",\"Negative\",\"Mixed\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Negative\",\"Mixed\",\"Positive\",\"Very Positive\",\"Positive\",\"Negative\",\"Very Positive\",\"Mostly Positive\",\"Negative\",\"Mixed\",\"Very Positive\",\"Positive\",\"Negative\",\"Mixed\",\"Negative\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Negative\",\"Very Positive\",\"Positive\",\"Negative\",\"Mixed\",\"Very Positive\",\"Very Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Negative\",\"Mostly Positive\",\"Mixed\",\"Very Positive\",\"Very Positive\",\"Mixed\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Negative\",\"Positive\",\"Positive\",\"Negative\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Mixed\",\"Positive\",\"Negative\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Negative\",\"Very Positive\",\"Positive\",\"Negative\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Positive\",\"Negative\",\"Very Positive\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Negative\",\"Negative\",\"Positive\",\"Mixed\",\"Very Positive\",\"Negative\",\"Positive\",\"Very Positive\",\"Very Positive\",\"Negative\",\"Positive\",\"Positive\",\"Positive\",\"Very Positive\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Mixed\",\"Negative\",\"Negative\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Very Positive\",\"Positive\",\"Positive\",\"Very Positive\",\"Mostly Positive\",\"Negative\",\"Mixed\",\"Mixed\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Negative\",\"Positive\",\"Negative\",\"Mixed\",\"Negative\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Negative\",\"Very Positive\",\"Very Positive\",\"Positive\",\"Mixed\",\"Mixed\",\"Positive\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Mixed\",\"Positive\",\"Mixed\",\"Negative\",\"Negative\",\"Very Positive\",\"Very Positive\",\"Mixed\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Positive\",\"Mixed\",\"Mixed\",\"Mixed\",\"Negative\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Very Positive\",\"Negative\",\"Mostly Positive\",\"Negative\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Very Positive\",\"Mostly Positive\",\"Negative\",\"Very Positive\",\"Mixed\",\"Positive\",\"Mixed\",\"Positive\",\"Negative\",\"Positive\",\"Mixed\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Negative\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Mixed\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Negative\",\"Positive\",\"Positive\",\"Negative\",\"Negative\",\"Mixed\",\"Very Positive\",\"Mixed\",\"Mixed\",\"Very Positive\",\"Positive\",\"Positive\",\"Mixed\",\"Very Positive\",\"Mixed\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Negative\",\"Mixed\",\"Positive\",\"Mixed\",\"Mixed\",\"Positive\",\"Negative\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Mixed\",\"Positive\",\"Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Very Positive\",\"Positive\",\"Positive\",\"Negative\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Very Positive\",\"Negative\",\"Mostly Positive\",\"Mixed\",\"Very Positive\",\"Negative\",\"Mostly Positive\",\"Mixed\",\"Mostly Positive\",\"Mixed\",\"Mixed\",\"Positive\",\"Negative\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Negative\",\"Negative\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Negative\",\"Very Positive\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Mixed\",\"Mixed\",\"Very Positive\",\"Negative\",\"Positive\",\"Positive\",\"Positive\",\"Mixed\",\"Very Positive\",\"Positive\",\"Positive\",\"Mixed\",\"Negative\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Mixed\",\"Negative\",\"Mixed\",\"Positive\",\"Mixed\",\"Mixed\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Negative\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Mixed\",\"Very Positive\",\"Mixed\",\"Positive\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Very Positive\",\"Positive\",\"Mixed\",\"Mixed\",\"Negative\",\"Negative\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Very Positive\",\"Negative\",\"Mixed\",\"Negative\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Negative\",\"Negative\",\"Mixed\",\"Mixed\",\"Negative\",\"Negative\",\"Negative\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Positive\",\"Negative\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Negative\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Mostly Positive\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Positive\",\"Negative\",\"Mixed\",\"Negative\",\"Negative\",\"Very Positive\",\"Very Positive\",\"Positive\",\"Negative\",\"Negative\",\"Positive\",\"Negative\",\"Mixed\",\"Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Positive\",\"Mixed\",\"Very Positive\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Negative\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Positive\",\"Positive\",\"Negative\",\"Negative\",\"Very Positive\",\"Very Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Very Positive\",\"Mixed\",\"Mixed\",\"Mixed\",\"Very Positive\",\"Positive\",\"Very Positive\",\"Very Positive\",\"Negative\",\"Mixed\",\"Negative\",\"Negative\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Mixed\",\"Positive\",\"Positive\",\"Very Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Mixed\",\"Negative\",\"Very Positive\",\"Mostly Positive\",\"Mixed\",\"Mixed\",\"Positive\",\"Very Positive\",\"Mixed\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Negative\",\"Positive\",\"Very Positive\",\"Negative\",\"Very Positive\",\"Very Positive\",\"Very Positive\",\"Positive\",\"Negative\",\"Negative\",\"Positive\",\"Negative\",\"Negative\",\"Mixed\",\"Positive\",\"Negative\",\"Positive\",\"Mixed\",\"Mixed\",\"Mixed\",\"Negative\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Very Positive\",\"Very Positive\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Very Positive\",\"Very Positive\",\"Positive\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mixed\",\"Mostly Positive\",\"Negative\",\"Negative\",\"Mostly Positive\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Mixed\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Mixed\",\"Very Positive\",\"Positive\",\"Mixed\",\"Mixed\",\"Positive\",\"Positive\",\"Positive\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Positive\",\"Mixed\",\"Mixed\",\"Very Positive\",\"Very Positive\",\"Very Positive\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Negative\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Mixed\",\"Very Positive\",\"Mixed\",\"Mostly Positive\",\"Mixed\",\"Mixed\",\"Mixed\",\"Very Positive\",\"Positive\",\"Positive\",\"Very Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Mixed\",\"Mixed\",\"Negative\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Mixed\",\"Mixed\",\"Negative\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Negative\",\"Very Positive\",\"Mostly Positive\",\"Negative\",\"Negative\",\"Very Positive\",\"Negative\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Very Positive\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Negative\",\"Negative\",\"Positive\",\"Negative\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Positive\",\"Positive\",\"Mixed\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Very Positive\",\"Very Positive\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Positive\",\"Very Positive\",\"Mixed\",\"Positive\",\"Very Positive\",\"Mostly Positive\",\"Positive\",\"Negative\",\"Mostly Positive\",\"Mixed\",\"Mixed\",\"Mixed\",\"Negative\",\"Positive\",\"Positive\",\"Very Positive\",\"Very Positive\",\"Very Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Negative\",\"Very Positive\",\"Negative\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mixed\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Negative\",\"Negative\",\"Positive\",\"Very Positive\",\"Mixed\",\"Negative\",\"Mixed\",\"Positive\",\"Very Positive\",\"Mixed\",\"Very Positive\",\"Very Positive\",\"Very Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Mixed\",\"Negative\",\"Negative\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Negative\",\"Positive\",\"Negative\",\"Mostly Positive\",\"Mostly Positive\",\"Mixed\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Negative\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Very Positive\",\"Very Positive\",\"Very Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Very Positive\",\"Very Positive\",\"Very Positive\",\"Negative\",\"Very Positive\",\"Positive\",\"Negative\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Negative\",\"Mixed\",\"Negative\",\"Mixed\",\"Mixed\",\"Negative\",\"Mixed\",\"Mixed\",\"Negative\",\"Positive\",\"Negative\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Mixed\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Negative\",\"Mixed\",\"Mostly Positive\",\"Negative\",\"Negative\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Mostly Positive\",\"Mixed\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Negative\",\"Very Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Negative\",\"Positive\",\"Negative\",\"Very Positive\",\"Positive\",\"Very Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Very Positive\",\"Mostly Positive\",\"Mixed\",\"Very Positive\",\"Negative\",\"Negative\",\"Mostly Positive\",\"Negative\",\"Negative\",\"Very Positive\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Mostly Positive\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Negative\",\"Very Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Positive\",\"Negative\",\"Very Positive\",\"Mixed\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Negative\",\"Mostly Positive\",\"Positive\",\"Negative\",\"Very Positive\",\"Mostly Positive\",\"Negative\",\"Very Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Positive\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Negative\",\"Negative\",\"Mixed\",\"Negative\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Mostly Positive\",\"Negative\",\"Negative\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Mixed\",\"Negative\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Mostly Positive\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Mostly Positive\",\"Very Positive\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Mixed\",\"Positive\",\"Mixed\",\"Negative\",\"Positive\",\"Positive\",\"Negative\",\"Positive\",\"Negative\",\"Very Positive\",\"Positive\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Negative\",\"Positive\",\"Negative\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Negative\",\"Mostly Positive\",\"Positive\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Mixed\",\"Positive\",\"Very Positive\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Positive\",\"Positive\",\"Negative\",\"Very Positive\",\"Mixed\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Negative\",\"Mixed\",\"Very Positive\",\"Mixed\",\"Mostly Positive\",\"Very Positive\",\"Negative\",\"Mixed\",\"Positive\",\"Negative\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Very Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Very Positive\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Very Positive\",\"Mixed\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Negative\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Mixed\",\"Negative\",\"Negative\",\"Very Positive\",\"Mixed\",\"Mixed\",\"Very Positive\",\"Negative\",\"Mixed\",\"Mixed\",\"Very Positive\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Mixed\",\"Positive\",\"Positive\",\"Positive\",\"Very Positive\",\"Positive\",\"Very Positive\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Positive\",\"Mixed\",\"Mixed\",\"Mixed\",\"Negative\",\"Very Positive\",\"Very Positive\",\"Mixed\",\"Positive\",\"Positive\",\"Negative\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Very Positive\",\"Very Positive\",\"Mixed\",\"Mostly Positive\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Very Positive\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Mixed\",\"Mixed\",\"Positive\",\"Mixed\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Very Positive\",\"Mixed\",\"Positive\",\"Positive\",\"Mixed\",\"Negative\",\"Negative\",\"Mixed\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Negative\",\"Negative\",\"Very Positive\",\"Negative\",\"Positive\",\"Very Positive\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Mixed\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Very Positive\",\"Negative\",\"Mixed\",\"Mostly Positive\",\"Negative\",\"Mixed\",\"Mixed\",\"Negative\",\"Positive\",\"Mixed\",\"Very Positive\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Very Positive\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Positive\",\"Very Positive\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Negative\",\"Mostly Positive\",\"Negative\",\"Negative\",\"Very Positive\",\"Very Positive\",\"Mostly Positive\",\"Very Positive\",\"Very Positive\",\"Mixed\",\"Mixed\",\"Very Positive\",\"Mixed\",\"Positive\",\"Negative\",\"Mostly Positive\",\"Mixed\",\"Mixed\",\"Negative\",\"Very Positive\",\"Mixed\",\"Positive\",\"Mixed\",\"Negative\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Negative\",\"Positive\",\"Positive\",\"Very Positive\",\"Negative\",\"Positive\",\"Positive\",\"Negative\",\"Mixed\",\"Very Positive\",\"Positive\",\"Mostly Positive\",\"Negative\",\"Negative\",\"Mixed\",\"Mixed\",\"Negative\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Very Positive\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Mostly Positive\",\"Very Positive\",\"Negative\",\"Positive\",\"Positive\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Mixed\",\"Mostly Positive\",\"Very Positive\",\"Mostly Positive\",\"Positive\",\"Very Positive\",\"Negative\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Very Positive\",\"Very Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Negative\",\"Very Positive\",\"Negative\",\"Mostly Positive\",\"Positive\",\"Very Positive\",\"Mostly Positive\",\"Negative\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Negative\",\"Mixed\",\"Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Very Positive\",\"Very Positive\",\"Mostly Positive\",\"Very Positive\",\"Mixed\",\"Negative\",\"Very Positive\",\"Mixed\",\"Mostly Positive\",\"Very Positive\",\"Very Positive\",\"Mixed\",\"Mixed\",\"Negative\",\"Positive\",\"Positive\",\"Positive\",\"Positive\",\"Negative\",\"Mixed\",\"Mixed\",\"Mixed\",\"Negative\",\"Negative\",\"Positive\",\"Very Positive\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mixed\",\"Mostly Positive\",\"Mixed\",\"Very Positive\",\"Negative\",\"Very Positive\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Very Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Positive\",\"Mixed\",\"Positive\",\"Very Positive\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Very Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Positive\",\"Negative\",\"Positive\",\"Very Positive\",\"Very Positive\",\"Positive\",\"Mostly Positive\",\"Negative\",\"Very Positive\",\"Negative\",\"Very Positive\",\"Positive\",\"Mixed\",\"Positive\",\"Positive\",\"Mixed\",\"Very Positive\",\"Mostly Positive\",\"Mixed\",\"Mostly Positive\",\"Very Positive\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Very Positive\",\"Negative\",\"Positive\",\"Very Positive\",\"Mixed\",\"Positive\",\"Positive\",\"Mixed\",\"Positive\",\"Very Positive\",\"Mixed\",\"Positive\",\"Very Positive\",\"Positive\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Very Positive\",\"Mixed\",\"Mixed\",\"Very Positive\",\"Very Positive\",\"Mixed\",\"Positive\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Mostly Positive\",\"Negative\",\"Mixed\",\"Very Positive\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Very Positive\",\"Negative\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Positive\",\"Negative\",\"Mostly Positive\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Negative\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Very Positive\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Mixed\",\"Negative\",\"Very Positive\",\"Positive\",\"Very Positive\",\"Positive\",\"Mixed\",\"Positive\",\"Mixed\",\"Mixed\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Very Positive\",\"Negative\",\"Mostly Positive\",\"Very Positive\",\"Negative\",\"Positive\",\"Mixed\",\"Positive\",\"Negative\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Very Positive\",\"Mostly Positive\",\"Very Positive\",\"Very Positive\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Very Positive\",\"Mixed\",\"Very Positive\",\"Mixed\",\"Positive\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Mixed\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Very Positive\",\"Positive\",\"Very Positive\",\"Mixed\",\"Positive\",\"Negative\",\"Mixed\",\"Positive\",\"Mixed\",\"Mixed\",\"Mixed\",\"Positive\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Very Positive\",\"Mixed\",\"Very Positive\",\"Mixed\",\"Mixed\",\"Positive\",\"Negative\",\"Mixed\",\"Negative\",\"Very Positive\",\"Very Positive\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Very Positive\",\"Negative\",\"Mixed\",\"Mixed\",\"Mixed\",\"Negative\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Mixed\",\"Mixed\",\"Negative\",\"Positive\",\"Mixed\",\"Negative\",\"Mostly Positive\",\"Negative\",\"Very Positive\",\"Very Positive\",\"Very Positive\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Positive\",\"Negative\",\"Positive\",\"Mixed\",\"Positive\",\"Very Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Positive\",\"Positive\",\"Negative\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Negative\",\"Mostly Positive\",\"Mixed\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Negative\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Very Positive\",\"Positive\",\"Negative\",\"Positive\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Mixed\",\"Mixed\",\"Very Positive\",\"Mixed\",\"Negative\",\"Mostly Positive\",\"Very Positive\",\"Very Positive\",\"Positive\",\"Very Positive\",\"Negative\",\"Positive\",\"Negative\",\"Positive\",\"Positive\",\"Very Positive\",\"Mostly Positive\",\"Mixed\",\"Very Positive\",\"Negative\",\"Mostly Positive\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Positive\",\"Very Positive\",\"Mixed\",\"Negative\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Positive\",\"Very Positive\",\"Positive\",\"Positive\",\"Very Positive\",\"Negative\",\"Very Positive\",\"Negative\",\"Positive\",\"Positive\",\"Mixed\",\"Mixed\",\"Negative\",\"Mostly Positive\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Very Positive\",\"Mixed\",\"Positive\",\"Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Very Positive\",\"Negative\",\"Positive\",\"Negative\",\"Very Positive\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Negative\",\"Positive\",\"Negative\",\"Positive\",\"Mixed\",\"Very Positive\",\"Very Positive\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Mixed\",\"Mixed\",\"Mixed\",\"Mixed\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Negative\",\"Very Positive\",\"Mostly Positive\",\"Very Positive\",\"Very Positive\",\"Negative\",\"Very Positive\",\"Mixed\",\"Mixed\",\"Negative\",\"Very Positive\",\"Mixed\",\"Negative\",\"Mostly Positive\",\"Positive\",\"Negative\",\"Very Positive\",\"Negative\",\"Positive\",\"Very Positive\",\"Negative\",\"Positive\",\"Mixed\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Very Positive\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Negative\",\"Negative\",\"Positive\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Negative\",\"Mostly Positive\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Very Positive\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Very Positive\",\"Negative\",\"Very Positive\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Negative\",\"Mostly Positive\",\"Negative\",\"Negative\",\"Mixed\",\"Positive\",\"Negative\",\"Very Positive\",\"Very Positive\",\"Very Positive\",\"Mixed\",\"Very Positive\",\"Positive\",\"Mostly Positive\",\"Negative\",\"Mixed\",\"Mixed\",\"Mixed\",\"Positive\",\"Positive\",\"Negative\",\"Positive\",\"Positive\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Mixed\",\"Very Positive\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Mostly Positive\",\"Mixed\",\"Very Positive\",\"Negative\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Negative\",\"Very Positive\",\"Mixed\",\"Mixed\",\"Positive\",\"Mixed\",\"Positive\",\"Very Positive\",\"Very Positive\",\"Negative\",\"Positive\",\"Mixed\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Very Positive\",\"Negative\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mixed\",\"Very Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Positive\",\"Very Positive\",\"Mixed\",\"Negative\",\"Mostly Positive\",\"Very Positive\",\"Mixed\",\"Mixed\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Negative\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Very Positive\",\"Mixed\",\"Positive\",\"Mixed\",\"Negative\",\"Mixed\",\"Negative\",\"Mixed\",\"Positive\",\"Mixed\",\"Negative\",\"Positive\",\"Very Positive\",\"Positive\",\"Mixed\",\"Positive\",\"Very Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Very Positive\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Mixed\",\"Mostly Positive\",\"Mixed\",\"Mixed\",\"Mixed\",\"Very Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Very Positive\",\"Negative\",\"Positive\",\"Mixed\",\"Mixed\",\"Very Positive\",\"Very Positive\",\"Negative\",\"Very Positive\",\"Mixed\",\"Very Positive\",\"Mixed\",\"Very Positive\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Very Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Negative\",\"Mixed\",\"Positive\",\"Negative\",\"Positive\",\"Very Positive\",\"Positive\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Very Positive\",\"Negative\",\"Negative\",\"Mostly Positive\",\"Positive\",\"Negative\",\"Very Positive\",\"Mostly Positive\",\"Positive\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Negative\",\"Negative\",\"Very Positive\",\"Mixed\",\"Positive\",\"Very Positive\",\"Mixed\",\"Negative\",\"Negative\",\"Very Positive\",\"Very Positive\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Negative\",\"Mixed\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Very Positive\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Very Positive\",\"Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Mixed\",\"Mixed\",\"Negative\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Mostly Positive\",\"Mixed\",\"Mixed\",\"Very Positive\",\"Very Positive\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Very Positive\",\"Negative\",\"Negative\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Positive\",\"Negative\",\"Mixed\",\"Negative\",\"Very Positive\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Negative\",\"Mostly Positive\",\"Mixed\",\"Mostly Positive\",\"Negative\",\"Negative\",\"Negative\",\"Mixed\",\"Positive\",\"Mixed\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Very Positive\",\"Mostly Positive\",\"Mixed\",\"Mixed\",\"Negative\",\"Very Positive\",\"Mostly Positive\",\"Mixed\",\"Very Positive\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Mixed\",\"Very Positive\",\"Mostly Positive\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Very Positive\",\"Mixed\",\"Positive\",\"Negative\",\"Negative\",\"Mostly Positive\",\"Negative\",\"Mostly Positive\",\"Positive\",\"Very Positive\",\"Positive\",\"Mixed\",\"Very Positive\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Very Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Negative\",\"Very Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Mixed\",\"Mixed\",\"Positive\",\"Very Positive\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Very Positive\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Negative\",\"Very Positive\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Mixed\",\"Positive\",\"Negative\",\"Mostly Positive\",\"Very Positive\",\"Mixed\",\"Very Positive\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Very Positive\",\"Mostly Positive\",\"Very Positive\",\"Negative\",\"Mixed\",\"Very Positive\",\"Positive\",\"Positive\",\"Negative\",\"Mostly Positive\",\"Positive\",\"Negative\",\"Mixed\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Positive\",\"Mixed\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Very Positive\",\"Mixed\",\"Mixed\",\"Mixed\",\"Negative\",\"Very Positive\",\"Mixed\",\"Mixed\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Negative\",\"Negative\",\"Positive\",\"Negative\",\"Very Positive\",\"Mixed\",\"Very Positive\",\"Negative\",\"Positive\",\"Mixed\",\"Very Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Mixed\",\"Very Positive\",\"Mostly Positive\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Mixed\",\"Negative\",\"Mixed\",\"Negative\",\"Mostly Positive\",\"Mostly Positive\",\"Mixed\",\"Mixed\",\"Negative\",\"Mostly Positive\",\"Negative\",\"Mostly Positive\",\"Negative\",\"Very Positive\",\"Mixed\",\"Very Positive\",\"Positive\",\"Mixed\",\"Negative\",\"Positive\",\"Mixed\",\"Positive\",\"Positive\",\"Very Positive\",\"Mixed\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Mixed\",\"Mixed\",\"Very Positive\",\"Mixed\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Mixed\",\"Mixed\",\"Mixed\",\"Positive\",\"Negative\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Mixed\",\"Very Positive\",\"Positive\",\"Mixed\",\"Positive\",\"Very Positive\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Mixed\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Positive\",\"Positive\",\"Very Positive\",\"Mixed\",\"Mixed\",\"Negative\",\"Positive\",\"Positive\",\"Very Positive\",\"Positive\",\"Mixed\",\"Negative\",\"Mostly Positive\",\"Mixed\",\"Mostly Positive\",\"Negative\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Negative\",\"Very Positive\",\"Negative\",\"Negative\",\"Positive\",\"Very Positive\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Very Positive\",\"Negative\",\"Negative\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Mostly Positive\",\"Negative\",\"Mixed\",\"Very Positive\",\"Negative\",\"Very Positive\",\"Very Positive\",\"Mixed\",\"Very Positive\",\"Mostly Positive\",\"Mixed\",\"Mixed\",\"Negative\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Very Positive\",\"Mostly Positive\",\"Negative\",\"Mixed\",\"Positive\",\"Positive\",\"Negative\",\"Very Positive\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Negative\",\"Very Positive\",\"Negative\",\"Positive\",\"Positive\",\"Positive\",\"Negative\",\"Mixed\",\"Negative\",\"Very Positive\",\"Mixed\",\"Very Positive\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Negative\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Positive\",\"Negative\",\"Very Positive\",\"Negative\",\"Very Positive\",\"Very Positive\",\"Mixed\",\"Positive\",\"Positive\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Very Positive\",\"Negative\",\"Mixed\",\"Mixed\",\"Positive\",\"Very Positive\",\"Negative\",\"Very Positive\",\"Negative\",\"Negative\",\"Mostly Positive\",\"Very Positive\",\"Very Positive\",\"Negative\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Mixed\",\"Positive\",\"Positive\",\"Negative\",\"Mixed\",\"Very Positive\",\"Negative\",\"Very Positive\",\"Very Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Negative\",\"Mixed\",\"Positive\",\"Negative\",\"Positive\",\"Positive\",\"Negative\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Mixed\",\"Mixed\",\"Negative\",\"Very Positive\",\"Positive\",\"Mixed\",\"Negative\",\"Very Positive\",\"Very Positive\",\"Negative\",\"Very Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mixed\",\"Very Positive\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Negative\",\"Mostly Positive\",\"Very Positive\",\"Mixed\",\"Very Positive\",\"Mixed\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Negative\",\"Very Positive\",\"Very Positive\",\"Mixed\",\"Positive\",\"Mixed\",\"Negative\",\"Very Positive\",\"Positive\",\"Positive\",\"Positive\",\"Mixed\",\"Negative\",\"Positive\",\"Very Positive\",\"Negative\",\"Mixed\",\"Very Positive\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Very Positive\",\"Negative\",\"Mixed\",\"Negative\",\"Positive\",\"Negative\",\"Positive\",\"Negative\",\"Negative\",\"Mixed\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Mostly Positive\",\"Negative\",\"Mixed\",\"Very Positive\",\"Negative\",\"Negative\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Very Positive\",\"Mixed\",\"Very Positive\",\"Negative\",\"Positive\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Negative\",\"Mostly Positive\",\"Mixed\",\"Mixed\",\"Mixed\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Negative\",\"Very Positive\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Mostly Positive\",\"Negative\",\"Negative\",\"Mostly Positive\",\"Mixed\",\"Mixed\",\"Positive\",\"Negative\",\"Positive\",\"Very Positive\",\"Very Positive\",\"Mixed\",\"Very Positive\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Very Positive\",\"Negative\",\"Mixed\",\"Very Positive\",\"Mixed\",\"Positive\",\"Negative\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Mixed\",\"Mixed\",\"Positive\",\"Mixed\",\"Mixed\",\"Negative\",\"Positive\",\"Positive\",\"Positive\",\"Positive\",\"Positive\",\"Mixed\",\"Very Positive\",\"Mostly Positive\",\"Very Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Mostly Positive\",\"Very Positive\",\"Very Positive\",\"Negative\",\"Mixed\",\"Positive\",\"Mixed\",\"Positive\",\"Mixed\",\"Very Positive\",\"Mixed\",\"Very Positive\",\"Negative\",\"Negative\",\"Very Positive\",\"Very Positive\",\"Mixed\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Mostly Positive\",\"Mostly Positive\",\"Mixed\",\"Mixed\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Very Positive\",\"Very Positive\",\"Positive\",\"Very Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Mixed\",\"Positive\",\"Very Positive\",\"Positive\",\"Positive\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Mixed\",\"Positive\",\"Very Positive\",\"Very Positive\",\"Positive\",\"Positive\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Positive\",\"Very Positive\",\"Very Positive\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Mostly Positive\",\"Negative\",\"Negative\",\"Mixed\",\"Negative\",\"Very Positive\",\"Mostly Positive\",\"Mixed\",\"Mixed\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Negative\",\"Mostly Positive\",\"Mixed\",\"Very Positive\",\"Mixed\",\"Mixed\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Negative\",\"Mixed\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Positive\",\"Positive\",\"Mixed\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Negative\",\"Mostly Positive\",\"Very Positive\",\"Mostly Positive\",\"Negative\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Very Positive\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Negative\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Negative\",\"Mixed\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Very Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Mixed\",\"Positive\",\"Positive\",\"Mixed\",\"Positive\",\"Mixed\",\"Positive\",\"Very Positive\",\"Positive\",\"Positive\",\"Mixed\",\"Mixed\",\"Very Positive\",\"Positive\",\"Very Positive\",\"Mixed\",\"Mixed\",\"Negative\",\"Very Positive\",\"Very Positive\",\"Negative\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Negative\",\"Mostly Positive\",\"Mixed\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Very Positive\",\"Very Positive\",\"Very Positive\",\"Mixed\",\"Mixed\",\"Mixed\",\"Positive\",\"Mixed\",\"Very Positive\",\"Mostly Positive\",\"Positive\",\"Negative\",\"Positive\",\"Mixed\",\"Negative\",\"Very Positive\",\"Negative\",\"Mixed\",\"Very Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Very Positive\",\"Negative\",\"Positive\",\"Very Positive\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Positive\",\"Very Positive\",\"Negative\",\"Mostly Positive\",\"Very Positive\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Very Positive\",\"Mixed\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Negative\",\"Mostly Positive\",\"Very Positive\",\"Negative\",\"Very Positive\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Positive\",\"Positive\",\"Positive\",\"Mixed\",\"Positive\",\"Negative\",\"Positive\",\"Negative\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Mixed\",\"Mostly Positive\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Mixed\",\"Mixed\",\"Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Very Positive\",\"Very Positive\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Very Positive\",\"Mostly Positive\",\"Negative\",\"Very Positive\",\"Mostly Positive\",\"Negative\",\"Very Positive\",\"Positive\",\"Positive\",\"Positive\",\"Very Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Very Positive\",\"Mixed\",\"Mostly Positive\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Negative\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Very Positive\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Very Positive\",\"Negative\",\"Mixed\",\"Negative\",\"Mostly Positive\",\"Positive\",\"Very Positive\",\"Very Positive\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Mixed\",\"Positive\",\"Positive\",\"Negative\",\"Mostly Positive\",\"Very Positive\",\"Negative\",\"Mostly Positive\",\"Mixed\",\"Very Positive\",\"Very Positive\",\"Mixed\",\"Mostly Positive\",\"Very Positive\",\"Mostly Positive\",\"Mixed\",\"Very Positive\",\"Negative\",\"Positive\",\"Positive\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Very Positive\",\"Very Positive\",\"Positive\",\"Very Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Negative\",\"Mostly Positive\",\"Negative\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Very Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Very Positive\",\"Positive\",\"Mixed\",\"Positive\",\"Positive\",\"Very Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Mostly Positive\",\"Mixed\",\"Very Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Mixed\",\"Positive\",\"Positive\",\"Positive\",\"Mixed\",\"Positive\",\"Negative\",\"Mixed\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Negative\",\"Mostly Positive\",\"Negative\",\"Negative\",\"Negative\",\"Positive\",\"Mixed\",\"Positive\",\"Positive\",\"Positive\",\"Mixed\",\"Very Positive\",\"Negative\",\"Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Negative\",\"Negative\",\"Mixed\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Positive\",\"Positive\",\"Very Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Negative\",\"Mixed\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mixed\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Positive\",\"Mixed\",\"Mixed\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Very Positive\",\"Mixed\",\"Negative\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Negative\",\"Very Positive\",\"Positive\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Very Positive\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Negative\",\"Positive\",\"Mixed\",\"Negative\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Negative\",\"Mostly Positive\",\"Negative\",\"Mixed\",\"Mixed\",\"Very Positive\",\"Very Positive\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Mixed\",\"Negative\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Positive\",\"Positive\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Negative\",\"Mixed\",\"Positive\",\"Positive\",\"Very Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Very Positive\",\"Mostly Positive\",\"Very Positive\",\"Mixed\",\"Very Positive\",\"Positive\",\"Positive\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Negative\",\"Very Positive\",\"Positive\",\"Positive\",\"Very Positive\",\"Mostly Positive\",\"Negative\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Very Positive\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Mostly Positive\",\"Mixed\",\"Very Positive\",\"Very Positive\",\"Very Positive\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Very Positive\",\"Negative\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Mixed\",\"Negative\",\"Mixed\",\"Negative\",\"Mixed\",\"Very Positive\",\"Negative\",\"Positive\",\"Negative\",\"Very Positive\",\"Very Positive\",\"Mostly Positive\",\"Positive\",\"Negative\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Mixed\",\"Very Positive\",\"Positive\",\"Mixed\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Mixed\",\"Negative\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Very Positive\",\"Mostly Positive\",\"Mixed\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Mixed\",\"Positive\",\"Negative\",\"Mixed\",\"Very Positive\",\"Positive\",\"Mixed\",\"Positive\",\"Mixed\",\"Positive\",\"Positive\",\"Positive\",\"Positive\",\"Mixed\",\"Very Positive\",\"Very Positive\",\"Mixed\",\"Positive\",\"Very Positive\",\"Mostly Positive\",\"Mixed\",\"Mostly Positive\",\"Mixed\",\"Very Positive\",\"Positive\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Very Positive\",\"Mostly Positive\",\"Mixed\",\"Mixed\",\"Positive\",\"Positive\",\"Mixed\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Negative\",\"Negative\",\"Positive\",\"Very Positive\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Very Positive\",\"Very Positive\",\"Negative\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Very Positive\",\"Positive\",\"Negative\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Negative\",\"Mixed\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Negative\",\"Positive\",\"Very Positive\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Mixed\",\"Positive\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Positive\",\"Negative\",\"Mixed\",\"Positive\",\"Positive\",\"Positive\",\"Negative\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Negative\",\"Mixed\",\"Very Positive\",\"Mixed\",\"Very Positive\",\"Mixed\",\"Negative\",\"Mostly Positive\",\"Very Positive\",\"Mixed\",\"Very Positive\",\"Mostly Positive\",\"Negative\",\"Very Positive\",\"Negative\",\"Negative\",\"Negative\",\"Positive\",\"Mixed\",\"Positive\",\"Mixed\",\"Positive\",\"Positive\",\"Mixed\",\"Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Positive\",\"Negative\",\"Negative\",\"Mostly Positive\",\"Positive\",\"Negative\",\"Mixed\",\"Mixed\",\"Positive\",\"Negative\",\"Mixed\",\"Negative\",\"Very Positive\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Positive\",\"Mixed\",\"Positive\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Positive\",\"Mixed\",\"Negative\",\"Positive\",\"Negative\",\"Negative\",\"Negative\",\"Mixed\",\"Negative\",\"Positive\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Very Positive\",\"Positive\",\"Positive\",\"Positive\",\"Mixed\",\"Negative\",\"Mixed\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Very Positive\",\"Negative\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Positive\",\"Positive\",\"Positive\",\"Negative\",\"Mixed\",\"Negative\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Positive\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Mixed\",\"Positive\",\"Mixed\",\"Positive\",\"Positive\",\"Positive\",\"Very Positive\",\"Very Positive\",\"Mixed\",\"Very Positive\",\"Positive\",\"Negative\",\"Mixed\",\"Positive\",\"Positive\",\"Positive\",\"Mixed\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Negative\",\"Very Positive\",\"Mostly Positive\",\"Negative\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Very Positive\",\"Very Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Negative\",\"Mixed\",\"Positive\",\"Negative\",\"Positive\",\"Mixed\",\"Positive\",\"Negative\",\"Very Positive\",\"Positive\",\"Negative\",\"Mixed\",\"Negative\",\"Mixed\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Negative\",\"Very Positive\",\"Negative\",\"Negative\",\"Mixed\",\"Mixed\",\"Mixed\",\"Positive\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Very Positive\",\"Very Positive\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Mixed\",\"Positive\",\"Negative\",\"Mostly Positive\",\"Positive\",\"Very Positive\",\"Negative\",\"Positive\",\"Negative\",\"Positive\",\"Very Positive\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Very Positive\",\"Mixed\",\"Mixed\",\"Positive\",\"Mixed\",\"Very Positive\",\"Positive\",\"Negative\",\"Positive\",\"Very Positive\",\"Negative\",\"Mixed\",\"Very Positive\",\"Negative\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Mixed\",\"Negative\",\"Very Positive\",\"Mixed\",\"Very Positive\",\"Mixed\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Negative\",\"Mixed\",\"Positive\",\"Mixed\",\"Positive\",\"Positive\",\"Positive\",\"Negative\",\"Negative\",\"Positive\",\"Mixed\",\"Very Positive\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Negative\",\"Mixed\",\"Very Positive\",\"Negative\",\"Mixed\",\"Mixed\",\"Very Positive\",\"Mixed\",\"Very Positive\",\"Positive\",\"Positive\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Negative\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Very Positive\",\"Mostly Positive\",\"Mixed\",\"Mostly Positive\",\"Mixed\",\"Very Positive\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Negative\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Negative\",\"Positive\",\"Positive\",\"Positive\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Mixed\",\"Positive\",\"Positive\",\"Negative\",\"Positive\",\"Very Positive\",\"Mostly Positive\",\"Negative\",\"Mostly Positive\",\"Positive\",\"Very Positive\",\"Very Positive\",\"Mixed\",\"Very Positive\",\"Positive\",\"Positive\",\"Mixed\",\"Mixed\",\"Very Positive\",\"Mixed\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Very Positive\",\"Very Positive\",\"Very Positive\",\"Negative\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Mixed\",\"Very Positive\",\"Very Positive\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mixed\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Very Positive\",\"Very Positive\",\"Positive\",\"Negative\",\"Positive\",\"Positive\",\"Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Negative\",\"Very Positive\",\"Positive\",\"Positive\",\"Mixed\",\"Negative\",\"Negative\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Very Positive\",\"Mostly Positive\",\"Negative\",\"Mostly Positive\",\"Very Positive\",\"Mostly Positive\",\"Positive\",\"Very Positive\",\"Very Positive\",\"Positive\",\"Positive\",\"Positive\",\"Positive\",\"Mixed\",\"Negative\",\"Very Positive\",\"Positive\",\"Positive\",\"Positive\",\"Negative\",\"Negative\",\"Negative\",\"Very Positive\",\"Very Positive\",\"Negative\",\"Positive\",\"Positive\",\"Mixed\",\"Mixed\",\"Mixed\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mixed\",\"Very Positive\",\"Mostly Positive\",\"Positive\",\"Negative\",\"Very Positive\",\"Very Positive\",\"Negative\",\"Mixed\",\"Mixed\",\"Negative\",\"Mixed\",\"Mostly Positive\",\"Negative\",\"Mostly Positive\",\"Mixed\",\"Mixed\",\"Very Positive\",\"Negative\",\"Positive\",\"Very Positive\",\"Mixed\",\"Mostly Positive\",\"Mixed\",\"Mixed\",\"Mixed\",\"Very Positive\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Mixed\",\"Negative\",\"Very Positive\",\"Mixed\",\"Positive\",\"Very Positive\",\"Negative\",\"Positive\",\"Mixed\",\"Negative\",\"Positive\",\"Mixed\",\"Very Positive\",\"Positive\",\"Positive\",\"Mixed\",\"Negative\",\"Mixed\",\"Mostly Positive\",\"Negative\",\"Very Positive\",\"Mixed\",\"Mostly Positive\",\"Mixed\",\"Very Positive\",\"Mixed\",\"Mixed\",\"Positive\",\"Mixed\",\"Mixed\",\"Very Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mixed\",\"Very Positive\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Positive\",\"Negative\",\"Mixed\",\"Positive\",\"Positive\",\"Positive\",\"Positive\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Very Positive\",\"Mixed\",\"Positive\",\"Positive\",\"Very Positive\",\"Negative\",\"Very Positive\",\"Very Positive\",\"Positive\",\"Negative\",\"Positive\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Mixed\",\"Mixed\",\"Positive\",\"Very Positive\",\"Very Positive\",\"Mostly Positive\",\"Positive\",\"Very Positive\",\"Mostly Positive\",\"Positive\",\"Very Positive\",\"Very Positive\",\"Negative\",\"Positive\",\"Negative\",\"Positive\",\"Mixed\",\"Positive\",\"Very Positive\",\"Negative\",\"Positive\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Mixed\",\"Mixed\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Negative\",\"Negative\",\"Mixed\",\"Positive\",\"Positive\",\"Positive\",\"Negative\",\"Mixed\",\"Negative\",\"Mostly Positive\",\"Mixed\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Negative\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Positive\",\"Very Positive\",\"Negative\",\"Negative\",\"Negative\",\"Positive\",\"Very Positive\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Negative\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Very Positive\",\"Mixed\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Mixed\",\"Positive\",\"Positive\",\"Positive\",\"Negative\",\"Mixed\",\"Negative\",\"Mixed\",\"Mixed\",\"Very Positive\",\"Negative\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Very Positive\",\"Positive\",\"Mostly Positive\",\"Negative\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Very Positive\",\"Mixed\",\"Mostly Positive\",\"Negative\",\"Very Positive\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Negative\",\"Positive\",\"Positive\",\"Mixed\",\"Negative\",\"Negative\",\"Mostly Positive\",\"Very Positive\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Positive\",\"Very Positive\",\"Very Positive\",\"Negative\",\"Positive\",\"Very Positive\",\"Mostly Positive\",\"Very Positive\",\"Mostly Positive\",\"Negative\",\"Mostly Positive\",\"Negative\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Negative\",\"Very Positive\",\"Mostly Positive\",\"Negative\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Negative\",\"Very Positive\",\"Negative\",\"Very Positive\",\"Positive\",\"Mixed\",\"Positive\",\"Mixed\",\"Positive\",\"Mixed\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Very Positive\",\"Negative\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Very Positive\",\"Positive\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Mixed\",\"Negative\",\"Very Positive\",\"Very Positive\",\"Negative\",\"Very Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Mixed\",\"Negative\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Mostly Positive\",\"Negative\",\"Very Positive\",\"Mostly Positive\",\"Positive\",\"Very Positive\",\"Very Positive\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Negative\",\"Mostly Positive\",\"Very Positive\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Very Positive\",\"Very Positive\",\"Very Positive\",\"Positive\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Very Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Negative\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Negative\",\"Very Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Very Positive\",\"Mixed\",\"Negative\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Negative\",\"Very Positive\",\"Negative\",\"Mixed\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Negative\",\"Negative\",\"Positive\",\"Mixed\",\"Mixed\",\"Positive\",\"Positive\",\"Positive\",\"Very Positive\",\"Negative\",\"Mixed\",\"Mixed\",\"Positive\",\"Negative\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Very Positive\",\"Mostly Positive\",\"Negative\",\"Mixed\",\"Positive\",\"Mixed\",\"Very Positive\",\"Positive\",\"Negative\",\"Mostly Positive\",\"Positive\",\"Negative\",\"Mixed\",\"Very Positive\",\"Very Positive\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Positive\",\"Positive\",\"Mixed\",\"Negative\",\"Positive\",\"Mixed\",\"Very Positive\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Mixed\",\"Very Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Very Positive\",\"Mixed\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Positive\",\"Mixed\",\"Positive\",\"Mixed\",\"Positive\",\"Very Positive\",\"Positive\",\"Negative\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Very Positive\",\"Very Positive\",\"Very Positive\",\"Negative\",\"Very Positive\",\"Positive\",\"Very Positive\",\"Negative\",\"Negative\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Negative\",\"Mostly Positive\",\"Negative\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Very Positive\",\"Mostly Positive\",\"Negative\",\"Mostly Positive\",\"Mostly Positive\",\"Mixed\",\"Mixed\",\"Mixed\",\"Negative\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Negative\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Positive\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Very Positive\",\"Negative\",\"Mostly Positive\",\"Positive\",\"Negative\",\"Mostly Positive\",\"Mixed\",\"Mostly Positive\",\"Very Positive\",\"Mostly Positive\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Very Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Mixed\",\"Positive\",\"Positive\",\"Negative\",\"Mixed\",\"Mixed\",\"Mixed\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Very Positive\",\"Very Positive\",\"Mixed\",\"Mostly Positive\",\"Mixed\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Mixed\",\"Mixed\",\"Mixed\",\"Positive\",\"Mixed\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Negative\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Negative\",\"Mixed\",\"Positive\",\"Negative\",\"Mostly Positive\",\"Negative\",\"Mixed\",\"Very Positive\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Positive\",\"Very Positive\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Negative\",\"Mixed\",\"Positive\",\"Positive\",\"Negative\",\"Mostly Positive\",\"Very Positive\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Mixed\",\"Mixed\",\"Positive\",\"Positive\",\"Positive\",\"Mixed\",\"Mixed\",\"Very Positive\",\"Negative\",\"Mostly Positive\",\"Very Positive\",\"Negative\",\"Very Positive\",\"Very Positive\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Negative\",\"Negative\",\"Very Positive\",\"Very Positive\",\"Negative\",\"Mixed\",\"Positive\",\"Very Positive\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Mixed\",\"Negative\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Negative\",\"Negative\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Negative\",\"Negative\",\"Negative\",\"Very Positive\",\"Positive\",\"Very Positive\",\"Positive\",\"Very Positive\",\"Negative\",\"Positive\",\"Negative\",\"Negative\",\"Positive\",\"Positive\",\"Positive\",\"Negative\",\"Very Positive\",\"Mixed\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Negative\",\"Negative\",\"Positive\",\"Positive\",\"Very Positive\",\"Positive\",\"Positive\",\"Positive\",\"Very Positive\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Very Positive\",\"Mostly Positive\",\"Negative\",\"Mixed\",\"Mixed\",\"Negative\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Mixed\",\"Very Positive\",\"Mixed\",\"Positive\",\"Very Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Mixed\",\"Very Positive\",\"Very Positive\",\"Negative\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Negative\",\"Mostly Positive\",\"Negative\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Mixed\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Very Positive\",\"Mostly Positive\",\"Positive\",\"Negative\",\"Mixed\",\"Positive\",\"Positive\",\"Negative\",\"Mixed\",\"Mixed\",\"Negative\",\"Mostly Positive\",\"Mixed\",\"Mixed\",\"Very Positive\",\"Positive\",\"Negative\",\"Negative\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Negative\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Negative\",\"Negative\",\"Positive\",\"Mixed\",\"Positive\",\"Mixed\",\"Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Mostly Positive\",\"Positive\",\"Very Positive\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Mostly Positive\",\"Mixed\",\"Very Positive\",\"Mostly Positive\",\"Positive\",\"Very Positive\",\"Negative\",\"Mixed\",\"Mixed\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Negative\",\"Positive\",\"Very Positive\",\"Negative\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Very Positive\",\"Positive\",\"Very Positive\",\"Mixed\",\"Positive\",\"Very Positive\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Very Positive\",\"Positive\",\"Mostly Positive\",\"Negative\",\"Negative\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Negative\",\"Very Positive\",\"Positive\",\"Positive\",\"Negative\",\"Positive\",\"Positive\",\"Mixed\",\"Negative\",\"Mixed\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Mostly Positive\",\"Mixed\",\"Very Positive\",\"Very Positive\",\"Positive\",\"Very Positive\",\"Mostly Positive\",\"Mixed\",\"Very Positive\",\"Positive\",\"Positive\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Negative\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Mixed\",\"Mixed\",\"Very Positive\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Negative\",\"Negative\",\"Very Positive\",\"Mixed\",\"Very Positive\",\"Very Positive\",\"Positive\",\"Very Positive\",\"Negative\",\"Mixed\",\"Positive\",\"Negative\",\"Mostly Positive\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Mostly Positive\",\"Very Positive\",\"Negative\",\"Positive\",\"Mixed\",\"Positive\",\"Mixed\",\"Very Positive\",\"Negative\",\"Negative\",\"Very Positive\",\"Very Positive\",\"Mixed\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Very Positive\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Positive\",\"Very Positive\",\"Negative\",\"Negative\",\"Very Positive\",\"Mostly Positive\",\"Positive\",\"Negative\",\"Mostly Positive\",\"Positive\",\"Very Positive\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Very Positive\",\"Mixed\",\"Mostly Positive\",\"Very Positive\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Negative\",\"Positive\",\"Positive\",\"Mixed\",\"Negative\",\"Mixed\",\"Negative\",\"Very Positive\",\"Very Positive\",\"Negative\",\"Very Positive\",\"Negative\",\"Mixed\",\"Negative\",\"Positive\",\"Very Positive\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Mixed\",\"Positive\",\"Positive\",\"Mixed\",\"Positive\",\"Mixed\",\"Very Positive\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Negative\",\"Positive\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Negative\",\"Mixed\",\"Mixed\",\"Very Positive\",\"Positive\",\"Negative\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Negative\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Very Positive\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Negative\",\"Very Positive\",\"Very Positive\",\"Mostly Positive\",\"Very Positive\",\"Mixed\",\"Very Positive\",\"Negative\",\"Very Positive\",\"Negative\",\"Very Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Very Positive\",\"Very Positive\",\"Very Positive\",\"Mixed\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Mixed\",\"Positive\",\"Negative\",\"Mixed\",\"Mixed\",\"Negative\",\"Positive\",\"Negative\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mixed\",\"Very Positive\",\"Negative\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Negative\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Mixed\",\"Very Positive\",\"Mixed\",\"Mixed\",\"Mixed\",\"Mixed\",\"Positive\",\"Positive\",\"Negative\",\"Positive\",\"Negative\",\"Mixed\",\"Mixed\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Negative\",\"Mixed\",\"Very Positive\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Negative\",\"Positive\",\"Positive\",\"Positive\",\"Mixed\",\"Negative\",\"Positive\",\"Negative\",\"Positive\",\"Very Positive\",\"Very Positive\",\"Positive\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Mixed\",\"Very Positive\",\"Negative\",\"Positive\",\"Negative\",\"Positive\",\"Negative\",\"Very Positive\",\"Mixed\",\"Positive\",\"Negative\",\"Mixed\",\"Positive\",\"Mixed\",\"Very Positive\",\"Mostly Positive\",\"Positive\",\"Negative\",\"Negative\",\"Very Positive\",\"Very Positive\",\"Very Positive\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Positive\",\"Negative\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Negative\",\"Positive\",\"Negative\",\"Very Positive\",\"Positive\",\"Negative\",\"Negative\",\"Very Positive\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Mostly Positive\",\"Negative\",\"Negative\",\"Mixed\",\"Positive\",\"Mixed\",\"Positive\",\"Positive\",\"Very Positive\",\"Mixed\",\"Mixed\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Negative\",\"Negative\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Negative\",\"Positive\",\"Positive\",\"Very Positive\",\"Very Positive\",\"Mixed\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Positive\",\"Positive\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Negative\",\"Very Positive\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Positive\",\"Very Positive\",\"Negative\",\"Mixed\",\"Very Positive\",\"Positive\",\"Mixed\",\"Mixed\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Very Positive\",\"Positive\",\"Very Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mixed\",\"Mixed\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Positive\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Mixed\",\"Very Positive\",\"Very Positive\",\"Very Positive\",\"Mixed\",\"Very Positive\",\"Mostly Positive\",\"Mixed\",\"Very Positive\",\"Very Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Very Positive\",\"Negative\",\"Very Positive\",\"Very Positive\",\"Positive\",\"Mixed\",\"Mixed\",\"Mixed\",\"Positive\",\"Negative\",\"Mostly Positive\",\"Positive\",\"Very Positive\",\"Positive\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Very Positive\",\"Very Positive\",\"Mixed\",\"Very Positive\",\"Mixed\",\"Negative\",\"Very Positive\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Negative\",\"Mixed\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Negative\",\"Positive\",\"Positive\",\"Mixed\",\"Mixed\",\"Very Positive\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Very Positive\",\"Negative\",\"Mostly Positive\",\"Mixed\",\"Mixed\",\"Negative\",\"Very Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mixed\",\"Very Positive\",\"Very Positive\",\"Positive\",\"Positive\",\"Positive\",\"Mixed\",\"Mixed\",\"Very Positive\",\"Very Positive\",\"Negative\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Negative\",\"Mostly Positive\",\"Mixed\",\"Mostly Positive\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Negative\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Very Positive\",\"Mostly Positive\",\"Very Positive\",\"Mostly Positive\",\"Mixed\",\"Very Positive\",\"Mixed\",\"Very Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Mixed\",\"Positive\",\"Negative\",\"Negative\",\"Positive\",\"Very Positive\",\"Very Positive\",\"Mostly Positive\",\"Very Positive\",\"Mixed\",\"Mostly Positive\",\"Negative\",\"Very Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Negative\",\"Very Positive\",\"Mostly Positive\",\"Positive\",\"Very Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Very Positive\",\"Mixed\",\"Very Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Very Positive\",\"Mixed\",\"Very Positive\",\"Very Positive\",\"Very Positive\",\"Very Positive\",\"Mixed\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Negative\",\"Very Positive\",\"Positive\",\"Negative\",\"Negative\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Negative\",\"Mostly Positive\",\"Very Positive\",\"Mixed\",\"Mixed\",\"Very Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Mixed\",\"Negative\",\"Negative\",\"Mixed\",\"Positive\",\"Negative\",\"Mixed\",\"Very Positive\",\"Positive\",\"Very Positive\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Negative\",\"Mostly Positive\",\"Very Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Mixed\",\"Positive\",\"Negative\",\"Positive\",\"Positive\",\"Mixed\",\"Very Positive\",\"Very Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Negative\",\"Negative\",\"Very Positive\",\"Negative\",\"Positive\",\"Very Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Mixed\",\"Positive\",\"Positive\",\"Positive\",\"Negative\",\"Positive\",\"Very Positive\",\"Negative\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Positive\",\"Negative\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Negative\",\"Very Positive\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Positive\",\"Positive\",\"Mixed\",\"Very Positive\",\"Very Positive\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Negative\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Negative\",\"Mixed\",\"Negative\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Negative\",\"Mostly Positive\",\"Very Positive\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Negative\",\"Very Positive\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Very Positive\",\"Positive\",\"Positive\",\"Very Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Positive\",\"Mixed\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Very Positive\",\"Mostly Positive\",\"Mixed\",\"Mostly Positive\",\"Negative\",\"Mostly Positive\",\"Negative\",\"Mostly Positive\",\"Mixed\",\"Very Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mixed\",\"Mixed\",\"Very Positive\",\"Mixed\",\"Positive\",\"Negative\",\"Very Positive\",\"Mixed\",\"Mixed\",\"Very Positive\",\"Mostly Positive\",\"Very Positive\",\"Negative\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Mixed\",\"Positive\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Very Positive\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Very Positive\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Mixed\",\"Negative\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Positive\",\"Very Positive\",\"Very Positive\",\"Positive\",\"Negative\",\"Mixed\",\"Positive\",\"Negative\",\"Mostly Positive\",\"Mixed\",\"Very Positive\",\"Mixed\",\"Mixed\",\"Very Positive\",\"Mostly Positive\",\"Mixed\",\"Very Positive\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Negative\",\"Positive\",\"Mixed\",\"Negative\",\"Mostly Positive\",\"Negative\",\"Very Positive\",\"Positive\",\"Positive\",\"Very Positive\",\"Very Positive\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Mixed\",\"Very Positive\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Positive\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Mixed\",\"Mixed\",\"Very Positive\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Positive\",\"Positive\",\"Very Positive\",\"Very Positive\",\"Positive\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Negative\",\"Negative\",\"Positive\",\"Very Positive\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Mixed\",\"Positive\",\"Negative\",\"Mostly Positive\",\"Negative\",\"Mostly Positive\",\"Negative\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Negative\",\"Mixed\",\"Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Very Positive\",\"Positive\",\"Positive\",\"Very Positive\",\"Mixed\",\"Negative\",\"Mixed\",\"Positive\",\"Very Positive\",\"Positive\",\"Positive\",\"Very Positive\",\"Mixed\",\"Positive\",\"Positive\",\"Positive\",\"Very Positive\",\"Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Negative\",\"Negative\",\"Very Positive\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Very Positive\",\"Negative\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Negative\",\"Negative\",\"Negative\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Very Positive\",\"Negative\",\"Mostly Positive\",\"Mostly Positive\",\"Very Positive\",\"Mixed\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Very Positive\",\"Very Positive\",\"Very Positive\",\"Negative\",\"Negative\",\"Positive\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Negative\",\"Mixed\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Mixed\",\"Mostly Positive\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Positive\",\"Positive\",\"Negative\",\"Negative\",\"Negative\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Very Positive\",\"Mostly Positive\",\"Mixed\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Positive\",\"Mixed\",\"Mixed\",\"Negative\",\"Negative\",\"Positive\",\"Positive\",\"Very Positive\",\"Positive\",\"Mixed\",\"Negative\",\"Positive\",\"Mixed\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Very Positive\",\"Mostly Positive\",\"Positive\",\"Negative\",\"Mostly Positive\",\"Very Positive\",\"Very Positive\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Negative\",\"Mixed\",\"Positive\",\"Positive\",\"Mixed\",\"Mixed\",\"Very Positive\",\"Mixed\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Very Positive\",\"Negative\",\"Positive\",\"Positive\",\"Mixed\",\"Positive\",\"Negative\",\"Mixed\",\"Mostly Positive\",\"Negative\",\"Negative\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Very Positive\",\"Mixed\",\"Very Positive\",\"Very Positive\",\"Positive\",\"Very Positive\",\"Very Positive\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Positive\",\"Positive\",\"Negative\",\"Mixed\",\"Very Positive\",\"Mostly Positive\",\"Very Positive\",\"Negative\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Mixed\",\"Negative\",\"Mixed\",\"Very Positive\",\"Mostly Positive\",\"Negative\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Mixed\",\"Mixed\",\"Negative\",\"Negative\",\"Negative\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Negative\",\"Mixed\",\"Very Positive\",\"Negative\",\"Mixed\",\"Negative\",\"Mixed\",\"Negative\",\"Positive\",\"Mixed\",\"Negative\",\"Very Positive\",\"Mostly Positive\",\"Negative\",\"Negative\",\"Very Positive\",\"Very Positive\",\"Negative\",\"Positive\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Negative\",\"Very Positive\",\"Mostly Positive\",\"Mixed\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Very Positive\",\"Negative\",\"Negative\",\"Mixed\",\"Positive\",\"Mixed\",\"Very Positive\",\"Mixed\",\"Negative\",\"Negative\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Negative\",\"Very Positive\",\"Negative\",\"Positive\",\"Negative\",\"Very Positive\",\"Very Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Negative\",\"Negative\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Negative\",\"Negative\",\"Mostly Positive\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Very Positive\",\"Positive\",\"Positive\",\"Negative\",\"Mostly Positive\",\"Negative\",\"Negative\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Mostly Positive\",\"Negative\",\"Very Positive\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Negative\",\"Very Positive\",\"Mixed\",\"Very Positive\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Negative\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Negative\",\"Very Positive\",\"Positive\",\"Very Positive\",\"Mixed\",\"Negative\",\"Negative\",\"Mostly Positive\",\"Negative\",\"Mixed\",\"Very Positive\",\"Mixed\",\"Very Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Very Positive\",\"Mixed\",\"Very Positive\",\"Mixed\",\"Negative\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Very Positive\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Very Positive\",\"Very Positive\",\"Mixed\",\"Mostly Positive\",\"Negative\",\"Negative\",\"Very Positive\",\"Mostly Positive\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Mixed\",\"Mixed\",\"Mixed\",\"Very Positive\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Positive\",\"Negative\",\"Positive\",\"Negative\",\"Mixed\",\"Mixed\",\"Very Positive\",\"Negative\",\"Mostly Positive\",\"Mixed\",\"Mostly Positive\",\"Negative\",\"Negative\",\"Mixed\",\"Very Positive\",\"Negative\",\"Mixed\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Negative\",\"Mostly Positive\",\"Negative\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Positive\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Negative\",\"Mixed\",\"Very Positive\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Negative\",\"Negative\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Very Positive\",\"Positive\",\"Mixed\",\"Very Positive\",\"Mixed\",\"Very Positive\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Very Positive\",\"Mixed\",\"Very Positive\",\"Mixed\",\"Very Positive\",\"Mostly Positive\",\"Negative\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Positive\",\"Mixed\",\"Very Positive\",\"Negative\",\"Positive\",\"Mixed\",\"Mixed\",\"Positive\",\"Negative\",\"Mixed\",\"Mixed\",\"Negative\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Mixed\",\"Mixed\",\"Mixed\",\"Very Positive\",\"Very Positive\",\"Negative\",\"Negative\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Negative\",\"Mostly Positive\",\"Negative\",\"Mixed\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Positive\",\"Very Positive\",\"Mostly Positive\",\"Mixed\",\"Very Positive\",\"Positive\",\"Negative\",\"Mixed\",\"Negative\",\"Mostly Positive\",\"Mixed\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Positive\",\"Very Positive\",\"Very Positive\",\"Very Positive\",\"Mixed\",\"Positive\",\"Positive\",\"Mixed\",\"Positive\",\"Negative\",\"Very Positive\",\"Mixed\",\"Mixed\",\"Mixed\",\"Negative\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Very Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Very Positive\"],\"xaxis\":\"x\",\"yaxis\":\"y\",\"type\":\"histogram\"},{\"alignmentgroup\":\"True\",\"bingroup\":\"x\",\"hovertemplate\":\"required_age=16<br>rating=%{x}<br>count=%{y}<extra></extra>\",\"legendgroup\":\"16\",\"marker\":{\"color\":\"#EF553B\",\"pattern\":{\"shape\":\"\"}},\"name\":\"16\",\"offsetgroup\":\"16\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[\"Very Positive\",\"Mixed\",\"Mixed\",\"Mixed\",\"Positive\",\"Positive\",\"Very Positive\",\"Mixed\",\"Positive\",\"Mixed\",\"Mixed\",\"Mixed\",\"Very Positive\",\"Mixed\",\"Mostly Positive\",\"Very Positive\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Very Positive\",\"Mixed\",\"Very Positive\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Very Positive\",\"Positive\",\"Mostly Positive\",\"Negative\",\"Very Positive\",\"Mixed\",\"Positive\",\"Mixed\",\"Mixed\",\"Very Positive\",\"Positive\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Very Positive\",\"Very Positive\",\"Negative\",\"Very Positive\",\"Mixed\",\"Mixed\",\"Mixed\",\"Very Positive\",\"Mixed\",\"Negative\",\"Mostly Positive\",\"Very Positive\",\"Mostly Positive\",\"Very Positive\",\"Mixed\",\"Positive\",\"Positive\",\"Positive\",\"Positive\",\"Very Positive\",\"Positive\",\"Positive\",\"Negative\",\"Mixed\",\"Very Positive\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Very Positive\",\"Very Positive\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Mixed\",\"Negative\",\"Very Positive\",\"Negative\",\"Mostly Positive\",\"Mostly Positive\",\"Mixed\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Mixed\",\"Positive\",\"Mixed\",\"Very Positive\",\"Mostly Positive\",\"Negative\",\"Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Negative\",\"Very Positive\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Mixed\",\"Very Positive\",\"Mixed\",\"Positive\",\"Mixed\",\"Very Positive\",\"Negative\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Positive\",\"Very Positive\",\"Mostly Positive\",\"Mixed\",\"Positive\",\"Negative\",\"Positive\",\"Negative\",\"Mixed\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Mixed\",\"Negative\",\"Positive\",\"Mostly Positive\"],\"xaxis\":\"x\",\"yaxis\":\"y\",\"type\":\"histogram\"},{\"alignmentgroup\":\"True\",\"bingroup\":\"x\",\"hovertemplate\":\"required_age=18<br>rating=%{x}<br>count=%{y}<extra></extra>\",\"legendgroup\":\"18\",\"marker\":{\"color\":\"#00cc96\",\"pattern\":{\"shape\":\"\"}},\"name\":\"18\",\"offsetgroup\":\"18\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[\"Mostly Positive\",\"Mixed\",\"Very Positive\",\"Positive\",\"Mixed\",\"Negative\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Very Positive\",\"Very Positive\",\"Positive\",\"Positive\",\"Positive\",\"Very Positive\",\"Positive\",\"Very Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Very Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Very Positive\",\"Negative\",\"Very Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Very Positive\",\"Mixed\",\"Negative\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Mixed\",\"Positive\",\"Negative\",\"Very Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Very Positive\",\"Positive\",\"Very Positive\",\"Positive\",\"Negative\",\"Positive\",\"Positive\",\"Positive\",\"Very Positive\",\"Mostly Positive\",\"Positive\",\"Negative\",\"Mixed\",\"Positive\",\"Very Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Negative\",\"Very Positive\",\"Very Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Negative\",\"Very Positive\",\"Very Positive\",\"Mixed\",\"Positive\",\"Negative\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Very Positive\",\"Negative\",\"Very Positive\",\"Very Positive\",\"Mixed\",\"Mixed\",\"Positive\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Mixed\",\"Mixed\",\"Mixed\",\"Mixed\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Negative\",\"Very Positive\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Mostly Positive\",\"Mixed\",\"Mixed\",\"Mixed\",\"Negative\",\"Mostly Positive\",\"Very Positive\",\"Negative\",\"Mostly Positive\",\"Mixed\",\"Very Positive\",\"Mixed\",\"Positive\",\"Positive\",\"Very Positive\",\"Positive\",\"Very Positive\",\"Negative\",\"Very Positive\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Negative\",\"Very Positive\",\"Mostly Positive\",\"Mixed\",\"Very Positive\",\"Mixed\",\"Mixed\",\"Very Positive\",\"Positive\",\"Negative\",\"Positive\",\"Negative\",\"Mostly Positive\",\"Mostly Positive\",\"Very Positive\",\"Mostly Positive\",\"Very Positive\",\"Mixed\",\"Positive\",\"Very Positive\",\"Very Positive\",\"Very Positive\",\"Very Positive\",\"Mixed\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Mostly Positive\",\"Positive\",\"Very Positive\",\"Mixed\",\"Very Positive\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Negative\",\"Positive\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Negative\",\"Very Positive\",\"Mixed\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Mostly Positive\",\"Very Positive\",\"Very Positive\",\"Negative\",\"Mostly Positive\",\"Mostly Positive\",\"Very Positive\",\"Mostly Positive\",\"Positive\",\"Very Positive\",\"Negative\",\"Mixed\",\"Positive\",\"Very Positive\",\"Negative\",\"Positive\",\"Negative\",\"Mostly Positive\",\"Mixed\"],\"xaxis\":\"x\",\"yaxis\":\"y\",\"type\":\"histogram\"},{\"alignmentgroup\":\"True\",\"bingroup\":\"x\",\"hovertemplate\":\"required_age=12<br>rating=%{x}<br>count=%{y}<extra></extra>\",\"legendgroup\":\"12\",\"marker\":{\"color\":\"#ab63fa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"12\",\"offsetgroup\":\"12\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[\"Positive\",\"Very Positive\",\"Very Positive\",\"Negative\",\"Very Positive\",\"Mixed\",\"Mostly Positive\",\"Mixed\",\"Mixed\",\"Mixed\",\"Very Positive\",\"Mostly Positive\",\"Very Positive\",\"Positive\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Very Positive\",\"Very Positive\",\"Negative\",\"Negative\",\"Very Positive\",\"Positive\",\"Positive\",\"Mostly Positive\",\"Negative\",\"Mostly Positive\",\"Positive\",\"Mixed\",\"Mostly Positive\",\"Mixed\",\"Negative\",\"Very Positive\",\"Positive\"],\"xaxis\":\"x\",\"yaxis\":\"y\",\"type\":\"histogram\"},{\"alignmentgroup\":\"True\",\"bingroup\":\"x\",\"hovertemplate\":\"required_age=7<br>rating=%{x}<br>count=%{y}<extra></extra>\",\"legendgroup\":\"7\",\"marker\":{\"color\":\"#FFA15A\",\"pattern\":{\"shape\":\"\"}},\"name\":\"7\",\"offsetgroup\":\"7\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[\"Negative\",\"Positive\",\"Negative\",\"Mixed\",\"Positive\",\"Mixed\"],\"xaxis\":\"x\",\"yaxis\":\"y\",\"type\":\"histogram\"},{\"alignmentgroup\":\"True\",\"bingroup\":\"x\",\"hovertemplate\":\"required_age=3<br>rating=%{x}<br>count=%{y}<extra></extra>\",\"legendgroup\":\"3\",\"marker\":{\"color\":\"#19d3f3\",\"pattern\":{\"shape\":\"\"}},\"name\":\"3\",\"offsetgroup\":\"3\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[\"Negative\",\"Positive\",\"Negative\",\"Positive\"],\"xaxis\":\"x\",\"yaxis\":\"y\",\"type\":\"histogram\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"rating\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"count\"}},\"legend\":{\"title\":{\"text\":\"required_age\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Cantidad de ratings por cada required_age\"},\"barmode\":\"group\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('57246412-ad98-422d-a154-9b79056d91fd');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.box(df_train, y=\"achievements\", color=\"rating\", log_y=True, title=\"Distribución de achievements según rating\")\n",
        "fig.show()\n",
        "fig.write_image(\"achievements_rating.png\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "b4OYDRvOFvqq",
        "outputId": "709fae87-d9b6-4739-ba87-e83d8b2dd4d6"
      },
      "id": "b4OYDRvOFvqq",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.16.1.min.js\"></script>                <div id=\"25d61db9-17af-44b1-abb2-09dddaf91b7d\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"25d61db9-17af-44b1-abb2-09dddaf91b7d\")) {                    Plotly.newPlot(                        \"25d61db9-17af-44b1-abb2-09dddaf91b7d\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"rating=Mixed<br>achievements=%{y}<extra></extra>\",\"legendgroup\":\"Mixed\",\"marker\":{\"color\":\"#636efa\"},\"name\":\"Mixed\",\"notched\":false,\"offsetgroup\":\"Mixed\",\"orientation\":\"v\",\"showlegend\":true,\"x0\":\" \",\"xaxis\":\"x\",\"y\":[23,53,0,24,0,0,84,21,16,0,0,0,103,0,0,16,48,13,24,0,7,15,10,34,25,32,20,10,12,0,39,8,45,0,0,0,0,0,24,11,20,36,17,10,45,55,35,20,12,45,30,51,8,53,55,14,0,52,58,0,0,1,0,0,10,0,47,21,11,11,0,0,0,46,59,0,37,14,73,99,18,0,12,34,0,18,19,57,0,19,17,27,42,49,50,12,13,8,62,0,0,14,30,0,0,0,3006,0,28,56,0,16,20,26,19,47,0,17,0,23,0,51,0,29,30,0,19,0,46,54,0,52,50,45,5,41,0,71,0,26,0,0,0,0,41,15,0,39,0,35,15,13,0,0,22,42,25,0,56,18,125,25,0,0,0,29,37,35,15,1448,71,43,25,0,0,0,0,0,0,80,10,0,47,49,6,0,41,27,8,0,18,0,0,21,0,0,28,0,12,28,5,12,66,0,0,50,0,51,0,0,0,21,25,0,10,9,36,0,51,150,0,21,26,8,70,0,80,18,7,0,9,0,0,47,0,0,0,0,0,0,0,33,45,0,5000,30,22,50,0,39,0,48,7,0,104,0,0,28,0,13,14,7,0,0,0,43,0,5,0,60,0,0,56,17,16,12,17,12,0,5,35,33,50,35,0,11,0,6,0,42,50,0,26,51,0,16,40,0,0,0,222,31,23,0,0,88,0,41,0,0,15,45,12,0,19,0,100,0,24,68,59,0,0,0,0,60,31,0,35,28,0,165,30,23,11,74,13,0,9,0,0,52,46,0,0,14,0,18,98,33,19,18,0,15,17,0,0,33,0,38,34,40,46,86,0,22,0,0,0,0,37,60,39,0,28,46,4094,0,73,70,0,20,22,12,14,14,14,13,30,9,24,63,18,0,0,43,60,0,0,14,18,0,0,0,8,10,15,0,12,30,0,46,30,43,85,73,0,0,0,30,15,0,25,0,64,33,37,198,20,0,28,56,40,0,13,41,0,0,10,14,0,46,41,0,17,0,0,24,35,0,526,9,20,4,61,61,15,37,25,9,0,18,56,20,20,16,61,16,0,14,0,0,0,85,0,1,0,0,0,0,0,5,49,54,0,5000,0,13,0,100,39,0,32,36,0,0,48,48,27,32,26,0,0,17,0,25,0,0,65,19,6,0,50,20,1,40,43,0,50,0,43,32,49,241,0,11,15,130,15,8,0,34,0,38,57,0,0,50,32,0,23,14,27,12,49,22,16,120,38,6,64,39,0,52,26,0,26,0,42,3,0,0,0,0,0,35,5000,11,35,25,48,41,3,0,10,0,0,62,0,39,0,23,13,72,19,50,0,0,0,0,7,35,0,0,7,25,2,0,0,34,25,19,0,10,0,16,0,28,20,0,0,15,10,0,52,3,9,0,8,38,0,10,12,50,18,16,30,12,0,39,0,0,62,0,29,0,0,56,0,36,0,0,0,22,0,2995,0,0,54,45,0,0,0,0,48,183,0,50,22,46,87,46,28,0,87,0,26,79,12,0,14,0,0,50,0,10,100,0,34,0,47,18,30,0,34,0,0,11,11,9,10,0,0,49,0,29,0,0,0,19,81,30,42,60,133,0,12,0,7,29,0,0,0,24,0,13,6,49,27,0,0,0,0,34,0,16,0,11,27,60,44,0,0,17,0,109,0,50,27,12,2,0,65,53,6,0,0,0,68,26,0,36,28,40,24,0,0,26,30,50,53,6,0,24,0,8,44,1559,42,32,38,0,22,0,12,12,7,0,0,5,0,25,0,0,0,0,1,0,33,73,1002,37,27,22,8,13,30,24,20,0,28,40,12,77,308,0,16,43,10,0,0,64,0,0,30,61,17,30,52,29,1165,20,0,0,0,13,6,64,32,0,45,21,20,11,0,0,0,0,31,0,20,54,50,7,16,0,16,44,12,10,9,27,0,0,29,0,0,0,0,0,31,0,63,56,11,8,0,20,0,36,0,97,12,0,10,394,60,36,0,0,0,0,74,59,58,104,0,46,13,18,20,26,43,0,34,0,36,18,9,11,29,15,0,0,319,0,50,6,54,0,98,81,0,5,0,0,0,0,0,34,5,12,29,0,23,10,0,0,10,0,45,16,35,0,0,21,7,1,14,80,0,16,10,0,30,37,26,0,44,10,17,0,16,51,0,0,0,17,0,15,41,52,59,0,0,0,0,0,0,42,7,32,22,0,46,0,40,0,0,3,16,62,0,27,18,0,15,30,25,52,31,0,0,0,0,37,0,44,14,0,0,40,0,42,0,0,0,0,572,7,44,23,0,50,13,0,26,10,7,34,31,8,52,30,159,0,13,21,18,0,0,0,7,32,0,11,15,18,17,0,29,26,57,0,12,1,0,0,22,40,11,11,10,0,0,0,30,35,0,0,0,46,6,29,109,21,20,10,116,33,0,2976,13,42,0,42,0,0,30,0,20,15,12,0,55,0,32,0,30,0,10,0,19,96,13,48,22,20,22,53,35,36,0,12,0,33,0,30,67,10,0,0,0,0,16,57,20,12,225,14,30,37,0,0,38,0,37,36,23,10,40,50,25,4,4987,31,0,28,37,0,0,35,51,54,44,0,0,0,76,25,41,24,0,40,4,0,14,0,0,44,26,10,9,111,37,45,34,44,0,1,0,31,0,38,34,18,29,0,50,15,18,52,0,16,34,102,5,28,24,0,0,102,1,45,23,0,109,0,10,47,21,0,14,15,0,28,40,33,12,18,61,13,0,114,47,45,42,0,8,50,6,63,229,19,17,15,48,0,39,0,9,0,5,16,48,60,20,6,13,0,74,0,21,0,18,36,49,408,15,63,30,0,0,0,0,0,0,123,45,30,27,25,0,0,28,0,24,0,42,0,8,0,14,0,3,0,31,6,24,19,0,39,71,24,49,60,29,0,28,14,12,24,49,0,14,42,101,243,50,35,30,40,0,6,176,24,0,8,0,0,0,0,32,22,4497,2007,0,10,0,0,13,59,10,54,0,20,0,59,40,0,29,0,47,46,12,0,80,15,12,18,42,35,7,0,22,20,9,3452,0,21,35,6,0,0,5,20,42,97,45,11,0,0,0,0,14,0,12,11,0,18,0,0,81,0,0,0,0,0,0,15,12,36,0,19,18,36,100,12,7,0,17,75,0,21,0,83,121,74,24,0,60,0,10,0,45,0,43,69,0,428,50,46,55,0,41,10,48,41,0,22,163,31,35,0,22,0,13,0,3,0,137,14,0,42,40,86,54,50,13,49,50,24,10,16,0,89,25,0,107,11,23,50,0,3,26,0,59,27,10,0,10,20,0,38,69,0,18,28,43,15,35,15,34,13,0,0,23,46,16,50,0,27,34,50,0,0,0,0,323,6,0,0,64,28,12,0,55,10,13,22,62,0,10,0,11,20,10,26,50,7,10,12,30,8,0,50,0,0,30,0,29,0,0,4,0,0,20,0,0,34,24,25,0,0,15,25,18,0,45,37,102,15,7,1080,21,0,23,13,21,22,10,5,7,20,40,12,35,0,32,0,17,16,10,21,8,39,29,65,28,0,0,8,11,10,0,45,11,0,45,20,0,7,35,12,33,0,0,38,14,29,24,42,13,22,47,28,11,12,8,108,0,0,15,6,21,8,12,0,22,30,0,44,0,0,0,12,15,0,54,0,12,13,51,12,50,0,0,50,3,20,24,0,20,12,28,20,28,12,10,0,26,25,15,59,82,29,7,6,0,29,0,0,12,28,18,19],\"y0\":\" \",\"yaxis\":\"y\",\"type\":\"box\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"rating=Positive<br>achievements=%{y}<extra></extra>\",\"legendgroup\":\"Positive\",\"marker\":{\"color\":\"#EF553B\"},\"name\":\"Positive\",\"notched\":false,\"offsetgroup\":\"Positive\",\"orientation\":\"v\",\"showlegend\":true,\"x0\":\" \",\"xaxis\":\"x\",\"y\":[19,121,87,25,48,96,14,26,38,78,15,0,22,16,20,37,0,25,0,0,67,25,11,57,22,1,38,0,60,0,0,12,5,0,13,118,18,24,63,50,22,0,12,6,15,35,50,22,60,68,39,10,17,24,1,0,6,13,47,31,14,20,412,22,4,0,9,0,0,7,14,27,0,16,13,0,83,21,23,7,85,59,17,32,12,0,32,30,45,0,0,0,322,0,0,20,0,0,28,26,0,21,0,18,60,0,19,14,0,25,127,27,0,68,0,65,0,139,27,30,0,104,19,55,0,8,10,40,20,64,0,71,105,4,47,8,25,16,33,60,43,15,0,20,0,10,9,7,20,81,0,18,35,14,0,90,0,0,0,23,23,72,0,103,15,0,0,0,0,58,0,175,0,602,54,0,0,0,0,0,0,0,32,43,0,67,39,17,30,24,13,20,10,35,70,0,21,37,40,0,22,0,50,0,11,13,39,30,0,55,28,13,16,23,19,0,55,0,0,0,12,21,30,0,30,0,23,30,129,0,20,38,26,0,30,13,0,13,0,77,29,0,21,16,8,58,7,19,30,40,11,10,0,36,61,0,14,31,0,0,26,82,42,25,0,54,100,43,29,16,0,0,0,33,22,0,0,0,0,27,34,17,16,20,32,0,40,44,0,39,13,65,30,0,16,11,17,4,0,9,0,12,0,0,0,16,10,3,18,40,60,15,11,0,0,12,24,0,59,107,11,47,0,1,0,4,0,60,32,6,0,65,23,10,53,82,77,0,31,0,0,28,31,22,8,16,0,46,0,28,20,48,0,13,0,35,42,0,13,5,0,59,84,0,0,24,53,72,27,8,12,18,20,11,12,16,3,0,19,76,23,13,13,0,141,0,30,34,0,0,24,86,19,33,27,19,1,13,73,40,23,32,18,50,9,38,18,12,32,22,17,0,0,41,32,56,0,0,0,39,18,51,36,13,0,0,9,12,0,32,0,32,50,20,7,0,0,0,0,0,37,21,106,20,15,15,0,0,0,12,15,0,0,3,21,0,48,20,38,0,42,14,13,0,31,36,14,0,0,0,0,0,0,17,92,0,0,23,38,33,8,0,8,0,6,8,0,0,115,0,0,26,15,0,13,29,40,21,85,0,10,25,109,35,37,55,236,0,0,50,0,0,44,0,0,50,0,0,16,52,36,88,77,19,20,26,140,13,20,0,20,38,34,25,0,50,39,38,20,57,13,21,0,0,0,0,22,20,14,25,0,0,0,30,34,16,12,43,4,20,19,50,222,31,150,15,8,0,33,20,10,5,0,65,17,101,0,25,0,0,22,11,0,58,33,0,32,45,0,16,24,76,0,18,1,172,10,6,13,0,20,0,14,48,44,27,50,70,247,47,0,0,10,20,11,0,38,46,42,21,26,0,13,0,33,35,12,0,30,48,12,27,41,17,14,40,8,32,26,19,134,0,0,0,29,0,0,36,27,13,12,31,66,34,0,41,25,0,29,60,19,0,0,20,21,127,31,24,0,12,84,36,35,39,2,50,15,42,41,28,19,0,4,23,7,36,0,23,21,69,12,490,18,257,29,17,0,50,20,10,0,38,23,240,21,67,95,0,30,22,50,46,0,27,0,45,14,0,0,0,70,0,74,36,0,252,0,11,54,56,47,40,46,46,19,13,34,12,106,27,16,6,0,0,49,27,57,0,20,44,15,12,12,0,0,42,0,0,29,0,0,42,65,0,9,8,123,20,42,33,17,0,13,0,30,0,0,0,0,13,0,0,20,19,31,105,0,36,52,0,28,0,0,36,12,201,73,0,0,30,18,34,15,6,36,0,86,0,20,52,0,0,0,21,14,25,65,0,44,15,17,39,0,0,50,62,17,0,32,0,30,0,28,0,31,77,9,21,0,27,36,33,25,0,84,0,0,18,26,100,27,67,51,21,15,60,32,5,31,100,55,20,32,22,12,0,9,0,0,0,21,0,0,0,28,21,18,17,40,47,7,60,0,34,166,60,46,0,12,0,30,21,0,0,34,36,29,161,18,0,0,46,11,0,51,0,0,13,26,51,69,24,1800,31,8,0,20,71,13,52,51,36,10,18,9,90,0,50,43,0,0,8,36,0,11,67,48,19,0,10,44,17,20,10,0,0,9,20,56,40,29,45,40,46,0,0,24,17,30,0,27,18,24,25,12,0,4,75,0,33,17,33,0,9,0,54,35,0,0,12,0,10,14,0,27,45,31,55,37,10,0,0,0,31,0,66,18,36,69,21,0,53,10,16,35,38,0,0,5,51,22,0,20,4,0,0,0,0,0,46,81,0,78,21,23,36,58,0,27,53,19,0,27,25,36,22,555,27,21,0,9,33,0,0,0,13,70,99,44,37,16,0,0,7,0,32,0,0,58,15,26,0,26,25,33,0,26,500,73,39,20,53,0,31,160,0,0,604,40,50,15,22,0,46,22,0,20,56,83,0,0,22,16,10,0,0,0,115,30,17,23,22,10,0,0,42,28,0,58,14,24,30,19,30,111,62,24,0,125,0,11,21,11,29,35,24,34,20,6,15,12,51,40,31,53,15,0,0,3,37,31,33,0,20,37,8,0,31,0,78,22,44,48,0,61,35,38,25,0,5,12,0,53,49,55,124,24,77,1,18,34,0,0,66,15,9,84,0,60,56,0,16,45,0,39,13,54,8,20,60,16,14,0,0,36,17,0,50,0,69,0,12,16,8,0,6,58,39,29,15,90,4,29,43,0,44,29,40,42,44,26,33,64,19,322,8,0,12,50,0,10,24,34,40,33,41,0,12,20,0,0,20,10,0,0,21,170,0,0,0,30,30,0,13,15,7,12,15,26,0,93,67,10,0,31,38,32,0,26,1,9,30,0,20,16,0,25,2,0,11,0,17,15,7,32,23,21,32,15,0,25,29,9,59,59,0,68,0,0,17,58,0,26,21,60,12,0,17,5,0,39,51,41,0,31,20,10,10,0,12,51,12,15,17,0,42,46,0,22,15,13,5,50,0,0,30,16,25,0,10,53,116,11,30,16,18,18,28,18,0,0,22,95,9,0,100,110,10,18,42,27,61,0,52,0,144,0,13,5,0,49,0,17,73,17,145,59,0,41,0,16,10,14,0,0,0,2,16,0,14,50,105,0,46,25,11,0,0,0,19,7,0,0,31,11,27,8,17,90,43,10,19,40,44,44,25,15,53,40,53,0,0,26,25,36,0,49,11,35,16,0,31,46,0,11,1130,354,49,35,24,18,15,49,162,12,28,0,0,0,12,0,0,0,18,28,0,26,0,20,29,19,0,30,71,50,70,0,0,34,0,0,0,15,33,7,30,39,9,29,0,21,30,0,22,0,38,89,29,0,0,72,24,0,50,20,24,9,27,10,74,22,25,0,104,51,31,13,100,31,46,0,18,0,9,16,21,26,0,41,6,0,21,30,40,0,0,12,21,0,17,27,0,37,26,40,10,13,89,295,17,32,29,6,0,20,80,63,35,54,37,24,0,0,100,34,21,11,0,29,17,12,24,45,15,0,11,100,34,67,0,58,63,0,0,32,0,27,37,0,0,46,0,20,0,75,70,16,47,48,0,0,99,54,66,51,14,15,76,0,0,38,53,14,11,0,72,6,28,15,0,63,20,7,63,8,0,83,25,22,10,39,14,41,0,27,0,0,40,42,50,47,27,35,47,11,16,6,13,0,21,8,0,1,0,50,24,0,50,35,8,66,17,27,37,37,0,0,16,464,0,12,51,49,33,0,0,17,0,12,17,0,0,0,92,0,0,0,59,27,0,45,9,0,13,0,35,4,0,21,53,55,43,43,45,19,0,22,11,7,20,0,20,0,12,6,54,23,22,31,27,0,17,50,11,19,9,8,75,32,20,29,19,0,0,75,62,9,0,30,21,39,0,40,29,302,0,0,0,24,28,0,0,67,20,30,15,0,26,59,33,0,0,32,4,75,44,0,19,13,0,50,0,0,0,13,18,55,32,0,11,31,6,16,0,64,41,33,10,21,0,33,0,39,0,18,25,13,0,29,38,37,31,4,0,0,53,35,31,709,0,20,25,13,52,0,52,114,0,0,92,24,20,10,29,0,0,34,6,23,0,0,35,9,0,8,50,36,11,34,43,32,99,0,0,133,34,19,9,23,35,41,0,14,0,13,46,46,14,0,16,0,54,22,0,0,0,48,0,12,1203,0,20,0,0,0,0,0,22,0,14,38,60,0,12,0,22,12,34,0,22,44,29,12,0,47,37,13,22,7,23,39,35,9,0,0,0,10,0,20,57,5,0,6,33,19,21,7,40,0,35,0,55,9,47,21,0,44,0,40,0,0,61,0,6,0,38,30,0,33,0,0,21,141,0,25,100,30,31,36,44,30,20,0,0,0,16,22,7,49,85,0,20,0,13,20,63,19,27,12,0,11,15,18,20,0,24,28,67,19,15,0,0,15,18,20,50,0,40,57,75,17,19,31,40,0,29,44,0,0,0,4,23,20,22,0,35,30,0,0,0,0,0,0,0,12,14,34,12,36,11,0,0,24,20,22,58,45,10,9,0,0,64,0,0,26,17,0,34,24,24,20],\"y0\":\" \",\"yaxis\":\"y\",\"type\":\"box\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"rating=Mostly Positive<br>achievements=%{y}<extra></extra>\",\"legendgroup\":\"Mostly Positive\",\"marker\":{\"color\":\"#00cc96\"},\"name\":\"Mostly Positive\",\"notched\":false,\"offsetgroup\":\"Mostly Positive\",\"orientation\":\"v\",\"showlegend\":true,\"x0\":\" \",\"xaxis\":\"x\",\"y\":[7,15,24,17,45,15,30,22,26,27,42,58,55,8,27,0,70,97,39,38,46,0,25,24,32,25,16,36,0,33,44,16,70,15,16,30,0,39,48,23,27,294,0,0,133,709,32,0,48,21,0,15,7,48,0,0,25,117,15,13,66,0,19,35,32,55,25,0,43,6,0,68,13,118,25,0,14,11,0,32,0,0,54,0,20,18,31,25,30,22,30,47,48,0,0,14,45,60,20,15,0,7,30,39,39,0,14,0,0,0,42,0,265,10,4,38,0,0,80,23,12,0,32,0,0,0,0,15,19,31,12,31,43,37,4,27,20,14,11,1,0,55,6,30,40,49,37,51,0,15,50,14,31,86,0,128,37,10,18,0,0,0,0,0,82,80,31,0,20,14,28,37,27,3,0,0,49,0,15,0,28,0,100,0,51,9,40,25,0,20,0,0,14,20,42,28,15,10,14,40,0,55,20,15,0,0,12,21,16,0,500,7,0,0,0,38,0,19,0,86,23,63,16,71,75,68,25,58,23,0,0,1,37,16,19,60,0,10,0,22,9,9,30,38,0,21,14,0,55,22,0,42,52,34,19,39,18,179,40,18,15,8,54,19,26,0,36,6,0,82,0,25,41,93,15,99,12,12,27,47,0,50,0,27,9,57,30,48,47,0,0,0,38,0,59,47,16,17,11,13,35,18,9,48,37,26,58,77,0,30,9,15,18,54,21,17,45,0,0,2,50,0,58,20,0,51,0,0,9,52,0,15,26,0,27,31,32,77,28,31,20,38,123,0,188,43,0,29,0,32,4,0,0,35,45,24,29,49,0,0,0,59,27,0,0,0,18,52,0,0,4,61,0,0,60,47,17,30,21,32,45,0,19,28,0,18,0,15,3,23,31,12,46,15,0,52,5,13,53,0,43,0,17,0,24,33,0,131,45,0,52,72,0,0,0,29,105,46,21,54,4,16,13,23,0,20,0,23,103,13,11,23,21,74,0,33,0,12,24,38,0,0,0,37,35,0,98,20,12,20,18,23,60,29,0,0,33,4,64,0,62,17,0,40,48,21,39,0,0,1,50,20,0,29,26,10,180,16,0,8,12,0,32,0,20,41,69,15,21,4,48,998,0,11,29,0,0,12,220,70,56,12,8,0,0,57,0,19,14,52,0,21,0,8,12,45,25,15,115,0,15,14,27,22,0,43,22,50,0,6,0,0,29,10,22,5,10,51,19,27,12,32,60,20,38,64,37,0,44,0,30,26,62,17,100,0,0,10,81,0,14,12,50,43,26,50,31,67,17,0,46,12,88,0,20,19,78,36,70,52,136,11,39,11,8,81,14,44,0,0,0,84,20,14,12,0,0,41,35,0,31,64,0,0,13,20,17,47,23,0,0,46,0,18,28,79,35,25,68,26,19,17,35,0,12,12,15,16,20,32,0,84,34,13,6,47,0,12,50,25,96,0,0,23,22,9,0,107,15,0,484,0,46,25,99,36,31,60,39,0,64,0,20,27,29,0,34,0,47,19,0,1,0,12,64,0,28,0,0,0,21,50,0,25,27,0,24,0,18,0,16,69,73,10,33,0,5,45,40,44,18,11,11,0,0,17,0,34,10,36,0,0,49,18,19,0,25,8,9,7,1,13,19,0,0,0,0,36,0,19,38,23,0,61,20,59,0,53,37,50,84,0,30,108,51,129,0,11,25,13,12,0,0,73,17,0,38,23,45,15,15,14,13,78,10,26,31,9821,4,256,0,42,0,35,16,0,0,10,129,0,6,14,20,0,56,0,41,36,13,25,42,9,30,7,0,21,0,6,11,19,0,59,20,0,20,48,32,20,49,0,47,0,44,0,85,237,4034,0,32,28,30,0,0,0,40,22,0,30,0,12,0,0,0,53,34,96,0,53,38,28,0,42,43,0,0,24,33,0,5,11,20,10,0,30,18,9,31,12,29,33,0,19,0,24,0,13,28,5,55,22,43,25,16,48,25,50,0,16,1,47,50,26,0,26,0,16,77,44,13,64,33,14,0,38,14,9,0,12,51,8,25,63,0,27,12,35,0,0,12,19,19,42,0,0,0,0,131,13,29,73,43,31,0,20,0,0,0,50,26,31,0,57,0,12,0,14,21,13,20,8,0,44,37,0,75,24,18,20,8,20,30,66,0,56,48,79,24,0,0,0,137,15,0,58,0,51,32,0,0,0,31,31,0,44,18,4,36,0,40,0,15,33,43,36,5,93,0,12,0,47,0,10,25,9,50,0,0,50,0,30,0,100,37,0,0,0,10,0,0,0,29,36,45,22,69,0,0,30,20,0,0,23,0,8,8,45,0,169,36,1070,14,0,0,13,25,32,0,0,60,54,52,1,35,10,0,27,29,75,0,48,43,19,54,0,45,47,8,21,78,50,24,14,49,23,0,26,49,86,0,60,7,1,89,0,7,37,0,45,0,0,3,8,43,14,54,0,17,0,28,77,0,50,82,42,0,38,0,0,6,30,56,50,52,0,45,78,19,27,34,0,5,11,33,12,26,91,34,101,62,35,109,10,69,0,10,28,63,153,10,0,0,0,45,29,17,15,12,40,0,14,42,38,28,43,14,12,10,11,23,0,10,0,10,10,0,0,0,20,9,45,7,0,38,0,15,25,30,12,40,21,29,11,25,0,27,57,8,24,0,0,51,31,98,50,26,23,26,0,57,0,0,0,29,18,26,50,0,50,54,0,21,3,7,0,226,220,12,40,21,0,50,0,61,70,18,0,60,38,20,42,84,15,10,18,43,24,0,0,140,32,10,51,0,14,20,0,10,29,71,14,0,16,84,14,16,0,17,34,35,42,46,30,14,52,0,31,47,30,25,11,0,60,0,0,0,0,36,0,12,0,0,62,25,15,15,74,0,43,70,18,23,35,0,71,36,36,6,23,21,0,5,22,12,14,103,13,0,49,36,10,12,38,30,31,15,15,50,0,2,20,6,31,0,13,5,5,56,20,26,92,8,128,53,452,7,17,0,67,4,8,1505,20,32,21,16,13,3,0,0,113,57,0,71,0,0,45,27,7,0,53,0,27,0,0,0,0,0,44,47,6,47,0,0,37,29,36,43,24,0,6,78,20,24,22,300,0,0,0,0,0,0,36,0,24,0,50,12,0,6,97,21,44,15,11,10,0,12,46,0,0,24,0,35,51,18,0,20,0,0,10,20,57,0,0,25,40,8,31,19,22,20,35,0,0,0,10,0,0,0,6,0,69,0,47,0,0,0,15,0,8,0,21,49,21,29,49,22,7,10,0,136,74,0,10,19,10,52,0,0,0,0,43,0,6,26,62,4293,54,37,44,27,0,8,54,185,24,0,28,27,48,590,12,57,5,21,0,45,25,98,88,128,6,0,32,24,32,6,0,18,0,0,10,23,28,0,0,26,50,10,21,27,46,13,20,7,16,12,20,0,24,14,24,25,0,0,38,0,1224,13,35,77,0,18,31,81,17,32,72,50,1,0,0,10,10,136,20,24,36,0,15,5,36,11,0,0,20,10,0,25,0,26,0,35,28,6,15,18,30,24,45,251,44,0,34,37,50,0,0,24,0,0,0,43,1,0,0,0,79,0,0,65,0,50,71,0,46,56,13,27,22,0,22,14,0,0,34,0,0,106,10,0,58,46,0,57,10,27,25,21,14,29,64,18,17,0,69,23,30,0,12,22,95,25,37,9,0,0,16,0,14,19,13,28,0,23,9,7,22,0,0,0,11,59,27,21,34,29,0,0,6,25,27,0,213,0,10,10,10,40,30,18,34,14,33,0,9,0,13,61,0,0,15,16,61,0,121,0,73,15,0,362,12,11,17,32,50,49,40,11,30,0,13,37,0,0,72,0],\"y0\":\" \",\"yaxis\":\"y\",\"type\":\"box\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"rating=Very Positive<br>achievements=%{y}<extra></extra>\",\"legendgroup\":\"Very Positive\",\"marker\":{\"color\":\"#ab63fa\"},\"name\":\"Very Positive\",\"notched\":false,\"offsetgroup\":\"Very Positive\",\"orientation\":\"v\",\"showlegend\":true,\"x0\":\" \",\"xaxis\":\"x\",\"y\":[0,0,15,22,43,17,12,0,25,0,294,29,28,33,44,51,47,23,0,9,12,0,0,0,0,60,33,0,11,16,0,88,4,0,164,10,0,16,19,8,20,2,0,0,36,28,30,46,0,50,66,5,16,20,52,55,27,12,28,19,7,12,0,58,0,0,4,0,50,0,0,0,27,0,0,33,57,14,52,0,23,20,12,29,85,29,0,33,0,0,143,9,12,12,40,9,69,51,30,11,29,0,53,0,30,13,0,13,0,0,8,0,285,16,0,11,0,0,60,17,0,50,0,6,53,25,20,0,69,38,0,202,0,0,64,12,32,55,31,16,124,29,80,42,114,35,232,68,13,17,14,66,38,30,18,30,20,29,38,63,26,14,0,11,28,8,58,16,17,10,1,81,34,37,256,0,0,100,63,97,11,58,0,20,0,14,1,35,17,22,16,15,70,0,52,16,608,6,0,403,45,64,4,25,0,0,49,22,8,28,13,44,1746,0,12,0,0,32,34,15,78,40,37,12,3,47,14,21,10,76,0,0,20,30,16,7,2448,10,0,0,208,33,55,49,20,0,125,0,34,0,12,21,18,27,50,0,35,0,0,0,35,0,8,16,10,0,75,0,482,37,63,37,20,0,36,20,31,14,0,15,64,0,73,0,9,17,18,16,69,48,0,75,15,9,0,34,12,0,1,14,14,0,47,0,40,30,41,9,0,0,0,45,15,20,160,28,29,0,35,0,8,0,8,18,1043,0,31,19,49,0,30,105,72,33,26,0,2880,72,0,7,0,0,21,0,3000,0,26,187,22,23,12,36,9,24,60,22,9,36,39,39,50,88,37,0,13,0,0,31,75,0,0,58,0,0,0,56,0,0,13,95,0,30,0,28,31,20,51,0,0,5,0,53,0,57,45,23,48,19,0,24,44,35,49,44,91,0,1,15,0,24,100,54,0,26,34,35,18,9,16,17,12,51,6,3,10,27,18,0,0,1,48,100,19,1,49,0,39,45,30,0,6,0,20,8,27,419,17,15,35,25,20,303,40,10,65,10,33,28,0,0,36,7,10,28,0,0,152,0,12,29,24,56,303,49,10,32,25,16,21,5,43,51,0,11,0,15,26,0,0,14,15,39,11,29,85,20,28,7,51,16,0,37,47,0,14,57,42,0,0,42,0,11,32,73,11,27,20,31,70,34,0,12,22,0,0,0,10,17,13,27,10,33,0,21,32,0,20,102,0,80,0,0,19,33,30,0,27,480,0,43,139,1172,30,172,54,31,33,16,25,27,0,0,20,0,100,44,0,100,50,15,27,0,13,7,52,30,52,20,0,37,88,43,50,13,0,3,3,63,14,19,0,40,1,0,0,22,88,74,28,0,40,29,25,10,0,19,14,2,9,13,44,18,286,0,126,42,100,35,6,0,0,0,33,8,50,8,14,36,13,0,13,16,0,11,0,40,0,147,48,65,21,26,39,34,0,33,5,29,24,282,0,15,13,20,8,0,8,37,83,35,56,0,7,80,3,0,0,15,22,30,14,18,24,0,80,55,11,14,57,19,229,50,0,47,50,15,50,120,0,13,34,19,0,849,29,0,18,23,8,119,0,0,21,13,34,30,0,5,0,70,14,25,51,10,23,42,8,2130,0,0,36,0,31,50,65,18,26,27,30,19,0,0,59,49,15,13,0,43,92,0,5,0,19,0,0,38,0,0,15,24,16,85,7,5,14,0,0,13,13,32,38,50,50,75,20,6,53,42,35,21,16,37,0,0,30,17,0,100,75,7,67,39,20,48,25,0,13,12,11,3,40,0,7,38,24,0,46,0,68,24,0,29,0,21,35,29,0,0,520,78,35,21,14,20,11,11,40,0,21,1,0,14,24,4,0,0,0,13,19,41,10,24,0,14,22,35,50,0,12,87,20,10,35,49,8,16,80,55,14,8,12,20,32,20,106,14,0,34,0,9,57,0,0,33,36,66,38,17,0,0,88,0,0,28,35,30,20,21,10,25,16,50,51,0,9,13,60,0,10,23,30,18,60,2,27,30,18,0,41,62,11,51,6,30,40,70,888,0,84,0,25,82,9,1,1,17,0,0,0,28,0,6,12,0,14,0,11,22,11,17,199,16,30,15,6,89,0,27,23,0,32,37,0,22,0,6,0,8,20,85,9,59,20,0,47,7,12,1,2880,8,0,42,18,55,3,0,13,0,20,75,21,5,0,0,4,45,10,12,165,28,26,22,0,118,178,36,42,0,0,0,29,0,18,5,2220,0,31,119,21,60,43,31,27,53,27,20,272,14,50,18,38,79,0,20,28,14,0,36,12,15,0,0,22,59,0,47,35,0,0,28,65,14,19,0,10,0,0,25,74,26,32,1,0,17,0,0,25,0,5,30,31,0,22,0,28,34,34,0,60,17,13,25,0,0,44,0,0,59,45,17,66,21,23,0,70,39,24,55,0,7,0,0,0,17,11,56,13,0,30,12,0,19,43,44,0,19,41,45,36,12,0,29,0,24,0,26,67,29,0,33,17,10,21,0,19,51,97,12,0,0,43,35,38,0,40,119,42,50,42,0,0,0,30,23,0,0,68,99,27,365,0,29,0,0,0,152,0,33,18,9,0,30,0,0,0,16,6,12,16,5,32,24,88,10,25,67,26,140,4,0,20,8,1,0,63,11,18,19,13,14,30,0,8,41,14,51,0,17,0,0,21,12,36,22,13,15,77],\"y0\":\" \",\"yaxis\":\"y\",\"type\":\"box\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"rating=Negative<br>achievements=%{y}<extra></extra>\",\"legendgroup\":\"Negative\",\"marker\":{\"color\":\"#FFA15A\"},\"name\":\"Negative\",\"notched\":false,\"offsetgroup\":\"Negative\",\"orientation\":\"v\",\"showlegend\":true,\"x0\":\" \",\"xaxis\":\"x\",\"y\":[5,0,0,64,0,21,0,11,19,0,0,15,0,90,21,0,52,50,50,50,7,11,36,133,0,0,0,0,1317,0,0,0,0,0,0,50,0,0,0,30,0,0,48,33,45,10,0,83,44,0,0,0,0,0,0,0,27,33,0,0,0,9,29,0,4,0,0,0,0,0,14,0,3,13,10,0,20,0,0,22,7,51,12,8,0,0,0,43,0,500,9,0,67,0,0,0,0,0,0,7,21,11,0,0,0,0,0,4,0,0,12,29,0,0,9,0,60,16,30,0,0,30,12,0,26,0,20,0,0,25,0,29,25,0,23,41,8,59,31,0,0,27,38,8,8,0,0,16,0,5,0,40,6,35,38,0,224,0,0,0,0,0,0,0,0,12,21,12,0,7,0,590,129,0,0,13,74,27,9,61,0,0,17,0,17,1,10,0,6,29,5,0,0,1,0,30,0,0,10,0,20,1,10,2306,13,50,12,480,26,0,0,0,37,47,0,0,0,0,0,7,0,44,0,17,16,0,11,0,1,0,0,41,46,7,0,0,80,0,0,20,36,0,10,34,0,0,0,33,3,50,0,25,0,0,0,0,0,30,0,0,0,0,0,0,13,0,0,0,88,0,0,12,45,41,0,16,0,10,0,19,0,0,9,0,12,35,20,0,64,21,30,41,12,32,11,0,21,4,22,0,0,0,0,0,44,1,0,0,0,10,0,0,12,0,1,14,0,0,6,34,22,29,9,0,14,24,24,0,0,0,49,0,0,185,0,0,0,0,17,48,0,0,5,8,0,8,0,0,0,995,0,0,0,40,15,15,0,0,101,0,5,0,0,20,0,12,650,0,29,0,49,40,26,0,0,0,0,6,8,17,70,0,0,0,0,50,0,28,0,0,12,0,0,0,5,0,0,0,18,9,0,0,0,38,0,175,0,27,30,32,4,6,0,0,159,21,0,0,0,15,0,0,0,12,40,16,0,0,0,21,50,4,0,191,0,13,0,0,12,5,206,0,52,7,0,0,53,0,0,9,0,11,12,1,57,12,51,0,22,0,10,0,45,0,0,8,35,0,0,0,43,8,55,0,9,44,0,13,17,0,0,0,30,720,0,0,10,0,0,0,0,14,0,52,0,0,30,21,0,0,1095,3,0,94,6,0,9,11,0,0,16,23,13,0,12,0,0,53,157,30,0,0,7,12,0,0,0,24,15,0,39,0,61,4,0,20,21,0,9,0,37,1,20,0,40,27,41,18,0,13,0,35,13,4977,0,30,45,36,0,0,0,0,87,106,8,0,10,26,34,0,0,27,0,8,65,52,0,20,0,0,0,0,5,36,0,1,25,0,17,17,15,9,0,14,21,7,6,0,10,0,0,0,31,0,11,10,0,0,16,30,0,13,24,23,0,59,26,0,14,0,66,0,13,39,0,0,20,6,8,34,0,20,13,237,0,38,0,0,0,0,15,36,34,20,0,103,19,40,0,25,48,0,0,0,54,0,61,16,38,38,27,4757,0,30,48,55,0,15,0,0,44,505,34,73,0,13,56,0,21,0,20,8,160,24,0,11,0,9,0,0,0,25,12,0,0,20,0,0,3,13,0,0,0,0,0,26,2,0,28,6,21,60,0,19,32,0,0,27,25,35,32,0,40,20,72,0,55,6,30,0,0,0,0,17,0,8,1512,0,81,0,31,74,0,47,9,10,0,0,0,0,6,0,40,89,0,0,0,12,47,0,10,18,33,0,45,260,0,0,19,38,0,0,38,2,5,14,5000,17,29,8,27,0,59,12,14,40,12,0,0,0,0,0,55,0,15,63,43,0,0,0,0,0,33,10,0,22,20,0,16,0,8,0,11,20,21,0,0,0,0,0,8,67,5000,46,42,0,12,0,34,10,21,46,0,0,0,0,13,16,0,99,25,0,5,0,33,21,0,0,19,42,0,0,0,110,0,28,0,0,0,45,22,66,0,16,2,50,0,0,300,49,0,0,0,57,0,0,0,53,0,17,10,0,0,0,0,11,0,0,0,0,0,50,6,30,38,0,0,0,10,0,0,0,24,0,58,22,50,90,5,40,11,50,14,6,0,0,0,23,0,0,0,38,0,3,79,0,0,0,0,0,33,12,30,0,19,7,0,50,32,0,210,0,0,37,0,13,34,5,9,9,13,36,38,101,0,64,0,11,93,0,0,10,34,15,0,0,15,0,0,17,0,5000,0,0,50,9,8,0,0,0,16,44,0,0,0,16,45,0,44,0,0,24,15,27,17,21,7,0,21,0,0,46,14,25,0,0,0,31,7,0,0,0,0,0,0,49,0,21,3,0,13,10,0,0,0,6,30,0,50,0,0,26,0,20,9,17,0,0,0,17,0,15,0,45,0,95,0,17,0,53,16,10,49,20,21,18,50,8,71,44,0,4,13,11,0,0,0,51,11,6,13,14,10,31,81,0,0,0,75,18,2,18,23,0,12,0,26,0,17,6,0,7,12,0,18,0,29,0,0,0,0,2,0,0,0,0,18,0,24,0,0,50,32,30,0,48,0,0,0,55,0,5,0,76,0,0,0,20,11,178,0,0,0,0,0,23,0,97,0,0,0,14,27,0,82,18,0,0,96,23,0,10,45,0,0,0,37,30,0,13,54,0,2008,0,18,5,21,55,0,0,10,13,10,0,11,0,12,15,17,0,0,0,13,8,0,37,0,19,27,44,41,11,13,0,0,0,0,20,0,0,0,0,8,0,0,0,84,0,4,1090,1009,35,4,0,0,3,6,24,0,0,33,6,0,10,0,0,100,15,17,0,14,0,5394,12,26,30,23,18,14,50,63,0,0,0,41,0,186,0,0,26,89,0,0,12,0,25,0,0,0,0,0,500,0,3,29,0,0,29,20,20,0,49,73,56,18,82,0,0,5,0,11,0,119,20,0,134,52,0,0,29],\"y0\":\" \",\"yaxis\":\"y\",\"type\":\"box\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"achievements\"},\"type\":\"log\"},\"legend\":{\"title\":{\"text\":\"rating\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Distribuci\\u00f3n de achievements seg\\u00fan rating\"},\"boxmode\":\"group\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('25d61db9-17af-44b1-abb2-09dddaf91b7d');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.box(df_train, y=\"average_playtime\", color=\"rating\", log_y=True, title=\"Distribución de average_playtime según rating\")\n",
        "fig.show()\n",
        "fig.write_image(\"avg_playtime_rating.png\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "xcIW4ac7Gv37",
        "outputId": "19da1ea7-8276-4e06-9bd0-b9cd9c3c9a8c"
      },
      "id": "xcIW4ac7Gv37",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.16.1.min.js\"></script>                <div id=\"f787e436-6ae6-4511-85f6-47deaf5ea98f\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"f787e436-6ae6-4511-85f6-47deaf5ea98f\")) {                    Plotly.newPlot(                        \"f787e436-6ae6-4511-85f6-47deaf5ea98f\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"rating=Mixed<br>average_playtime=%{y}<extra></extra>\",\"legendgroup\":\"Mixed\",\"marker\":{\"color\":\"#636efa\"},\"name\":\"Mixed\",\"notched\":false,\"offsetgroup\":\"Mixed\",\"orientation\":\"v\",\"showlegend\":true,\"x0\":\" \",\"xaxis\":\"x\",\"y\":[0,65,237,0,73,0,46,0,64,227,374,0,0,5193,0,0,0,0,0,0,100,308,82,28,44,126,0,0,320,0,0,235,226,2218,0,35,0,0,0,0,268,181,0,32,174,0,341,121,0,201,5,0,0,325,1024,0,0,0,2834,0,281,139,0,0,55,88,0,15,242,322,1686,229,0,0,1716,0,0,0,0,0,268,1597,0,270,2766,0,0,0,0,584,0,207,0,68,41,0,280,8,67,229,141,0,382,0,187,12,0,82,347,0,3,206,0,413,0,0,1255,0,0,0,0,0,112,5185,341,0,9,0,0,63,14,114,412,0,0,239,18,12,0,180,0,0,0,0,731,0,0,0,541,82,261,0,0,0,163,227,863,274,456,0,205,20,0,230,0,1,201,0,214,244,0,378,0,209,2380,0,645,95,1869,0,0,16,0,2819,0,0,201,150,40,190,277,251,313,100,38,0,454,0,0,0,0,0,0,280,0,465,56,17,0,0,394,74,30,0,9,243,0,0,0,3497,0,299,338,246,0,0,0,217,0,146,0,0,0,1772,15507,0,0,81,0,0,0,349,29,9,8,0,157,155,294,0,0,0,0,0,0,639,3498,87,1,1,288,0,0,0,209,0,266,0,0,0,35,0,0,173,0,298,17,0,611,161,0,501,6512,220,46,217,0,0,0,0,0,0,129,0,43,0,341,27375,0,677,4164,247,0,0,997,596,17,0,0,236,0,116,330,0,338,0,252,0,0,27,0,0,0,131,0,0,218,415,0,91,282,355,354,0,309,80,0,478,0,319,0,175,216,2180,116,0,1,0,84,0,0,431,0,0,200,223,88,8180,97,0,304,0,0,85,0,10,0,0,6,24,0,185,280,1,0,0,22,429,0,0,106,222,0,383,0,111,231,0,88,0,14,0,0,0,405,181,209,0,0,345,0,0,476,50,0,8,0,217,0,949,0,0,0,0,1416,0,0,0,0,217,0,107,777,447,999,0,133,1930,0,0,5,272,0,62,1854,0,0,11,282,212,1824,379,1160,0,0,273,0,0,0,0,0,309,145,200,187,342,66,0,0,253,0,194,281,0,504,186,135,9,33,1529,183,285,0,0,94,91,0,0,1,52,28,220,0,2078,204,227,0,0,0,11,230,134,0,0,682,9,561,1868,0,0,82,30,0,0,0,222,384,119,234,5,0,2957,0,0,142,3,26,916,308,0,289,14154,0,3371,256,225,0,0,102,0,0,277,0,134,4,1014,0,0,0,0,160,1034,0,0,863,0,0,19,222,148,64,130,25,268,0,0,283,76,0,2259,0,0,0,148,413,220,0,23,0,325,0,0,12,75,0,0,254,0,162,34,0,0,125,503,200,0,43,13714,11,154,0,0,0,0,64,2138,0,0,0,269,0,681,0,258,50,9,198,0,0,0,0,0,252,96,314,6,0,6,232,0,46,0,241,365,0,545,0,288,0,246,418,332,0,0,619,209,4252,388,0,1264,0,0,132,0,0,337,5,0,0,143,233,3,0,0,873,450,0,1042,360,0,0,0,0,21,0,0,6,133,1866,0,135,0,124,586,0,180,0,214,0,351,0,962,0,74,0,0,831,202,0,0,0,27,0,288,232,89,220,15,457,31,9,0,557,318,292,3,24,0,0,0,328,0,0,0,0,7,0,317,229,1543,0,0,2018,0,0,136,1,1,312,0,0,478,889,54,0,100,0,0,0,0,0,69,247,0,147,0,210,0,0,0,0,8,0,233,49,71,437,348,0,161,4823,0,28,55,15906,0,0,220,0,0,26,7,11,1176,0,0,0,23,0,0,4866,0,206,0,0,592,0,149,0,0,157,518,13,0,0,130,0,31,0,7,195,0,0,19379,0,127,0,171,225,0,0,0,14,189,0,0,3,201,0,199,287,0,244,0,0,198,0,0,174,0,36,0,472,220,359,0,0,113,0,0,44,0,962,0,332,1,0,270,0,0,262,604,60,0,0,11,3,284,9,0,0,20,312,10,0,0,0,180,607,0,422,0,214,256,270,0,652,89,297,0,0,0,613,440,254,209,0,0,387,0,705,0,134,500,0,0,222,0,59,104,289,0,0,4,0,0,0,163,0,0,4925,259,0,0,0,206,284,0,2,0,0,0,404,105,0,20,29,0,441,319,14,748,0,647,8159,0,32,284,0,408,0,260,20,7235,0,114,184,934,70,0,0,0,48,0,0,0,364,278,0,0,0,0,0,0,499,0,0,236,0,64,0,145,0,0,810,0,131,285,0,0,0,434,0,42,240,0,0,273,0,326,0,0,23,0,0,0,0,125,0,0,22,31,165,195,72,0,127,330,346,0,873,0,0,151,1709,8,404,288,49,0,713,0,0,0,524,2,91,489,153,128,103,0,319,0,0,6,0,242,0,0,991,0,94,0,0,0,0,6,91,266,0,8,0,195,0,151,0,87,0,192,408,0,0,0,1441,0,0,29,2860,0,342,0,317,0,272,0,0,0,414,0,0,2112,773,155,96,0,425,35,0,879,72,0,0,327,0,51,279,0,0,306,155,0,0,0,0,37,9,0,0,0,0,0,0,15,0,0,0,307,34,0,0,21,0,249,0,39,0,0,186,275,222,0,4431,0,0,338,2,112,244,0,0,0,2951,0,73,11,222,261,14,0,0,200,16,67,0,0,115,53,0,527,0,381,253,0,0,1154,0,0,0,182,0,322,236,22,0,236,0,550,856,294,0,754,281,211,0,76,0,0,0,3,0,0,6,0,274,5046,0,0,0,0,0,0,0,0,0,248,0,0,0,0,327,199,170,5647,121,250,386,0,658,36,238,0,0,435,219,0,0,20,0,50,0,2119,0,188,0,3835,8,0,0,133,242,0,215,1180,0,277,0,161,0,0,0,9,99,0,3,46,0,0,12927,0,140,290,0,0,0,214,0,0,0,11,0,0,115,0,13,0,4,0,191,38,43632,0,0,0,0,1294,63,0,337,105,374,0,73,0,267,0,179,0,0,0,666,0,0,0,864,0,557,0,0,28,0,0,0,0,3,0,0,467,29,0,0,351,763,0,46,0,41,55204,0,0,58,206,0,54,0,0,280,0,73,0,0,434,223,329,0,0,10,86,0,131,184,0,3,215,0,0,0,11,0,0,0,934,7,152,0,1,317,0,879,0,82,235,798,0,3,0,0,0,0,0,0,57,0,726,210,0,0,242,0,0,139,221,0,523,951,61,2616,0,73,169,0,0,309,648,0,90,0,48,176,1,1195,0,664,86,0,396,0,68,10,112,225,0,932,0,0,2225,291,0,0,1,279,926,0,175,0,0,272,0,0,654,0,0,0,0,657,2098,2075,391,0,44,133,273,0,0,239,11517,0,0,2129,0,374,0,296,0,137,0,0,0,0,175,462,0,0,27,0,276,0,0,0,53,236,0,0,0,0,42,0,312,2,278,0,277,0,56,0,0,0,0,243,0,7,0,238,0,194,679,319,0,0,583,0,25,195,0,438,0,0,9,0,0,196,0,22,0,0,0,211,71,114,0,0,254,204,0,0,0,10,8,305,0,0,0,0,227,571,1,489,757,108,0,0,0,256,0,0,0,0,0,0,771,236,126,246,0,9,0,0,0,449,777,267,441,239,0,0,0,199,0,0,0,463,0,309,194,9,0,4975,0,0,157,9,0,0,591,271,0,0,10575,212,0,49,260,0,0,41,190,241,4545,0,17,1536,868,28,418,220,29,218,49,0,5,0,106,1649,71,0,141,0,193,0,0,367,231,12173,9,0,276,0,0,239,0,1388,5402,497,282,0,0,8,0,0,0,0,0,0,0,0,42],\"y0\":\" \",\"yaxis\":\"y\",\"type\":\"box\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"rating=Positive<br>average_playtime=%{y}<extra></extra>\",\"legendgroup\":\"Positive\",\"marker\":{\"color\":\"#EF553B\"},\"name\":\"Positive\",\"notched\":false,\"offsetgroup\":\"Positive\",\"orientation\":\"v\",\"showlegend\":true,\"x0\":\" \",\"xaxis\":\"x\",\"y\":[217,1240,513,53,2910,581,0,0,146,0,14,0,91,85,0,0,239,0,0,474,94,245,0,1325,2,0,689,0,521,0,45,6,2170,0,0,0,0,296,323,0,102,3,0,0,28,0,2575,0,279,400,133,0,96,152,0,0,46,0,285,0,0,145,120,0,63,1702,305,0,13,330,185,49,0,0,123,109,227,282,0,2,184,111,223,0,1004,1636,0,0,0,0,2,522,0,0,0,0,0,0,0,188,115,0,198,323,0,122,1,17,0,0,6,0,0,93,33,644,0,1045,1,517,2511,18823,130,1255,880,0,335,176,228,993,427,0,137,20,132,0,229,951,0,16,2492,20,102,0,1,0,272,0,140,881,0,507,254,308,0,0,9,0,20,529,0,538,36,338,221,230,0,1560,0,267,0,231,0,0,1360,0,306,484,1756,153,0,0,196,22,0,0,323,337,0,0,85,73,0,0,868,157,744,0,173,0,21,306,490,0,0,0,0,3176,0,2,139,200,359,0,0,0,3584,0,0,0,19,0,444,178,57,173,578,0,569,196,86,756,0,0,1712,0,0,19,13,121,0,0,5,183,0,0,151,211,0,87,0,0,6332,0,399,0,0,0,583,15,210,0,970,0,153,417,0,0,439,118,142,11,63,203,0,26,0,462,164,0,216,237,0,6,0,88,62,0,346,0,0,3601,326,70,221,133,17,3233,20,0,0,165,2,988,0,117,221,0,257,0,951,670,167,55,752,17,0,120,0,2661,0,0,8659,10,0,0,0,538,159,0,32,148,1718,54,0,3151,172,0,0,0,27,102,0,0,72,0,59,0,21168,0,21,282,0,0,0,0,99,34,0,21,0,999,186,0,0,0,95,1536,247,292,0,0,0,148,255,526,0,138,60,157,49,135,0,80,471,132,373,5,75,21,0,0,142,94,0,230,0,69,628,143,0,0,274,0,0,0,269,123,265,0,241,103,0,0,294,732,0,0,362,243,0,84,449,140,282,1,157,2,478,1262,35,0,0,0,0,204,0,902,4,17,0,0,0,0,501,174,0,0,3234,61,505,0,320,0,15,0,9352,3,3189,284,709,43,0,0,278,0,466,0,196,206,364,0,12,229,108,0,427,224,0,761,0,348,0,66,51,633,7504,233,0,0,150,0,0,0,301,82,311,912,522,13,0,0,297,1225,1103,13,0,319,0,1,2,0,433,0,0,1117,48,0,0,82,143,1891,0,139,0,2,40,9,0,187,212,109,0,0,0,539,0,278,0,0,0,0,29,2,222,0,12,129,0,75,295,994,663,8,188,16,0,0,0,0,26,1164,0,0,300,143,0,0,0,586,0,0,0,0,0,0,312,0,1153,0,0,19,669,1218,0,7,0,90,0,0,199,346,7,0,52,0,37,3,185,187,21,0,1595,570,95,121,245,59,117,285,121,0,0,288,103,0,1149,0,128,116,46,3925,95,431,254,93,80,453,175,97,0,0,0,124,0,348,701,65,157,386,4721,3,2580,356,216,906,0,301,329,0,29,168,0,0,0,352,443,7,0,358,291,0,0,0,0,309,67,254,0,0,587,0,12984,3967,0,151,0,3007,100,0,76,77,0,73,321,37,0,272,0,0,0,4678,4420,2967,207,0,13,202,0,331,0,381,617,305,208,627,572,30,0,0,655,325,0,0,303,0,183,0,82,0,175,170,0,256,233,25,0,214,1213,1445,1711,191,0,409,0,59,0,0,948,0,283,0,52,173,19,0,542,0,131,477,195,0,606,37,0,0,100,577,0,493,291,6704,125,773,0,158,266,0,331,249,0,3830,0,0,891,2355,0,63,1108,9,128,48,0,259,1048,614,244,225,0,0,0,716,0,0,0,311,225,0,301,117,0,0,0,169,608,0,0,0,240,216,0,177,197,361,0,0,15,169,0,16,10,17,1683,0,293,0,0,0,0,362,402,133,0,636,178,1234,244,233,1177,75,0,0,319,0,286,69,4730,62,365,193,0,84,47,112,3140,240,172,0,0,0,8,0,0,0,1,0,38,0,0,136,238,575,25,0,203,0,302,54,791,1834,698,0,193,0,178,1371,0,732,0,12,0,127,99,0,2059,4,0,1366,0,0,670,564,0,0,199,0,0,0,935,137,37,0,0,1617,0,0,168,0,0,838,305,247,0,160,0,0,311,0,0,167,396,0,98,0,0,835,1387,167,6516,206,1207,226,248,0,109,0,862,169,215,17,30,0,274,97,41,3,260,0,207,174,110,0,256,0,1329,20,273,1084,140,278,0,972,0,278,307,0,0,0,229,0,229,0,0,0,3739,278,17,2234,0,91,0,0,240,2,0,41,0,334,0,435,0,315,14620,0,524,73,0,200,364,26,0,0,231,0,213,0,0,646,0,135,822,313,220,411,229,0,1265,79,0,0,432,0,48,290,1209,229,338,373,0,0,31,613,222,0,39,0,237,423,0,618,0,0,239,673,1142,0,0,0,0,312,0,0,0,297,535,0,487,0,186,255,121,224,316,0,289,44169,0,78,124,0,0,508,0,0,126,0,0,0,607,39,0,0,21,0,201,6,0,158,0,0,0,672,0,736,264,0,0,0,0,162,0,324,157,150,9742,527,92,28897,636,62,0,0,0,0,3020,368,0,50,0,805,466,0,1,513,29,0,224,181,0,1,74,0,22,223,539,9,0,141,0,0,376,0,1024,260,327,0,14,0,296,1,0,1351,63,502,331,316,0,555,0,192,0,20,361,127,113,0,365,0,438,1922,267,3,24,554,27,102,0,0,0,428,320,182,23944,0,198,0,1614,17,409,283,0,449,18,0,360,0,674,0,0,254,306,0,0,326,190625,232,229,0,4367,0,372,133,384,0,248,0,0,0,355,0,0,0,353,0,283,2832,0,613,0,127,14,86,134,91,0,0,488,0,0,1159,0,294,49,107,97,325,0,24,149,0,1163,477,255,0,301,0,0,17,0,257,257,0,0,0,183,0,219,279,0,97,0,216,186,0,0,0,116,0,0,1046,270,7,0,1355,335,337,2672,0,363,0,1818,0,0,803,853,0,69,148,0,0,0,198,0,0,765,1047,0,226,0,0,0,0,0,0,0,308,121,8,80,11,0,0,0,126,76,0,169,0,621,0,9848,231,352,716,0,0,206,0,0,8,863,0,30,0,2,289,292,0,0,200,0,252,146,5,278,0,37,0,0,0,1397,0,0,4289,99,154,0,0,0,0,418,0,238,126,6,0,630,0,0,0,166,262,0,21247,82,0,408,644,22,0,283,0,0,321,1,227,28,5,0,0,316,22,0,604,0,162,954,0,0,56,807,0,0,8,0,1904,675,469,0,0,0,0,0,0,0,3975,1326,639,47,2735,234,0,1623,0,453,285,252,69,836,0,0,0,46,0,0,507,223,0,222,324,232,0,0,1251,159,443,0,244,351,0,0,96,0,0,0,629,164,51,237,0,0,0,260,307,1752,288,0,0,0,0,0,86,0,0,0,0,0,137,0,0,325,1070,0,1121,257,0,0,0,0,228,1055,100,147,333,33,17,23,0,221,17,18,271,146,207,0,0,0,46,192,890,434,1240,0,0,280,0,0,0,8138,0,31,570,128,0,222,300,1871,0,1559,826,277,1,0,0,445,105,0,902,0,47,7,123,37,4,8,0,6,1518,0,37,185,0,0,487,313,0,0,0,4,0,0,3,0,34,497,250,43,54,0,77,0,303,275,0,411,0,533,0,90,1270,0,454,85,58,0,0,0,7194,0,50,0,0,0,0,0,0,871,58,90,198,505,342,0,0,1,0,227,262,0,254,6,518,23,189,259,0,0,0,271,723,0,32,0,100,276,0,0,59,0,335,0,145,0,171,272,0,12,73,203,0,147,193,184,243,9,0,195,658,1073,740,188,93,491,9413,152,0,1051,636,75,12,4,0,2,108,18,0,227,1336,0,2021,280,0,84,153,0,0,0,27,17,297,132,0,100,0,273,363,199,0,722,217,0,112,683,0,178,121,16,140,260,540,1241,0,0,1330,1891,378,0,0,219,223,117,239,15,0,482,258,0,98,0,0,0,18,464,301,3,0,0,102,2201,0,0,7,1069,0,0,0,0,52,196,277,288,221,0,239,0,9,0,371,0,102,211,0,6,0,67,0,283,0,418,387,648,42,223,3,44,435,14,1166,365,2377,145,0,0,0,716,767,3,3531,3107,0,0,0,0,85,714,188,384,600,0,70,214,190,83,0,1812,0,250,0,326,63,27,194,20,54,0,170,0,52,0,333,1221,125,1349,0,601,54,67,0,0,0,72,249,207,331,8,0,451,0,0,168,7,0,350,0,43,0,110,53,54,0,224,202,0,0,67,0,14,5,268,0,29,38,30,0,450,260,0,221,130,176,0,316,201,38805,12,0,0,360,140,7919,80,63,0,20,0,0,16,0,0,0,80,0,0,0,16,0,206,0,0,1160,0,0,7,2022,0,0,0,15,0,0,183,0,0,0,50,0,672,0,553,0,18,2162,286,21,0,153,527,0,0,0,0,319,254,294,0,0,168,0,331,0,0,322,801,0,432,99,254,0,188,0,0,0,189,0,6,297,584,2908,306,5,0,31,357,220,10,239,0,0,990,70,14,0,2747,1345,79,261,0,233,1475,28,0,0,0,0,396,0,0,120,209,0,660,1244,0,1069,131,0,84,132,637,0,40,0,25,0,354,1595,271,170,0,46,211,593,0,213,0,275,112,341,0,0,65],\"y0\":\" \",\"yaxis\":\"y\",\"type\":\"box\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"rating=Mostly Positive<br>average_playtime=%{y}<extra></extra>\",\"legendgroup\":\"Mostly Positive\",\"marker\":{\"color\":\"#00cc96\"},\"name\":\"Mostly Positive\",\"notched\":false,\"offsetgroup\":\"Mostly Positive\",\"orientation\":\"v\",\"showlegend\":true,\"x0\":\" \",\"xaxis\":\"x\",\"y\":[245,0,224,61,232,556,4,875,0,0,0,0,289,0,0,0,276,0,0,281,0,0,0,0,840,399,0,0,0,250,1373,0,333,229,0,37,10,368,0,1164,244,607,0,213,1409,12952,123,0,80,1,0,42,0,278,0,77,0,0,245,0,0,6,760,0,0,0,133,1,0,0,0,0,0,2147,251,305,517,127,43,135,3,83,221,0,242,0,0,382,243,189,0,826,26,0,0,242,416,146,71,0,4048,0,162,6,0,10659,267,0,222,518,752,27,1954,317,0,234,0,517,921,0,0,82,0,0,20,495,268,0,483,192,166,75,0,26,419,139,0,126,0,0,1084,0,0,1069,54,1278,11,0,120,0,252,346,3958,0,8,139,252,0,0,111,0,0,1273,130,195,0,174,260,132,0,262,276,0,0,0,3292,434,112,53,5123,101,0,5889,0,0,209,76,385,0,0,0,0,73,0,2639,134,6362,45,0,0,0,0,218,0,0,10,0,0,267,261,282,0,4104,422,0,0,0,0,0,0,254,1413,211,0,2418,338,0,971,96,0,0,0,90,0,0,337,0,0,953,220,0,16,140,0,0,2991,0,0,5,214,0,49,0,117,0,50,137,324,0,0,1,0,0,0,0,947,13,0,49,0,0,0,0,439,0,672,0,0,172,235,1232,519,144,219,224,0,0,0,1545,3,10,645,78,0,40,0,430,0,223,0,957,0,0,1432,0,0,307,640,99,0,289,0,152,0,0,136,869,337,0,0,891,0,0,0,43074,414,36,0,0,272,0,99,78,0,46,62,321,9837,0,0,0,75,1293,5,5760,1369,228,92,0,34,0,0,136,4,506,73,77,1854,54,0,586,75,57,102,228,143,667,253,135,216,1687,0,548,13,490,2016,300,0,15,284,67,0,0,187,10,0,17,342,169,156,307,0,80,107,0,39,1,187,0,0,0,0,0,14,0,0,10,350,0,0,137,0,175,0,0,0,0,150,190,1610,429,223,163,282,0,225,17,0,596,0,0,0,0,0,0,0,0,132,133,177,386,0,276,0,261,0,89,0,386,0,53,257,0,0,0,0,0,248,2654,213,4,41,0,359,162,551,152,15,0,28,3824,0,81,0,0,0,155,221,0,0,40,232,257,33,118,0,169,8,111,0,282,0,408,0,144,1556,0,14,249,0,51,234,0,112,156,0,28,0,101,84,1571,0,0,303,0,180,133,0,132,0,0,128,0,435,0,347,0,0,1,9,0,202,53,495,0,359,90,0,0,257,98,0,0,284,217,42,0,0,0,6,0,0,837,3,250,0,0,0,45,0,469,50,0,0,388,100,0,422,0,27,152,193,710,196,0,0,0,125,292,0,744,0,53,0,317,714,0,0,3,28,296,54,0,4,0,149,809,0,146,991,258,0,949,0,0,247,0,0,552,322,1242,28,53,14,0,0,239,383,13,0,0,0,0,16,216,0,0,10,5442,188,759,1433,310,132,0,942,72,0,1136,76,0,0,0,0,0,139,5,189,0,0,217,0,14,0,0,366,0,2454,480,0,210,182,0,171,36,0,0,0,1,0,17954,0,0,429,221,0,466,339,103,467,0,0,0,0,0,0,264,0,530,0,2602,352,0,0,0,194,219,183,78,0,295,862,219,319,217,0,0,0,0,165,1364,0,1334,0,510,0,647,0,0,0,0,0,252,0,95242,13,0,812,19,91,281,239,0,65,0,0,27,0,0,0,0,345,1360,1200,255,31,64,0,35,0,241,501,9,0,0,219,0,348,0,20,130,55,102,0,0,0,0,0,215,237,466,2721,0,93,0,0,1388,406,8508,0,0,0,0,109,114,0,0,73,135,0,0,0,199,0,0,0,15655,2,34,0,5439,154,173,13,215,142,36,52,519,0,794,108,0,98,0,332,0,7,0,0,385,0,23,0,0,0,72,0,44,0,588,0,0,14,0,168,0,605,40,318,0,95245,16,251,20,3,0,1,20,271,162,370,0,369,56,44,0,21,0,271,0,214,272,150,0,5,258,0,0,96,175,282,25,8,177,0,129,161,0,0,453,467,0,238,0,0,715,0,36,583,312,0,0,0,0,0,0,0,773,84,0,1661,1,0,422,96,271,0,321,97,663,0,9,939,23,0,253,130,271,1030,166,0,9,18,124,311,0,163,2025,0,2197,803,38,131,2514,249,13,233,0,0,0,0,96,102,114,0,0,108,0,77,0,347,74,69,0,0,0,0,0,159,84,23,93,172,0,0,1848,0,53,53,0,237,400,0,0,0,0,35,0,36,284,85,943,0,138,1102,264,220,186,478,0,443,307,213,0,13,25,1108,0,0,1905,0,479,0,261,36,136,892,0,0,0,121,0,0,1399,0,0,656,241,0,0,0,0,298,0,179,143,2990,203,0,0,0,0,0,126,0,0,0,228,187,0,1,57,4,485,0,0,0,115,0,2953,168,0,0,0,0,0,137,0,992,0,0,0,283,2,277,363,2902,2343,340,0,0,0,87,0,299,0,373,0,0,191,0,0,0,0,0,11,19,0,3865,0,322,0,231,12,0,337,0,29,388,0,3315,0,0,0,0,17,139,0,119,0,199,0,0,0,0,0,777,503,237,0,296,423,0,189,84,140,0,0,231,192,109,213,424,20,0,0,0,308,533,169,0,0,452,121,124,0,0,0,0,0,0,0,1,419,736,0,381,216,0,0,0,0,48,23,232,31,0,0,0,67,0,214,0,0,168,0,0,0,77,0,0,0,969,0,0,0,564,819,0,0,68,0,0,0,529,0,3,1394,0,21,301,0,778,142,107,121,396,260,107,168,0,0,1602,0,1231,283,3,0,1244,4822,202,19,0,94,181,142,2583,2938,1373,118,43,0,0,0,0,156,11,0,0,16,0,2550,0,173,39,14,10,0,148,4200,0,48,0,0,0,198,13,129,0,0,724,724,0,0,50,1,315,23,14,195,1201,189,0,0,984,1448,0,0,0,0,105,1062,723,61,174,183,0,172,10,89,363,1264,180,0,0,0,0,332,215,0,0,135,1064,14,0,0,1987,365,0,0,52,151,0,0,0,231,0,130,361,0,5904,849,1846,256,34,10,1642,216,337,1,574,57,0,0,0,34,0,0,1266,0,0,2106,7,0,127,0,1016,0,0,0,430,382,15924,0,284,0,0,0,422,0,0,240,101,282,1835,0,0,17,0,372,603,5,0,6,0,0,0,0,0,27,0,0,0,0,815,329,0,201,851,0,341,0,432,0,0,149,377,0,0,241,0,1497,101,0,13,380,991,0,0,280,0,65,0,0,392,387,0,0,0,0,69,796,518,180,61,547,1492,0,276,29,91,13,35,330,11,0,0,508,0,617,913,1937,0,0,1508,0,264,530,46,0,103,257,128,0,245,135,0,0,204,169,4,32,1423,520,0,1,237,0,112,55,428,162,52,3610,273,0,0,93,381,0,0,104,0,0,448,64,216,199,224,1641,12,0,1,76,182,0,313,292,0,0,0,21,0,9,0,567,435,177,42,0,188,0,864,0,0,48,382,0,43,0,357,2287,586,47,0,0,0,11,42,105,21,0,0,112,288,171,1587,0,152,0,245,0,184,235,0,258,0,490,0,247,0,0,0,0,0,0,0,143,0,544,8368,0,0,0,0,1454,0,0,0,263,280,0,0,1425,310,592,145,0,270,243,0,200,0,7999,0,320,3456,0,167,87,0,0,7,97,226,51,0,0,342,0,218,0,0,0,83,0,0,1278,291,14,89,139,14,1296,408,79,290,45,5,341,326,0,189,0,0,0,0,141,0,243,2729,377,206,0,0,0,0,0,0,156,250,64,134,413,2,0,0,0,72,0,0,1667,0,0,0,182,267,437,154,0,238,0,4623,153,0,0,0,465,0,234,19,0,0,22,0,484,257,3194,0,247,69,151,276,4,4277,0,243,277,3,104,50,0,0,0,272,107,0,23,150,0,0,450,4,205,0,0],\"y0\":\" \",\"yaxis\":\"y\",\"type\":\"box\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"rating=Very Positive<br>average_playtime=%{y}<extra></extra>\",\"legendgroup\":\"Very Positive\",\"marker\":{\"color\":\"#ab63fa\"},\"name\":\"Very Positive\",\"notched\":false,\"offsetgroup\":\"Very Positive\",\"orientation\":\"v\",\"showlegend\":true,\"x0\":\" \",\"xaxis\":\"x\",\"y\":[5017,0,266,298,841,1446,0,0,0,54,1569,0,371,314,0,1737,41,14,5,1,1094,419,43,287,239,263,156,0,0,228,0,0,0,0,0,762,0,39,0,0,75,0,0,0,0,64,47,3248,0,82,0,0,347,892,0,56,317,165,0,235,0,236,0,189,34,256,3,4187,167,0,125,0,0,0,0,0,0,1624,171,0,592,134,287,0,1911,99,0,0,135,0,817,307,367,1008,2868,130,167,3556,0,227,234,30,16,135,899,674,0,223,1254,469,0,2331,1328,705,1584,0,1417,764,863,0,32,229,256,0,207,464,177,493,143,162,0,124,0,120,1554,341,0,324,0,0,800,447,950,79,1993,207,0,2033,0,0,0,371,0,515,607,0,0,0,2379,0,142,751,413,1520,799,0,823,160,1731,296,200,6,0,1616,1,148,385,0,1286,421,0,533,344,124,275,526,310,807,1,0,207,0,518,0,0,0,0,15907,8,4583,475,2191,0,454,175,82,0,0,215,420,0,147,7117,0,116,1,0,0,294,0,0,129,0,25,0,388,0,74,805,303,405,2235,537,774,0,0,166,0,95,446,2356,0,571,719,213,26,1127,404,143,297,0,0,28,223,527,803,233,414,0,0,0,0,318,0,0,0,7089,768,0,0,437,0,203,5,242,0,622,455,0,193,0,1135,897,8,0,498,127,286,0,185,0,0,0,0,8,6345,0,222,133,178,0,0,6704,226,229,0,0,0,22,0,0,4034,315,0,0,620,350,476,818,40,150,545,0,14,187,0,0,264,255,509,173,0,0,494,478,9223,110,225,65,181,897,0,308,309,77,42,0,5845,0,325,29,0,59,0,139,232,134,21,0,1112,519,0,491,393,0,0,24,0,0,36029,230,2622,0,0,0,0,13,0,206,0,219,70,0,2343,52,0,1299,175,435,167,350,54,157,0,35,258,688,0,0,169,326,0,1030,243,2094,0,0,946,67,391,712,1625,158,80,0,250,32,345,0,0,0,74,18,0,2092,429,205,123,1,8,7,9,296,216,1228,0,117,64,31,0,0,0,180,0,0,2273,0,0,675,0,0,792,0,397,85,149,635,441,1300,221,2974,388,226,0,139,292,1678,14,310,0,2,444,1541,165,98,637,0,0,530,0,4222,916,8488,76,0,0,0,0,0,249,288,177,121,379,589,224,249,1697,1102,0,9,623,0,296,0,0,0,0,304,180,214,0,220,1279,327,3755,551,0,0,255,256,128,0,92,0,0,158,275,364,327,333,176,3,219,275,0,0,0,0,7932,73,624,76,778,215,0,0,0,282,188,862,0,284,0,11,0,691,177,0,3,7076,58,0,0,31,125,0,51,166,417,159,100,0,2038,13,0,381,24,167,278,589,3034,274,75,0,0,0,437,0,0,6679,15,0,0,1,0,739,3530,0,91,0,12422,0,11,982,140,83,2115,0,117,168,0,4760,0,346,1474,13,348,0,0,0,0,1448,9,191,180,214,2443,1,96,430,140,287,0,394,0,0,6842,225,0,364,0,17,0,0,191,21233,0,0,0,3,343,0,0,57,0,205,10647,1848,604,0,317,0,0,0,0,76,12,188,638,279,392,305,0,749,1277,0,0,87,0,237,1045,0,22,0,390,563,5263,7131,20,746,0,14,275,769,237,131,0,252,1037,12,395,0,0,478,272,389,0,0,486,137,229,0,0,295,432,0,170,35,324,0,83,887,0,309,0,57,0,249,0,1455,680,461,102,122,123,85,125,319,0,78,248,0,0,0,0,432,43,344,146,622,1470,0,0,0,369,0,34,120,0,353,1993,0,0,2741,0,371,0,72,151,0,0,543,683,691,0,0,0,2485,0,4942,0,0,25,176,270,0,178,0,0,760,162,87,10087,4,209,826,0,882,148,0,421,612,407,394,57,0,404,8495,3068,656,0,75,648,0,0,0,1111,239,0,108,217,364,270,68,68,15961,281,69,118,0,0,17,0,0,277,27,0,0,455,0,258,380,0,0,26,614,105,47,0,152,0,401,0,73,0,0,122,0,0,322,74,334,0,137,1108,0,125,1070,0,5585,188,1204,0,524,370,264,0,113,172,476,196,805,90,126,0,712,0,170,0,1107,1,1,0,0,0,147,751,0,0,0,0,49,568,0,1615,0,0,342,290,0,0,0,166,251,7,291,1087,86,496,686,140,0,0,0,750,0,0,0,58,585,0,258,707,80,257,0,154,0,5,174,0,580,354,78,332,266,194,0,501,0,547,586,494,1909,30,0,568,65,63481,662,0,0,348,15,123,183,0,784,150,163,0,1433,246,13,613,129,288,1109,0,115,1094,213,237,3651,207,512,2061,0,1,2,0,508,796,193,0,68,11,0,66,2086,241,172,568,0,431,1469,167,232,0,306,352,0,0,225,297,177,1203,0,67,324,169,230,947,55,0,0,1,25,0,0,12787,0,407,325,618,0,715,15,458,0,0,0,3079,21,18,0,789,1096,0,0,49,0,58,82,0,227,834,412,116,70,0,0,0,0,4774,3,0,212,0,0,1117,0,293,693,0,351,1225,345,218,93,0,1969,0,84,259,0,247,0,42,1,0,0,0,72,101,81,2417,0,5,0,377,170,11,139,644,0,0,19,78,4377,0,0,0,24,75,2938,260,0,128,366,289,0,0,314,935,212,293,2628,54,0,176,337,75,41,0,507,1849,280,140,69,0,129,145,525,149,384,323,0,0,0,340,679,816,0,0,0,144,1902,5,0,751,5825,196,242,1029,144,771,0,4,245,6,86,1307,880,278,1472,211,258,0,266,3350,114,101,5852,2398,351,0,33,0,480,0,0,21,0,174,75],\"y0\":\" \",\"yaxis\":\"y\",\"type\":\"box\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"rating=Negative<br>average_playtime=%{y}<extra></extra>\",\"legendgroup\":\"Negative\",\"marker\":{\"color\":\"#FFA15A\"},\"name\":\"Negative\",\"notched\":false,\"offsetgroup\":\"Negative\",\"orientation\":\"v\",\"showlegend\":true,\"x0\":\" \",\"xaxis\":\"x\",\"y\":[274,5,0,247,0,320,0,0,0,186,0,3,228,0,209,0,0,0,684,43,235,178,331,11,0,0,0,327,232,36,240,1,204,0,0,0,7,218,384,0,26,1,85,212,0,236,0,162,39,0,191,0,0,67,0,0,2,87,302,0,201,249,75,0,679,7,0,272,238,89,3,0,321,0,287,0,542,0,0,449,387,157,347,0,260,161,0,0,0,222,274,39,495,18,4,0,0,0,0,0,556,4122,1350,0,200,0,0,0,0,664,55,0,0,0,16,0,197,0,0,0,283,0,0,2,0,202,0,352,218,0,5,0,0,223,182,21,0,0,196,0,0,0,6,212,0,0,0,252,44,232,384,15,0,0,391,476,200,229,251,0,2,206,23,20,8,24,0,11,255,0,178,289,0,16,0,0,408,321,0,0,0,2,130,8,0,0,0,58,1,43,0,339,233,0,206,84,0,0,0,222,0,0,0,0,0,208,90,223,224,0,0,0,22938,8,275,0,0,200,80,218,0,0,198,0,0,205,222,0,0,65,291,342,19,0,4,240,68,0,58,0,15,56,0,203,2755,0,0,0,0,3499,0,0,0,0,3,0,0,0,34,303,10,213,204,0,0,0,209,230,3609,235,232,289,0,1,0,261,0,964,231,3,0,0,25,0,258,1986,234,2107,211,14,218,0,0,0,294,90,121,0,0,0,0,0,211,129,0,59,35,212,0,253,255,0,0,158,0,83,18,66,9,0,0,0,189,0,0,0,0,223,22,3,0,219,0,0,0,0,1244,211,11,8,237,112,0,0,227,31,11,233,62,0,80,0,15,13,0,256,257,0,0,0,0,0,358,281,231,0,107,0,3736,0,0,101,0,1520,0,150,228,256,238,0,28,218,99,35,0,241,250,82,0,266,0,258,175,0,0,204,0,343,0,292,16,0,272,0,33,144,0,11,152,0,0,0,25,0,163,0,0,0,331,0,0,263,0,23,9,0,759,0,0,268,0,201,113,0,221,18,9,213,0,127,74,0,1337,289,205,13,0,45,223,0,77,33,272,332,2486,403,0,237,0,0,0,0,148,282,201,77,0,9,220,0,309,0,204,0,288,75,91,7,22,264,0,0,169,304,119,192,292,0,36,123,0,0,0,0,0,0,2577,0,271,0,164,55,0,74,276,0,0,0,3,0,202,2,0,0,0,0,0,0,7,365,4,0,86,54,255,0,0,113,237,76,110,0,0,207,522,271,0,244,0,0,0,0,0,213,0,0,369,115,248,0,0,354,142,0,0,0,793,0,227,0,0,0,3,375,0,188,1,2284,0,0,0,0,242,0,577,22,11,64,0,0,0,115,215,0,0,0,0,44,0,203,0,55,0,45,0,243,0,320,0,0,0,0,0,201,253,6,0,285,282,0,0,339,230,0,262,27,122,76,263,51,397,400,0,5448,0,0,114,0,242,3,229,0,0,29,217,0,213,4,6,0,0,270,0,78,257,1178,227,157,417,0,417,484,1,0,0,16,828,323,258,40,3,5,1995,0,1800,0,0,0,264,170,0,0,258,149,272,276,285,0,0,138,0,0,10247,207,456,178,0,197,6,213,116,238,28,0,0,0,0,0,413,0,0,0,0,0,326,0,96,4,81,232,0,0,27,0,0,204,334,0,71,0,0,2,240,125,0,20,5598,210,0,0,255,3,235,189,398,0,90,7,103,0,0,0,0,0,46,127,0,211,0,203,344,189,38,1061,0,236,262,24,92,639,0,11,0,0,182,10,0,12,262,0,0,1564,411,0,117,0,129,133,0,306,3,0,324,0,0,0,10,163,11,218,243,19,0,0,0,27,20,1,0,0,1,0,77,0,0,0,233,0,0,12,61,477,0,0,108,0,0,203,120,346,228,0,0,22,0,0,1,2,1500,22,0,228,16,285,4,366,2,0,0,760,301,185,220,0,290,0,0,0,0,0,193,0,210,272,247,0,138,246,0,0,0,0,10,184,7,370,6,0,208,0,0,0,80,8,182,8,0,341,686,0,232,160,0,0,121,0,0,0,0,46,0,0,0,0,347,0,69,0,73,75,0,0,0,0,0,0,31,932,307,1302,0,0,333,155,0,232,0,0,0,214,5237,0,83,197,0,256,0,0,232,0,0,0,0,0,15,0,0,286,0,0,0,314,149,0,0,12,0,0,268,0,231,2908,0,196,0,0,242,335,448,1281,19,132,2029,183,0,0,0,0,218,222,0,143,19,24,187,222,271,22,185,0,224,308,0,1970,14,669,454,5,188,41,143,212,382,336,210,175,0,28,15,0,13,470,38,22,184,0,6,316,0,39,0,0,46,0,187,106,0,0,252,0,339,84,255,0,0,0,0,108,338,0,0,0,0,0,0,0,0,256,10,0,3,250,506,81,241,244,142,2713,178,166,7,0,4672,0,0,0,141,46,0,0,0,212,365,213,0,0,0,0,0,0,105,0,0,0,0,0,0,226,8,0,254,27,141,0,129,220,212,17,0,0,0,206,0,0,235,214,0,183,0,0,19,392,245,0,73,297,457,106,110,313,210,2901,62,346,190,76,0,97,3142,1,0,0,269,0,257,194,528,0,112,162,0,274,173,0,343,1,28,17,1054,282,0,0,2004,0,2,0,230,9,0,0,298,264,0,1,0,216,23,129,0,0,129,15,5,32,12,211,16710,0,1797,42,2473,0,0,219,0,0,210,276,0,509,16,2365,17,0,326,212,0,9,0,0,0,0,693,55,206,0,271,0,136,0,0,88,0,147,0,143,704,215,0,205,256,285,521,241,253,226,0,269,0,232,0,0,236,0,306,194,0,275,174,0,0,28,0,0,0,0,46,0,0,0,376,0,1,379,0,264,0,0,0,67,37,1,208,299,967,435,257,243,0,297,292,179,0,214,0,0,0,1062,317,0,53,380,6569,280,0,279,0,355,232,0,266,245,0,0,0,5,0,54,0,54618],\"y0\":\" \",\"yaxis\":\"y\",\"type\":\"box\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"average_playtime\"},\"type\":\"log\"},\"legend\":{\"title\":{\"text\":\"rating\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Distribuci\\u00f3n de average_playtime seg\\u00fan rating\"},\"boxmode\":\"group\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('f787e436-6ae6-4511-85f6-47deaf5ea98f');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.box(df_train, y=\"price\", color=\"rating\", title=\"Distribución de price según rating\")\n",
        "fig.show()\n",
        "fig.write_image(\"price_rating.png\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "MB77Lh_SG9CI",
        "outputId": "e183ce81-4bf5-4806-e5c6-473cfa028a05"
      },
      "id": "MB77Lh_SG9CI",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.16.1.min.js\"></script>                <div id=\"c452bb3f-43b9-4173-b7b9-4c8a9d2ef651\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"c452bb3f-43b9-4173-b7b9-4c8a9d2ef651\")) {                    Plotly.newPlot(                        \"c452bb3f-43b9-4173-b7b9-4c8a9d2ef651\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"rating=Mixed<br>price=%{y}<extra></extra>\",\"legendgroup\":\"Mixed\",\"marker\":{\"color\":\"#636efa\"},\"name\":\"Mixed\",\"notched\":false,\"offsetgroup\":\"Mixed\",\"orientation\":\"v\",\"showlegend\":true,\"x0\":\" \",\"xaxis\":\"x\",\"y\":[0.0,10.99,0.75,19.49,0.0,0.0,0.0,7.19,6.99,1.69,0.0,14.99,22.99,0.0,18.99,14.99,34.99,2.79,22.99,1.69,14.99,2.79,0.0,8.99,0.0,7.19,6.99,6.99,3.99,0.0,14.99,2.79,7.19,0.0,3.99,10.99,2.09,11.39,10.29,8.29,4.99,11.39,6.99,12.99,26.99,7.19,15.49,3.99,19.99,0.79,0.0,5.19,0.79,9.99,34.99,6.99,3.99,14.99,27.99,0.0,0.79,14.99,6.99,11.0,4.49,4.99,14.99,15.49,1.99,6.99,25.99,12.49,13.59,6.99,44.99,12.99,5.79,19.99,14.99,0.79,1.99,37.99,10.99,2.79,27.99,29.99,2.99,6.99,0.0,0.0,0.0,1.69,15.49,22.99,6.99,5.59,1.59,6.99,7.19,3.19,13.99,3.99,17.99,4.79,1.69,0.0,0.79,0.0,13.49,19.49,0.0,0.0,12.49,0.0,15.49,14.99,19.99,32.99,0.0,5.19,6.99,14.99,7.99,0.0,9.99,0.0,0.0,29.99,11.5,7.19,3.99,0.0,10.99,17.49,0.79,2.79,0.0,0.0,0.0,0.79,4.29,0.79,29.99,8.99,14.99,4.79,14.99,14.99,6.99,16.99,0.79,10.99,10.99,6.99,7.19,15.49,10.99,4.79,23.79,5.59,1.59,4.79,3.99,0.79,3.99,0.0,6.99,3.99,6.99,0.0,0.0,0.0,8.99,14.99,4.99,0.0,0.0,0.0,49.99,22.99,18.99,0.0,32.99,6.99,2.09,5.99,14.99,0.79,0.0,0.59,10.29,0.0,6.99,14.99,0.0,19.49,10.99,3.99,6.99,7.19,1.99,6.99,10.99,11.39,3.99,11.39,6.99,0.0,3.99,6.99,0.79,6.99,2.09,3.99,2.89,1.99,7.49,3.99,5.59,15.49,5.99,6.99,8.99,1.99,11.39,7.19,39.99,6.99,3.99,1.69,3.99,3.99,9.99,14.99,7.99,0.0,6.19,6.99,0.79,1.99,0.79,24.99,3.99,0.0,0.79,5.19,3.99,19.99,10.99,29.99,4.99,39.99,3.99,4.99,6.99,0.0,7.19,18.99,3.99,6.99,10.99,0.0,14.99,2.79,0.79,14.99,0.79,6.99,0.0,22.99,0.79,7.19,29.99,10.99,10.99,1.69,23.79,9.99,0.79,1.59,8.99,19.99,49.99,19.49,5.99,1.99,10.29,5.79,10.99,0.0,10.99,7.99,4.99,15.49,13.99,6.99,3.19,3.99,15.49,11.39,14.49,10.99,11.9,4.79,39.99,24.99,7.99,10.29,11.39,5.99,1.69,15.99,0.79,0.0,0.79,7.19,0.79,11.39,3.99,0.0,39.99,15.49,6.99,10.99,15.49,14.49,3.99,2.79,0.0,6.99,6.99,0.79,0.0,2.49,3.99,10.99,3.99,1.59,14.99,6.99,0.0,3.99,4.99,0.0,3.99,0.0,0.0,10.59,0.0,15.49,0.79,3.99,11.39,11.99,1.99,0.79,0.0,0.0,8.99,26.99,6.99,7.19,7.99,23.79,3.99,5.59,16.99,0.0,3.99,0.0,19.49,14.99,8.99,0.0,0.79,18.99,0.79,0.79,0.79,23.79,0.0,3.99,6.99,2.79,8.99,6.99,4.79,18.99,7.19,8.99,0.79,3.99,15.99,0.79,3.99,0.0,10.99,1.69,0.0,3.99,6.99,15.49,0.79,0.0,15.49,0.79,2.79,3.99,10.99,0.0,4.99,15.99,29.99,39.99,23.99,2.89,14.99,10.99,3.99,18.99,3.99,7.19,4.99,0.0,24.99,15.49,3.99,33.99,11.99,0.79,0.0,14.99,3.49,0.0,12.49,12.99,14.99,0.0,1.69,0.79,14.99,14.99,34.99,0.0,4.99,10.99,3.99,19.49,23.79,8.99,4.99,3.19,16.99,4.79,0.79,1.99,1.99,11.99,7.19,1.99,9.99,1.59,6.99,14.99,1.99,6.99,0.0,11.39,5.19,1.59,11.0,2.09,10.29,11.99,0.0,0.79,4.49,14.99,0.0,0.0,0.0,6.99,7.19,44.99,0.0,0.79,4.99,15.49,10.99,19.99,22.99,8.59,5.19,9.99,8.99,1.69,0.0,24.99,6.99,4.99,0.0,2.09,0.0,0.0,5.99,3.99,8.59,0.0,14.99,4.79,1.69,10.99,5.99,0.0,10.99,7.99,4.79,9.99,44.99,4.49,5.59,44.99,39.99,49.99,3.99,1.59,10.99,3.99,14.99,3.99,32.99,1.49,3.19,0.0,0.0,8.99,7.19,24.99,14.49,8.99,3.99,33.99,0.79,12.39,26.99,10.29,0.0,0.0,17.99,1.59,9.99,14.99,0.0,1.99,10.99,2.89,0.79,1.59,14.49,23.79,15.49,7.19,5.99,0.0,6.99,7.99,0.79,5.99,1.99,3.99,0.0,15.49,0.0,0.0,15.49,2.79,4.99,3.99,0.0,14.99,6.99,15.49,4.99,19.99,3.99,14.99,0.0,2.09,3.99,9.99,5.19,16.99,19.49,0.0,3.99,4.99,0.0,7.19,6.99,3.99,7.19,14.99,0.0,3.99,4.99,7.19,7.19,2.89,19.49,0.0,6.99,13.99,10.99,7.19,34.99,0.0,3.99,0.0,1.59,0.79,0.0,3.99,0.79,18.99,6.99,7.19,0.79,3.19,0.0,1.69,16.99,0.0,30.99,5.49,19.49,4.99,41.99,0.0,3.99,15.49,2.79,4.99,6.99,6.99,2.89,3.99,6.99,11.39,11.39,10.99,1.59,9.99,2.99,0.79,44.99,0.0,2.79,10.99,0.0,15.49,6.99,14.99,0.0,0.0,5.59,11.39,0.0,17.99,6.99,0.0,2.89,23.79,7.99,11.39,15.49,3.99,9.99,3.99,24.99,3.99,39.99,8.29,7.19,0.0,19.99,11.39,9.99,3.99,0.0,6.99,0.0,3.99,7.19,4.79,0.0,18.99,0.79,1.69,13.0,0.0,7.19,1.99,4.99,19.99,6.99,0.0,0.0,0.0,3.99,1.69,8.59,19.99,4.79,14.99,6.99,6.99,8.99,14.99,6.99,0.0,7.19,11.39,22.49,11.99,4.99,7.99,9.99,0.0,7.99,10.99,4.99,7.19,9.99,0.0,14.99,10.99,3.99,11.39,6.99,3.99,7.19,10.99,9.99,10.99,0.79,0.0,0.79,0.0,15.49,6.99,0.0,2.09,34.99,22.99,0.0,3.99,0.0,14.99,3.99,39.99,15.49,3.99,2.09,6.99,0.0,0.79,32.99,0.0,0.0,0.0,6.99,4.39,10.99,25.99,5.99,6.99,6.99,0.0,10.99,1.49,14.99,14.99,0.79,0.79,5.79,19.49,0.0,7.19,6.99,14.49,0.79,9.99,1.99,10.29,2.79,6.99,19.99,0.0,0.0,3.99,4.99,0.0,9.99,37.99,0.0,7.19,14.99,20.51,2.79,3.99,3.99,0.79,6.99,0.79,15.49,39.99,0.0,9.99,15.99,1.59,34.99,14.99,2.09,6.99,2.79,7.19,0.0,0.0,3.99,7.19,7.19,6.99,0.0,7.19,0.0,6.99,2.09,3.99,6.99,9.29,3.99,39.99,19.49,14.99,6.99,0.0,6.99,10.99,14.99,1.69,4.99,1.59,7.99,6.99,44.99,0.0,0.0,8.59,0.79,0.79,8.99,6.49,10.99,14.99,3.99,5.19,1.59,24.99,24.5,7.19,1.99,14.99,3.19,3.99,6.99,0.0,0.0,6.99,3.99,6.99,3.99,0.0,3.99,5.59,0.79,0.0,3.99,3.99,0.0,0.79,11.99,6.99,2.99,0.79,5.59,4.79,7.19,6.99,0.79,0.79,5.99,10.99,11.39,0.0,5.99,0.79,39.99,0.79,0.0,5.59,44.99,24.99,25.99,1.59,3.99,4.79,1.69,2.89,0.0,0.0,0.79,0.0,9.29,14.99,5.79,6.99,0.0,6.99,7.19,5.99,0.0,4.99,10.99,0.0,33.99,15.49,10.99,7.19,11.39,24.99,0.0,3.99,0.0,33.99,6.99,10.99,6.99,16.99,2.79,6.99,7.19,3.99,0.0,0.0,1.0,4.25,24.0,4.79,0.0,4.79,34.99,15.99,22.99,3.99,0.0,6.99,18.99,0.79,7.19,5.59,6.99,3.99,3.99,8.29,15.49,0.0,0.79,0.79,6.19,4.99,5.79,14.99,6.99,0.0,2.09,7.19,3.99,13.49,24.99,26.99,3.99,7.99,0.0,19.99,7.19,3.99,7.19,14.99,12.99,6.99,5.99,0.0,5.99,6.99,0.0,1.69,5.99,1.99,0.0,3.99,39.99,10.99,7.19,11.49,0.79,0.0,11.99,4.79,0.79,1.59,12.99,5.79,13.99,11.99,10.99,0.0,0.79,14.99,6.99,0.0,15.49,13.99,1.59,17.99,14.99,0.0,6.99,3.99,15.49,0.0,7.99,14.99,4.79,0.0,3.99,1.69,0.0,7.99,6.99,39.99,9.29,0.0,6.99,15.49,5.79,3.19,0.79,7.19,2.79,2.09,12.49,0.0,1.59,11.99,29.99,8.29,0.0,0.0,0.0,14.99,4.99,0.79,3.99,22.99,0.79,14.99,5.59,22.99,14.99,6.99,10.99,0.79,6.99,10.99,14.99,6.99,6.99,3.99,5.59,12.99,19.99,6.99,14.99,4.99,2.79,1.99,3.99,3.99,5.99,3.99,6.99,6.99,26.99,3.99,0.0,6.99,0.0,18.99,0.0,4.99,6.99,0.0,11.39,6.49,5.59,4.99,6.99,3.99,0.0,4.79,12.39,0.0,22.99,15.49,9.99,19.49,6.99,0.0,5.59,3.19,3.99,24.99,33.99,10.99,0.0,5.99,3.99,6.95,29.99,10.99,15.49,0.0,9.29,2.09,0.0,0.0,3.99,0.0,14.99,17.99,2.79,0.79,10.99,23.99,5.99,1.99,5.59,6.99,14.99,14.99,6.99,2.79,1.69,10.99,5.19,6.99,8.29,0.79,0.0,0.79,8.59,3.99,2.79,0.0,6.99,1.99,19.99,0.0,24.99,6.99,6.95,0.0,4.99,0.79,7.19,0.0,6.99,11.39,0.79,0.0,1.59,21.99,0.0,24.99,2.79,0.0,0.79,6.99,0.0,6.99,14.99,3.99,14.99,3.99,0.0,6.99,4.99,15.49,1.99,29.99,14.99,1.69,4.99,0.0,44.99,39.99,6.99,9.99,0.79,6.99,0.79,3.99,1.1,6.99,6.99,14.99,3.99,0.79,6.99,0.0,15.49,0.0,4.79,1.69,6.99,0.0,0.0,2.09,24.99,14.99,12.99,15.49,0.79,3.99,8.99,5.99,5.79,0.0,6.99,14.99,6.99,0.0,5.99,3.99,0.0,1.79,5.59,44.8,0.0,10.99,3.99,0.79,8.99,0.0,26.99,2.09,6.99,15.49,3.99,0.0,11.99,3.99,14.99,8.99,0.0,15.49,6.99,11.39,3.99,3.99,2.89,24.99,13.5,9.29,14.99,1.69,1.99,3.99,6.99,7.19,7.99,0.99,19.99,14.99,9.99,0.0,11.99,0.79,24.99,15.49,14.99,7.19,2.79,2.79,0.0,6.99,0.0,19.99,3.99,8.99,10.99,13.5,19.99,9.99,0.79,1.69,0.0,3.99,0.0,4.49,0.79,7.19,9.99,15.49,0.0,1.69,0.0,32.99,13.59,0.0,5.99,1.99,39.99,7.19,6.99,0.79,10.99,10.99,0.0,4.79,7.19,22.99,2.99,0.0,6.99,10.99,0.0,0.79,3.99,0.0,11.99,6.99,0.0,0.79,1.69,7.19,14.99,0.0,2.79,6.99,3.49,0.0,3.99,0.0,9.99,0.0,3.99,1.59,16.99,3.99,10.59,1.99,19.99,0.0,0.0,10.99,0.0,6.99,1.69,1.59,0.0,54.99,0.79,12.39,2.79,10.29,14.99,6.99,1.69,3.1,7.99,7.19,0.0,18.1,12.49,0.0,0.0,14.99,12.99,0.79,10.99,7.19,0.79,3.49,5.99,15.99,24.99,6.99,3.99,0.0,14.99,49.99,0.0,0.0,30.99,0.0,14.99,49.99,0.0,2.99,22.99,9.29,49.99,11.39,6.99,0.0,13.99,0.0,7.19,4.49,29.99,14.99,10.99,0.0,14.99,15.49,7.19,39.99,3.99,6.99,15.49,0.0,2.09,3.99,25.99,0.79,6.99,1.59,0.0,11.39,34.99,4.99,13.99,1.49,2.99,12.99,11.39,8.99,2.89,3.99,3.19,4.99,14.99,6.99,0.0,6.19,11.39,2.09,24.99,1.59,0.0,14.99,24.99,22.99,6.99,0.0,5.19,6.99,10.99,0.0,0.79,1.59,7.19,0.79,10.29,5.59,0.0,1.59,0.0,0.79,0.0,6.99,3.99,14.99,3.99,5.99,12.99,6.99,0.79,13.49,0.0,23.79,0.79,4.99,3.19,6.99,5.99,2.09,6.99,3.99,2.09,3.99,5.59,10.99,1.69,39.99,2.99,0.0,0.79,0.0,0.0,6.99,0.0,0.0,0.0,0.0,5.99,0.0,14.99,14.99,10.99,18.99,0.79,5.19,10.29,14.99,0.0,0.0,29.99,8.99,22.99,6.99,2.09,0.79,3.19,0.0,7.19,0.79,6.99,8.99,6.99,2.79,0.79,6.99,6.99,0.0,0.0,15.49,6.99,6.99,0.79,18.99,0.79,0.0,0.0,34.99,10.99,4.79,15.99,22.99,5.19,9.99,3.99,11.39,2.89,0.79,14.99,6.99,7.19,15.49,3.99,4.99,44.99,0.79,0.0,3.99,7.99,14.99,4.79,14.99,7.19,6.19,4.79,1.59,4.79,6.99,5.99,0.0,1.59,6.99,0.0,1.69,1.59,1.59,9.99,3.99,1.59,19.99,4.99,6.99,29.99,10.99,3.99,18.99,4.99,1.69,0.79,0.0,0.0,0.0,15.99,3.99,34.99,6.19,29.99,4.79,0.0,3.99,78.99,3.99,0.79,0.79,14.99,7.99,29.99,14.99,10.99,0.79,2.09,18.99,24.99,0.79,0.0,7.99,22.99,5.54,3.99,0.79,4.49,3.99,3.99,0.0,1.99,15.49,9.99,10.99],\"y0\":\" \",\"yaxis\":\"y\",\"type\":\"box\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"rating=Positive<br>price=%{y}<extra></extra>\",\"legendgroup\":\"Positive\",\"marker\":{\"color\":\"#EF553B\"},\"name\":\"Positive\",\"notched\":false,\"offsetgroup\":\"Positive\",\"orientation\":\"v\",\"showlegend\":true,\"x0\":\" \",\"xaxis\":\"x\",\"y\":[6.99,0.0,0.0,3.99,29.99,0.0,4.99,3.99,6.99,15.49,0.0,6.99,8.49,2.99,6.99,3.99,4.99,34.99,0.0,3.99,15.49,10.99,19.49,15.49,0.79,0.0,10.99,0.0,29.99,2.79,10.99,5.59,0.79,34.99,3.99,0.79,9.29,10.99,3.99,14.99,7.19,4.99,12.39,0.0,1.99,3.99,31.99,4.99,10.29,29.99,14.99,6.99,16.99,8.99,0.0,7.99,0.79,10.29,10.99,3.99,2.79,8.99,0.0,0.79,0.0,24.99,0.79,3.99,0.0,0.9,14.99,7.19,15.49,3.99,4.99,2.99,3.99,1.99,30.99,0.0,6.99,10.99,0.79,14.99,0.79,2.49,19.49,6.99,2.99,12.39,4.99,4.99,7.19,0.0,14.99,7.99,13.37,12.99,1.99,7.99,18.99,1.69,2.09,8.59,6.99,14.99,0.0,1.99,36.99,10.29,6.99,3.99,22.99,0.0,0.0,14.99,5.59,22.99,3.99,11.99,14.99,29.99,5.59,14.99,18.99,11.39,0.9,1.69,4.99,34.99,7.19,15.49,18.99,0.0,15.99,3.99,6.99,7.19,11.99,10.99,49.99,3.99,8.99,10.99,60.99,0.0,0.79,3.99,1.69,6.99,4.79,6.99,6.99,4.79,22.99,13.99,27.99,19.49,13.99,6.99,10.99,9.99,12.99,6.99,6.99,1.99,1.59,14.99,3.99,5.59,11.39,3.99,5.99,2.09,14.99,0.79,3.99,10.99,22.99,15.49,5.99,11.99,6.99,3.99,7.99,0.0,4.79,3.99,2.79,1.69,6.99,13.49,6.99,19.99,13.99,14.99,9.99,14.99,6.99,0.0,6.99,8.99,14.99,1.99,1.59,0.79,1.69,19.99,10.99,46.49,6.99,2.09,6.99,1.99,23.79,3.99,13.59,1.99,15.49,1.69,3.99,4.79,23.79,4.79,11.99,9.99,1.59,8.99,14.99,0.0,11.39,10.99,5.99,11.39,19.49,7.99,0.0,0.79,0.0,11.39,7.99,6.99,10.99,4.99,6.99,14.99,6.99,10.99,9.99,4.79,6.99,11.39,23.79,6.99,6.99,13.99,6.99,5.99,0.0,4.79,6.49,6.99,0.0,4.99,0.0,13.99,10.99,1.99,12.39,8.99,3.99,2.99,0.0,0.0,10.99,0.0,11.39,9.99,4.29,15.99,29.99,1.69,7.19,1.99,7.19,2.49,29.99,9.99,8.59,9.99,7.99,10.99,11.99,0.0,11.99,3.99,0.0,18.99,15.99,9.29,7.19,3.99,1.99,14.99,11.39,3.99,3.99,7.99,10.99,0.72,17.99,14.99,10.99,3.99,7.99,5.59,10.99,3.99,14.99,0.0,1.49,3.99,4.79,0.0,0.0,0.0,0.0,0.0,3.99,6.99,7.99,6.99,1.59,3.99,22.99,49.99,6.99,15.49,3.99,11.39,7.99,1.99,1.69,6.99,6.99,2.09,3.99,19.49,0.0,14.99,2.79,19.99,0.0,7.19,1.69,3.99,0.0,0.0,5.19,3.99,6.99,0.0,6.99,18.99,0.99,4.99,0.0,15.49,6.99,0.99,7.19,10.29,15.49,3.99,7.19,0.0,2.89,11.39,6.99,1.69,14.99,7.19,4.99,0.0,22.99,3.99,10.99,5.59,6.99,0.79,7.19,12.39,1.99,6.99,5.79,10.99,0.79,3.99,14.99,10.99,11.99,9.29,2.79,7.19,1.69,3.99,1.99,6.99,9.29,14.99,0.49,0.0,4.99,8.99,3.99,24.99,6.99,7.99,6.99,10.99,1.99,34.99,6.99,1.79,5.79,0.0,7.19,7.99,3.99,10.99,0.0,11.39,11.39,7.99,3.99,2.09,7.99,29.99,7.99,0.0,49.99,0.0,14.49,6.99,5.59,5.99,19.49,6.99,16.99,6.99,15.49,4.99,7.99,0.0,11.39,4.99,27.79,2.79,29.99,3.99,7.99,4.79,2.79,7.99,6.99,10.99,3.99,7.5,15.49,3.99,18.99,10.99,0.0,6.99,1.59,0.0,7.19,11.39,3.99,11.39,6.99,1.99,0.0,2.99,7.19,3.99,16.99,0.0,15.49,0.0,29.99,7.19,5.99,0.0,0.79,3.99,31.99,3.99,39.99,5.99,2.09,14.99,11.39,19.99,14.99,14.99,6.99,9.99,4.99,0.0,4.99,1.69,13.59,0.0,11.39,29.99,3.99,5.99,11.39,6.99,11.39,34.99,19.49,5.99,23.79,0.0,7.19,5.59,0.79,15.49,3.99,10.99,22.99,25.79,15.99,14.99,22.99,10.99,19.49,19.49,10.99,14.99,0.0,0.0,5.59,0.79,0.79,6.99,6.19,0.0,14.99,7.99,15.49,7.19,6.99,15.49,10.29,12.99,3.99,13.99,0.0,44.99,3.19,9.29,6.99,10.99,4.79,6.99,7.19,6.99,11.39,0.79,0.0,14.99,10.99,23.79,9.99,10.99,12.49,23.79,13.49,13.59,16.99,4.99,3.99,0.0,3.99,2.09,6.99,14.99,4.59,7.19,0.0,14.99,0.0,4.79,4.79,0.0,0.79,3.99,14.99,4.79,8.59,14.99,10.99,3.99,14.99,24.99,0.0,0.79,15.49,10.99,0.0,6.99,3.99,1.69,6.99,23.79,29.99,14.99,29.99,8.29,1.99,9.99,6.99,14.99,5.99,0.0,16.99,0.0,7.19,9.29,30.99,9.99,0.0,2.89,0.0,11.49,10.99,12.39,39.99,0.0,14.99,4.99,0.0,11.39,0.0,29.99,7.19,10.99,0.0,26.99,5.79,25.99,52.99,3.99,18.99,6.99,4.99,10.99,2.09,1.59,19.49,23.79,10.99,7.19,5.59,1.59,1.99,2.09,14.99,0.0,0.0,23.39,0.0,3.99,10.99,24.99,9.99,10.99,7.49,6.99,5.79,10.99,0.9,4.99,5.79,5.19,7.99,0.79,3.99,19.99,0.0,19.99,6.99,6.99,8.59,14.99,10.29,6.99,10.99,0.0,0.0,0.79,6.99,6.99,10.99,0.0,14.99,7.19,0.0,6.49,60.99,6.99,5.99,14.99,7.19,2.09,14.99,0.0,10.99,4.99,23.79,8.99,18.99,0.79,4.79,3.99,23.79,39.99,27.79,0.0,29.99,14.99,11.39,1.99,13.99,5.99,0.0,6.99,7.19,1.69,6.99,14.49,22.99,4.79,13.99,18.99,10.99,14.95,10.99,14.99,15.49,16.99,4.99,23.79,4.79,2.09,10.99,14.99,7.99,10.99,0.79,6.99,6.99,0.79,6.99,5.19,29.99,3.19,5.59,0.0,14.99,18.99,19.99,14.99,10.99,3.99,19.49,7.19,4.99,0.0,4.99,6.99,25.99,23.79,3.19,14.99,19.99,5.99,7.99,7.99,0.0,19.49,5.59,0.79,11.99,6.99,9.99,1.99,10.99,19.49,14.99,17.99,9.9,7.19,5.59,2.79,11.99,18.99,15.49,2.79,6.99,11.99,6.99,5.99,7.18,4.99,19.99,10.99,5.59,1.99,10.99,6.99,11.39,8.99,10.99,1.99,14.99,0.0,11.99,5.79,7.19,5.59,29.99,10.99,1.99,3.99,4.99,10.99,11.39,3.99,10.99,3.99,3.99,1.59,24.99,10.99,10.99,14.99,9.99,7.19,10.99,3.99,19.99,6.99,6.99,0.0,4.99,0.79,29.99,7.99,4.99,9.99,6.99,29.99,10.99,0.0,7.19,2.99,6.99,9.99,4.99,18.99,3.99,7.19,5.59,7.19,14.99,8.99,6.99,0.0,0.79,23.79,19.49,25.99,0.0,9.99,7.19,3.99,1.99,7.19,4.79,3.99,49.9,0.0,10.99,29.99,4.79,22.99,3.99,23.79,6.99,15.99,14.99,3.99,29.99,0.79,0.0,14.99,22.99,18.99,0.79,24.99,7.19,9.99,6.99,7.99,6.99,14.99,12.99,14.99,3.99,0.79,19.49,5.99,3.99,49.99,1.99,8.59,8.59,3.99,6.99,4.99,5.99,22.99,24.99,6.99,8.59,14.99,54.99,6.99,10.99,29.99,3.99,12.39,10.99,3.99,22.99,6.99,0.0,11.39,15.49,16.99,3.99,0.0,4.99,3.99,5.59,6.99,6.99,9.99,1.99,0.0,6.99,0.0,1.59,24.99,1.59,8.99,2.09,15.99,4.29,0.79,8.59,34.99,24.99,1.99,0.0,2.89,15.49,6.99,0.0,0.0,15.49,2.49,10.99,32.99,7.99,4.79,4.99,0.0,0.0,1.99,7.5,0.0,15.49,1.99,4.99,6.99,0.0,2.99,0.0,2.79,39.99,3.99,4.99,6.99,0.79,6.99,1.99,0.0,6.99,0.0,1.99,15.49,1.99,9.99,3.99,1.59,14.99,9.99,4.99,4.79,10.99,49.99,6.99,9.99,10.99,8.99,5.19,5.79,6.99,10.99,14.99,1.99,0.79,6.99,9.99,3.99,1.59,10.99,0.79,0.0,4.79,11.99,0.79,0.0,14.99,14.99,8.99,0.0,6.99,1.99,14.99,0.0,2.89,10.99,11.39,10.99,10.99,14.99,8.29,1.59,14.99,15.49,1.59,0.79,14.99,14.99,0.0,1.99,5.99,3.99,5.19,54.99,3.99,0.79,14.99,19.99,19.49,3.99,0.0,6.99,1.99,2.49,5.59,6.99,6.99,8.99,0.0,2.09,6.99,10.29,3.99,4.79,4.99,9.99,6.99,2.89,6.99,8.29,1.59,9.99,19.49,25.99,5.59,7.19,1.69,10.99,1.99,11.99,3.99,1.59,0.0,19.99,6.99,9.99,44.99,17.99,7.19,1.99,17.49,18.99,44.99,3.19,19.49,18.99,15.49,5.99,6.99,18.99,14.99,15.49,9.99,13.59,0.79,5.59,1.59,7.19,1.59,14.99,3.99,9.99,29.99,0.0,4.79,3.99,0.0,6.99,10.59,10.99,14.99,4.99,14.99,15.49,6.99,14.99,6.99,0.0,5.79,0.0,6.99,15.99,18.74,2.09,0.0,10.99,3.99,0.0,12.99,3.99,3.99,0.72,2.79,2.79,11.39,14.99,14.99,9.99,4.25,6.99,10.99,11.39,7.99,6.99,5.19,4.79,7.19,19.99,16.99,3.99,0.0,1.59,10.99,10.99,0.0,7.19,0.0,10.99,0.0,10.99,9.99,14.99,8.59,3.99,19.99,11.39,9.99,3.99,15.99,2.79,5.79,19.99,0.0,3.99,15.49,5.99,34.99,15.9,4.99,10.99,0.0,6.99,6.99,14.99,15.49,15.99,14.99,10.99,0.79,5.79,26.99,10.99,4.49,30.99,14.99,18.99,5.59,7.19,4.79,2.79,4.99,0.0,6.99,5.19,24.99,15.49,0.0,19.49,3.99,3.99,0.0,1.59,6.99,0.9,0.0,0.0,6.99,1.69,14.99,1.99,0.79,9.99,14.99,14.99,1.69,7.19,6.99,2.79,5.19,3.99,4.99,6.99,18.99,15.49,7.19,1.69,0.0,0.0,0.0,9.99,9.99,3.99,11.39,11.99,6.99,1.69,3.99,8.59,5.59,0.0,10.99,23.99,18.99,6.99,29.99,6.99,10.29,7.19,10.99,6.99,8.29,14.99,10.99,2.79,3.99,4.99,2.79,0.0,26.99,14.99,29.99,4.99,7.19,5.19,3.99,1.99,10.99,0.79,6.99,6.99,6.99,7.19,14.99,9.99,8.99,4.79,7.19,0.0,3.99,5.59,11.99,6.99,4.79,10.29,3.99,5.79,6.99,1.99,34.99,6.99,3.99,10.99,13.99,15.49,0.79,10.99,15.99,5.59,15.99,10.99,9.99,1.69,0.0,0.79,7.19,16.99,0.79,7.99,2.5,19.99,1.59,11.39,10.99,30.99,0.0,4.99,1.65,0.0,39.99,0.0,6.99,24.99,3.99,1.79,11.39,14.99,15.49,0.0,11.99,11.39,3.99,8.59,0.0,0.79,29.99,2.09,14.99,4.79,15.99,25.99,0.0,0.0,2.99,15.99,6.99,15.49,3.99,11.99,6.99,41.99,0.0,6.19,0.0,14.99,6.99,3.99,22.99,4.79,14.99,0.0,6.99,15.99,0.0,6.99,4.99,18.99,14.99,0.0,9.99,0.0,15.49,1.99,6.99,14.99,18.99,1.99,5.99,0.0,7.99,7.19,10.99,6.99,4.79,7.49,10.99,9.99,29.99,0.0,3.99,4.99,14.99,14.99,5.59,5.99,26.99,4.29,16.99,11.39,0.0,15.49,0.0,10.99,3.49,16.99,6.99,26.99,1.99,1.99,11.99,1.99,10.99,0.0,5.59,19.99,15.49,0.0,15.49,39.99,1.99,0.0,11.99,6.99,19.49,11.99,18.74,0.0,6.99,0.79,19.99,2.09,9.99,6.99,0.0,6.99,22.99,9.99,18.99,49.99,3.99,2.79,0.0,6.99,23.99,11.39,14.99,1.49,2.09,2.79,1.99,6.99,0.0,18.99,15.49,3.99,9.99,0.79,13.59,6.99,0.0,4.79,4.79,2.79,8.59,7.19,5.79,0.79,34.99,0.0,1.99,2.09,10.99,0.0,5.59,10.99,3.99,6.99,3.99,5.99,1.69,16.99,10.99,10.99,11.39,0.0,0.0,11.39,34.99,22.99,29.99,11.99,6.99,14.99,2.79,14.99,49.99,11.99,29.99,12.99,23.79,6.99,1.59,0.79,10.99,15.99,18.99,0.0,10.99,0.0,5.99,2.79,24.99,2.79,6.99,7.19,0.79,6.99,5.79,6.99,14.99,11.39,3.99,5.59,10.99,0.0,3.99,13.49,7.99,6.99,6.99,0.0,7.19,4.99,15.99,3.99,1.59,19.99,0.0,10.99,0.0,23.79,0.0,2.09,10.99,5.99,5.59,10.99,11.39,15.49,6.99,6.99,6.49,0.0,0.0,5.59,5.79,0.0,16.99,2.99,14.99,10.99,1.69,10.99,2.89,30.99,10.99,3.99,15.99,13.99,10.99,11.99,13.49,5.59,2.89,0.0,9.99,6.99,3.99,0.0,10.99,7.19,0.79,7.19,0.79,2.79,0.0,0.0,2.79,7.99,7.19,0.0,9.29,5.79,22.99,5.79,0.0,30.99,14.99,0.79,2.89,7.99,10.99,14.99,10.99,7.49,15.49,5.79,29.99,0.0,9.99,6.99,49.99,24.99,0.0,3.99,1.59,9.99,14.99,10.99,0.79,11.39,0.79,34.99,3.99,1.59,0.0,19.99,3.99,12.99,5.99,0.0,7.19,1.99,2.99,3.49,1.99,30.99,7.19,14.99,6.99,10.29,15.49,9.99,4.79,4.99,11.39,6.99,0.0,7.19,22.99,5.79,4.79,15.49,3.19,6.99,10.99,14.99,14.99,9.99,0.0,1.99,23.99,0.79,0.79,2.09,0.0,39.99,5.59,10.99,14.99,6.99,6.99,4.99,13.99,29.99,0.0,6.99,14.99,1.59,8.99,1.69,10.99,4.79,4.99,3.99,6.99,5.99,4.79,14.99,6.99,0.79,14.99,3.99,11.39,12.99,0.0,18.99,18.99,6.99,7.19,0.0,29.99,0.0,34.99,5.99,4.99,19.99,6.99,3.99,14.99,0.79,6.99,5.59,15.49,3.99,3.99,3.99,0.0,15.49,11.39,0.0,0.79,10.99,10.99,14.99,10.99,5.59,10.99,1.99,8.99,14.99,14.99,0.0,14.99,4.79,6.19,2.99,2.09,29.99,9.99,5.99,15.49,7.19,11.39,24.99,7.19,0.0,15.49,2.99,2.79,11.99,5.79,39.99,4.99,3.99,0.0,12.49,0.0,10.99,6.99,10.0,13.49,7.19,8.69,1.49,3.99,8.99,6.99,8.29,12.99,3.99,0.79,0.0,0.79,9.99,12.99,4.79,6.99,10.99,23.79,24.99,8.59,3.99,23.79,0.0,10.99,5.19,22.99,2.89,6.99,12.49,2.09,60.99,9.99,2.89,14.99,14.99,0.0,4.99,0.0,6.99,0.79,0.0,0.0,7.19,7.19,3.99,5.19,0.79,0.79,1.99,0.0,2.09,5.99,0.0,3.99,4.99,0.0,1.59,14.99,15.49,11.99,2.79,7.19,3.99,10.99,10.99,6.99,3.99,10.99,6.99,0.79,10.99,0.0,15.49,4.99,15.49,0.79,1.99,6.99,13.0,11.39,0.0,6.99,14.99,0.0,3.99,15.99,49.99,0.0,18.99,0.0,7.99,6.19,11.99,6.99,24.99,5.79,4.79,2.69,5.99,0.0,29.99,2.79,7.19,26.99,8.29,7.19,7.19,5.99,2.09,6.99,2.89,3.99,15.99,10.99,0.0,5.59,7.19,7.99,14.99,11.39,3.99,1.69,7.19,6.99,2.09,2.79,5.59,3.99,0.0,6.99,14.99,15.49,6.99,7.19,14.99,3.99,11.39,9.99,6.99,4.79,3.99,10.99,14.99,1.99,6.99,9.99,1.99,6.99,3.99,7.99,19.99,0.0,0.79,3.99,49.99,6.99,9.99,15.49,1.99,14.99,3.99,0.0,16.99,15.49,54.99,7.19,0.0,0.0,6.99,0.0,39.99,4.99,6.99,39.99,6.99,0.0,4.29,0.0,9.99,3.99,11.99,14.99,11.39,8.99,6.99,22.99,6.99,7.19,2.99,1.59,14.99,7.19,15.49,11.39,14.99,14.99,2.79,14.99,8.59,9.99,6.99,5.59,0.0,11.39,6.99,0.0,0.0,0.79,6.99,10.99,9.99,6.99,11.99,0.0,6.99,6.99,7.19,0.0],\"y0\":\" \",\"yaxis\":\"y\",\"type\":\"box\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"rating=Mostly Positive<br>price=%{y}<extra></extra>\",\"legendgroup\":\"Mostly Positive\",\"marker\":{\"color\":\"#00cc96\"},\"name\":\"Mostly Positive\",\"notched\":false,\"offsetgroup\":\"Mostly Positive\",\"orientation\":\"v\",\"showlegend\":true,\"x0\":\" \",\"xaxis\":\"x\",\"y\":[7.99,0.0,6.99,4.99,23.39,6.99,6.99,5.99,17.99,10.99,0.79,14.99,2.09,18.99,14.99,1.69,10.99,3.99,4.79,15.49,14.99,3.99,4.99,0.79,1.99,19.99,5.99,7.19,0.0,1.99,34.99,9.99,4.99,11.99,9.99,6.99,14.99,10.99,14.99,29.99,6.99,11.99,1.69,2.09,19.99,0.0,6.99,0.79,12.99,11.39,0.79,0.0,6.99,14.99,4.49,3.99,10.99,7.19,1.59,6.99,14.99,4.99,11.99,12.99,1.59,11.99,14.99,0.0,11.49,0.0,6.99,12.39,3.49,29.99,1.99,8.59,3.99,4.99,0.0,6.99,0.0,14.99,15.49,0.79,4.49,2.79,10.29,5.99,6.99,0.0,6.99,14.99,29.99,4.99,4.79,2.79,5.59,6.99,5.59,10.99,12.99,7.19,13.99,39.99,5.99,14.99,3.19,4.99,7.19,9.99,18.99,6.99,0.0,14.99,1.59,6.99,7.19,19.99,39.99,1.99,3.99,4.49,3.99,0.99,7.99,14.99,0.99,1.99,7.19,2.79,4.99,2.89,14.99,6.99,3.99,0.0,6.99,3.99,12.99,10.99,11.39,23.79,10.99,15.49,6.99,7.99,5.99,34.99,0.99,0.0,7.19,11.99,13.99,3.99,0.0,4.99,1.59,18.99,4.79,6.99,3.99,0.0,0.0,10.99,10.99,7.7,23.79,5.19,16.99,0.0,15.49,19.99,1.69,4.79,6.99,0.0,14.99,1.59,3.99,0.0,7.99,15.49,0.0,2.89,11.39,0.79,39.99,11.99,1.99,2.79,0.79,19.49,4.99,1.49,12.99,11.99,10.99,14.99,0.79,24.99,3.99,4.79,3.99,14.99,11.39,0.0,10.29,3.99,1.99,0.79,0.79,2.79,0.0,3.99,4.99,6.99,4.79,7.19,0.32,2.89,6.99,34.99,0.79,10.99,29.99,5.99,6.99,6.99,7.19,15.99,6.99,0.0,0.79,3.99,6.99,11.99,11.39,4.79,0.0,4.79,0.79,0.0,6.99,23.79,4.99,0.0,6.99,0.0,3.99,11.99,0.0,3.99,1.59,34.99,2.79,3.99,3.19,10.99,0.0,0.0,4.99,1.99,15.49,6.19,7.19,11.99,4.79,0.0,6.99,10.99,2.79,10.99,5.79,0.0,6.99,44.99,5.99,6.99,2.79,18.99,15.49,27.79,15.49,0.79,0.79,7.19,24.99,5.59,34.99,6.99,0.0,14.99,34.99,7.19,0.0,44.99,2.79,4.99,10.29,13.49,4.49,6.19,0.0,24.99,2.28,12.99,14.99,0.0,9.29,5.59,0.79,15.49,5.99,39.99,3.99,7.19,8.99,0.79,5.59,2.89,10.99,0.0,0.0,6.99,29.99,29.99,3.99,5.59,10.99,4.79,6.99,6.99,6.99,8.99,10.99,5.99,3.99,24.99,22.99,7.19,10.99,14.99,6.99,9.29,29.99,0.0,4.99,3.99,3.99,0.0,0.0,6.99,9.99,6.99,14.99,3.99,9.99,0.0,7.19,22.99,6.99,6.99,14.99,0.0,9.99,15.49,19.49,5.99,6.99,2.79,2.89,14.99,0.0,0.0,39.99,30.99,0.0,5.19,2.99,3.99,34.99,11.39,6.99,15.99,4.99,9.99,15.49,3.99,5.79,15.99,9.99,23.79,3.99,6.99,19.49,0.0,0.0,14.99,4.99,32.99,1.69,23.79,6.99,0.0,6.99,6.19,9.99,4.99,0.0,9.99,0.0,7.19,3.99,3.99,6.99,0.0,2.89,0.0,10.99,19.49,10.29,2.89,7.19,14.99,3.99,19.99,4.79,9.99,14.99,3.99,3.99,5.99,15.49,15.49,3.99,30.99,2.79,7.19,15.49,10.59,1.99,0.0,2.99,4.79,3.99,0.0,0.0,7.99,13.99,6.99,1.59,10.99,7.19,14.99,9.99,14.99,10.99,10.99,6.99,3.99,0.0,3.99,13.99,19.99,12.99,5.49,3.99,0.0,0.79,0.79,44.99,15.49,0.0,7.19,6.99,3.99,8.99,6.99,7.19,3.99,4.24,0.79,10.99,4.79,4.99,8.99,1.59,0.0,7.19,2.99,6.99,0.79,0.0,46.49,12.39,8.99,14.99,9.99,6.99,6.99,8.99,12.99,0.0,19.49,0.0,9.29,3.49,6.99,7.99,2.79,0.0,3.99,4.79,3.99,6.99,10.99,6.99,0.0,14.99,0.0,2.99,4.99,11.99,7.19,1.99,0.79,6.99,15.49,3.99,2.09,0.0,1.59,7.99,5.59,2.89,0.79,10.99,39.99,14.99,6.99,6.99,6.99,17.99,2.09,4.99,10.99,6.99,0.0,6.99,0.0,2.09,23.79,15.49,6.99,3.99,11.39,5.99,15.49,9.29,3.99,0.0,6.99,49.99,19.49,0.79,29.99,10.99,24.99,6.99,5.19,14.99,4.29,4.99,0.0,13.99,4.79,19.49,14.99,14.99,23.79,14.99,6.99,3.99,3.99,0.79,5.69,7.19,6.99,3.99,9.99,1.59,0.0,4.79,4.99,14.99,3.99,7.99,11.95,9.99,25.99,10.99,10.99,41.99,1.59,11.99,3.99,10.99,10.99,14.99,9.99,14.99,10.99,0.0,0.79,7.19,14.99,5.59,6.99,14.99,10.99,22.99,15.49,10.29,1.99,3.99,3.99,6.99,0.0,6.99,2.79,4.99,0.0,4.99,6.99,0.0,39.99,0.0,12.99,29.99,3.99,0.0,9.99,6.99,4.99,1.99,10.99,7.19,17.99,14.99,1.69,1.59,44.99,0.0,9.99,6.99,6.99,6.49,26.99,3.99,12.99,0.79,7.19,6.99,11.99,15.49,2.09,23.79,15.49,14.99,1.69,44.99,0.0,6.99,7.19,5.99,6.99,18.99,9.99,3.99,14.99,10.99,14.99,6.99,13.99,3.99,19.99,0.79,10.99,4.79,15.49,0.0,34.99,19.49,3.99,3.29,0.0,7.19,0.0,49.99,15.49,9.99,4.79,0.79,14.99,3.99,1.99,10.99,3.99,11.39,0.0,6.99,0.0,0.0,10.99,14.99,0.0,18.99,3.99,5.99,6.99,3.99,3.99,9.99,12.99,0.0,0.0,3.99,0.0,0.0,22.99,9.99,3.19,6.99,6.99,5.79,6.99,1.59,4.99,3.99,18.99,0.0,0.0,12.99,22.99,19.49,6.99,3.99,11.99,3.99,15.49,3.99,16.99,0.0,8.29,11.39,26.99,1.59,4.99,2.09,14.99,2.79,0.0,0.0,11.39,1.99,14.99,0.0,6.99,1.99,0.0,16.99,32.99,0.0,6.99,10.99,29.99,6.99,3.99,0.0,0.79,13.49,6.99,6.99,0.79,6.99,4.99,3.99,4.79,0.79,3.99,9.99,9.29,11.39,9.99,9.99,0.0,0.79,1.99,0.0,22.99,19.49,10.99,11.99,5.59,7.99,10.29,1.59,6.99,18.49,0.0,11.39,3.99,3.99,0.0,11.39,5.19,0.0,0.79,0.79,22.99,11.99,29.99,2.79,1.69,9.99,10.99,3.99,6.99,22.99,6.99,7.99,6.99,15.49,24.99,4.99,0.0,7.99,39.99,14.99,4.99,0.0,0.0,6.99,1.99,0.0,6.99,8.99,7.19,0.0,6.99,8.99,5.59,0.0,2.79,3.99,3.99,0.0,7.99,11.39,6.99,6.99,3.99,10.99,9.99,10.99,10.99,6.99,3.99,0.0,9.99,14.99,14.99,14.99,14.99,10.99,17.99,29.99,10.99,0.0,4.79,39.99,6.99,0.0,0.79,11.39,15.99,0.0,3.99,3.99,10.99,22.99,1.99,0.0,7.99,11.39,0.79,3.99,15.49,2.79,1.59,3.99,29.99,9.99,1.59,3.99,7.99,3.99,1.59,0.0,4.79,2.09,10.99,0.0,3.99,2.99,29.99,3.99,0.0,0.0,15.99,9.99,3.99,4.99,12.39,10.99,6.99,21.99,10.99,23.79,0.0,23.79,6.99,1.99,14.99,0.0,4.79,14.99,3.19,6.39,4.99,0.0,11.39,6.99,7.99,24.99,3.99,7.19,23.79,1.99,0.0,23.79,0.0,9.99,30.99,7.19,10.99,13.99,11.39,0.79,3.99,3.99,7.19,0.0,6.99,11.39,6.99,0.0,19.49,6.99,0.0,22.99,8.59,6.99,18.99,0.79,0.0,29.99,0.0,14.99,3.99,2.89,1.59,14.99,14.99,2.79,0.0,0.79,3.99,3.99,6.99,10.99,0.79,3.99,2.79,24.99,14.99,4.99,14.99,13.99,4.79,9.99,0.79,15.99,29.99,10.99,6.99,6.99,0.0,3.99,1.59,22.99,10.99,3.99,34.99,24.99,13.0,4.25,4.99,1.99,14.99,3.99,4.79,14.99,4.79,1.99,2.79,1.69,0.0,11.39,15.49,5.79,14.99,13.49,0.79,13.59,15.99,8.59,4.99,24.99,23.79,15.49,0.0,34.99,0.0,0.0,7.99,11.39,5.59,4.99,7.19,18.99,10.99,15.99,4.69,49.99,49.99,6.99,1.59,22.99,24.99,6.99,6.99,39.99,10.99,10.29,0.99,14.99,9.99,0.0,19.98,2.79,27.79,1.59,1.99,2.89,15.49,75.99,3.99,0.0,29.99,0.0,2.89,15.99,0.0,26.99,6.19,0.0,8.59,6.99,37.99,14.99,10.99,10.99,14.99,3.99,49.99,3.19,6.99,0.0,6.99,8.99,49.99,49.99,14.99,11.39,10.99,3.99,7.19,6.99,11.99,4.99,3.99,24.99,3.99,14.99,13.49,11.39,18.74,0.0,14.99,10.99,6.99,5.59,7.19,4.99,12.99,10.99,8.49,7.19,3.19,6.99,5.59,1.59,19.99,6.99,10.99,4.79,6.99,1.99,18.99,2.79,11.39,9.99,4.99,10.99,6.99,3.99,0.79,17.49,0.0,13.49,3.99,0.0,3.99,10.99,0.0,0.0,24.99,1.99,1.59,0.0,14.99,49.99,0.0,0.79,6.99,5.79,1.99,10.99,3.99,6.99,6.99,9.99,1.59,4.99,14.99,5.59,9.99,3.99,4.99,22.99,18.99,7.19,19.99,1.59,19.49,11.99,33.99,15.49,22.99,11.49,0.0,10.99,2.79,9.99,9.99,0.79,14.99,19.99,1.69,7.19,1.99,1.59,38.99,4.79,0.0,7.19,7.99,7.99,6.99,14.99,14.99,10.99,19.99,7.19,49.99,6.99,3.99,8.99,14.99,19.99,4.99,2.89,7.19,6.99,0.0,19.49,45.0,8.99,39.99,4.99,6.99,0.0,6.99,10.99,0.0,10.29,7.99,10.99,7.19,7.99,4.79,0.0,11.99,0.79,6.99,6.99,1.99,14.99,10.99,0.0,29.99,6.99,2.09,11.39,11.39,10.99,6.99,9.99,0.0,6.99,14.99,25.99,7.19,1.69,1.69,15.49,1.69,2.79,2.79,14.99,34.99,6.99,9.99,5.59,22.99,0.0,8.99,4.99,3.99,9.99,6.99,25.99,24.99,11.39,10.99,0.79,6.99,9.99,2.99,14.99,8.99,14.99,6.99,23.79,5.19,4.79,24.99,4.99,1.99,4.99,5.19,15.49,6.99,8.99,23.99,15.49,41.99,2.79,3.99,6.0,3.99,0.79,8.99,10.99,0.0,6.99,12.99,0.0,5.59,3.19,14.99,26.99,14.99,7.19,6.99,2.99,34.99,1.59,0.79,0.79,0.79,10.99,14.99,3.99,2.99,2.09,5.59,7.19,15.99,9.29,14.99,29.99,0.0,3.99,1.99,11.99,6.99,23.79,3.99,0.0,9.99,3.99,0.0,9.99,7.99,6.99,29.99,19.49,6.99,10.99,22.99,0.79,4.79,4.79,0.0,29.99,1.99,0.0,3.99,0.79,3.99,0.0,3.99,0.0,10.99,3.99,12.49,4.99,4.49,7.19,7.19,5.79,4.79,3.99,14.99,1.99,23.79,0.79,34.99,10.99,0.0,2.89,0.79,0.0,10.99,10.99,1.99,6.99,14.99,10.99,0.0,10.99,3.99,14.99,6.99,5.19,19.99,1.99,0.79,3.99,49.99,15.49,6.99,5.79,14.99,8.99,10.99,4.99,7.99,11.39,27.99,0.0,11.39,3.99,7.99,10.99,0.0,7.19,0.79,4.29,3.99,7.99,14.99,6.99,0.0,11.99,4.99,14.99,2.99,0.0,19.99,15.49,17.99,1.99,19.99,11.99,0.79,14.99,8.59,14.99,39.99,8.59,2.99,6.99,1.59,6.99,3.99,3.99,0.79,0.0,0.0,2.09,4.79,15.49,18.99,1.69,14.99,0.0,4.79,14.99,0.79,1.59,15.49,39.99,4.79,0.0,10.99,10.99,44.99,0.79,0.0,6.99,3.99,10.29,0.0,0.0,29.99,23.79,14.99,34.99,0.0,4.99,10.99,14.99,5.59,0.79,6.99,22.99,3.99,3.99,7.19,10.99,7.19,3.99,0.0,14.99,14.99,1.59,5.99,15.49,3.99,14.99,0.0,2.09,5.99,0.0,0.0,2.09,6.99,5.79,5.99,4.99,14.99,7.19,5.19,6.99,3.99,10.99,0.0,4.99,0.79,1.69,18.99,7.99,10.99,1.59,34.99,19.49,3.99,0.0,3.99,3.99,10.29,0.0,8.29,2.89,1.49,14.99,13.49,0.79,0.0,11.39,10.99,0.0,7.19,2.09,0.0,3.99,6.99,29.99,14.99,15.49,19.99,0.79,1.59,5.79,10.99,11.39,15.49,0.79,0.79,23.79,4.79,25.99,12.99,15.99,15.49,11.99,4.49,2.79,14.99,3.99,22.99,27.11,7.19,0.79,39.99,4.79,3.99,11.49,0.0,24.99,0.0,4.79,10.29,10.99,0.79,15.99,11.99,0.0,7.19,4.99,15.49,2.79,11.39,0.0,6.99,34.99,1.99,0.0,0.0,11.99,0.0,6.99,3.99,6.99,4.79,0.0,2.79,19.49,14.99,11.39,3.99,3.99,0.79,3.99,9.99,33.99,7.99,3.99,34.99,3.99,10.99,6.99,1.69,8.99,2.09,11.99,7.99,10.99,2.09,29.99,6.99,0.79,6.99,5.59,10.99,1.99,8.59,15.49,6.99,0.0,5.99,0.79,6.99,6.99,9.99,0.79,0.79,15.49,1.59,23.79,0.0,0.0,9.29,0.0,6.99,10.99,9.99,0.79,10.99,8.99,6.99,0.0,3.99,6.99,0.79,39.99,15.49,7.19,5.99,0.79,3.99,0.0,5.99,0.0,7.19,18.99,0.0,0.0,3.99,11.39,14.99,6.99,10.99,29.99,6.99,0.0,0.0,0.79,11.99,15.49,0.0,8.59,2.89,10.99],\"y0\":\" \",\"yaxis\":\"y\",\"type\":\"box\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"rating=Very Positive<br>price=%{y}<extra></extra>\",\"legendgroup\":\"Very Positive\",\"marker\":{\"color\":\"#ab63fa\"},\"name\":\"Very Positive\",\"notched\":false,\"offsetgroup\":\"Very Positive\",\"orientation\":\"v\",\"showlegend\":true,\"x0\":\" \",\"xaxis\":\"x\",\"y\":[27.79,0.0,7.19,1.99,44.99,19.49,11.39,10.99,6.99,0.0,14.99,3.99,1.99,9.99,6.99,15.99,4.99,6.99,10.99,19.49,9.99,4.79,4.29,6.99,0.0,6.99,8.99,15.49,1.99,3.99,22.99,0.79,0.0,10.99,2.09,9.99,2.79,6.99,1.69,6.99,8.29,0.0,5.19,2.99,6.99,5.19,14.99,0.0,10.99,14.99,7.19,6.99,6.99,14.99,10.99,15.99,6.99,7.99,4.79,6.99,0.79,5.59,9.99,10.99,4.99,6.99,0.0,29.99,14.99,7.19,3.99,0.0,2.79,7.99,11.39,11.39,2.89,0.0,11.39,15.49,10.99,1.99,0.99,6.99,15.99,6.99,0.0,29.99,3.99,0.0,39.99,10.99,10.99,7.99,10.99,14.99,1.59,11.99,6.99,18.99,6.99,14.99,7.99,0.0,10.99,6.99,5.99,6.99,7.19,0.0,6.99,19.99,14.99,11.39,4.99,7.19,19.99,12.99,19.99,6.99,3.99,14.99,1.69,1.99,6.99,19.99,6.99,9.99,1.69,15.49,0.0,19.99,4.79,19.49,14.99,9.99,11.39,10.99,4.99,2.89,3.49,11.99,15.8,6.99,9.99,2.89,0.79,24.99,9.29,14.49,4.25,0.0,14.21,16.99,9.99,9.99,11.39,3.99,14.99,5.79,6.69,15.49,11.39,1.99,14.99,0.0,19.99,15.49,2.79,10.99,6.99,6.99,15.49,14.99,15.49,14.99,14.99,0.79,10.99,13.99,11.39,23.99,6.99,6.99,2.79,6.99,3.99,6.99,0.0,4.99,6.99,3.99,12.49,5.19,1.69,6.99,11.39,0.0,0.0,10.99,29.99,10.99,2.89,6.99,5.99,0.0,15.49,18.99,5.59,2.89,29.99,0.0,4.99,23.79,14.99,1.69,0.79,10.99,8.99,0.0,15.49,10.99,1.69,1.69,0.0,10.99,5.19,0.79,6.99,6.99,52.99,2.99,10.29,10.99,0.0,0.0,0.79,6.99,0.0,6.99,13.59,3.99,4.49,26.99,10.29,0.0,6.99,10.99,9.99,11.39,2.09,6.99,10.99,7.19,14.99,8.99,2.09,8.99,12.39,7.19,10.99,27.79,1.59,6.99,3.99,0.0,9.99,9.99,0.79,11.39,14.99,22.99,10.99,0.0,1.99,23.79,10.99,24.99,4.99,9.99,4.79,12.99,7.19,0.0,1.69,11.99,4.99,5.59,1.69,22.99,6.99,8.99,3.99,15.49,0.0,4.99,7.19,10.29,0.79,0.79,6.99,8.99,25.99,9.99,6.99,7.19,6.99,10.99,8.59,1.99,6.99,14.99,0.79,10.29,0.79,14.99,0.79,8.59,22.99,6.99,10.99,14.99,4.79,6.99,0.79,1.99,15.99,11.39,6.99,12.49,6.99,7.19,4.79,10.99,15.49,29.99,0.79,6.99,6.99,3.99,8.99,0.0,0.0,9.99,0.79,0.0,10.29,0.0,1.99,14.99,2.79,7.99,9.29,7.19,1.99,3.99,6.99,1.69,4.12,15.99,9.99,6.99,6.99,23.79,10.29,4.99,6.99,10.99,5.79,0.0,4.99,39.99,0.0,7.19,15.49,11.39,0.0,4.79,3.99,6.99,3.99,6.99,4.99,10.99,0.79,3.99,39.99,0.0,9.29,3.99,14.99,29.99,1.99,2.79,15.49,9.99,14.99,11.39,0.0,6.99,10.99,6.99,15.99,5.59,24.99,19.49,3.99,6.99,1.99,11.39,6.99,10.99,13.99,5.59,5.99,3.99,11.39,12.39,5.99,5.79,10.99,6.99,5.19,0.0,14.99,11.99,6.99,11.39,0.0,0.0,0.79,0.79,7.19,3.99,14.99,7.19,10.99,10.99,6.99,22.99,0.0,1.99,2.09,1.69,27.79,6.99,3.99,23.79,11.99,0.0,0.79,4.99,14.99,4.99,4.25,1.99,9.99,8.29,7.19,1.59,11.39,1.99,6.99,0.0,1.59,14.99,4.99,0.0,11.39,13.99,1.59,10.99,0.0,0.0,5.19,6.99,3.99,18.99,3.99,0.0,39.99,44.99,11.99,4.99,1.99,2.99,4.79,0.0,6.99,0.0,7.19,6.99,11.39,10.99,9.99,3.99,10.99,3.99,7.19,6.99,13.99,13.59,10.99,5.99,3.99,14.99,3.99,22.99,3.49,19.49,4.25,5.2,7.19,10.99,6.99,12.99,19.49,15.49,15.49,9.29,6.99,10.99,14.99,14.99,4.79,11.39,10.99,6.99,6.99,15.49,3.99,1.99,1.99,6.99,6.99,0.0,13.99,11.49,14.99,14.99,11.39,3.99,3.99,14.99,8.99,12.39,11.39,11.49,14.99,11.39,11.39,11.39,15.0,14.99,3.99,6.99,7.19,2.09,7.19,0.79,0.0,14.99,14.99,15.49,0.79,3.99,19.49,22.99,10.99,11.99,7.99,0.0,0.0,18.99,6.99,29.99,6.99,14.99,3.99,15.49,7.99,19.49,2.89,1.69,0.0,4.79,1.99,6.99,10.29,30.99,8.59,10.99,9.29,15.49,0.0,2.89,17.99,34.99,27.79,4.99,10.99,6.99,11.99,5.59,14.99,3.99,10.99,18.99,0.0,6.99,30.99,3.99,19.99,0.0,3.59,22.99,0.79,6.99,11.99,14.99,3.99,11.39,15.49,0.0,19.99,2.79,6.99,9.99,0.0,3.99,1.99,1.99,0.0,0.79,14.99,8.99,2.79,7.19,6.99,6.99,5.99,26.99,10.99,6.99,4.99,14.99,0.0,6.99,3.99,3.99,0.0,17.99,5.59,6.99,1.69,11.39,3.99,0.0,6.99,6.99,10.99,10.59,0.0,14.99,0.0,0.0,0.0,0.0,29.99,14.99,4.79,1.99,10.99,3.99,7.99,11.39,19.49,10.29,0.0,4.99,0.79,25.99,60.99,10.99,2.79,5.59,29.99,0.0,0.0,11.99,10.99,1.99,5.99,3.99,10.99,4.25,1.59,1.69,4.79,14.99,0.0,15.49,6.99,29.99,13.99,6.99,35.96,0.0,0.0,1.59,4.99,7.19,29.99,1.69,6.99,19.99,1.69,0.79,7.49,4.99,29.99,1.59,19.49,1.3,14.99,5.19,10.99,2.09,11.49,11.39,14.99,14.99,10.99,14.99,8.99,3.99,0.0,14.99,29.99,23.79,1.59,15.49,10.99,22.99,0.0,23.79,6.99,6.99,6.99,6.99,6.99,14.99,0.79,0.0,4.79,7.19,3.99,8.99,4.79,3.99,3.99,24.99,24.99,14.99,6.99,2.09,14.99,7.19,5.99,6.99,3.99,15.49,9.99,1.99,9.99,6.99,13.49,0.79,7.99,0.79,14.99,1.69,0.79,0.0,3.99,2.09,10.99,10.99,0.0,15.49,23.79,0.0,5.99,21.0,11.39,5.99,12.99,0.0,6.99,3.99,11.39,10.99,7.99,6.99,10.99,3.99,13.49,6.99,0.0,24.99,23.79,12.39,14.99,10.29,10.99,2.09,15.49,6.99,6.99,0.0,5.99,10.29,6.99,0.79,2.79,0.0,0.0,5.79,6.99,7.99,1.59,3.99,15.49,2.09,7.19,10.99,6.19,0.79,10.99,6.99,4.99,22.99,6.99,4.79,0.79,15.49,19.99,24.99,0.79,2.09,12.99,5.59,23.79,5.99,10.99,2.09,0.0,11.39,0.0,0.79,14.99,26.99,5.79,12.99,0.79,10.99,11.39,0.79,10.99,22.99,6.99,0.0,15.49,0.0,11.99,11.99,18.99,9.99,10.99,6.99,5.59,23.79,22.99,3.99,12.49,3.99,19.99,0.0,9.99,22.99,6.99,5.99,0.0,1.69,10.99,2.79,14.99,7.19,10.99,10.99,3.99,24.99,1.99,6.19,1.69,7.19,1.99,14.99,6.99,7.19,10.99,11.99,5.19,6.99,0.79,0.79,3.99,19.99,7.99,7.19,19.99,1.99,10.99,7.19,9.29,14.99,1.99,6.19,6.99,6.99,11.99,14.99,1.99,3.99,4.79,6.99,0.0,10.29,24.99,4.79,11.99,3.19,14.99,5.79,4.99,10.99,8.59,6.99,15.49,18.99,2.89,2.29,6.99,6.99,14.99,0.0,6.99,14.99,0.79,0.0,14.99,3.99,6.99,11.99,0.0,12.99,10.99,0.0,10.99,10.99,0.0,3.99,9.99,10.99,0.0,19.49,11.99,7.19,14.99,5.19,0.0,18.99,6.99,0.79,19.99,5.59,14.99,14.99,7.99,6.99,7.19,15.49,10.99,1.99,0.79,0.0,23.79,9.99,15.49,0.0,14.99,3.99,4.79,22.99,3.99,0.0,3.99,7.19,14.99,27.79,4.79,10.99,6.99,7.19,8.99,14.99,6.99,0.79,10.99,12.99,6.99,3.99,4.79,12.99,0.0,0.0,3.99,14.99,0.0,2.89,2.89,0.0,6.99,0.0,4.99,7.19,10.29,14.99,6.99,6.99,2.79,0.79,0.0,0.0,0.0,0.0,4.99,15.99,15.49,10.99,14.99,9.99,0.0,7.19,0.0,19.49,15.99,3.99,0.0,6.99,10.99,6.99,9.99,0.0,10.99,25.99,0.0,15.49,6.99,15.49,7.19,3.99,12.99,5.99,10.99,3.99,0.0,14.99,26.99,6.99,7.99,0.0,12.99,10.99,0.0,10.99,6.99,7.49,11.39,7.99,7.77,6.99,10.99,4.79,7.99,11.39,19.49,15.49,23.79,14.99,7.19,14.99,8.99,6.99,5.79,6.99,6.99,6.99,0.0,2.79,15.99,0.0,15.49,6.99,15.99,29.99,29.99,6.99,11.39,0.0,14.99,6.99,22.99,2.09,10.99,6.99,6.0,19.99,23.99,0.0,7.5,14.99,10.99,6.99,0.0,16.99,30.99,3.99,14.99,0.79,2.99,15.49,2.49,2.99,30.99,3.99,23.79,15.49,7.19,1.59,0.0,10.99,6.99,7.19,0.79,0.79,3.99,6.99,15.49,0.0,0.79,0.0,14.99,10.99,15.49,19.99,15.49,14.99,0.0,10.99,0.79,10.99,0.79,12.99,7.99,7.19,23.79,11.39,14.99,14.99,6.99,24.99,3.99,26.99,0.0,39.99,0.0,0.79,0.0,0.0,4.25,6.99,6.99,0.79,19.49,0.79,6.99],\"y0\":\" \",\"yaxis\":\"y\",\"type\":\"box\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"rating=Negative<br>price=%{y}<extra></extra>\",\"legendgroup\":\"Negative\",\"marker\":{\"color\":\"#FFA15A\"},\"name\":\"Negative\",\"notched\":false,\"offsetgroup\":\"Negative\",\"orientation\":\"v\",\"showlegend\":true,\"x0\":\" \",\"xaxis\":\"x\",\"y\":[1.99,13.99,3.99,10.99,9.99,3.99,14.99,10.99,14.99,3.99,5.79,6.99,0.0,0.0,0.79,14.99,6.99,34.99,14.99,9.99,1.99,1.59,11.39,0.0,0.0,0.0,0.0,3.99,1.59,0.0,0.79,0.0,2.09,2.89,6.99,7.99,0.0,0.79,3.99,6.99,10.99,0.0,0.0,4.99,15.49,0.79,4.99,4.99,0.0,3.99,6.99,8.99,7.99,0.0,4.79,13.5,5.19,10.29,3.99,11.39,5.79,10.99,3.99,3.99,5.59,0.0,5.19,0.79,1.69,10.99,0.0,6.99,1.59,1.59,3.19,5.99,11.39,0.0,5.59,1.99,0.79,14.99,1.69,2.79,6.99,9.99,3.99,34.99,4.99,3.99,14.99,0.0,0.0,15.49,0.0,2.09,0.0,2.99,4.49,1.59,0.0,3.19,14.99,3.99,0.79,1.69,14.99,0.0,2.09,2.79,0.0,6.99,11.39,0.79,0.0,10.99,2.79,11.39,14.99,4.49,2.09,10.99,3.99,15.49,0.0,0.79,14.99,1.59,3.99,4.99,6.99,24.99,22.49,1.59,0.79,39.99,0.0,14.99,6.99,6.99,0.99,3.99,9.29,0.79,0.0,4.49,14.99,0.72,2.09,3.99,6.99,3.99,0.0,15.49,9.99,0.79,0.79,0.79,3.99,2.09,11.99,0.79,5.59,4.29,3.99,5.19,14.99,2.99,0.79,5.59,14.99,3.99,18.99,0.0,6.99,4.99,24.99,1.99,29.99,39.99,3.99,3.99,0.0,0.0,4.79,10.29,0.0,6.99,0.0,3.99,0.0,0.79,3.99,0.0,2.99,22.99,0.79,22.99,7.19,0.79,3.99,13.59,12.99,0.79,11.99,0.79,1.99,1.59,1.69,4.99,8.59,3.49,26.99,0.0,1.99,0.0,25.99,0.79,0.0,0.79,6.99,15.49,2.79,6.99,1.69,1.99,3.99,29.99,1.99,12.99,0.0,14.99,6.99,15.49,3.99,0.79,3.99,3.99,17.99,1.99,4.99,6.99,0.0,6.99,23.79,5.79,1.99,0.0,0.79,39.99,3.49,7.99,6.99,2.09,6.19,5.59,1.59,9.99,5.79,12.49,0.0,3.19,3.99,9.99,4.79,0.79,3.99,3.99,39.99,3.19,0.79,5.99,0.0,10.99,0.0,1.69,4.99,2.09,4.99,0.0,2.79,7.19,1.59,22.99,0.79,6.99,7.19,0.0,34.99,3.49,1.59,18.99,11.99,34.99,0.79,1.69,6.99,1.69,9.99,3.99,2.79,0.0,3.1,0.0,13.49,0.0,0.0,1.59,6.99,1.59,3.99,0.79,3.99,0.79,0.0,3.99,3.99,7.19,0.79,5.79,0.0,6.99,0.79,3.99,10.99,11.99,10.99,1.99,3.99,0.0,0.0,0.79,1.59,24.99,0.79,14.99,13.99,0.72,0.0,0.0,22.99,6.99,24.99,6.99,0.79,0.0,1.59,3.19,4.49,0.79,3.99,3.99,3.99,20.99,0.0,3.19,3.99,15.49,1.69,6.99,0.79,0.0,4.79,6.99,0.79,3.99,0.0,3.99,39.99,0.0,39.99,6.99,14.99,25.99,4.99,14.99,6.99,1.59,1.59,3.99,15.99,1.69,0.0,0.0,3.99,3.99,1.69,4.79,0.0,4.79,10.99,1.59,10.99,2.09,0.79,1.59,2.09,0.79,15.99,1.59,0.79,6.99,6.99,15.99,14.99,0.0,1.69,0.0,3.99,4.99,0.0,2.89,0.0,6.99,0.0,6.99,10.99,22.99,1.69,6.99,6.99,1.59,1.99,0.0,5.59,18.99,9.29,4.99,14.99,0.79,0.0,0.79,0.0,0.0,5.59,0.0,4.99,1.99,0.0,0.79,6.99,0.0,44.99,0.79,9.99,4.79,5.79,0.79,1.99,3.19,0.0,0.0,18.99,2.79,9.99,3.99,3.99,3.19,6.99,7.99,1.99,29.99,6.99,3.99,0.79,3.99,1.69,0.0,3.19,2.09,7.19,15.99,0.79,1.99,1.59,10.59,0.0,0.0,0.0,0.79,9.29,6.99,4.99,7.99,3.49,0.79,6.99,14.99,0.0,6.99,0.0,12.99,3.99,14.69,6.99,9.99,10.99,6.99,3.19,3.99,3.99,4.79,4.79,0.0,0.79,29.99,3.99,0.0,3.99,3.99,0.79,3.99,0.0,9.99,10.99,0.0,19.49,5.19,0.0,3.99,2.09,1.99,2.09,5.79,0.79,0.0,2.09,5.99,0.79,0.0,6.99,9.99,10.99,1.59,16.99,3.99,10.99,9.99,2.09,2.09,29.99,11.39,0.0,0.79,0.0,30.99,10.99,14.99,3.19,9.29,0.0,8.29,0.0,0.79,3.99,10.99,15.99,3.99,3.99,0.0,7.19,0.79,0.0,0.0,1.59,3.99,2.89,8.99,17.99,6.99,0.0,8.02,3.99,5.19,7.49,11.99,0.0,19.99,0.0,10.99,6.99,0.0,0.79,14.99,15.49,1.59,5.19,0.0,6.99,1.99,0.0,2.89,0.0,0.0,7.19,0.79,0.79,6.99,0.79,0.79,6.99,0.0,2.89,3.1,0.79,0.0,2.09,1.99,0.79,29.99,5.19,3.99,0.79,0.79,3.19,3.99,3.99,5.99,6.19,0.0,6.99,3.99,5.99,0.0,0.0,10.29,1.99,0.79,1.69,6.99,0.79,6.99,10.29,8.99,0.79,7.19,2.09,0.0,4.79,24.99,15.49,9.99,6.99,0.0,0.79,21.99,0.79,11.99,0.0,17.99,39.99,0.0,3.99,5.59,17.99,2.99,22.49,1.99,1.69,10.99,14.99,0.79,4.99,3.99,23.79,14.99,0.0,6.99,3.99,4.99,3.99,0.79,3.19,6.99,1.99,3.19,0.0,7.19,14.99,0.75,6.99,13.59,0.0,0.79,3.99,1.59,23.79,3.99,4.99,0.79,3.99,2.09,8.99,0.0,0.0,0.0,0.0,5.99,0.79,3.99,18.99,1.99,9.99,8.99,2.79,3.99,0.0,2.09,7.99,1.99,0.0,6.19,0.0,3.99,3.99,0.79,1.59,14.99,6.99,39.99,10.99,0.0,3.99,3.99,31.99,1.69,0.0,3.99,16.66,0.0,3.19,0.0,1.69,5.99,17.99,13.59,3.99,1.99,10.99,6.99,0.0,22.99,1.59,8.99,0.79,7.99,6.99,0.79,26.99,2.09,0.79,1.99,14.99,0.0,0.0,3.19,2.79,11.99,6.99,15.99,6.99,1.99,33.99,2.99,10.99,1.69,0.79,3.99,2.79,10.99,6.99,0.0,8.99,7.19,0.79,29.99,0.79,4.99,19.49,3.99,0.0,22.99,0.0,14.99,10.99,3.99,0.0,1.69,5.59,9.99,3.19,17.98,6.99,17.99,3.99,8.99,1.59,0.0,0.0,0.79,0.0,0.0,0.0,2.09,10.99,14.99,3.19,6.99,14.99,0.0,10.99,1.99,5.99,22.99,0.0,3.99,0.0,1.69,2.79,0.79,0.79,22.99,0.79,15.99,19.99,2.79,0.0,3.99,22.99,10.99,9.99,11.39,0.0,0.79,9.99,6.99,15.99,13.99,6.99,11.29,3.99,3.99,0.79,14.99,4.79,0.0,6.99,0.0,11.39,17.99,3.19,0.0,0.79,0.0,0.79,6.99,3.99,0.79,22.99,7.19,16.99,14.99,0.0,6.99,0.0,10.99,3.99,7.99,0.79,44.99,0.0,4.99,33.99,11.99,0.0,4.79,0.79,0.79,0.0,14.99,0.79,9.99,3.99,16.3,0.79,7.19,3.99,2.09,1.99,6.99,7.19,0.79,27.0,0.0,7.19,2.79,10.99,7.19,0.0,0.0,0.0,3.99,6.99,10.59,26.99,1.99,7.19,29.99,1.99,23.79,5.79,10.99,15.99,15.49,0.79,1.59,11.99,6.99,0.0,0.79,0.0,6.99,0.0,0.99,27.1,3.19,6.99,6.19,1.69,0.0,6.99,6.99,3.99,0.0,1.69,3.99,0.0,6.99,14.99,49.99,0.0,3.99,0.0,49.99,3.99,10.99,15.49,3.99,0.79,2.89,9.99,3.99,0.0,0.79,5.59,34.99,0.79,6.99,0.0,20.99,0.0,0.0,49.99,4.99,0.0,4.79,17.99,5.19,1.99,5.99,3.99,0.79,3.99,0.0,29.99,0.79,0.79,6.99,3.99,1.69,3.99,1.69,4.99,0.0,0.0,0.78,0.79,0.0,0.0,0.0,0.0,15.99,3.99,6.99,0.79,18.1,0.0,0.0,0.0,1.99,0.0,22.99,14.99,3.99,3.99,3.99,6.99,4.79,0.0,0.0,12.99,4.79,9.99,3.99,3.99,0.0,3.99,6.99,0.99,0.0,3.99,0.79,3.19,1.99,0.0,0.79,10.99,4.99,49.99,3.99,14.99,24.99,3.99,7.19,1.59,8.99,3.99,3.99,4.79,3.99,0.0,2.89,0.0,19.99,1.59,6.99,3.99,6.99,0.79,13.99,3.99,11.39,39.99,17.99,0.0,14.99,0.0,5.79,39.99,4.79,7.19,0.99,2.09,1.99,10.99,14.99,2.09,7.99,0.0,6.99,6.99,0.0,6.99,10.99,0.0,9.99,3.99,0.79,6.99,14.99,0.79,9.99,3.99,5.59,0.79,3.99,4.79,7.19,2.09,5.19,7.19,0.79,6.99,3.99,3.19,3.99,22.49,1.99,3.99,1.99,7.49,0.79,3.99,0.0,3.99,0.79,9.99,0.0,0.79,4.79,1.99,39.99,0.0,3.99,0.0,14.99,0.0,1.99,0.0,14.99,2.09,6.19,0.79,9.29,2.79,3.99,0.0,0.0,0.79,4.99,1.59,3.99,1.59,19.99,1.69,0.0,4.49,0.0,8.99,3.99,2.79,1.59,39.99,6.99,2.09,7.99,2.09,0.0,0.0,5.79,5.79,1.59,24.99,0.0,6.99,0.79,15.49,14.99,6.99,15.49,0.0,0.0,3.99,0.0,3.99,3.19,0.0,10.99,15.99,10.99,0.0,6.99,13.99,4.99,0.0,14.99,1.69,0.79,11.39,14.99,10.99,9.99,0.79,1.69,4.99,1.99,0.0,0.0,29.99,25.99,34.99,15.49,14.99,0.0,0.79,0.79,0.79,19.49,22.99,8.99,2.09,0.0,0.0,6.99,0.79,6.49,29.99,0.79,0.0,1.99,3.99,2.09,5.19,0.79,3.19,0.0,0.0,14.99,0.0,0.79,7.99,3.99,0.79,5.59,4.99,9.99,0.0,0.79,0.79,5.59,6.99,3.99,1.59,6.99,4.99,2.99,7.99,0.0,2.49,0.0,0.0,0.0,0.0,2.79,0.0,3.19,0.0,3.99,6.99,6.99,0.0,4.79,9.99,0.79,14.99,0.79,6.99,0.99,0.0,3.19,0.79,3.99,6.99,0.79,17.99,2.99,3.99,13.99,3.99,2.79,5.19,6.99,0.0,0.79,10.99,15.49,7.99,6.99,3.19,2.79,3.19,2.89,14.99,8.99,6.99,6.99,39.99,15.49,0.0,0.0],\"y0\":\" \",\"yaxis\":\"y\",\"type\":\"box\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"price\"}},\"legend\":{\"title\":{\"text\":\"rating\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Distribuci\\u00f3n de price seg\\u00fan rating\"},\"boxmode\":\"group\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('c452bb3f-43b9-4173-b7b9-4c8a9d2ef651');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## 3. Preparación de Datos\n",
        "\n",
        "Para preparar nuestros datos, primero copiamos el dataframe original para modificarlo.\n",
        "Se extrae la columna de mes de las fechas.\n",
        "Se crea la columna `developer_list` con la cual se trabaja y se obtienen los mejores `N` deveolpers del conjunto, mientras que los demás son catalogados como `Other`.\n",
        "Esto se realiza con el fin de mantener solo a los considerados previamente como relevantes.\n",
        "\n",
        "Se realiza un procedimiento similar para los publishers creando la columna `publisher_list` que finalmente contendrá solo los mejores `publishers`."
      ],
      "metadata": {
        "cell_id": "00010-41569a5a-d2db-40c6-a236-99a8d5ef58b7",
        "deepnote_cell_type": "markdown",
        "id": "63G38UBn3pv2"
      },
      "id": "63G38UBn3pv2"
    },
    {
      "cell_type": "code",
      "source": [
        "def bestN( df, col_name, n):\n",
        "  '''\n",
        "  Obtiene los mejores N de una columna.\n",
        "  '''\n",
        "  all = []\n",
        "  for row in df_train2[col_name]:\n",
        "    all.extend( row )\n",
        "\n",
        "  count = Counter(all)\n",
        "\n",
        "  ordered_count = list(sorted(count.items(), key=lambda item: item[1], reverse=True))\n",
        "  # top 20\n",
        "  unique = len( ordered_count )\n",
        "  topN = ordered_count[:n]\n",
        "\n",
        "  topNnames = [el[0] for el in topN]\n",
        "\n",
        "  print(f'Hay {unique} developers diferentes')\n",
        "  print(f'Los {n} registros de {col_name} con más juegos son {topN}')\n",
        "\n",
        "  return topNnames"
      ],
      "metadata": {
        "id": "ZxBdNMFC-0n8"
      },
      "id": "ZxBdNMFC-0n8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_best(list_in,list_best_N):\n",
        "  '''\n",
        "  Recibe una lista con los datos de una fila del dataframe, y una lista con los\n",
        "  los top N. Retorna los primeros elementos de la lista que se encuentren\n",
        "  en la segunda.\n",
        "  '''\n",
        "  c = 0\n",
        "  best_elements = []\n",
        "  for el in list_in:\n",
        "    if el in list_best_N: \n",
        "      best_elements.append(el)\n",
        "      c+=1\n",
        "  return best_elements"
      ],
      "metadata": {
        "id": "2xVG8OCc-2-2"
      },
      "id": "2xVG8OCc-2-2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train2 = df_train.copy()\n",
        "df_train2[\"developer_list\"] = df_train2.developer.apply(lambda x: [dev for dev in x.split(';')])\n",
        "\n",
        "# preparacion para datos de fechas\n",
        "df_train2[\"month\"] = df_train2.release_date.dt.month.astype(\"category\")"
      ],
      "metadata": {
        "id": "LOtrBhwR-55P"
      },
      "id": "LOtrBhwR-55P",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Agrupacion de casos especiales\n",
        "df_train2[\"developer_list\"] = df_train2.developer_list.apply(lambda x: [\"Ubisoft\" if \"Ubisoft\" in dev else dev for dev in x])\n",
        "df_train2[\"developer_list\"] = df_train2.developer_list.apply(lambda x: [\"Feral Interactive\" if \"Feral Interactive\" in dev else dev for dev in x])\n",
        "df_train2[\"developer_list\"] = df_train2.developer_list.apply(lambda x: [\"Capcom\" if (\"Capcom\" in dev or \"CAPCOM\" in dev) else dev for dev in x])\n",
        "\n",
        "# Evitando repeticiones de los casos especiales en string separado por ';\n",
        "df_train2[\"developer_list\"] = df_train2.developer_list.apply(lambda x: list(set(x)))  # une a los repetidos en un mismo registro\n",
        "df_train2[\"developer\"] = df_train2.developer_list.apply(lambda x: ';'.join(list(set(x))))"
      ],
      "metadata": {
        "id": "rJKXvobb-7wS"
      },
      "id": "rJKXvobb-7wS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Si en el registro esta uno de los mejores, absorbe al resto\n",
        "n_devs = 10\n",
        "topNdevs = bestN(df_train2, \"developer_list\", n=n_devs)\n",
        "df_train2[\"developer_list\"] = df_train2.developer_list.apply(lambda x: count_best(x, topNdevs) if len( count_best(x, topNdevs) ) >= 1 else [\"Other\"])\n",
        "\n",
        "df_top_devs = df_train2.loc[df_train2.developer_list.apply(lambda x: any(dev in x for dev in topNdevs))]  # nuevo df para graficar los n mejores\n",
        "df_train2[\"developer_list\"] = df_train2.developer_list.apply(lambda x: x[0])  # selecciona solo el primero de los mejores"
      ],
      "metadata": {
        "id": "g71YfNHQ-9YH"
      },
      "id": "g71YfNHQ-9YH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# modificacion de publisher\n",
        "n_pub = 20\n",
        "# separacion de publisher en una lista por fila\n",
        "df_train2[\"publisher_list\"] = df_train2.publisher.apply(lambda x: [pub for pub in x.split(';')])\n",
        "\n",
        "# Obtiene el top N de publishers\n",
        "topNpublisher = bestN(df_train2, \"publisher_list\", n_pub)\n",
        "df_train2[\"publisher_list\"] = df_train2.publisher_list.apply(lambda x: x[0])\n",
        "\n",
        "# Agrupa los que no esten dentro de los mejores en categoria \"Other\"\n",
        "df_train2[\"publisher_list\"] = df_train2.publisher_list.apply(lambda x: x if x in topNpublisher else \"Other\")"
      ],
      "metadata": {
        "id": "9VLcacFL-_Xj"
      },
      "id": "9VLcacFL-_Xj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = df_train2.drop(columns=[\"estimated_sells\", \"rating\", \"short_description\"])\n",
        "target_sells = df_train2[\"estimated_sells\"]\n",
        "target_rating = df_train2[\"rating\"]"
      ],
      "metadata": {
        "id": "Q07rcyd__Bc0"
      },
      "id": "Q07rcyd__Bc0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gráfico de los developers mas concurridos\n",
        "fig = px.box(df_top_devs,\n",
        "              y=\"estimated_sells\",\n",
        "              color=\"developer\",\n",
        "              title=f\"Ventas estimadas para las {n_devs} developers más recurrentes\",\n",
        "              log_y=True)\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "YcchKgdN_Dm5"
      },
      "id": "YcchKgdN_Dm5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gráfico de los publishers mas concurridos\n",
        "df_top_publisher = df_train2.loc[df_train2.publisher_list.apply(lambda x: any(dev in x for dev in topNpublisher))]\n",
        "\n",
        "fig = px.box(df_top_publisher,\n",
        "              y=\"estimated_sells\",\n",
        "              color=\"developer\",\n",
        "              title=f\"Ventas estimadas para las {n_pub} publishers más recurrentes\",\n",
        "              log_y=True)\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "-ugsXAoi_IBq"
      },
      "id": "-ugsXAoi_IBq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.histogram(df_train2, x=\"rating\", color=\"developer_list\", barmode=\"group\", title=\"Cantidad de ratings por cada developer\")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "IimxqHHE_Kah"
      },
      "id": "IimxqHHE_Kah",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.histogram(df_train2, x=\"rating\", color=\"publisher_list\", barmode=\"group\", title=\"Cantidad de ratings por cada publisher\")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "Qyx_IUre_MUH"
      },
      "id": "Qyx_IUre_MUH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformación de datos test para realizar una predicción.\n",
        "\n",
        "Se replica el mismo procedimiento para test."
      ],
      "metadata": {
        "id": "CM1LZdzQ_O1l"
      },
      "id": "CM1LZdzQ_O1l"
    },
    {
      "cell_type": "code",
      "source": [
        "df_test2 = df_test.copy()\n",
        "\n",
        "df_test2[\"developer_list\"] = df_test2.developer.apply(lambda x: [dev for dev in x.split(';')])\n",
        "\n",
        "# preparacion para datos de fechas\n",
        "df_test2[\"month\"] = df_test2.release_date.dt.month.astype(\"category\")"
      ],
      "metadata": {
        "id": "Xs5tfs3S_RWT"
      },
      "id": "Xs5tfs3S_RWT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Agrupacion de casos especiales\n",
        "df_test2[\"developer_list\"] = df_test2.developer_list.apply(lambda x: [\"Ubisoft\" if \"Ubisoft\" in dev else dev for dev in x])\n",
        "df_test2[\"developer_list\"] = df_test2.developer_list.apply(lambda x: [\"Feral Interactive\" if \"Feral Interactive\" in dev else dev for dev in x])\n",
        "df_test2[\"developer_list\"] = df_test2.developer_list.apply(lambda x: [\"Capcom\" if (\"Capcom\" in dev or \"CAPCOM\" in dev) else dev for dev in x])\n",
        "\n",
        "# Evitando repeticiones de los casos especiales en string separado por ';\n",
        "df_test2[\"developer_list\"] = df_test2.developer_list.apply(lambda x: list(set(x)))  # une a los repetidos en un mismo registro\n",
        "df_test2[\"developer\"] = df_test2.developer_list.apply(lambda x: ';'.join(list(set(x))))"
      ],
      "metadata": {
        "id": "6_9UaMLV_TZ5"
      },
      "id": "6_9UaMLV_TZ5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Si en el registro esta uno de los mejores, absorbe al resto\n",
        "# Si tengo 2 o mas de los mejores N, se crean registros\n",
        "n_devs = 10\n",
        "topNdevs = bestN(df_test2, \"developer_list\", n=n_devs)\n",
        "df_test2[\"developer_list\"] = df_test2.developer_list.apply(lambda x: count_best(x, topNdevs) if len( count_best(x, topNdevs) ) >= 1 else [\"Other\"])\n",
        "\n",
        "df_top_devs = df_test2.loc[df_test2.developer_list.apply(lambda x: any(dev in x for dev in topNdevs))]  # nuevo df para graficar los n mejores\n",
        "df_test2[\"developer_list\"] = df_test2.developer_list.apply(lambda x: x[0])  # selecciona solo el primero de los mejores"
      ],
      "metadata": {
        "id": "1zc7z4vN_VPu"
      },
      "id": "1zc7z4vN_VPu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# modificacion de publisher\n",
        "n_pub = 20\n",
        "# separacion de publisher en una lista por fila\n",
        "df_test2[\"publisher_list\"] = df_test2.publisher.apply(lambda x: [pub for pub in x.split(';')])\n",
        "\n",
        "# Obtiene el top N de publishers\n",
        "topNpublisher = bestN(df_test2, \"publisher_list\", n_pub)\n",
        "df_test2[\"publisher_list\"] = df_test2.publisher_list.apply(lambda x: x[0])\n",
        "\n",
        "# Agrupa los que no esten dentro de los mejores en categoria \"Other\"\n",
        "df_test2[\"publisher_list\"] = df_test2.publisher_list.apply(lambda x: x if x in topNpublisher else \"Other\")"
      ],
      "metadata": {
        "id": "ouu-t5wn_XA3"
      },
      "id": "ouu-t5wn_XA3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## 4. Baseline"
      ],
      "metadata": {
        "cell_id": "00017-3b51644a-c255-4a6a-84d8-91f2e0044198",
        "deepnote_cell_type": "markdown",
        "id": "cAdXCpNn3pv3"
      },
      "id": "cAdXCpNn3pv3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Consideramos una función de evaluación para la regresión.\n",
        "Se trasnforman las columnas de la siguiente forma:\n",
        "- MinMaxScaler: `required_age`.\n",
        "- SantardardScaler: `achievements`, `average_playtime`, `price`.\n",
        "- OrdinalEncoder: `month`.\n",
        "- One Hot Encoder: `english`, `deveolper_list`, `publisher_list`, `platforms`.\n",
        "\n",
        "El resto de las filas son ignoradas en este primer aproach."
      ],
      "metadata": {
        "cell_id": "00018-1eac8423-b445-4d49-aaed-64eeb70be3ca",
        "deepnote_cell_type": "markdown",
        "id": "2xk9ZyAk3pv3"
      },
      "id": "2xk9ZyAk3pv3"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, median_absolute_error\n",
        "\n",
        "# funcion de evaluacion para la regresion\n",
        "def evaluate(y_test, y_pred):\n",
        "\n",
        "    print('MSE:', mean_squared_error(y_test, y_pred), '\\n')\n",
        "    print('RMSE:', mean_squared_error(y_test, y_pred, squared=False))\n",
        "    print('MAE:', mean_absolute_error(y_test, y_pred))\n",
        "    print('MedAE:', median_absolute_error(y_test, y_pred), '\\n')\n",
        "    print('R²:', r2_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "SISMh2JAF6gu"
      },
      "execution_count": null,
      "outputs": [],
      "id": "SISMh2JAF6gu"
    },
    {
      "cell_type": "code",
      "source": [
        "# # separacion en train y test\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train_reg, X_test_reg, y_train_reg, y_test_reg  = train_test_split(\n",
        "    features, target_sells, shuffle=True, test_size=0.3, random_state=33\n",
        ")\n",
        "\n",
        "X_train_clf, X_test_clf, y_train_clf, y_test_clf  = train_test_split(\n",
        "    features, target_rating, shuffle=True, test_size=0.3, random_state=33\n",
        ")"
      ],
      "metadata": {
        "id": "4AN8o-rUEBma"
      },
      "execution_count": null,
      "outputs": [],
      "id": "4AN8o-rUEBma"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
        "from sklearn.feature_selection import SelectPercentile, f_classif\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report\n",
        "# transformando columnas\n",
        "\n",
        "ct1 = ColumnTransformer(\n",
        "    [\n",
        "        (\n",
        "            \"MinMax\",\n",
        "            MinMaxScaler(),\n",
        "            [\n",
        "                \"required_age\",\n",
        "            ],\n",
        "        ),\n",
        "        (\n",
        "            \"Standard\",\n",
        "            StandardScaler(),\n",
        "            [\n",
        "                \"achievements\",\n",
        "                \"average_playtime\",\n",
        "                \"price\",\n",
        "            ]\n",
        "        ),\n",
        "     \n",
        "        (\"Ordinal\", OrdinalEncoder(), [\"month\"]),\n",
        "     \n",
        "        ( \"Ohe\",\n",
        "          OneHotEncoder(sparse=False, handle_unknown='ignore'),\n",
        "          [\n",
        "              \"english\",\n",
        "              \"developer_list\",\n",
        "              \"platforms\",\n",
        "              \"publisher_list\",\n",
        "          ]),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# pipline para regresion\n",
        "pipe_reg = Pipeline([(\"Preprocesamiento\", ct1),\n",
        "                    ('Feature selection', SelectPercentile(f_classif, percentile=90)),\n",
        "                    ('regresor', LinearRegression())])\n",
        "\n",
        "# pipline para clasificacion\n",
        "pipe_clf = Pipeline([(\"Preprocesamiento\", ct1),\n",
        "                   ('Feature selection', SelectPercentile(f_classif, percentile=90)),\n",
        "                    ('Classifier', SVC(C=1, kernel=\"rbf\"))])"
      ],
      "metadata": {
        "id": "I05x1CzJayAb"
      },
      "execution_count": null,
      "outputs": [],
      "id": "I05x1CzJayAb"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez realizado un column transformer y preparado las pipelines respectivas, se generan las grillas presentadas a continuación, que consideran los modelos `SVM` y `Random Forest` para la clasificación, mientras que para la regresión se usan los modelos `Linea Regresion`, `Random Forest Regresor`, `Ridge` y `Lasso`."
      ],
      "metadata": {
        "id": "ZTH42ZLf3of9"
      },
      "id": "ZTH42ZLf3of9"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.experimental import enable_halving_search_cv\n",
        "from sklearn.model_selection import HalvingGridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "# grilla de parametros para clasificacion\n",
        "params_clf = [\n",
        "    {\n",
        "    'Feature selection__percentile': [20, 40, 60, 80],\n",
        "     'Classifier': [SVC()],\n",
        "     'Classifier__C': [0.1, 1, 10]\n",
        "    },\n",
        "    {\n",
        "    'Feature selection__percentile': [20, 40, 60, 80],\n",
        "     'Classifier': [RandomForestClassifier(random_state=42)],\n",
        "    'Classifier__n_estimators': [100, 500],\n",
        "    'Classifier__min_samples_split': [2, 3]\n",
        "    }\n",
        "]\n",
        "\n",
        "# grilla de parametros para regresion\n",
        "params_reg = [\n",
        "    {\n",
        "    'Feature selection__percentile': [20, 40, 60, 80],\n",
        "     'regresor': [LinearRegression()],\n",
        "    },\n",
        "    {\n",
        "    'Feature selection__percentile': [20, 40, 60, 80],\n",
        "    'regresor': [RandomForestRegressor(random_state=42)],\n",
        "    'regresor__n_estimators': [100, 200, 300],\n",
        "    'regresor__min_samples_split': [2, 3, 4]\n",
        "    },\n",
        "    {\n",
        "    'Feature selection__percentile': [20, 40, 60, 80],\n",
        "    'regresor': [Ridge()],\n",
        "    'regresor__alpha': [0.1, 0.5, 1, 5],\n",
        "    },\n",
        "    {\n",
        "    'Feature selection__percentile': [20, 40, 60, 80],\n",
        "    'regresor': [Lasso()],\n",
        "    'regresor__alpha': [0.1, 0.5, 1, 5],\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "6BjmbuwAJyoi"
      },
      "execution_count": null,
      "outputs": [],
      "id": "6BjmbuwAJyoi"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se ajustan las grillas con los datos."
      ],
      "metadata": {
        "id": "qncG8nXU4Jb-"
      },
      "id": "qncG8nXU4Jb-"
    },
    {
      "cell_type": "code",
      "source": [
        "# se ajusta grilla con los mejores parametros para clasificacion\n",
        "search_clf = HalvingGridSearchCV(\n",
        "              pipe_clf,\n",
        "              params_clf,\n",
        "              cv=3,\n",
        "              random_state=42,\n",
        "              verbose=10).fit(X_train_clf, y_train_clf)"
      ],
      "metadata": {
        "id": "GD1oDrntKg2H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c19a270f-846a-4429-fff1-47780aaf91ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_iterations: 4\n",
            "n_required_iterations: 4\n",
            "n_possible_iterations: 4\n",
            "min_resources_: 204\n",
            "max_resources_: 5516\n",
            "aggressive_elimination: False\n",
            "factor: 3\n",
            "----------\n",
            "iter: 0\n",
            "n_candidates: 28\n",
            "n_resources: 204\n",
            "Fitting 3 folds for each of 28 candidates, totalling 84 fits\n",
            "[CV 1/3; 1/28] START Classifier=SVC(), Classifier__C=0.1, Feature selection__percentile=20\n",
            "[CV 1/3; 1/28] END Classifier=SVC(), Classifier__C=0.1, Feature selection__percentile=20;, score=(train=0.259, test=0.162) total time=   0.0s\n",
            "[CV 2/3; 1/28] START Classifier=SVC(), Classifier__C=0.1, Feature selection__percentile=20\n",
            "[CV 2/3; 1/28] END Classifier=SVC(), Classifier__C=0.1, Feature selection__percentile=20;, score=(train=0.237, test=0.221) total time=   0.0s\n",
            "[CV 3/3; 1/28] START Classifier=SVC(), Classifier__C=0.1, Feature selection__percentile=20\n",
            "[CV 3/3; 1/28] END Classifier=SVC(), Classifier__C=0.1, Feature selection__percentile=20;, score=(train=0.301, test=0.343) total time=   0.0s\n",
            "[CV 1/3; 2/28] START Classifier=SVC(), Classifier__C=0.1, Feature selection__percentile=40\n",
            "[CV 1/3; 2/28] END Classifier=SVC(), Classifier__C=0.1, Feature selection__percentile=40;, score=(train=0.230, test=0.132) total time=   0.0s\n",
            "[CV 2/3; 2/28] START Classifier=SVC(), Classifier__C=0.1, Feature selection__percentile=40\n",
            "[CV 2/3; 2/28] END Classifier=SVC(), Classifier__C=0.1, Feature selection__percentile=40;, score=(train=0.237, test=0.221) total time=   0.0s\n",
            "[CV 3/3; 2/28] START Classifier=SVC(), Classifier__C=0.1, Feature selection__percentile=40\n",
            "[CV 3/3; 2/28] END Classifier=SVC(), Classifier__C=0.1, Feature selection__percentile=40;, score=(train=0.301, test=0.343) total time=   0.0s\n",
            "[CV 1/3; 3/28] START Classifier=SVC(), Classifier__C=0.1, Feature selection__percentile=60\n",
            "[CV 1/3; 3/28] END Classifier=SVC(), Classifier__C=0.1, Feature selection__percentile=60;, score=(train=0.230, test=0.132) total time=   0.0s\n",
            "[CV 2/3; 3/28] START Classifier=SVC(), Classifier__C=0.1, Feature selection__percentile=60\n",
            "[CV 2/3; 3/28] END Classifier=SVC(), Classifier__C=0.1, Feature selection__percentile=60;, score=(train=0.237, test=0.221) total time=   0.0s\n",
            "[CV 3/3; 3/28] START Classifier=SVC(), Classifier__C=0.1, Feature selection__percentile=60\n",
            "[CV 3/3; 3/28] END Classifier=SVC(), Classifier__C=0.1, Feature selection__percentile=60;, score=(train=0.301, test=0.343) total time=   0.0s\n",
            "[CV 1/3; 4/28] START Classifier=SVC(), Classifier__C=0.1, Feature selection__percentile=80\n",
            "[CV 1/3; 4/28] END Classifier=SVC(), Classifier__C=0.1, Feature selection__percentile=80;, score=(train=0.230, test=0.132) total time=   0.0s\n",
            "[CV 2/3; 4/28] START Classifier=SVC(), Classifier__C=0.1, Feature selection__percentile=80\n",
            "[CV 2/3; 4/28] END Classifier=SVC(), Classifier__C=0.1, Feature selection__percentile=80;, score=(train=0.237, test=0.221) total time=   0.0s\n",
            "[CV 3/3; 4/28] START Classifier=SVC(), Classifier__C=0.1, Feature selection__percentile=80\n",
            "[CV 3/3; 4/28] END Classifier=SVC(), Classifier__C=0.1, Feature selection__percentile=80;, score=(train=0.301, test=0.343) total time=   0.0s\n",
            "[CV 1/3; 5/28] START Classifier=SVC(), Classifier__C=1, Feature selection__percentile=20\n",
            "[CV 1/3; 5/28] END Classifier=SVC(), Classifier__C=1, Feature selection__percentile=20;, score=(train=0.407, test=0.147) total time=   0.0s\n",
            "[CV 2/3; 5/28] START Classifier=SVC(), Classifier__C=1, Feature selection__percentile=20\n",
            "[CV 2/3; 5/28] END Classifier=SVC(), Classifier__C=1, Feature selection__percentile=20;, score=(train=0.393, test=0.309) total time=   0.0s\n",
            "[CV 3/3; 5/28] START Classifier=SVC(), Classifier__C=1, Feature selection__percentile=20\n",
            "[CV 3/3; 5/28] END Classifier=SVC(), Classifier__C=1, Feature selection__percentile=20;, score=(train=0.368, test=0.358) total time=   0.0s\n",
            "[CV 1/3; 6/28] START Classifier=SVC(), Classifier__C=1, Feature selection__percentile=40\n",
            "[CV 1/3; 6/28] END Classifier=SVC(), Classifier__C=1, Feature selection__percentile=40;, score=(train=0.452, test=0.162) total time=   0.0s\n",
            "[CV 2/3; 6/28] START Classifier=SVC(), Classifier__C=1, Feature selection__percentile=40\n",
            "[CV 2/3; 6/28] END Classifier=SVC(), Classifier__C=1, Feature selection__percentile=40;, score=(train=0.400, test=0.324) total time=   0.0s\n",
            "[CV 3/3; 6/28] START Classifier=SVC(), Classifier__C=1, Feature selection__percentile=40\n",
            "[CV 3/3; 6/28] END Classifier=SVC(), Classifier__C=1, Feature selection__percentile=40;, score=(train=0.353, test=0.328) total time=   0.0s\n",
            "[CV 1/3; 7/28] START Classifier=SVC(), Classifier__C=1, Feature selection__percentile=60\n",
            "[CV 1/3; 7/28] END Classifier=SVC(), Classifier__C=1, Feature selection__percentile=60;, score=(train=0.444, test=0.176) total time=   0.0s\n",
            "[CV 2/3; 7/28] START Classifier=SVC(), Classifier__C=1, Feature selection__percentile=60\n",
            "[CV 2/3; 7/28] END Classifier=SVC(), Classifier__C=1, Feature selection__percentile=60;, score=(train=0.296, test=0.235) total time=   0.0s\n",
            "[CV 3/3; 7/28] START Classifier=SVC(), Classifier__C=1, Feature selection__percentile=60\n",
            "[CV 3/3; 7/28] END Classifier=SVC(), Classifier__C=1, Feature selection__percentile=60;, score=(train=0.324, test=0.343) total time=   0.0s\n",
            "[CV 1/3; 8/28] START Classifier=SVC(), Classifier__C=1, Feature selection__percentile=80\n",
            "[CV 1/3; 8/28] END Classifier=SVC(), Classifier__C=1, Feature selection__percentile=80;, score=(train=0.422, test=0.206) total time=   0.0s\n",
            "[CV 2/3; 8/28] START Classifier=SVC(), Classifier__C=1, Feature selection__percentile=80\n",
            "[CV 2/3; 8/28] END Classifier=SVC(), Classifier__C=1, Feature selection__percentile=80;, score=(train=0.304, test=0.250) total time=   0.0s\n",
            "[CV 3/3; 8/28] START Classifier=SVC(), Classifier__C=1, Feature selection__percentile=80\n",
            "[CV 3/3; 8/28] END Classifier=SVC(), Classifier__C=1, Feature selection__percentile=80;, score=(train=0.331, test=0.343) total time=   0.0s\n",
            "[CV 1/3; 9/28] START Classifier=SVC(), Classifier__C=10, Feature selection__percentile=20\n",
            "[CV 1/3; 9/28] END Classifier=SVC(), Classifier__C=10, Feature selection__percentile=20;, score=(train=0.437, test=0.147) total time=   0.0s\n",
            "[CV 2/3; 9/28] START Classifier=SVC(), Classifier__C=10, Feature selection__percentile=20\n",
            "[CV 2/3; 9/28] END Classifier=SVC(), Classifier__C=10, Feature selection__percentile=20;, score=(train=0.407, test=0.324) total time=   0.0s\n",
            "[CV 3/3; 9/28] START Classifier=SVC(), Classifier__C=10, Feature selection__percentile=20\n",
            "[CV 3/3; 9/28] END Classifier=SVC(), Classifier__C=10, Feature selection__percentile=20;, score=(train=0.368, test=0.343) total time=   0.0s\n",
            "[CV 1/3; 10/28] START Classifier=SVC(), Classifier__C=10, Feature selection__percentile=40\n",
            "[CV 1/3; 10/28] END Classifier=SVC(), Classifier__C=10, Feature selection__percentile=40;, score=(train=0.496, test=0.191) total time=   0.0s\n",
            "[CV 2/3; 10/28] START Classifier=SVC(), Classifier__C=10, Feature selection__percentile=40\n",
            "[CV 2/3; 10/28] END Classifier=SVC(), Classifier__C=10, Feature selection__percentile=40;, score=(train=0.430, test=0.294) total time=   0.0s\n",
            "[CV 3/3; 10/28] START Classifier=SVC(), Classifier__C=10, Feature selection__percentile=40\n",
            "[CV 3/3; 10/28] END Classifier=SVC(), Classifier__C=10, Feature selection__percentile=40;, score=(train=0.426, test=0.313) total time=   0.0s\n",
            "[CV 1/3; 11/28] START Classifier=SVC(), Classifier__C=10, Feature selection__percentile=60\n",
            "[CV 1/3; 11/28] END Classifier=SVC(), Classifier__C=10, Feature selection__percentile=60;, score=(train=0.489, test=0.147) total time=   0.0s\n",
            "[CV 2/3; 11/28] START Classifier=SVC(), Classifier__C=10, Feature selection__percentile=60\n",
            "[CV 2/3; 11/28] END Classifier=SVC(), Classifier__C=10, Feature selection__percentile=60;, score=(train=0.444, test=0.324) total time=   0.0s\n",
            "[CV 3/3; 11/28] START Classifier=SVC(), Classifier__C=10, Feature selection__percentile=60\n",
            "[CV 3/3; 11/28] END Classifier=SVC(), Classifier__C=10, Feature selection__percentile=60;, score=(train=0.449, test=0.284) total time=   0.0s\n",
            "[CV 1/3; 12/28] START Classifier=SVC(), Classifier__C=10, Feature selection__percentile=80\n",
            "[CV 1/3; 12/28] END Classifier=SVC(), Classifier__C=10, Feature selection__percentile=80;, score=(train=0.519, test=0.235) total time=   0.0s\n",
            "[CV 2/3; 12/28] START Classifier=SVC(), Classifier__C=10, Feature selection__percentile=80\n",
            "[CV 2/3; 12/28] END Classifier=SVC(), Classifier__C=10, Feature selection__percentile=80;, score=(train=0.504, test=0.324) total time=   0.0s\n",
            "[CV 3/3; 12/28] START Classifier=SVC(), Classifier__C=10, Feature selection__percentile=80\n",
            "[CV 3/3; 12/28] END Classifier=SVC(), Classifier__C=10, Feature selection__percentile=80;, score=(train=0.507, test=0.313) total time=   0.0s\n",
            "[CV 1/3; 13/28] START Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=100, Feature selection__percentile=20\n",
            "[CV 1/3; 13/28] END Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=100, Feature selection__percentile=20;, score=(train=0.652, test=0.221) total time=   0.2s\n",
            "[CV 2/3; 13/28] START Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=100, Feature selection__percentile=20\n",
            "[CV 2/3; 13/28] END Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=100, Feature selection__percentile=20;, score=(train=0.741, test=0.235) total time=   0.2s\n",
            "[CV 3/3; 13/28] START Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=100, Feature selection__percentile=20\n",
            "[CV 3/3; 13/28] END Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=100, Feature selection__percentile=20;, score=(train=0.713, test=0.269) total time=   0.2s\n",
            "[CV 1/3; 14/28] START Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=100, Feature selection__percentile=40\n",
            "[CV 1/3; 14/28] END Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=100, Feature selection__percentile=40;, score=(train=0.726, test=0.279) total time=   0.2s\n",
            "[CV 2/3; 14/28] START Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=100, Feature selection__percentile=40\n",
            "[CV 2/3; 14/28] END Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=100, Feature selection__percentile=40;, score=(train=0.756, test=0.191) total time=   0.2s\n",
            "[CV 3/3; 14/28] START Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=100, Feature selection__percentile=40\n",
            "[CV 3/3; 14/28] END Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=100, Feature selection__percentile=40;, score=(train=0.890, test=0.209) total time=   0.2s\n",
            "[CV 1/3; 15/28] START Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=100, Feature selection__percentile=60\n",
            "[CV 1/3; 15/28] END Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=100, Feature selection__percentile=60;, score=(train=0.733, test=0.265) total time=   0.2s\n",
            "[CV 2/3; 15/28] START Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=100, Feature selection__percentile=60\n",
            "[CV 2/3; 15/28] END Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=100, Feature selection__percentile=60;, score=(train=0.889, test=0.250) total time=   0.2s\n",
            "[CV 3/3; 15/28] START Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=100, Feature selection__percentile=60\n",
            "[CV 3/3; 15/28] END Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=100, Feature selection__percentile=60;, score=(train=0.912, test=0.164) total time=   0.2s\n",
            "[CV 1/3; 16/28] START Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=100, Feature selection__percentile=80\n",
            "[CV 1/3; 16/28] END Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=100, Feature selection__percentile=80;, score=(train=0.956, test=0.324) total time=   0.2s\n",
            "[CV 2/3; 16/28] START Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=100, Feature selection__percentile=80\n",
            "[CV 2/3; 16/28] END Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=100, Feature selection__percentile=80;, score=(train=0.985, test=0.309) total time=   0.2s\n",
            "[CV 3/3; 16/28] START Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=100, Feature selection__percentile=80\n",
            "[CV 3/3; 16/28] END Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=100, Feature selection__percentile=80;, score=(train=0.912, test=0.149) total time=   0.2s\n",
            "[CV 1/3; 17/28] START Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=500, Feature selection__percentile=20\n",
            "[CV 1/3; 17/28] END Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=500, Feature selection__percentile=20;, score=(train=0.652, test=0.191) total time=   0.7s\n",
            "[CV 2/3; 17/28] START Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=500, Feature selection__percentile=20\n",
            "[CV 2/3; 17/28] END Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=500, Feature selection__percentile=20;, score=(train=0.741, test=0.235) total time=   0.7s\n",
            "[CV 3/3; 17/28] START Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=500, Feature selection__percentile=20\n",
            "[CV 3/3; 17/28] END Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=500, Feature selection__percentile=20;, score=(train=0.713, test=0.269) total time=   0.7s\n",
            "[CV 1/3; 18/28] START Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=500, Feature selection__percentile=40\n",
            "[CV 1/3; 18/28] END Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=500, Feature selection__percentile=40;, score=(train=0.726, test=0.265) total time=   0.7s\n",
            "[CV 2/3; 18/28] START Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=500, Feature selection__percentile=40\n",
            "[CV 2/3; 18/28] END Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=500, Feature selection__percentile=40;, score=(train=0.756, test=0.206) total time=   0.7s\n",
            "[CV 3/3; 18/28] START Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=500, Feature selection__percentile=40\n",
            "[CV 3/3; 18/28] END Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=500, Feature selection__percentile=40;, score=(train=0.890, test=0.209) total time=   0.7s\n",
            "[CV 1/3; 19/28] START Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=500, Feature selection__percentile=60\n",
            "[CV 1/3; 19/28] END Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=500, Feature selection__percentile=60;, score=(train=0.733, test=0.265) total time=   0.7s\n",
            "[CV 2/3; 19/28] START Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=500, Feature selection__percentile=60\n",
            "[CV 2/3; 19/28] END Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=500, Feature selection__percentile=60;, score=(train=0.889, test=0.250) total time=   0.8s\n",
            "[CV 3/3; 19/28] START Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=500, Feature selection__percentile=60\n",
            "[CV 3/3; 19/28] END Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=500, Feature selection__percentile=60;, score=(train=0.912, test=0.164) total time=   0.8s\n",
            "[CV 1/3; 20/28] START Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=500, Feature selection__percentile=80\n",
            "[CV 1/3; 20/28] END Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=500, Feature selection__percentile=80;, score=(train=0.956, test=0.324) total time=   0.8s\n",
            "[CV 2/3; 20/28] START Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=500, Feature selection__percentile=80\n",
            "[CV 2/3; 20/28] END Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=500, Feature selection__percentile=80;, score=(train=0.985, test=0.294) total time=   0.8s\n",
            "[CV 3/3; 20/28] START Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=500, Feature selection__percentile=80\n",
            "[CV 3/3; 20/28] END Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=500, Feature selection__percentile=80;, score=(train=0.912, test=0.164) total time=   0.7s\n",
            "[CV 1/3; 21/28] START Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=3, Classifier__n_estimators=100, Feature selection__percentile=20\n",
            "[CV 1/3; 21/28] END Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=3, Classifier__n_estimators=100, Feature selection__percentile=20;, score=(train=0.644, test=0.221) total time=   0.2s\n",
            "[CV 2/3; 21/28] START Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=3, Classifier__n_estimators=100, Feature selection__percentile=20\n",
            "[CV 2/3; 21/28] END Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=3, Classifier__n_estimators=100, Feature selection__percentile=20;, score=(train=0.711, test=0.235) total time=   0.2s\n",
            "[CV 3/3; 21/28] START Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=3, Classifier__n_estimators=100, Feature selection__percentile=20\n",
            "[CV 3/3; 21/28] END Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=3, Classifier__n_estimators=100, Feature selection__percentile=20;, score=(train=0.691, test=0.269) total time=   0.2s\n",
            "[CV 1/3; 22/28] START Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=3, Classifier__n_estimators=100, Feature selection__percentile=40\n",
            "[CV 1/3; 22/28] END Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=3, Classifier__n_estimators=100, Feature selection__percentile=40;, score=(train=0.726, test=0.294) total time=   0.2s\n",
            "[CV 2/3; 22/28] START Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=3, Classifier__n_estimators=100, Feature selection__percentile=40\n",
            "[CV 2/3; 22/28] END Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=3, Classifier__n_estimators=100, Feature selection__percentile=40;, score=(train=0.726, test=0.206) total time=   0.2s\n",
            "[CV 3/3; 22/28] START Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=3, Classifier__n_estimators=100, Feature selection__percentile=40\n",
            "[CV 3/3; 22/28] END Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=3, Classifier__n_estimators=100, Feature selection__percentile=40;, score=(train=0.875, test=0.194) total time=   0.2s\n",
            "[CV 1/3; 23/28] START Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=3, Classifier__n_estimators=100, Feature selection__percentile=60\n",
            "[CV 1/3; 23/28] END Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=3, Classifier__n_estimators=100, Feature selection__percentile=60;, score=(train=0.726, test=0.250) total time=   0.2s\n",
            "[CV 2/3; 23/28] START Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=3, Classifier__n_estimators=100, Feature selection__percentile=60\n",
            "[CV 2/3; 23/28] END Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=3, Classifier__n_estimators=100, Feature selection__percentile=60;, score=(train=0.881, test=0.294) total time=   0.2s\n",
            "[CV 3/3; 23/28] START Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=3, Classifier__n_estimators=100, Feature selection__percentile=60\n",
            "[CV 3/3; 23/28] END Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=3, Classifier__n_estimators=100, Feature selection__percentile=60;, score=(train=0.912, test=0.149) total time=   0.2s\n",
            "[CV 1/3; 24/28] START Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=3, Classifier__n_estimators=100, Feature selection__percentile=80\n",
            "[CV 1/3; 24/28] END Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=3, Classifier__n_estimators=100, Feature selection__percentile=80;, score=(train=0.941, test=0.309) total time=   0.2s\n",
            "[CV 2/3; 24/28] START Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=3, Classifier__n_estimators=100, Feature selection__percentile=80\n",
            "[CV 2/3; 24/28] END Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=3, Classifier__n_estimators=100, Feature selection__percentile=80;, score=(train=0.970, test=0.294) total time=   0.2s\n",
            "[CV 3/3; 24/28] START Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=3, Classifier__n_estimators=100, Feature selection__percentile=80\n",
            "[CV 3/3; 24/28] END Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=3, Classifier__n_estimators=100, Feature selection__percentile=80;, score=(train=0.897, test=0.179) total time=   0.2s\n",
            "[CV 1/3; 25/28] START Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=3, Classifier__n_estimators=500, Feature selection__percentile=20\n",
            "[CV 1/3; 25/28] END Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=3, Classifier__n_estimators=500, Feature selection__percentile=20;, score=(train=0.644, test=0.206) total time=   0.7s\n",
            "[CV 2/3; 25/28] START Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=3, Classifier__n_estimators=500, Feature selection__percentile=20\n",
            "[CV 2/3; 25/28] END Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=3, Classifier__n_estimators=500, Feature selection__percentile=20;, score=(train=0.726, test=0.250) total time=   0.7s\n",
            "[CV 3/3; 25/28] START Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=3, Classifier__n_estimators=500, Feature selection__percentile=20\n",
            "[CV 3/3; 25/28] END Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=3, Classifier__n_estimators=500, Feature selection__percentile=20;, score=(train=0.706, test=0.269) total time=   0.8s\n",
            "[CV 1/3; 26/28] START Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=3, Classifier__n_estimators=500, Feature selection__percentile=40\n",
            "[CV 1/3; 26/28] END Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=3, Classifier__n_estimators=500, Feature selection__percentile=40;, score=(train=0.726, test=0.265) total time=   0.7s\n",
            "[CV 2/3; 26/28] START Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=3, Classifier__n_estimators=500, Feature selection__percentile=40\n",
            "[CV 2/3; 26/28] END Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=3, Classifier__n_estimators=500, Feature selection__percentile=40;, score=(train=0.741, test=0.221) total time=   0.8s\n",
            "[CV 3/3; 26/28] START Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=3, Classifier__n_estimators=500, Feature selection__percentile=40\n",
            "[CV 3/3; 26/28] END Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=3, Classifier__n_estimators=500, Feature selection__percentile=40;, score=(train=0.890, test=0.224) total time=   0.8s\n",
            "[CV 1/3; 27/28] START Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=3, Classifier__n_estimators=500, Feature selection__percentile=60\n",
            "[CV 1/3; 27/28] END Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=3, Classifier__n_estimators=500, Feature selection__percentile=60;, score=(train=0.733, test=0.250) total time=   0.9s\n",
            "[CV 2/3; 27/28] START Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=3, Classifier__n_estimators=500, Feature selection__percentile=60\n",
            "[CV 2/3; 27/28] END Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=3, Classifier__n_estimators=500, Feature selection__percentile=60;, score=(train=0.874, test=0.279) total time=   1.3s\n",
            "[CV 3/3; 27/28] START Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=3, Classifier__n_estimators=500, Feature selection__percentile=60\n",
            "[CV 3/3; 27/28] END Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=3, Classifier__n_estimators=500, Feature selection__percentile=60;, score=(train=0.904, test=0.149) total time=   1.3s\n",
            "[CV 1/3; 28/28] START Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=3, Classifier__n_estimators=500, Feature selection__percentile=80\n",
            "[CV 1/3; 28/28] END Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=3, Classifier__n_estimators=500, Feature selection__percentile=80;, score=(train=0.948, test=0.324) total time=   1.2s\n",
            "[CV 2/3; 28/28] START Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=3, Classifier__n_estimators=500, Feature selection__percentile=80\n",
            "[CV 2/3; 28/28] END Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=3, Classifier__n_estimators=500, Feature selection__percentile=80;, score=(train=0.978, test=0.279) total time=   0.8s\n",
            "[CV 3/3; 28/28] START Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=3, Classifier__n_estimators=500, Feature selection__percentile=80\n",
            "[CV 3/3; 28/28] END Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=3, Classifier__n_estimators=500, Feature selection__percentile=80;, score=(train=0.904, test=0.149) total time=   0.8s\n",
            "----------\n",
            "iter: 1\n",
            "n_candidates: 10\n",
            "n_resources: 612\n",
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
            "[CV 1/3; 1/10] START Classifier=SVC(), Classifier__C=1, Feature selection__percentile=60\n",
            "[CV 1/3; 1/10] END Classifier=SVC(), Classifier__C=1, Feature selection__percentile=60;, score=(train=0.388, test=0.284) total time=   0.0s\n",
            "[CV 2/3; 1/10] START Classifier=SVC(), Classifier__C=1, Feature selection__percentile=60\n",
            "[CV 2/3; 1/10] END Classifier=SVC(), Classifier__C=1, Feature selection__percentile=60;, score=(train=0.405, test=0.275) total time=   0.0s\n",
            "[CV 3/3; 1/10] START Classifier=SVC(), Classifier__C=1, Feature selection__percentile=60\n",
            "[CV 3/3; 1/10] END Classifier=SVC(), Classifier__C=1, Feature selection__percentile=60;, score=(train=0.338, test=0.286) total time=   0.1s\n",
            "[CV 1/3; 2/10] START Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=100, Feature selection__percentile=80\n",
            "[CV 1/3; 2/10] END Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=100, Feature selection__percentile=80;, score=(train=0.899, test=0.314) total time=   0.2s\n",
            "[CV 2/3; 2/10] START Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=100, Feature selection__percentile=80\n",
            "[CV 2/3; 2/10] END Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=100, Feature selection__percentile=80;, score=(train=0.975, test=0.294) total time=   0.2s\n",
            "[CV 3/3; 2/10] START Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=100, Feature selection__percentile=80\n",
            "[CV 3/3; 2/10] END Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=100, Feature selection__percentile=80;, score=(train=0.998, test=0.310) total time=   0.2s\n",
            "[CV 1/3; 3/10] START Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=500, Feature selection__percentile=80\n",
            "[CV 1/3; 3/10] END Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=500, Feature selection__percentile=80;, score=(train=0.899, test=0.299) total time=   0.9s\n",
            "[CV 2/3; 3/10] START Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=500, Feature selection__percentile=80\n",
            "[CV 2/3; 3/10] END Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=500, Feature selection__percentile=80;, score=(train=0.975, test=0.294) total time=   0.9s\n",
            "[CV 3/3; 3/10] START Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=500, Feature selection__percentile=80\n",
            "[CV 3/3; 3/10] END Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=500, Feature selection__percentile=80;, score=(train=0.998, test=0.281) total time=   0.9s\n",
            "[CV 1/3; 4/10] START Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=3, Classifier__n_estimators=100, Feature selection__percentile=80\n",
            "[CV 1/3; 4/10] END Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=3, Classifier__n_estimators=100, Feature selection__percentile=80;, score=(train=0.897, test=0.294) total time=   0.2s\n",
            "[CV 2/3; 4/10] START Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=3, Classifier__n_estimators=100, Feature selection__percentile=80\n",
            "[CV 2/3; 4/10] END Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=3, Classifier__n_estimators=100, Feature selection__percentile=80;, score=(train=0.968, test=0.260) total time=   0.2s\n",
            "[CV 3/3; 4/10] START Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=3, Classifier__n_estimators=100, Feature selection__percentile=80\n",
            "[CV 3/3; 4/10] END Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=3, Classifier__n_estimators=100, Feature selection__percentile=80;, score=(train=0.993, test=0.266) total time=   0.2s\n",
            "[CV 1/3; 5/10] START Classifier=SVC(), Classifier__C=10, Feature selection__percentile=40\n",
            "[CV 1/3; 5/10] END Classifier=SVC(), Classifier__C=10, Feature selection__percentile=40;, score=(train=0.403, test=0.221) total time=   0.1s\n",
            "[CV 2/3; 5/10] START Classifier=SVC(), Classifier__C=10, Feature selection__percentile=40\n",
            "[CV 2/3; 5/10] END Classifier=SVC(), Classifier__C=10, Feature selection__percentile=40;, score=(train=0.452, test=0.270) total time=   0.1s\n",
            "[CV 3/3; 5/10] START Classifier=SVC(), Classifier__C=10, Feature selection__percentile=40\n",
            "[CV 3/3; 5/10] END Classifier=SVC(), Classifier__C=10, Feature selection__percentile=40;, score=(train=0.390, test=0.281) total time=   0.1s\n",
            "[CV 1/3; 6/10] START Classifier=SVC(), Classifier__C=1, Feature selection__percentile=80\n",
            "[CV 1/3; 6/10] END Classifier=SVC(), Classifier__C=1, Feature selection__percentile=80;, score=(train=0.386, test=0.299) total time=   0.1s\n",
            "[CV 2/3; 6/10] START Classifier=SVC(), Classifier__C=1, Feature selection__percentile=80\n",
            "[CV 2/3; 6/10] END Classifier=SVC(), Classifier__C=1, Feature selection__percentile=80;, score=(train=0.310, test=0.294) total time=   0.1s\n",
            "[CV 3/3; 6/10] START Classifier=SVC(), Classifier__C=1, Feature selection__percentile=80\n",
            "[CV 3/3; 6/10] END Classifier=SVC(), Classifier__C=1, Feature selection__percentile=80;, score=(train=0.343, test=0.276) total time=   0.1s\n",
            "[CV 1/3; 7/10] START Classifier=SVC(), Classifier__C=1, Feature selection__percentile=40\n",
            "[CV 1/3; 7/10] END Classifier=SVC(), Classifier__C=1, Feature selection__percentile=40;, score=(train=0.386, test=0.279) total time=   0.0s\n",
            "[CV 2/3; 7/10] START Classifier=SVC(), Classifier__C=1, Feature selection__percentile=40\n",
            "[CV 2/3; 7/10] END Classifier=SVC(), Classifier__C=1, Feature selection__percentile=40;, score=(train=0.391, test=0.279) total time=   0.1s\n",
            "[CV 3/3; 7/10] START Classifier=SVC(), Classifier__C=1, Feature selection__percentile=40\n",
            "[CV 3/3; 7/10] END Classifier=SVC(), Classifier__C=1, Feature selection__percentile=40;, score=(train=0.336, test=0.281) total time=   0.1s\n",
            "[CV 1/3; 8/10] START Classifier=SVC(), Classifier__C=10, Feature selection__percentile=20\n",
            "[CV 1/3; 8/10] END Classifier=SVC(), Classifier__C=10, Feature selection__percentile=20;, score=(train=0.354, test=0.289) total time=   0.1s\n",
            "[CV 2/3; 8/10] START Classifier=SVC(), Classifier__C=10, Feature selection__percentile=20\n",
            "[CV 2/3; 8/10] END Classifier=SVC(), Classifier__C=10, Feature selection__percentile=20;, score=(train=0.364, test=0.275) total time=   0.1s\n",
            "[CV 3/3; 8/10] START Classifier=SVC(), Classifier__C=10, Feature selection__percentile=20\n",
            "[CV 3/3; 8/10] END Classifier=SVC(), Classifier__C=10, Feature selection__percentile=20;, score=(train=0.370, test=0.296) total time=   0.1s\n",
            "[CV 1/3; 9/10] START Classifier=SVC(), Classifier__C=1, Feature selection__percentile=20\n",
            "[CV 1/3; 9/10] END Classifier=SVC(), Classifier__C=1, Feature selection__percentile=20;, score=(train=0.346, test=0.289) total time=   0.0s\n",
            "[CV 2/3; 9/10] START Classifier=SVC(), Classifier__C=1, Feature selection__percentile=20\n",
            "[CV 2/3; 9/10] END Classifier=SVC(), Classifier__C=1, Feature selection__percentile=20;, score=(train=0.344, test=0.270) total time=   0.0s\n",
            "[CV 3/3; 9/10] START Classifier=SVC(), Classifier__C=1, Feature selection__percentile=20\n",
            "[CV 3/3; 9/10] END Classifier=SVC(), Classifier__C=1, Feature selection__percentile=20;, score=(train=0.333, test=0.281) total time=   0.0s\n",
            "[CV 1/3; 10/10] START Classifier=SVC(), Classifier__C=10, Feature selection__percentile=80\n",
            "[CV 1/3; 10/10] END Classifier=SVC(), Classifier__C=10, Feature selection__percentile=80;, score=(train=0.447, test=0.275) total time=   0.1s\n",
            "[CV 2/3; 10/10] START Classifier=SVC(), Classifier__C=10, Feature selection__percentile=80\n",
            "[CV 2/3; 10/10] END Classifier=SVC(), Classifier__C=10, Feature selection__percentile=80;, score=(train=0.428, test=0.304) total time=   0.1s\n",
            "[CV 3/3; 10/10] START Classifier=SVC(), Classifier__C=10, Feature selection__percentile=80\n",
            "[CV 3/3; 10/10] END Classifier=SVC(), Classifier__C=10, Feature selection__percentile=80;, score=(train=0.404, test=0.281) total time=   0.1s\n",
            "----------\n",
            "iter: 2\n",
            "n_candidates: 4\n",
            "n_resources: 1836\n",
            "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
            "[CV 1/3; 1/4] START Classifier=SVC(), Classifier__C=10, Feature selection__percentile=20\n",
            "[CV 1/3; 1/4] END Classifier=SVC(), Classifier__C=10, Feature selection__percentile=20;, score=(train=0.325, test=0.297) total time=   0.3s\n",
            "[CV 2/3; 1/4] START Classifier=SVC(), Classifier__C=10, Feature selection__percentile=20\n",
            "[CV 2/3; 1/4] END Classifier=SVC(), Classifier__C=10, Feature selection__percentile=20;, score=(train=0.315, test=0.294) total time=   0.3s\n",
            "[CV 3/3; 1/4] START Classifier=SVC(), Classifier__C=10, Feature selection__percentile=20\n",
            "[CV 3/3; 1/4] END Classifier=SVC(), Classifier__C=10, Feature selection__percentile=20;, score=(train=0.329, test=0.286) total time=   0.3s\n",
            "[CV 1/3; 2/4] START Classifier=SVC(), Classifier__C=1, Feature selection__percentile=80\n",
            "[CV 1/3; 2/4] END Classifier=SVC(), Classifier__C=1, Feature selection__percentile=80;, score=(train=0.333, test=0.278) total time=   0.2s\n",
            "[CV 2/3; 2/4] START Classifier=SVC(), Classifier__C=1, Feature selection__percentile=80\n",
            "[CV 2/3; 2/4] END Classifier=SVC(), Classifier__C=1, Feature selection__percentile=80;, score=(train=0.323, test=0.297) total time=   0.2s\n",
            "[CV 3/3; 2/4] START Classifier=SVC(), Classifier__C=1, Feature selection__percentile=80\n",
            "[CV 3/3; 2/4] END Classifier=SVC(), Classifier__C=1, Feature selection__percentile=80;, score=(train=0.306, test=0.283) total time=   0.2s\n",
            "[CV 1/3; 3/4] START Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=500, Feature selection__percentile=80\n",
            "[CV 1/3; 3/4] END Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=500, Feature selection__percentile=80;, score=(train=0.814, test=0.275) total time=   1.6s\n",
            "[CV 2/3; 3/4] START Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=500, Feature selection__percentile=80\n",
            "[CV 2/3; 3/4] END Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=500, Feature selection__percentile=80;, score=(train=0.917, test=0.250) total time=   1.6s\n",
            "[CV 3/3; 3/4] START Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=500, Feature selection__percentile=80\n",
            "[CV 3/3; 3/4] END Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=500, Feature selection__percentile=80;, score=(train=0.986, test=0.277) total time=   1.5s\n",
            "[CV 1/3; 4/4] START Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=100, Feature selection__percentile=80\n",
            "[CV 1/3; 4/4] END Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=100, Feature selection__percentile=80;, score=(train=0.814, test=0.275) total time=   0.3s\n",
            "[CV 2/3; 4/4] START Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=100, Feature selection__percentile=80\n",
            "[CV 2/3; 4/4] END Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=100, Feature selection__percentile=80;, score=(train=0.917, test=0.242) total time=   0.3s\n",
            "[CV 3/3; 4/4] START Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=100, Feature selection__percentile=80\n",
            "[CV 3/3; 4/4] END Classifier=RandomForestClassifier(random_state=42), Classifier__min_samples_split=2, Classifier__n_estimators=100, Feature selection__percentile=80;, score=(train=0.986, test=0.265) total time=   0.3s\n",
            "----------\n",
            "iter: 3\n",
            "n_candidates: 2\n",
            "n_resources: 5508\n",
            "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
            "[CV 1/3; 1/2] START Classifier=SVC(), Classifier__C=1, Feature selection__percentile=80\n",
            "[CV 1/3; 1/2] END Classifier=SVC(), Classifier__C=1, Feature selection__percentile=80;, score=(train=0.320, test=0.289) total time=   2.1s\n",
            "[CV 2/3; 1/2] START Classifier=SVC(), Classifier__C=1, Feature selection__percentile=80\n",
            "[CV 2/3; 1/2] END Classifier=SVC(), Classifier__C=1, Feature selection__percentile=80;, score=(train=0.306, test=0.282) total time=   2.0s\n",
            "[CV 3/3; 1/2] START Classifier=SVC(), Classifier__C=1, Feature selection__percentile=80\n",
            "[CV 3/3; 1/2] END Classifier=SVC(), Classifier__C=1, Feature selection__percentile=80;, score=(train=0.279, test=0.255) total time=   2.1s\n",
            "[CV 1/3; 2/2] START Classifier=SVC(), Classifier__C=10, Feature selection__percentile=20\n",
            "[CV 1/3; 2/2] END Classifier=SVC(), Classifier__C=10, Feature selection__percentile=20;, score=(train=0.309, test=0.290) total time=   2.2s\n",
            "[CV 2/3; 2/2] START Classifier=SVC(), Classifier__C=10, Feature selection__percentile=20\n",
            "[CV 2/3; 2/2] END Classifier=SVC(), Classifier__C=10, Feature selection__percentile=20;, score=(train=0.305, test=0.282) total time=   2.2s\n",
            "[CV 3/3; 2/2] START Classifier=SVC(), Classifier__C=10, Feature selection__percentile=20\n",
            "[CV 3/3; 2/2] END Classifier=SVC(), Classifier__C=10, Feature selection__percentile=20;, score=(train=0.303, test=0.286) total time=   2.3s\n"
          ]
        }
      ],
      "id": "GD1oDrntKg2H"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se presenta el resultado de la clasificación sobre el conjunto de test (split del conjunto df_train)."
      ],
      "metadata": {
        "id": "PYsyHYGm4Od1"
      },
      "id": "PYsyHYGm4Od1"
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluacion sobre conjunto test\n",
        "y_pred_clf = search_clf.predict(X_test_clf)\n",
        "\n",
        "# resultados de la prediccion\n",
        "print(classification_report(y_test_clf, y_pred_clf))\n",
        "\n",
        "print('Los mejores parametros del clasificador son:', search_clf.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEm9jB8kONDN",
        "outputId": "644009bd-0f78-4abe-fe13-89654d17e159"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 precision    recall  f1-score   support\n",
            "\n",
            "          Mixed       0.26      0.25      0.25       497\n",
            "Mostly Positive       0.19      0.02      0.04       521\n",
            "       Negative       0.34      0.38      0.36       389\n",
            "       Positive       0.28      0.65      0.39       588\n",
            "  Very Positive       0.42      0.03      0.06       370\n",
            "\n",
            "       accuracy                           0.29      2365\n",
            "      macro avg       0.30      0.27      0.22      2365\n",
            "   weighted avg       0.29      0.29      0.23      2365\n",
            "\n",
            "Los mejores parametros del clasificador son: {'Classifier': SVC(C=10), 'Classifier__C': 10, 'Feature selection__percentile': 20}\n"
          ]
        }
      ],
      "id": "cEm9jB8kONDN"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se realiza el proceso de ajuste y predicción de manera análoga para la regresión."
      ],
      "metadata": {
        "id": "Rz8pOFSh4bIO"
      },
      "id": "Rz8pOFSh4bIO"
    },
    {
      "cell_type": "code",
      "source": [
        "# se ajusta grilla de regresión\n",
        "search_reg = HalvingGridSearchCV(\n",
        "              pipe_reg,\n",
        "              params_reg,\n",
        "              cv=3,\n",
        "              random_state=42,\n",
        "              verbose=10).fit(X_train_reg, y_train_reg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPbtQN8faRZi",
        "outputId": "db45ca51-dfe7-43f4-d4e9-b9bcf69a906f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_iterations: 4\n",
            "n_required_iterations: 4\n",
            "n_possible_iterations: 4\n",
            "min_resources_: 204\n",
            "max_resources_: 5516\n",
            "aggressive_elimination: False\n",
            "factor: 3\n",
            "----------\n",
            "iter: 0\n",
            "n_candidates: 72\n",
            "n_resources: 204\n",
            "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
            "[CV 1/3; 1/72] START Feature selection__percentile=20, regresor=LinearRegression()\n",
            "[CV 1/3; 1/72] END Feature selection__percentile=20, regresor=LinearRegression();, score=(train=0.071, test=0.102) total time=   0.0s\n",
            "[CV 2/3; 1/72] START Feature selection__percentile=20, regresor=LinearRegression()\n",
            "[CV 2/3; 1/72] END Feature selection__percentile=20, regresor=LinearRegression();, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 1/72] START Feature selection__percentile=20, regresor=LinearRegression()\n",
            "[CV 3/3; 1/72] END Feature selection__percentile=20, regresor=LinearRegression();, score=(train=0.418, test=-9.179) total time=   0.0s\n",
            "[CV 1/3; 2/72] START Feature selection__percentile=40, regresor=LinearRegression()\n",
            "[CV 1/3; 2/72] END Feature selection__percentile=40, regresor=LinearRegression();, score=(train=0.141, test=-0.155) total time=   0.0s\n",
            "[CV 2/3; 2/72] START Feature selection__percentile=40, regresor=LinearRegression()\n",
            "[CV 2/3; 2/72] END Feature selection__percentile=40, regresor=LinearRegression();, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 2/72] START Feature selection__percentile=40, regresor=LinearRegression()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 2/72] END Feature selection__percentile=40, regresor=LinearRegression();, score=(train=0.420, test=-9.143) total time=   0.0s\n",
            "[CV 1/3; 3/72] START Feature selection__percentile=60, regresor=LinearRegression()\n",
            "[CV 1/3; 3/72] END Feature selection__percentile=60, regresor=LinearRegression();, score=(train=0.154, test=0.088) total time=   0.0s\n",
            "[CV 2/3; 3/72] START Feature selection__percentile=60, regresor=LinearRegression()\n",
            "[CV 2/3; 3/72] END Feature selection__percentile=60, regresor=LinearRegression();, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 3/72] START Feature selection__percentile=60, regresor=LinearRegression()\n",
            "[CV 3/3; 3/72] END Feature selection__percentile=60, regresor=LinearRegression();, score=(train=0.433, test=-9.824) total time=   0.0s\n",
            "[CV 1/3; 4/72] START Feature selection__percentile=80, regresor=LinearRegression()\n",
            "[CV 1/3; 4/72] END Feature selection__percentile=80, regresor=LinearRegression();, score=(train=0.158, test=0.077) total time=   0.0s\n",
            "[CV 2/3; 4/72] START Feature selection__percentile=80, regresor=LinearRegression()\n",
            "[CV 2/3; 4/72] END Feature selection__percentile=80, regresor=LinearRegression();, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 4/72] START Feature selection__percentile=80, regresor=LinearRegression()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 4/72] END Feature selection__percentile=80, regresor=LinearRegression();, score=(train=0.461, test=-11.518) total time=   0.0s\n",
            "[CV 1/3; 5/72] START Feature selection__percentile=20, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=100\n",
            "[CV 1/3; 5/72] END Feature selection__percentile=20, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=100;, score=(train=0.878, test=0.100) total time=   0.2s\n",
            "[CV 2/3; 5/72] START Feature selection__percentile=20, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/3; 5/72] END Feature selection__percentile=20, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 5/72] START Feature selection__percentile=20, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 5/72] END Feature selection__percentile=20, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=100;, score=(train=0.844, test=-4.470) total time=   0.2s\n",
            "[CV 1/3; 6/72] START Feature selection__percentile=20, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=200\n",
            "[CV 1/3; 6/72] END Feature selection__percentile=20, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=200;, score=(train=0.876, test=0.128) total time=   0.3s\n",
            "[CV 2/3; 6/72] START Feature selection__percentile=20, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=200\n",
            "[CV 2/3; 6/72] END Feature selection__percentile=20, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=200;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 6/72] START Feature selection__percentile=20, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 6/72] END Feature selection__percentile=20, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=200;, score=(train=0.846, test=-5.093) total time=   0.3s\n",
            "[CV 1/3; 7/72] START Feature selection__percentile=20, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3; 7/72] END Feature selection__percentile=20, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=300;, score=(train=0.872, test=0.160) total time=   0.5s\n",
            "[CV 2/3; 7/72] START Feature selection__percentile=20, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=300\n",
            "[CV 2/3; 7/72] END Feature selection__percentile=20, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=300;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 7/72] START Feature selection__percentile=20, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 7/72] END Feature selection__percentile=20, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=300;, score=(train=0.846, test=-4.766) total time=   0.5s\n",
            "[CV 1/3; 8/72] START Feature selection__percentile=20, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3; 8/72] END Feature selection__percentile=20, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=100;, score=(train=0.846, test=0.087) total time=   0.2s\n",
            "[CV 2/3; 8/72] START Feature selection__percentile=20, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=100\n",
            "[CV 2/3; 8/72] END Feature selection__percentile=20, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 8/72] START Feature selection__percentile=20, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 8/72] END Feature selection__percentile=20, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=100;, score=(train=0.609, test=-5.502) total time=   0.2s\n",
            "[CV 1/3; 9/72] START Feature selection__percentile=20, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3; 9/72] END Feature selection__percentile=20, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=200;, score=(train=0.841, test=0.124) total time=   0.3s\n",
            "[CV 2/3; 9/72] START Feature selection__percentile=20, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=200\n",
            "[CV 2/3; 9/72] END Feature selection__percentile=20, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=200;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 9/72] START Feature selection__percentile=20, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 9/72] END Feature selection__percentile=20, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=200;, score=(train=0.604, test=-6.550) total time=   0.3s\n",
            "[CV 1/3; 10/72] START Feature selection__percentile=20, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3; 10/72] END Feature selection__percentile=20, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=300;, score=(train=0.837, test=0.148) total time=   0.5s\n",
            "[CV 2/3; 10/72] START Feature selection__percentile=20, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=300\n",
            "[CV 2/3; 10/72] END Feature selection__percentile=20, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=300;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 10/72] START Feature selection__percentile=20, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 10/72] END Feature selection__percentile=20, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=300;, score=(train=0.594, test=-6.367) total time=   0.5s\n",
            "[CV 1/3; 11/72] START Feature selection__percentile=20, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=100\n",
            "[CV 1/3; 11/72] END Feature selection__percentile=20, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=100;, score=(train=0.799, test=0.095) total time=   0.2s\n",
            "[CV 2/3; 11/72] START Feature selection__percentile=20, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/3; 11/72] END Feature selection__percentile=20, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 11/72] START Feature selection__percentile=20, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=100\n",
            "[CV 3/3; 11/72] END Feature selection__percentile=20, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=100;, score=(train=0.564, test=-5.322) total time=   0.2s\n",
            "[CV 1/3; 12/72] START Feature selection__percentile=20, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3; 12/72] END Feature selection__percentile=20, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=200;, score=(train=0.793, test=0.141) total time=   0.3s\n",
            "[CV 2/3; 12/72] START Feature selection__percentile=20, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=200\n",
            "[CV 2/3; 12/72] END Feature selection__percentile=20, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=200;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 12/72] START Feature selection__percentile=20, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 12/72] END Feature selection__percentile=20, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=200;, score=(train=0.565, test=-6.346) total time=   0.3s\n",
            "[CV 1/3; 13/72] START Feature selection__percentile=20, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3; 13/72] END Feature selection__percentile=20, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=300;, score=(train=0.789, test=0.150) total time=   0.5s\n",
            "[CV 2/3; 13/72] START Feature selection__percentile=20, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=300\n",
            "[CV 2/3; 13/72] END Feature selection__percentile=20, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=300;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 13/72] START Feature selection__percentile=20, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 13/72] END Feature selection__percentile=20, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=300;, score=(train=0.562, test=-6.188) total time=   0.5s\n",
            "[CV 1/3; 14/72] START Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=100\n",
            "[CV 1/3; 14/72] END Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=100;, score=(train=0.878, test=-0.002) total time=   0.2s\n",
            "[CV 2/3; 14/72] START Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/3; 14/72] END Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 14/72] START Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 14/72] END Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=100;, score=(train=0.840, test=-3.716) total time=   0.2s\n",
            "[CV 1/3; 15/72] START Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3; 15/72] END Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=200;, score=(train=0.878, test=0.065) total time=   0.4s\n",
            "[CV 2/3; 15/72] START Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=200\n",
            "[CV 2/3; 15/72] END Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=200;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 15/72] START Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 15/72] END Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=200;, score=(train=0.843, test=-4.449) total time=   0.4s\n",
            "[CV 1/3; 16/72] START Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3; 16/72] END Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=300;, score=(train=0.875, test=0.089) total time=   0.5s\n",
            "[CV 2/3; 16/72] START Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=300\n",
            "[CV 2/3; 16/72] END Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=300;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 16/72] START Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 16/72] END Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=300;, score=(train=0.843, test=-4.239) total time=   0.5s\n",
            "[CV 1/3; 17/72] START Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3; 17/72] END Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=100;, score=(train=0.843, test=0.017) total time=   0.2s\n",
            "[CV 2/3; 17/72] START Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=100\n",
            "[CV 2/3; 17/72] END Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 17/72] START Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 17/72] END Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=100;, score=(train=0.610, test=-5.592) total time=   0.2s\n",
            "[CV 1/3; 18/72] START Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3; 18/72] END Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=200;, score=(train=0.841, test=0.074) total time=   0.3s\n",
            "[CV 2/3; 18/72] START Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=200\n",
            "[CV 2/3; 18/72] END Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=200;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 18/72] START Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 18/72] END Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=200;, score=(train=0.608, test=-6.631) total time=   0.4s\n",
            "[CV 1/3; 19/72] START Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3; 19/72] END Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=300;, score=(train=0.837, test=0.095) total time=   0.5s\n",
            "[CV 2/3; 19/72] START Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=300\n",
            "[CV 2/3; 19/72] END Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=300;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 19/72] START Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 19/72] END Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=300;, score=(train=0.596, test=-6.399) total time=   0.5s\n",
            "[CV 1/3; 20/72] START Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3; 20/72] END Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=100;, score=(train=0.798, test=0.053) total time=   0.2s\n",
            "[CV 2/3; 20/72] START Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=100\n",
            "[CV 2/3; 20/72] END Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 20/72] START Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 20/72] END Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=100;, score=(train=0.565, test=-5.282) total time=   0.2s\n",
            "[CV 1/3; 21/72] START Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3; 21/72] END Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=200;, score=(train=0.793, test=0.096) total time=   0.3s\n",
            "[CV 2/3; 21/72] START Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=200\n",
            "[CV 2/3; 21/72] END Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=200;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 21/72] START Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 21/72] END Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=200;, score=(train=0.567, test=-6.350) total time=   0.3s\n",
            "[CV 1/3; 22/72] START Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3; 22/72] END Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=300;, score=(train=0.787, test=0.103) total time=   0.5s\n",
            "[CV 2/3; 22/72] START Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=300\n",
            "[CV 2/3; 22/72] END Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=300;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 22/72] START Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 22/72] END Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=300;, score=(train=0.562, test=-6.173) total time=   0.4s\n",
            "[CV 1/3; 23/72] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=100\n",
            "[CV 1/3; 23/72] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=100;, score=(train=0.877, test=-0.029) total time=   0.2s\n",
            "[CV 2/3; 23/72] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/3; 23/72] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 23/72] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=100\n",
            "[CV 3/3; 23/72] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=100;, score=(train=0.840, test=-8.432) total time=   0.2s\n",
            "[CV 1/3; 24/72] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3; 24/72] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=200;, score=(train=0.879, test=0.040) total time=   0.6s\n",
            "[CV 2/3; 24/72] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=200\n",
            "[CV 2/3; 24/72] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=200;, score=(train=nan, test=nan) total time=   0.1s\n",
            "[CV 3/3; 24/72] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 24/72] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=200;, score=(train=0.843, test=-8.675) total time=   0.5s\n",
            "[CV 1/3; 25/72] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3; 25/72] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=300;, score=(train=0.873, test=0.070) total time=   1.0s\n",
            "[CV 2/3; 25/72] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=300\n",
            "[CV 2/3; 25/72] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=300;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 25/72] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 25/72] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=300;, score=(train=0.841, test=-8.337) total time=   0.5s\n",
            "[CV 1/3; 26/72] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3; 26/72] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=100;, score=(train=0.848, test=-0.001) total time=   0.2s\n",
            "[CV 2/3; 26/72] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=100\n",
            "[CV 2/3; 26/72] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 26/72] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 26/72] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=100;, score=(train=0.627, test=-7.231) total time=   0.2s\n",
            "[CV 1/3; 27/72] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3; 27/72] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=200;, score=(train=0.845, test=0.074) total time=   0.3s\n",
            "[CV 2/3; 27/72] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=200\n",
            "[CV 2/3; 27/72] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=200;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 27/72] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 27/72] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=200;, score=(train=0.618, test=-8.201) total time=   0.3s\n",
            "[CV 1/3; 28/72] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3; 28/72] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=300;, score=(train=0.840, test=0.093) total time=   0.5s\n",
            "[CV 2/3; 28/72] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=300\n",
            "[CV 2/3; 28/72] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=300;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 28/72] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 28/72] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=300;, score=(train=0.604, test=-7.563) total time=   0.5s\n",
            "[CV 1/3; 29/72] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=100\n",
            "[CV 1/3; 29/72] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=100;, score=(train=0.804, test=0.036) total time=   0.2s\n",
            "[CV 2/3; 29/72] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/3; 29/72] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 29/72] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 29/72] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=100;, score=(train=0.589, test=-6.594) total time=   0.2s\n",
            "[CV 1/3; 30/72] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=200\n",
            "[CV 1/3; 30/72] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=200;, score=(train=0.798, test=0.090) total time=   0.3s\n",
            "[CV 2/3; 30/72] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=200\n",
            "[CV 2/3; 30/72] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=200;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 30/72] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 30/72] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=200;, score=(train=0.584, test=-7.507) total time=   0.3s\n",
            "[CV 1/3; 31/72] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3; 31/72] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=300;, score=(train=0.793, test=0.102) total time=   0.5s\n",
            "[CV 2/3; 31/72] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=300\n",
            "[CV 2/3; 31/72] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=300;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 31/72] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 31/72] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=300;, score=(train=0.574, test=-7.080) total time=   0.5s\n",
            "[CV 1/3; 32/72] START Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3; 32/72] END Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=100;, score=(train=0.879, test=0.004) total time=   0.2s\n",
            "[CV 2/3; 32/72] START Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=100\n",
            "[CV 2/3; 32/72] END Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 32/72] START Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 32/72] END Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=100;, score=(train=0.836, test=-7.708) total time=   0.2s\n",
            "[CV 1/3; 33/72] START Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3; 33/72] END Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=200;, score=(train=0.881, test=0.066) total time=   0.4s\n",
            "[CV 2/3; 33/72] START Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=200\n",
            "[CV 2/3; 33/72] END Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=200;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 33/72] START Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 33/72] END Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=200;, score=(train=0.842, test=-7.943) total time=   0.4s\n",
            "[CV 1/3; 34/72] START Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3; 34/72] END Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=300;, score=(train=0.876, test=0.088) total time=   0.5s\n",
            "[CV 2/3; 34/72] START Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=300\n",
            "[CV 2/3; 34/72] END Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=300;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 34/72] START Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 34/72] END Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=300;, score=(train=0.841, test=-7.130) total time=   0.5s\n",
            "[CV 1/3; 35/72] START Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3; 35/72] END Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=100;, score=(train=0.846, test=0.008) total time=   0.2s\n",
            "[CV 2/3; 35/72] START Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=100\n",
            "[CV 2/3; 35/72] END Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 35/72] START Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 35/72] END Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=100;, score=(train=0.630, test=-6.708) total time=   0.2s\n",
            "[CV 1/3; 36/72] START Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3; 36/72] END Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=200;, score=(train=0.845, test=0.072) total time=   0.4s\n",
            "[CV 2/3; 36/72] START Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=200\n",
            "[CV 2/3; 36/72] END Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=200;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 36/72] START Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 36/72] END Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=200;, score=(train=0.618, test=-7.776) total time=   0.4s\n",
            "[CV 1/3; 37/72] START Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3; 37/72] END Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=300;, score=(train=0.840, test=0.086) total time=   0.5s\n",
            "[CV 2/3; 37/72] START Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=300\n",
            "[CV 2/3; 37/72] END Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=300;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 37/72] START Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 37/72] END Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=300;, score=(train=0.605, test=-7.328) total time=   0.5s\n",
            "[CV 1/3; 38/72] START Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3; 38/72] END Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=100;, score=(train=0.805, test=0.031) total time=   0.2s\n",
            "[CV 2/3; 38/72] START Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=100\n",
            "[CV 2/3; 38/72] END Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 38/72] START Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 38/72] END Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=100;, score=(train=0.590, test=-6.444) total time=   0.2s\n",
            "[CV 1/3; 39/72] START Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3; 39/72] END Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=200;, score=(train=0.799, test=0.091) total time=   0.4s\n",
            "[CV 2/3; 39/72] START Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=200\n",
            "[CV 2/3; 39/72] END Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=200;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 39/72] START Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 39/72] END Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=200;, score=(train=0.586, test=-7.562) total time=   0.3s\n",
            "[CV 1/3; 40/72] START Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3; 40/72] END Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=300;, score=(train=0.794, test=0.104) total time=   0.5s\n",
            "[CV 2/3; 40/72] START Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=300\n",
            "[CV 2/3; 40/72] END Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=300;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 40/72] START Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 40/72] END Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=300;, score=(train=0.576, test=-7.118) total time=   0.5s\n",
            "[CV 1/3; 41/72] START Feature selection__percentile=20, regresor=Ridge(), regresor__alpha=0.1\n",
            "[CV 1/3; 41/72] END Feature selection__percentile=20, regresor=Ridge(), regresor__alpha=0.1;, score=(train=0.071, test=0.103) total time=   0.1s\n",
            "[CV 2/3; 41/72] START Feature selection__percentile=20, regresor=Ridge(), regresor__alpha=0.1\n",
            "[CV 2/3; 41/72] END Feature selection__percentile=20, regresor=Ridge(), regresor__alpha=0.1;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 41/72] START Feature selection__percentile=20, regresor=Ridge(), regresor__alpha=0.1\n",
            "[CV 3/3; 41/72] END Feature selection__percentile=20, regresor=Ridge(), regresor__alpha=0.1;, score=(train=0.418, test=-9.151) total time=   0.0s\n",
            "[CV 1/3; 42/72] START Feature selection__percentile=20, regresor=Ridge(), regresor__alpha=0.5\n",
            "[CV 1/3; 42/72] END Feature selection__percentile=20, regresor=Ridge(), regresor__alpha=0.5;, score=(train=0.071, test=0.106) total time=   0.0s\n",
            "[CV 2/3; 42/72] START Feature selection__percentile=20, regresor=Ridge(), regresor__alpha=0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/3; 42/72] END Feature selection__percentile=20, regresor=Ridge(), regresor__alpha=0.5;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 42/72] START Feature selection__percentile=20, regresor=Ridge(), regresor__alpha=0.5\n",
            "[CV 3/3; 42/72] END Feature selection__percentile=20, regresor=Ridge(), regresor__alpha=0.5;, score=(train=0.417, test=-9.044) total time=   0.0s\n",
            "[CV 1/3; 43/72] START Feature selection__percentile=20, regresor=Ridge(), regresor__alpha=1\n",
            "[CV 1/3; 43/72] END Feature selection__percentile=20, regresor=Ridge(), regresor__alpha=1;, score=(train=0.071, test=0.108) total time=   0.0s\n",
            "[CV 2/3; 43/72] START Feature selection__percentile=20, regresor=Ridge(), regresor__alpha=1\n",
            "[CV 2/3; 43/72] END Feature selection__percentile=20, regresor=Ridge(), regresor__alpha=1;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 43/72] START Feature selection__percentile=20, regresor=Ridge(), regresor__alpha=1\n",
            "[CV 3/3; 43/72] END Feature selection__percentile=20, regresor=Ridge(), regresor__alpha=1;, score=(train=0.417, test=-8.924) total time=   0.0s\n",
            "[CV 1/3; 44/72] START Feature selection__percentile=20, regresor=Ridge(), regresor__alpha=5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3; 44/72] END Feature selection__percentile=20, regresor=Ridge(), regresor__alpha=5;, score=(train=0.065, test=0.114) total time=   0.0s\n",
            "[CV 2/3; 44/72] START Feature selection__percentile=20, regresor=Ridge(), regresor__alpha=5\n",
            "[CV 2/3; 44/72] END Feature selection__percentile=20, regresor=Ridge(), regresor__alpha=5;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 44/72] START Feature selection__percentile=20, regresor=Ridge(), regresor__alpha=5\n",
            "[CV 3/3; 44/72] END Feature selection__percentile=20, regresor=Ridge(), regresor__alpha=5;, score=(train=0.414, test=-8.174) total time=   0.0s\n",
            "[CV 1/3; 45/72] START Feature selection__percentile=40, regresor=Ridge(), regresor__alpha=0.1\n",
            "[CV 1/3; 45/72] END Feature selection__percentile=40, regresor=Ridge(), regresor__alpha=0.1;, score=(train=0.136, test=0.013) total time=   0.0s\n",
            "[CV 2/3; 45/72] START Feature selection__percentile=40, regresor=Ridge(), regresor__alpha=0.1\n",
            "[CV 2/3; 45/72] END Feature selection__percentile=40, regresor=Ridge(), regresor__alpha=0.1;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 45/72] START Feature selection__percentile=40, regresor=Ridge(), regresor__alpha=0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 45/72] END Feature selection__percentile=40, regresor=Ridge(), regresor__alpha=0.1;, score=(train=0.420, test=-9.111) total time=   0.0s\n",
            "[CV 1/3; 46/72] START Feature selection__percentile=40, regresor=Ridge(), regresor__alpha=0.5\n",
            "[CV 1/3; 46/72] END Feature selection__percentile=40, regresor=Ridge(), regresor__alpha=0.5;, score=(train=0.117, test=0.116) total time=   0.0s\n",
            "[CV 2/3; 46/72] START Feature selection__percentile=40, regresor=Ridge(), regresor__alpha=0.5\n",
            "[CV 2/3; 46/72] END Feature selection__percentile=40, regresor=Ridge(), regresor__alpha=0.5;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 46/72] START Feature selection__percentile=40, regresor=Ridge(), regresor__alpha=0.5\n",
            "[CV 3/3; 46/72] END Feature selection__percentile=40, regresor=Ridge(), regresor__alpha=0.5;, score=(train=0.420, test=-8.999) total time=   0.0s\n",
            "[CV 1/3; 47/72] START Feature selection__percentile=40, regresor=Ridge(), regresor__alpha=1\n",
            "[CV 1/3; 47/72] END Feature selection__percentile=40, regresor=Ridge(), regresor__alpha=1;, score=(train=0.108, test=0.132) total time=   0.0s\n",
            "[CV 2/3; 47/72] START Feature selection__percentile=40, regresor=Ridge(), regresor__alpha=1\n",
            "[CV 2/3; 47/72] END Feature selection__percentile=40, regresor=Ridge(), regresor__alpha=1;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 47/72] START Feature selection__percentile=40, regresor=Ridge(), regresor__alpha=1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 47/72] END Feature selection__percentile=40, regresor=Ridge(), regresor__alpha=1;, score=(train=0.419, test=-8.876) total time=   0.0s\n",
            "[CV 1/3; 48/72] START Feature selection__percentile=40, regresor=Ridge(), regresor__alpha=5\n",
            "[CV 1/3; 48/72] END Feature selection__percentile=40, regresor=Ridge(), regresor__alpha=5;, score=(train=0.085, test=0.138) total time=   0.0s\n",
            "[CV 2/3; 48/72] START Feature selection__percentile=40, regresor=Ridge(), regresor__alpha=5\n",
            "[CV 2/3; 48/72] END Feature selection__percentile=40, regresor=Ridge(), regresor__alpha=5;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 48/72] START Feature selection__percentile=40, regresor=Ridge(), regresor__alpha=5\n",
            "[CV 3/3; 48/72] END Feature selection__percentile=40, regresor=Ridge(), regresor__alpha=5;, score=(train=0.415, test=-8.138) total time=   0.0s\n",
            "[CV 1/3; 49/72] START Feature selection__percentile=60, regresor=Ridge(), regresor__alpha=0.1\n",
            "[CV 1/3; 49/72] END Feature selection__percentile=60, regresor=Ridge(), regresor__alpha=0.1;, score=(train=0.154, test=0.091) total time=   0.0s\n",
            "[CV 2/3; 49/72] START Feature selection__percentile=60, regresor=Ridge(), regresor__alpha=0.1\n",
            "[CV 2/3; 49/72] END Feature selection__percentile=60, regresor=Ridge(), regresor__alpha=0.1;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 49/72] START Feature selection__percentile=60, regresor=Ridge(), regresor__alpha=0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 49/72] END Feature selection__percentile=60, regresor=Ridge(), regresor__alpha=0.1;, score=(train=0.433, test=-9.782) total time=   0.0s\n",
            "[CV 1/3; 50/72] START Feature selection__percentile=60, regresor=Ridge(), regresor__alpha=0.5\n",
            "[CV 1/3; 50/72] END Feature selection__percentile=60, regresor=Ridge(), regresor__alpha=0.5;, score=(train=0.149, test=0.101) total time=   0.0s\n",
            "[CV 2/3; 50/72] START Feature selection__percentile=60, regresor=Ridge(), regresor__alpha=0.5\n",
            "[CV 2/3; 50/72] END Feature selection__percentile=60, regresor=Ridge(), regresor__alpha=0.5;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 50/72] START Feature selection__percentile=60, regresor=Ridge(), regresor__alpha=0.5\n",
            "[CV 3/3; 50/72] END Feature selection__percentile=60, regresor=Ridge(), regresor__alpha=0.5;, score=(train=0.432, test=-9.641) total time=   0.0s\n",
            "[CV 1/3; 51/72] START Feature selection__percentile=60, regresor=Ridge(), regresor__alpha=1\n",
            "[CV 1/3; 51/72] END Feature selection__percentile=60, regresor=Ridge(), regresor__alpha=1;, score=(train=0.141, test=0.108) total time=   0.0s\n",
            "[CV 2/3; 51/72] START Feature selection__percentile=60, regresor=Ridge(), regresor__alpha=1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/3; 51/72] END Feature selection__percentile=60, regresor=Ridge(), regresor__alpha=1;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 51/72] START Feature selection__percentile=60, regresor=Ridge(), regresor__alpha=1\n",
            "[CV 3/3; 51/72] END Feature selection__percentile=60, regresor=Ridge(), regresor__alpha=1;, score=(train=0.432, test=-9.497) total time=   0.0s\n",
            "[CV 1/3; 52/72] START Feature selection__percentile=60, regresor=Ridge(), regresor__alpha=5\n",
            "[CV 1/3; 52/72] END Feature selection__percentile=60, regresor=Ridge(), regresor__alpha=5;, score=(train=0.109, test=0.120) total time=   0.0s\n",
            "[CV 2/3; 52/72] START Feature selection__percentile=60, regresor=Ridge(), regresor__alpha=5\n",
            "[CV 2/3; 52/72] END Feature selection__percentile=60, regresor=Ridge(), regresor__alpha=5;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 52/72] START Feature selection__percentile=60, regresor=Ridge(), regresor__alpha=5\n",
            "[CV 3/3; 52/72] END Feature selection__percentile=60, regresor=Ridge(), regresor__alpha=5;, score=(train=0.427, test=-8.667) total time=   0.0s\n",
            "[CV 1/3; 53/72] START Feature selection__percentile=80, regresor=Ridge(), regresor__alpha=0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3; 53/72] END Feature selection__percentile=80, regresor=Ridge(), regresor__alpha=0.1;, score=(train=0.158, test=0.082) total time=   0.0s\n",
            "[CV 2/3; 53/72] START Feature selection__percentile=80, regresor=Ridge(), regresor__alpha=0.1\n",
            "[CV 2/3; 53/72] END Feature selection__percentile=80, regresor=Ridge(), regresor__alpha=0.1;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 53/72] START Feature selection__percentile=80, regresor=Ridge(), regresor__alpha=0.1\n",
            "[CV 3/3; 53/72] END Feature selection__percentile=80, regresor=Ridge(), regresor__alpha=0.1;, score=(train=0.461, test=-11.333) total time=   0.0s\n",
            "[CV 1/3; 54/72] START Feature selection__percentile=80, regresor=Ridge(), regresor__alpha=0.5\n",
            "[CV 1/3; 54/72] END Feature selection__percentile=80, regresor=Ridge(), regresor__alpha=0.5;, score=(train=0.152, test=0.095) total time=   0.0s\n",
            "[CV 2/3; 54/72] START Feature selection__percentile=80, regresor=Ridge(), regresor__alpha=0.5\n",
            "[CV 2/3; 54/72] END Feature selection__percentile=80, regresor=Ridge(), regresor__alpha=0.5;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 54/72] START Feature selection__percentile=80, regresor=Ridge(), regresor__alpha=0.5\n",
            "[CV 3/3; 54/72] END Feature selection__percentile=80, regresor=Ridge(), regresor__alpha=0.5;, score=(train=0.459, test=-10.804) total time=   0.0s\n",
            "[CV 1/3; 55/72] START Feature selection__percentile=80, regresor=Ridge(), regresor__alpha=1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3; 55/72] END Feature selection__percentile=80, regresor=Ridge(), regresor__alpha=1;, score=(train=0.145, test=0.104) total time=   0.0s\n",
            "[CV 2/3; 55/72] START Feature selection__percentile=80, regresor=Ridge(), regresor__alpha=1\n",
            "[CV 2/3; 55/72] END Feature selection__percentile=80, regresor=Ridge(), regresor__alpha=1;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 55/72] START Feature selection__percentile=80, regresor=Ridge(), regresor__alpha=1\n",
            "[CV 3/3; 55/72] END Feature selection__percentile=80, regresor=Ridge(), regresor__alpha=1;, score=(train=0.456, test=-10.378) total time=   0.0s\n",
            "[CV 1/3; 56/72] START Feature selection__percentile=80, regresor=Ridge(), regresor__alpha=5\n",
            "[CV 1/3; 56/72] END Feature selection__percentile=80, regresor=Ridge(), regresor__alpha=5;, score=(train=0.110, test=0.119) total time=   0.0s\n",
            "[CV 2/3; 56/72] START Feature selection__percentile=80, regresor=Ridge(), regresor__alpha=5\n",
            "[CV 2/3; 56/72] END Feature selection__percentile=80, regresor=Ridge(), regresor__alpha=5;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 56/72] START Feature selection__percentile=80, regresor=Ridge(), regresor__alpha=5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 56/72] END Feature selection__percentile=80, regresor=Ridge(), regresor__alpha=5;, score=(train=0.439, test=-8.938) total time=   0.0s\n",
            "[CV 1/3; 57/72] START Feature selection__percentile=20, regresor=Lasso(), regresor__alpha=0.1\n",
            "[CV 1/3; 57/72] END Feature selection__percentile=20, regresor=Lasso(), regresor__alpha=0.1;, score=(train=0.071, test=0.102) total time=   0.1s\n",
            "[CV 2/3; 57/72] START Feature selection__percentile=20, regresor=Lasso(), regresor__alpha=0.1\n",
            "[CV 2/3; 57/72] END Feature selection__percentile=20, regresor=Lasso(), regresor__alpha=0.1;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 57/72] START Feature selection__percentile=20, regresor=Lasso(), regresor__alpha=0.1\n",
            "[CV 3/3; 57/72] END Feature selection__percentile=20, regresor=Lasso(), regresor__alpha=0.1;, score=(train=0.418, test=-9.179) total time=   0.0s\n",
            "[CV 1/3; 58/72] START Feature selection__percentile=20, regresor=Lasso(), regresor__alpha=0.5\n",
            "[CV 1/3; 58/72] END Feature selection__percentile=20, regresor=Lasso(), regresor__alpha=0.5;, score=(train=0.071, test=0.102) total time=   0.0s\n",
            "[CV 2/3; 58/72] START Feature selection__percentile=20, regresor=Lasso(), regresor__alpha=0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/3; 58/72] END Feature selection__percentile=20, regresor=Lasso(), regresor__alpha=0.5;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 58/72] START Feature selection__percentile=20, regresor=Lasso(), regresor__alpha=0.5\n",
            "[CV 3/3; 58/72] END Feature selection__percentile=20, regresor=Lasso(), regresor__alpha=0.5;, score=(train=0.418, test=-9.179) total time=   0.0s\n",
            "[CV 1/3; 59/72] START Feature selection__percentile=20, regresor=Lasso(), regresor__alpha=1\n",
            "[CV 1/3; 59/72] END Feature selection__percentile=20, regresor=Lasso(), regresor__alpha=1;, score=(train=0.071, test=0.102) total time=   0.0s\n",
            "[CV 2/3; 59/72] START Feature selection__percentile=20, regresor=Lasso(), regresor__alpha=1\n",
            "[CV 2/3; 59/72] END Feature selection__percentile=20, regresor=Lasso(), regresor__alpha=1;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 59/72] START Feature selection__percentile=20, regresor=Lasso(), regresor__alpha=1\n",
            "[CV 3/3; 59/72] END Feature selection__percentile=20, regresor=Lasso(), regresor__alpha=1;, score=(train=0.418, test=-9.179) total time=   0.0s\n",
            "[CV 1/3; 60/72] START Feature selection__percentile=20, regresor=Lasso(), regresor__alpha=5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3; 60/72] END Feature selection__percentile=20, regresor=Lasso(), regresor__alpha=5;, score=(train=0.071, test=0.102) total time=   0.0s\n",
            "[CV 2/3; 60/72] START Feature selection__percentile=20, regresor=Lasso(), regresor__alpha=5\n",
            "[CV 2/3; 60/72] END Feature selection__percentile=20, regresor=Lasso(), regresor__alpha=5;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 60/72] START Feature selection__percentile=20, regresor=Lasso(), regresor__alpha=5\n",
            "[CV 3/3; 60/72] END Feature selection__percentile=20, regresor=Lasso(), regresor__alpha=5;, score=(train=0.418, test=-9.178) total time=   0.0s\n",
            "[CV 1/3; 61/72] START Feature selection__percentile=40, regresor=Lasso(), regresor__alpha=0.1\n",
            "[CV 1/3; 61/72] END Feature selection__percentile=40, regresor=Lasso(), regresor__alpha=0.1;, score=(train=0.141, test=-0.155) total time=   0.0s\n",
            "[CV 2/3; 61/72] START Feature selection__percentile=40, regresor=Lasso(), regresor__alpha=0.1\n",
            "[CV 2/3; 61/72] END Feature selection__percentile=40, regresor=Lasso(), regresor__alpha=0.1;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 61/72] START Feature selection__percentile=40, regresor=Lasso(), regresor__alpha=0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 61/72] END Feature selection__percentile=40, regresor=Lasso(), regresor__alpha=0.1;, score=(train=0.420, test=-9.136) total time=   0.0s\n",
            "[CV 1/3; 62/72] START Feature selection__percentile=40, regresor=Lasso(), regresor__alpha=0.5\n",
            "[CV 1/3; 62/72] END Feature selection__percentile=40, regresor=Lasso(), regresor__alpha=0.5;, score=(train=0.141, test=-0.155) total time=   0.0s\n",
            "[CV 2/3; 62/72] START Feature selection__percentile=40, regresor=Lasso(), regresor__alpha=0.5\n",
            "[CV 2/3; 62/72] END Feature selection__percentile=40, regresor=Lasso(), regresor__alpha=0.5;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 62/72] START Feature selection__percentile=40, regresor=Lasso(), regresor__alpha=0.5\n",
            "[CV 3/3; 62/72] END Feature selection__percentile=40, regresor=Lasso(), regresor__alpha=0.5;, score=(train=0.420, test=-9.136) total time=   0.0s\n",
            "[CV 1/3; 63/72] START Feature selection__percentile=40, regresor=Lasso(), regresor__alpha=1\n",
            "[CV 1/3; 63/72] END Feature selection__percentile=40, regresor=Lasso(), regresor__alpha=1;, score=(train=0.141, test=-0.155) total time=   0.0s\n",
            "[CV 2/3; 63/72] START Feature selection__percentile=40, regresor=Lasso(), regresor__alpha=1\n",
            "[CV 2/3; 63/72] END Feature selection__percentile=40, regresor=Lasso(), regresor__alpha=1;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 63/72] START Feature selection__percentile=40, regresor=Lasso(), regresor__alpha=1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning:\n",
            "\n",
            "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.669e+11, tolerance: 7.590e+09\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 63/72] END Feature selection__percentile=40, regresor=Lasso(), regresor__alpha=1;, score=(train=0.420, test=-9.138) total time=   0.0s\n",
            "[CV 1/3; 64/72] START Feature selection__percentile=40, regresor=Lasso(), regresor__alpha=5\n",
            "[CV 1/3; 64/72] END Feature selection__percentile=40, regresor=Lasso(), regresor__alpha=5;, score=(train=0.141, test=-0.153) total time=   0.0s\n",
            "[CV 2/3; 64/72] START Feature selection__percentile=40, regresor=Lasso(), regresor__alpha=5\n",
            "[CV 2/3; 64/72] END Feature selection__percentile=40, regresor=Lasso(), regresor__alpha=5;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 64/72] START Feature selection__percentile=40, regresor=Lasso(), regresor__alpha=5\n",
            "[CV 3/3; 64/72] END Feature selection__percentile=40, regresor=Lasso(), regresor__alpha=5;, score=(train=0.420, test=-9.142) total time=   0.0s\n",
            "[CV 1/3; 65/72] START Feature selection__percentile=60, regresor=Lasso(), regresor__alpha=0.1\n",
            "[CV 1/3; 65/72] END Feature selection__percentile=60, regresor=Lasso(), regresor__alpha=0.1;, score=(train=0.154, test=0.088) total time=   0.0s\n",
            "[CV 2/3; 65/72] START Feature selection__percentile=60, regresor=Lasso(), regresor__alpha=0.1\n",
            "[CV 2/3; 65/72] END Feature selection__percentile=60, regresor=Lasso(), regresor__alpha=0.1;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 65/72] START Feature selection__percentile=60, regresor=Lasso(), regresor__alpha=0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning:\n",
            "\n",
            "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.930e+10, tolerance: 1.759e+09\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 65/72] END Feature selection__percentile=60, regresor=Lasso(), regresor__alpha=0.1;, score=(train=0.433, test=-9.826) total time=   0.0s\n",
            "[CV 1/3; 66/72] START Feature selection__percentile=60, regresor=Lasso(), regresor__alpha=0.5\n",
            "[CV 1/3; 66/72] END Feature selection__percentile=60, regresor=Lasso(), regresor__alpha=0.5;, score=(train=0.154, test=0.087) total time=   0.0s\n",
            "[CV 2/3; 66/72] START Feature selection__percentile=60, regresor=Lasso(), regresor__alpha=0.5\n",
            "[CV 2/3; 66/72] END Feature selection__percentile=60, regresor=Lasso(), regresor__alpha=0.5;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 66/72] START Feature selection__percentile=60, regresor=Lasso(), regresor__alpha=0.5\n",
            "[CV 3/3; 66/72] END Feature selection__percentile=60, regresor=Lasso(), regresor__alpha=0.5;, score=(train=0.433, test=-9.826) total time=   0.0s\n",
            "[CV 1/3; 67/72] START Feature selection__percentile=60, regresor=Lasso(), regresor__alpha=1\n",
            "[CV 1/3; 67/72] END Feature selection__percentile=60, regresor=Lasso(), regresor__alpha=1;, score=(train=0.154, test=0.084) total time=   0.0s\n",
            "[CV 2/3; 67/72] START Feature selection__percentile=60, regresor=Lasso(), regresor__alpha=1\n",
            "[CV 2/3; 67/72] END Feature selection__percentile=60, regresor=Lasso(), regresor__alpha=1;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 67/72] START Feature selection__percentile=60, regresor=Lasso(), regresor__alpha=1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning:\n",
            "\n",
            "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.934e+10, tolerance: 1.759e+09\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning:\n",
            "\n",
            "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.567e+11, tolerance: 7.590e+09\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 67/72] END Feature selection__percentile=60, regresor=Lasso(), regresor__alpha=1;, score=(train=0.433, test=-9.825) total time=   0.0s\n",
            "[CV 1/3; 68/72] START Feature selection__percentile=60, regresor=Lasso(), regresor__alpha=5\n",
            "[CV 1/3; 68/72] END Feature selection__percentile=60, regresor=Lasso(), regresor__alpha=5;, score=(train=0.154, test=0.063) total time=   0.0s\n",
            "[CV 2/3; 68/72] START Feature selection__percentile=60, regresor=Lasso(), regresor__alpha=5\n",
            "[CV 2/3; 68/72] END Feature selection__percentile=60, regresor=Lasso(), regresor__alpha=5;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 68/72] START Feature selection__percentile=60, regresor=Lasso(), regresor__alpha=5\n",
            "[CV 3/3; 68/72] END Feature selection__percentile=60, regresor=Lasso(), regresor__alpha=5;, score=(train=0.433, test=-9.823) total time=   0.0s\n",
            "[CV 1/3; 69/72] START Feature selection__percentile=80, regresor=Lasso(), regresor__alpha=0.1\n",
            "[CV 1/3; 69/72] END Feature selection__percentile=80, regresor=Lasso(), regresor__alpha=0.1;, score=(train=0.158, test=0.077) total time=   0.0s\n",
            "[CV 2/3; 69/72] START Feature selection__percentile=80, regresor=Lasso(), regresor__alpha=0.1\n",
            "[CV 2/3; 69/72] END Feature selection__percentile=80, regresor=Lasso(), regresor__alpha=0.1;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 69/72] START Feature selection__percentile=80, regresor=Lasso(), regresor__alpha=0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning:\n",
            "\n",
            "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.506e+10, tolerance: 1.759e+09\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning:\n",
            "\n",
            "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.211e+12, tolerance: 7.590e+09\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 69/72] END Feature selection__percentile=80, regresor=Lasso(), regresor__alpha=0.1;, score=(train=0.461, test=-11.516) total time=   0.0s\n",
            "[CV 1/3; 70/72] START Feature selection__percentile=80, regresor=Lasso(), regresor__alpha=0.5\n",
            "[CV 1/3; 70/72] END Feature selection__percentile=80, regresor=Lasso(), regresor__alpha=0.5;, score=(train=0.158, test=0.076) total time=   0.0s\n",
            "[CV 2/3; 70/72] START Feature selection__percentile=80, regresor=Lasso(), regresor__alpha=0.5\n",
            "[CV 2/3; 70/72] END Feature selection__percentile=80, regresor=Lasso(), regresor__alpha=0.5;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 70/72] START Feature selection__percentile=80, regresor=Lasso(), regresor__alpha=0.5\n",
            "[CV 3/3; 70/72] END Feature selection__percentile=80, regresor=Lasso(), regresor__alpha=0.5;, score=(train=0.461, test=-11.517) total time=   0.0s\n",
            "[CV 1/3; 71/72] START Feature selection__percentile=80, regresor=Lasso(), regresor__alpha=1\n",
            "[CV 1/3; 71/72] END Feature selection__percentile=80, regresor=Lasso(), regresor__alpha=1;, score=(train=0.158, test=0.073) total time=   0.0s\n",
            "[CV 2/3; 71/72] START Feature selection__percentile=80, regresor=Lasso(), regresor__alpha=1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning:\n",
            "\n",
            "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.510e+10, tolerance: 1.759e+09\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning:\n",
            "\n",
            "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.211e+12, tolerance: 7.590e+09\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning:\n",
            "\n",
            "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.514e+10, tolerance: 1.759e+09\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/3; 71/72] END Feature selection__percentile=80, regresor=Lasso(), regresor__alpha=1;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 71/72] START Feature selection__percentile=80, regresor=Lasso(), regresor__alpha=1\n",
            "[CV 3/3; 71/72] END Feature selection__percentile=80, regresor=Lasso(), regresor__alpha=1;, score=(train=0.461, test=-11.518) total time=   0.1s\n",
            "[CV 1/3; 72/72] START Feature selection__percentile=80, regresor=Lasso(), regresor__alpha=5\n",
            "[CV 1/3; 72/72] END Feature selection__percentile=80, regresor=Lasso(), regresor__alpha=5;, score=(train=0.158, test=0.053) total time=   0.0s\n",
            "[CV 2/3; 72/72] START Feature selection__percentile=80, regresor=Lasso(), regresor__alpha=5\n",
            "[CV 2/3; 72/72] END Feature selection__percentile=80, regresor=Lasso(), regresor__alpha=5;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 72/72] START Feature selection__percentile=80, regresor=Lasso(), regresor__alpha=5\n",
            "[CV 3/3; 72/72] END Feature selection__percentile=80, regresor=Lasso(), regresor__alpha=5;, score=(train=0.461, test=-11.525) total time=   0.0s\n",
            "----------\n",
            "iter: 1\n",
            "n_candidates: 24\n",
            "n_resources: 612\n",
            "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning:\n",
            "\n",
            "Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.212e+12, tolerance: 7.590e+09\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:109: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning:\n",
            "\n",
            "\n",
            "72 fits failed out of a total of 216.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "4 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\", line 394, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py\", line 662, in fit\n",
            "    X, y = self._validate_data(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/base.py\", line 581, in _validate_data\n",
            "    X, y = check_X_y(X, y, **check_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py\", line 964, in check_X_y\n",
            "    X = check_array(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py\", line 814, in check_array\n",
            "    raise ValueError(\n",
            "ValueError: Found array with 0 feature(s) (shape=(135, 0)) while a minimum of 1 is required.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "36 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\", line 394, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py\", line 327, in fit\n",
            "    X, y = self._validate_data(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/base.py\", line 581, in _validate_data\n",
            "    X, y = check_X_y(X, y, **check_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py\", line 964, in check_X_y\n",
            "    X = check_array(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py\", line 814, in check_array\n",
            "    raise ValueError(\n",
            "ValueError: Found array with 0 feature(s) (shape=(135, 0)) while a minimum of 1 is required.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "16 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\", line 394, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py\", line 1003, in fit\n",
            "    X, y = self._validate_data(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/base.py\", line 581, in _validate_data\n",
            "    X, y = check_X_y(X, y, **check_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py\", line 964, in check_X_y\n",
            "    X = check_array(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py\", line 814, in check_array\n",
            "    raise ValueError(\n",
            "ValueError: Found array with 0 feature(s) (shape=(135, 0)) while a minimum of 1 is required.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "16 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\", line 394, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py\", line 935, in fit\n",
            "    X, y = self._validate_data(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/base.py\", line 581, in _validate_data\n",
            "    X, y = check_X_y(X, y, **check_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py\", line 964, in check_X_y\n",
            "    X = check_array(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py\", line 814, in check_array\n",
            "    raise ValueError(\n",
            "ValueError: Found array with 0 feature(s) (shape=(135, 0)) while a minimum of 1 is required.\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py:969: UserWarning:\n",
            "\n",
            "One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py:969: UserWarning:\n",
            "\n",
            "One or more of the train scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3; 1/24] START Feature selection__percentile=80, regresor=LinearRegression()\n",
            "[CV 1/3; 1/24] END Feature selection__percentile=80, regresor=LinearRegression();, score=(train=0.172, test=-1.067) total time=   0.1s\n",
            "[CV 2/3; 1/24] START Feature selection__percentile=80, regresor=LinearRegression()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/3; 1/24] END Feature selection__percentile=80, regresor=LinearRegression();, score=(train=0.398, test=-10.092) total time=   0.1s\n",
            "[CV 3/3; 1/24] START Feature selection__percentile=80, regresor=LinearRegression()\n",
            "[CV 3/3; 1/24] END Feature selection__percentile=80, regresor=LinearRegression();, score=(train=0.128, test=-0.052) total time=   0.1s\n",
            "[CV 1/3; 2/24] START Feature selection__percentile=60, regresor=LinearRegression()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3; 2/24] END Feature selection__percentile=60, regresor=LinearRegression();, score=(train=0.149, test=-1.037) total time=   0.1s\n",
            "[CV 2/3; 2/24] START Feature selection__percentile=60, regresor=LinearRegression()\n",
            "[CV 2/3; 2/24] END Feature selection__percentile=60, regresor=LinearRegression();, score=(train=nan, test=nan) total time=   0.1s\n",
            "[CV 3/3; 2/24] START Feature selection__percentile=60, regresor=LinearRegression()\n",
            "[CV 3/3; 2/24] END Feature selection__percentile=60, regresor=LinearRegression();, score=(train=0.107, test=-0.073) total time=   0.1s\n",
            "[CV 1/3; 3/24] START Feature selection__percentile=40, regresor=LinearRegression()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4012: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3; 3/24] END Feature selection__percentile=40, regresor=LinearRegression();, score=(train=nan, test=nan) total time=   0.1s\n",
            "[CV 2/3; 3/24] START Feature selection__percentile=40, regresor=LinearRegression()\n",
            "[CV 2/3; 3/24] END Feature selection__percentile=40, regresor=LinearRegression();, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 3/24] START Feature selection__percentile=40, regresor=LinearRegression()\n",
            "[CV 3/3; 3/24] END Feature selection__percentile=40, regresor=LinearRegression();, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 4/24] START Feature selection__percentile=20, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=100\n",
            "[CV 1/3; 4/24] END Feature selection__percentile=20, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 4/24] START Feature selection__percentile=20, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=100\n",
            "[CV 2/3; 4/24] END Feature selection__percentile=20, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 4/24] START Feature selection__percentile=20, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 4/24] END Feature selection__percentile=20, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=100;, score=(train=nan, test=nan) total time=   0.1s\n",
            "[CV 1/3; 5/24] START Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=100\n",
            "[CV 1/3; 5/24] END Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=100;, score=(train=nan, test=nan) total time=   0.1s\n",
            "[CV 2/3; 5/24] START Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=100\n",
            "[CV 2/3; 5/24] END Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 5/24] START Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=100\n",
            "[CV 3/3; 5/24] END Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=100;, score=(train=nan, test=nan) total time=   0.1s\n",
            "[CV 1/3; 6/24] START Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3; 6/24] END Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=200;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 6/24] START Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=200\n",
            "[CV 2/3; 6/24] END Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=200;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 6/24] START Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=200\n",
            "[CV 3/3; 6/24] END Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=200;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 7/24] START Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=300\n",
            "[CV 1/3; 7/24] END Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=300;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 7/24] START Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=300\n",
            "[CV 2/3; 7/24] END Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=300;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 7/24] START Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 7/24] END Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=300;, score=(train=nan, test=nan) total time=   0.1s\n",
            "[CV 1/3; 8/24] START Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3; 8/24] END Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=300;, score=(train=0.833, test=-3.031) total time=   0.8s\n",
            "[CV 2/3; 8/24] START Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/3; 8/24] END Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=300;, score=(train=0.871, test=-0.750) total time=   0.8s\n",
            "[CV 3/3; 8/24] START Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 8/24] END Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=300;, score=(train=0.853, test=-1.178) total time=   0.8s\n",
            "[CV 1/3; 9/24] START Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3; 9/24] END Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=200;, score=(train=0.836, test=-3.390) total time=   0.5s\n",
            "[CV 2/3; 9/24] START Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/3; 9/24] END Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=200;, score=(train=0.871, test=-0.798) total time=   0.5s\n",
            "[CV 3/3; 9/24] START Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 9/24] END Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=200;, score=(train=0.848, test=-1.243) total time=   0.5s\n",
            "[CV 1/3; 10/24] START Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3; 10/24] END Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=100;, score=(train=0.838, test=-3.795) total time=   0.3s\n",
            "[CV 2/3; 10/24] START Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/3; 10/24] END Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=100;, score=(train=0.873, test=-1.006) total time=   0.3s\n",
            "[CV 3/3; 10/24] START Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 10/24] END Feature selection__percentile=80, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=100;, score=(train=0.841, test=-1.490) total time=   0.3s\n",
            "[CV 1/3; 11/24] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3; 11/24] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=300;, score=(train=0.223, test=-0.848) total time=   0.5s\n",
            "[CV 2/3; 11/24] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=300\n",
            "[CV 2/3; 11/24] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=300;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 11/24] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4012: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 11/24] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=300;, score=(train=0.113, test=-0.095) total time=   0.5s\n",
            "[CV 1/3; 12/24] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3; 12/24] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=200;, score=(train=0.223, test=-0.864) total time=   0.3s\n",
            "[CV 2/3; 12/24] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=200\n",
            "[CV 2/3; 12/24] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=200;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 12/24] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4012: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 12/24] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=200;, score=(train=0.113, test=-0.067) total time=   0.4s\n",
            "[CV 1/3; 13/24] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3; 13/24] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=100;, score=(train=0.222, test=-0.875) total time=   0.2s\n",
            "[CV 2/3; 13/24] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=100\n",
            "[CV 2/3; 13/24] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 13/24] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4012: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 13/24] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=100;, score=(train=0.112, test=-0.046) total time=   0.2s\n",
            "[CV 1/3; 14/24] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3; 14/24] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=300;, score=(train=0.224, test=-0.849) total time=   0.5s\n",
            "[CV 2/3; 14/24] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=300\n",
            "[CV 2/3; 14/24] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=300;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 14/24] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4012: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 14/24] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=300;, score=(train=0.115, test=-0.103) total time=   0.5s\n",
            "[CV 1/3; 15/24] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3; 15/24] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=200;, score=(train=0.223, test=-0.864) total time=   0.4s\n",
            "[CV 2/3; 15/24] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=200\n",
            "[CV 2/3; 15/24] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=200;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 15/24] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4012: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 15/24] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=200;, score=(train=0.115, test=-0.079) total time=   0.3s\n",
            "[CV 1/3; 16/24] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3; 16/24] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=100;, score=(train=0.222, test=-0.874) total time=   0.2s\n",
            "[CV 2/3; 16/24] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=100\n",
            "[CV 2/3; 16/24] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=100;, score=(train=nan, test=nan) total time=   0.1s\n",
            "[CV 3/3; 16/24] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4012: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 16/24] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=100;, score=(train=0.114, test=-0.059) total time=   0.2s\n",
            "[CV 1/3; 17/24] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3; 17/24] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=300;, score=(train=0.224, test=-0.849) total time=   0.5s\n",
            "[CV 2/3; 17/24] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=300\n",
            "[CV 2/3; 17/24] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=300;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 17/24] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4012: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 17/24] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=300;, score=(train=0.116, test=-0.125) total time=   0.5s\n",
            "[CV 1/3; 18/24] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3; 18/24] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=200;, score=(train=0.224, test=-0.863) total time=   0.3s\n",
            "[CV 2/3; 18/24] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=200\n",
            "[CV 2/3; 18/24] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=200;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 18/24] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4012: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 18/24] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=200;, score=(train=0.115, test=-0.072) total time=   0.3s\n",
            "[CV 1/3; 19/24] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3; 19/24] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=100;, score=(train=0.223, test=-0.873) total time=   0.2s\n",
            "[CV 2/3; 19/24] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=100\n",
            "[CV 2/3; 19/24] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 19/24] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4012: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 19/24] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=2, regresor__n_estimators=100;, score=(train=0.114, test=-0.057) total time=   0.2s\n",
            "[CV 1/3; 20/24] START Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=300\n",
            "[CV 1/3; 20/24] END Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=300;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 20/24] START Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=300\n",
            "[CV 2/3; 20/24] END Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=300;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 20/24] START Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=300\n",
            "[CV 3/3; 20/24] END Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=300;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 21/24] START Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=200\n",
            "[CV 1/3; 21/24] END Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=200;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 21/24] START Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/3; 21/24] END Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=200;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 21/24] START Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=200\n",
            "[CV 3/3; 21/24] END Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=200;, score=(train=nan, test=nan) total time=   0.1s\n",
            "[CV 1/3; 22/24] START Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=100\n",
            "[CV 1/3; 22/24] END Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 22/24] START Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=100\n",
            "[CV 2/3; 22/24] END Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 22/24] START Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 22/24] END Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=100;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 23/24] START Feature selection__percentile=80, regresor=Lasso(), regresor__alpha=1\n",
            "[CV 1/3; 23/24] END Feature selection__percentile=80, regresor=Lasso(), regresor__alpha=1;, score=(train=0.172, test=-1.066) total time=   0.1s\n",
            "[CV 2/3; 23/24] START Feature selection__percentile=80, regresor=Lasso(), regresor__alpha=1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/3; 23/24] END Feature selection__percentile=80, regresor=Lasso(), regresor__alpha=1;, score=(train=0.398, test=-10.091) total time=   0.1s\n",
            "[CV 3/3; 23/24] START Feature selection__percentile=80, regresor=Lasso(), regresor__alpha=1\n",
            "[CV 3/3; 23/24] END Feature selection__percentile=80, regresor=Lasso(), regresor__alpha=1;, score=(train=0.128, test=-0.052) total time=   0.1s\n",
            "[CV 1/3; 24/24] START Feature selection__percentile=80, regresor=Lasso(), regresor__alpha=5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3; 24/24] END Feature selection__percentile=80, regresor=Lasso(), regresor__alpha=5;, score=(train=0.172, test=-1.065) total time=   0.1s\n",
            "[CV 2/3; 24/24] START Feature selection__percentile=80, regresor=Lasso(), regresor__alpha=5\n",
            "[CV 2/3; 24/24] END Feature selection__percentile=80, regresor=Lasso(), regresor__alpha=5;, score=(train=0.398, test=-10.090) total time=   0.1s\n",
            "[CV 3/3; 24/24] START Feature selection__percentile=80, regresor=Lasso(), regresor__alpha=5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning:\n",
            "\n",
            "\n",
            "34 fits failed out of a total of 72.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "3 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\", line 394, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py\", line 662, in fit\n",
            "    X, y = self._validate_data(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/base.py\", line 581, in _validate_data\n",
            "    X, y = check_X_y(X, y, **check_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py\", line 964, in check_X_y\n",
            "    X = check_array(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py\", line 814, in check_array\n",
            "    raise ValueError(\n",
            "ValueError: Found array with 0 feature(s) (shape=(407, 0)) while a minimum of 1 is required.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\", line 394, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py\", line 662, in fit\n",
            "    X, y = self._validate_data(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/base.py\", line 581, in _validate_data\n",
            "    X, y = check_X_y(X, y, **check_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py\", line 964, in check_X_y\n",
            "    X = check_array(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py\", line 814, in check_array\n",
            "    raise ValueError(\n",
            "ValueError: Found array with 0 feature(s) (shape=(408, 0)) while a minimum of 1 is required.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "23 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\", line 394, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py\", line 327, in fit\n",
            "    X, y = self._validate_data(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/base.py\", line 581, in _validate_data\n",
            "    X, y = check_X_y(X, y, **check_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py\", line 964, in check_X_y\n",
            "    X = check_array(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py\", line 814, in check_array\n",
            "    raise ValueError(\n",
            "ValueError: Found array with 0 feature(s) (shape=(407, 0)) while a minimum of 1 is required.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "7 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\", line 394, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py\", line 327, in fit\n",
            "    X, y = self._validate_data(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/base.py\", line 581, in _validate_data\n",
            "    X, y = check_X_y(X, y, **check_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py\", line 964, in check_X_y\n",
            "    X = check_array(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py\", line 814, in check_array\n",
            "    raise ValueError(\n",
            "ValueError: Found array with 0 feature(s) (shape=(408, 0)) while a minimum of 1 is required.\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py:969: UserWarning:\n",
            "\n",
            "One or more of the test scores are non-finite: [        nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            " -3.73681522         nan         nan         nan         nan         nan\n",
            "         nan -1.65272417 -1.81031911 -2.09705884         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan -3.73616239 -3.73537226]\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py:969: UserWarning:\n",
            "\n",
            "One or more of the train scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.23255758        nan        nan        nan        nan        nan\n",
            "        nan 0.85222757 0.85202729 0.85056849        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan 0.23255756 0.23255724]\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 24/24] END Feature selection__percentile=80, regresor=Lasso(), regresor__alpha=5;, score=(train=0.128, test=-0.051) total time=   0.1s\n",
            "----------\n",
            "iter: 2\n",
            "n_candidates: 8\n",
            "n_resources: 1836\n",
            "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
            "[CV 1/3; 1/8] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=100\n",
            "[CV 1/3; 1/8] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=100;, score=(train=0.475, test=-0.260) total time=   0.5s\n",
            "[CV 2/3; 1/8] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/3; 1/8] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=100;, score=(train=0.528, test=-0.056) total time=   0.4s\n",
            "[CV 3/3; 1/8] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 1/8] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=100;, score=(train=0.791, test=-0.003) total time=   0.4s\n",
            "[CV 1/3; 2/8] START Feature selection__percentile=60, regresor=LinearRegression()\n",
            "[CV 1/3; 2/8] END Feature selection__percentile=60, regresor=LinearRegression();, score=(train=0.303, test=-0.901) total time=   0.1s\n",
            "[CV 2/3; 2/8] START Feature selection__percentile=60, regresor=LinearRegression()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/3; 2/8] END Feature selection__percentile=60, regresor=LinearRegression();, score=(train=0.311, test=-0.235) total time=   0.1s\n",
            "[CV 3/3; 2/8] START Feature selection__percentile=60, regresor=LinearRegression()\n",
            "[CV 3/3; 2/8] END Feature selection__percentile=60, regresor=LinearRegression();, score=(train=0.072, test=0.052) total time=   0.1s\n",
            "[CV 1/3; 3/8] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3; 3/8] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=300;, score=(train=0.494, test=-0.150) total time=   1.1s\n",
            "[CV 2/3; 3/8] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/3; 3/8] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=300;, score=(train=0.508, test=-0.070) total time=   1.2s\n",
            "[CV 3/3; 3/8] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 3/8] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=300;, score=(train=0.790, test=-0.002) total time=   1.0s\n",
            "[CV 1/3; 4/8] START Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3; 4/8] END Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=300;, score=(train=0.258, test=-0.559) total time=   0.6s\n",
            "[CV 2/3; 4/8] START Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/3; 4/8] END Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=300;, score=(train=0.635, test=0.112) total time=   0.8s\n",
            "[CV 3/3; 4/8] START Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 4/8] END Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=300;, score=(train=0.798, test=0.011) total time=   0.9s\n",
            "[CV 1/3; 5/8] START Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3; 5/8] END Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=200;, score=(train=0.259, test=-0.613) total time=   0.5s\n",
            "[CV 2/3; 5/8] START Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/3; 5/8] END Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=200;, score=(train=0.639, test=0.063) total time=   0.6s\n",
            "[CV 3/3; 5/8] START Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 5/8] END Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=200;, score=(train=0.794, test=0.015) total time=   0.6s\n",
            "[CV 1/3; 6/8] START Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3; 6/8] END Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=100;, score=(train=0.259, test=-0.639) total time=   0.3s\n",
            "[CV 2/3; 6/8] START Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/3; 6/8] END Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=100;, score=(train=0.616, test=0.131) total time=   0.4s\n",
            "[CV 3/3; 6/8] START Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 6/8] END Feature selection__percentile=40, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=100;, score=(train=0.803, test=0.011) total time=   0.3s\n",
            "[CV 1/3; 7/8] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3; 7/8] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=200;, score=(train=0.751, test=0.029) total time=   0.8s\n",
            "[CV 2/3; 7/8] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/3; 7/8] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=200;, score=(train=0.653, test=-0.057) total time=   0.9s\n",
            "[CV 3/3; 7/8] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 7/8] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=200;, score=(train=0.825, test=-0.002) total time=   0.8s\n",
            "[CV 1/3; 8/8] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3; 8/8] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=200;, score=(train=0.505, test=-0.198) total time=   0.8s\n",
            "[CV 2/3; 8/8] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/3; 8/8] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=200;, score=(train=0.529, test=-0.124) total time=   0.9s\n",
            "[CV 3/3; 8/8] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 8/8] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=200;, score=(train=0.784, test=-0.003) total time=   0.8s\n",
            "----------\n",
            "iter: 3\n",
            "n_candidates: 3\n",
            "n_resources: 5508\n",
            "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
            "[CV 1/3; 1/3] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py:969: UserWarning:\n",
            "\n",
            "One or more of the test scores are non-finite: [        nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            " -3.73681522         nan         nan         nan         nan         nan\n",
            "         nan -1.65272417 -1.81031911 -2.09705884         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan -3.73616239 -3.73537226\n",
            " -0.10614034 -0.3612891  -0.07384206 -0.14545135 -0.17830382 -0.16580494\n",
            " -0.00982614 -0.10824498]\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py:969: UserWarning:\n",
            "\n",
            "One or more of the train scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.23255758        nan        nan        nan        nan        nan\n",
            "        nan 0.85222757 0.85202729 0.85056849        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan 0.23255756 0.23255724\n",
            " 0.59805515 0.22892247 0.59709207 0.56354065 0.56420075 0.55908707\n",
            " 0.74279365 0.60611363]\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3; 1/3] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=100;, score=(train=0.447, test=-0.145) total time=   0.8s\n",
            "[CV 2/3; 1/3] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/3; 1/3] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=100;, score=(train=0.813, test=-0.058) total time=   1.1s\n",
            "[CV 3/3; 1/3] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 1/3] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=100;, score=(train=0.777, test=-0.003) total time=   1.0s\n",
            "[CV 1/3; 2/3] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3; 2/3] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=300;, score=(train=0.453, test=-0.147) total time=   1.9s\n",
            "[CV 2/3; 2/3] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/3; 2/3] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=300;, score=(train=0.826, test=-0.056) total time=   2.8s\n",
            "[CV 3/3; 2/3] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 2/3] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=4, regresor__n_estimators=300;, score=(train=0.779, test=0.009) total time=   2.7s\n",
            "[CV 1/3; 3/3] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3; 3/3] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=200;, score=(train=0.481, test=-0.178) total time=   1.3s\n",
            "[CV 2/3; 3/3] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/3; 3/3] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=200;, score=(train=0.846, test=-0.064) total time=   1.9s\n",
            "[CV 3/3; 3/3] START Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 3/3] END Feature selection__percentile=60, regresor=RandomForestRegressor(random_state=42), regresor__min_samples_split=3, regresor__n_estimators=200;, score=(train=0.823, test=-0.003) total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py:969: UserWarning:\n",
            "\n",
            "One or more of the test scores are non-finite: [        nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            " -3.73681522         nan         nan         nan         nan         nan\n",
            "         nan -1.65272417 -1.81031911 -2.09705884         nan         nan\n",
            "         nan         nan         nan         nan         nan         nan\n",
            "         nan         nan         nan         nan -3.73616239 -3.73537226\n",
            " -0.10614034 -0.3612891  -0.07384206 -0.14545135 -0.17830382 -0.16580494\n",
            " -0.00982614 -0.10824498 -0.06891985 -0.06473891 -0.08144617]\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py:969: UserWarning:\n",
            "\n",
            "One or more of the train scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.23255758        nan        nan        nan        nan        nan\n",
            "        nan 0.85222757 0.85202729 0.85056849        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan 0.23255756 0.23255724\n",
            " 0.59805515 0.22892247 0.59709207 0.56354065 0.56420075 0.55908707\n",
            " 0.74279365 0.60611363 0.67913325 0.68596863 0.71693379]\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        }
      ],
      "id": "jPbtQN8faRZi"
    },
    {
      "cell_type": "code",
      "source": [
        "# resultados de la prediccion\n",
        "y_pred_reg = search_reg.predict( X_test_reg )\n",
        "\n",
        "# evaluacion de la regresion\n",
        "evaluate(y_test_reg, y_pred_reg)\n",
        "\n",
        "print('Los mejores parametros del regresor son:', search_reg.best_params_)"
      ],
      "metadata": {
        "id": "rm3lCBgBa0gM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0c2f3b0-5171-47a0-b492-3266dd507012"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 1260778043487.012 \n",
            "\n",
            "RMSE: 1122843.730662024\n",
            "MAE: 225365.90775289663\n",
            "MedAE: 21619.284579773113 \n",
            "\n",
            "R²: 0.231664057714149\n",
            "Los mejores parametros del regresor son: {'Feature selection__percentile': 60, 'regresor': RandomForestRegressor(min_samples_split=4, n_estimators=300, random_state=42), 'regresor__min_samples_split': 4, 'regresor__n_estimators': 300}\n"
          ]
        }
      ],
      "id": "rm3lCBgBa0gM"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predicción sobre el conjunto de test"
      ],
      "metadata": {
        "id": "yx0LL91B5Rmt"
      },
      "id": "yx0LL91B5Rmt"
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediccion sobre el conjunto de test\n",
        "y_pred_test_clf = search_clf.predict(df_test2)\n",
        "\n",
        "y_pred_test_reg = search_reg.predict(df_test2)"
      ],
      "metadata": {
        "id": "6ksWNFRSQ90A"
      },
      "execution_count": null,
      "outputs": [],
      "id": "6ksWNFRSQ90A"
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## 5. Optimización del Modelo\n",
        "\n",
        "Para mejorar los modelos se tomaron en cuenta las variables de tipo texto que previamente no se tomaron en cuenta.\n",
        "Se eliminarion algunas variables que se cree que pueden empeorar el rendimiento del modelo.\n",
        "Para reducir el tiempo de cómputo de la grilla se redujo el espacio de búsqueda a pocos parámetros y soloamente se buscó la cantidad la cantidad de features a buscar en el modelo."
      ],
      "metadata": {
        "cell_id": "00024-97baa921-e984-460f-8c3f-2653d51eaba6",
        "deepnote_cell_type": "markdown",
        "id": "5L8iIkYD3pv3"
      },
      "id": "5L8iIkYD3pv3"
    },
    {
      "cell_type": "code",
      "source": [
        "# Librería Core del lab.\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.model_selection import train_test_split \n",
        "\n",
        "# Pre-procesamiento\n",
        "from sklearn.feature_selection import SelectPercentile, f_classif\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Clasifación\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "#Regresión\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Metricas de evaluación\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "# Librería para plotear\n",
        "!pip install --upgrade plotly\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# Proyecciones en baja dimensionalidad: UMAP\n",
        "!pip install umap-learn\n",
        "\n",
        "# Librería para NLP\n",
        "!pip install nltk\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize  \n",
        "from nltk.stem import PorterStemmer\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuPR6ez4Nax6",
        "outputId": "9f9a2ba1-2a19-408c-af09-c88ddd13b407"
      },
      "id": "VuPR6ez4Nax6",
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.8/dist-packages (5.11.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from plotly) (8.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting umap-learn\n",
            "  Downloading umap-learn-0.5.3.tar.gz (88 kB)\n",
            "\u001b[K     |████████████████████████████████| 88 kB 5.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from umap-learn) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.8/dist-packages (from umap-learn) (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.8/dist-packages (from umap-learn) (1.7.3)\n",
            "Requirement already satisfied: numba>=0.49 in /usr/local/lib/python3.8/dist-packages (from umap-learn) (0.56.4)\n",
            "Collecting pynndescent>=0.5\n",
            "  Downloading pynndescent-0.5.8.tar.gz (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 89.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from umap-learn) (4.64.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba>=0.49->umap-learn) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from numba>=0.49->umap-learn) (5.1.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba>=0.49->umap-learn) (0.39.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from pynndescent>=0.5->umap-learn) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.22->umap-learn) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->numba>=0.49->umap-learn) (3.11.0)\n",
            "Building wheels for collected packages: umap-learn, pynndescent\n",
            "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for umap-learn: filename=umap_learn-0.5.3-py3-none-any.whl size=82829 sha256=0b880a74a0db5ce89dd1bf9ff4b210f5c22cda79fd72f9eebb1eed39b03a7829\n",
            "  Stored in directory: /root/.cache/pip/wheels/a9/3a/67/06a8950e053725912e6a8c42c4a3a241410f6487b8402542ea\n",
            "  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pynndescent: filename=pynndescent-0.5.8-py3-none-any.whl size=55513 sha256=8fcbca624ff04ce53d81e3298a4d6bd30f87176f9b5126624b380190655aedd3\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/63/3a/29954bca1a27ba100ed8c27973a78cb71b43dc67aed62e80c3\n",
            "Successfully built umap-learn pynndescent\n",
            "Installing collected packages: pynndescent, umap-learn\n",
            "Successfully installed pynndescent-0.5.8 umap-learn-0.5.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (3.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk) (4.64.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk) (2022.6.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk) (1.2.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 217
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class StemmerTokenizer:\n",
        "    def __init__(self):\n",
        "        self.ps = PorterStemmer()\n",
        "    def __call__(self, doc):\n",
        "        doc_tok = word_tokenize(doc)\n",
        "        return [self.ps.stem(t) for t in doc_tok]"
      ],
      "metadata": {
        "id": "TSKQZj8BNlmT"
      },
      "id": "TSKQZj8BNlmT",
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxWwD0cbPVNw",
        "outputId": "3f13d982-dcd2-498a-d49d-3aeada4cba46"
      },
      "id": "KxWwD0cbPVNw",
      "execution_count": 321,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['name', 'release_date', 'english', 'developer', 'publisher',\n",
              "       'platforms', 'required_age', 'categories', 'genres', 'tags',\n",
              "       'achievements', 'average_playtime', 'price', 'short_description',\n",
              "       'estimated_sells', 'rating', 'release_month'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 321
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normalize_reg = [\n",
        "    'release_month',\n",
        "    'price'\n",
        "    ]\n",
        "\n",
        "normalize_clf = [\n",
        "    'required_age',\n",
        "    'price'\n",
        "]\n",
        "\n",
        "standardize_reg = [\n",
        "    'achievements',\n",
        "    'average_playtime'\n",
        "]\n",
        "\n",
        "standardize_clf = [\n",
        "    'average_playtime'\n",
        "]\n",
        "\n",
        "bow = CountVectorizer(\n",
        "    tokenizer = StemmerTokenizer(),\n",
        "    ngram_range = (1,2),\n",
        "    stop_words = [\";\"]\n",
        ")\n",
        "\n",
        "transformer_reg = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('Devs_bow', bow, 'developer'),\n",
        "        ('Pubs_bow', bow, 'publisher'),\n",
        "        ('Cat_bow', bow, 'categories'),\n",
        "        ('Genres_bow', bow, 'genres'),\n",
        "        ('tags_bow', bow, 'tags'),\n",
        "        ('MinMaxScaler', MinMaxScaler(), normalize_reg),\n",
        "        ('StandardScaler', StandardScaler(), standardize_reg)\n",
        "    ]\n",
        ")\n",
        "\n",
        "transformer_clf = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('Devs_bow', bow, 'developer'),\n",
        "        ('Pubs_bow', bow, 'publisher'),\n",
        "        ('Cat_bow', bow, 'categories'),\n",
        "        ('Genres_bow', bow, 'genres'),\n",
        "        ('tags_bow', bow, 'tags'),\n",
        "        ('MinMaxScaler', MinMaxScaler(), normalize_clf),\n",
        "        ('StandardScaler', StandardScaler(), standardize_clf)\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "FANiXyXQOW1P"
      },
      "id": "FANiXyXQOW1P",
      "execution_count": 322,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regressor_pipe = Pipeline([\n",
        "    ('Preprocessing', transformer_reg),\n",
        "    ('Feature selection', SelectPercentile(f_classif, percentile=90)),\n",
        "    ('Regressor', RandomForestRegressor())\n",
        "])\n",
        "\n",
        "classification_pipe = Pipeline([\n",
        "    ('Preprocessing', transformer_clf),\n",
        "    ('Feature selection', SelectPercentile(f_classif, percentile=90)),\n",
        "    ('Regressor', RandomForestClassifier())\n",
        "])"
      ],
      "metadata": {
        "id": "IIHWwUshQdOZ"
      },
      "id": "IIHWwUshQdOZ",
      "execution_count": 323,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_train.drop(['rating', 'estimated_sells'], axis=1)\n",
        "y_reg = df_train.estimated_sells\n",
        "y_clf = df_train.rating\n",
        "\n",
        "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
        "    X, y_reg, shuffle=True, test_size=0.3, random_state=33\n",
        ")\n",
        "\n",
        "X_train_clf, X_test_clf, y_train_clf, y_test_clf = train_test_split(\n",
        "    X, y_clf, shuffle=True, test_size=0.3, random_state=33\n",
        ")"
      ],
      "metadata": {
        "id": "93g6ORVaQ-xp"
      },
      "id": "93g6ORVaQ-xp",
      "execution_count": 324,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(y_test, y_pred):\n",
        "\n",
        "    print('MSE:', mean_squared_error(y_test, y_pred), '\\n')\n",
        "    print('RMSE:', mean_squared_error(y_test, y_pred, squared=False))\n",
        "    print('MAE:', mean_absolute_error(y_test, y_pred))\n",
        "    print('MedAE:', median_absolute_error(y_test, y_pred), '\\n')\n",
        "    print('R²:', r2_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "8i95HFJvVJw2"
      },
      "id": "8i95HFJvVJw2",
      "execution_count": 250,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params_reg = [\n",
        "    {\n",
        "    'Feature selection__percentile': [40, 60, 80],\n",
        "    'Regressor': [SVR(), RandomForestRegressor(random_state=42)],\n",
        "    }\n",
        "]\n",
        "\n",
        "search_reg = HalvingGridSearchCV(\n",
        "    regressor_pipe,\n",
        "    params_reg,\n",
        "    cv=3,\n",
        "    random_state=42,\n",
        "    verbose=10).fit(X_train_reg, y_train_reg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIS9LbDlYrHW",
        "outputId": "881e0c5c-c10a-4aeb-99a3-5222ddbd066d"
      },
      "id": "GIS9LbDlYrHW",
      "execution_count": 270,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_iterations: 2\n",
            "n_required_iterations: 2\n",
            "n_possible_iterations: 2\n",
            "min_resources_: 1838\n",
            "max_resources_: 5516\n",
            "aggressive_elimination: False\n",
            "factor: 3\n",
            "----------\n",
            "iter: 0\n",
            "n_candidates: 6\n",
            "n_resources: 1838\n",
            "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
            "[CV 1/3; 1/6] START Feature selection__percentile=40, Regressor=SVR()...........\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3; 1/6] END Feature selection__percentile=40, Regressor=SVR();, score=(train=nan, test=nan) total time=   3.3s\n",
            "[CV 2/3; 1/6] START Feature selection__percentile=40, Regressor=SVR()...........\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/3; 1/6] END Feature selection__percentile=40, Regressor=SVR();, score=(train=nan, test=nan) total time=   1.9s\n",
            "[CV 3/3; 1/6] START Feature selection__percentile=40, Regressor=SVR()...........\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 1/6] END Feature selection__percentile=40, Regressor=SVR();, score=(train=nan, test=nan) total time=   1.9s\n",
            "[CV 1/3; 2/6] START Feature selection__percentile=40, Regressor=RandomForestRegressor(random_state=42)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3; 2/6] END Feature selection__percentile=40, Regressor=RandomForestRegressor(random_state=42);, score=(train=nan, test=nan) total time=   1.9s\n",
            "[CV 2/3; 2/6] START Feature selection__percentile=40, Regressor=RandomForestRegressor(random_state=42)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/3; 2/6] END Feature selection__percentile=40, Regressor=RandomForestRegressor(random_state=42);, score=(train=nan, test=nan) total time=   2.0s\n",
            "[CV 3/3; 2/6] START Feature selection__percentile=40, Regressor=RandomForestRegressor(random_state=42)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 2/6] END Feature selection__percentile=40, Regressor=RandomForestRegressor(random_state=42);, score=(train=nan, test=nan) total time=   2.0s\n",
            "[CV 1/3; 3/6] START Feature selection__percentile=60, Regressor=SVR()...........\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3; 3/6] END Feature selection__percentile=60, Regressor=SVR();, score=(train=nan, test=nan) total time=   1.8s\n",
            "[CV 2/3; 3/6] START Feature selection__percentile=60, Regressor=SVR()...........\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/3; 3/6] END Feature selection__percentile=60, Regressor=SVR();, score=(train=nan, test=nan) total time=   1.8s\n",
            "[CV 3/3; 3/6] START Feature selection__percentile=60, Regressor=SVR()...........\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 3/6] END Feature selection__percentile=60, Regressor=SVR();, score=(train=nan, test=nan) total time=   1.8s\n",
            "[CV 1/3; 4/6] START Feature selection__percentile=60, Regressor=RandomForestRegressor(random_state=42)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3; 4/6] END Feature selection__percentile=60, Regressor=RandomForestRegressor(random_state=42);, score=(train=nan, test=nan) total time=   1.8s\n",
            "[CV 2/3; 4/6] START Feature selection__percentile=60, Regressor=RandomForestRegressor(random_state=42)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/3; 4/6] END Feature selection__percentile=60, Regressor=RandomForestRegressor(random_state=42);, score=(train=nan, test=nan) total time=   1.8s\n",
            "[CV 3/3; 4/6] START Feature selection__percentile=60, Regressor=RandomForestRegressor(random_state=42)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py:4009: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in subtract\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_base.py:96: UserWarning:\n",
            "\n",
            "No features were selected: either the data is too noisy or the selection test too strict.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 4/6] END Feature selection__percentile=60, Regressor=RandomForestRegressor(random_state=42);, score=(train=nan, test=nan) total time=   1.8s\n",
            "[CV 1/3; 5/6] START Feature selection__percentile=80, Regressor=SVR()...........\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3; 5/6] END Feature selection__percentile=80, Regressor=SVR();, score=(train=-0.010, test=-0.031) total time=   3.1s\n",
            "[CV 2/3; 5/6] START Feature selection__percentile=80, Regressor=SVR()...........\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/3; 5/6] END Feature selection__percentile=80, Regressor=SVR();, score=(train=-0.009, test=-0.024) total time=   3.1s\n",
            "[CV 3/3; 5/6] START Feature selection__percentile=80, Regressor=SVR()...........\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 5/6] END Feature selection__percentile=80, Regressor=SVR();, score=(train=-0.031, test=-0.007) total time=   3.0s\n",
            "[CV 1/3; 6/6] START Feature selection__percentile=80, Regressor=RandomForestRegressor(random_state=42)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3; 6/6] END Feature selection__percentile=80, Regressor=RandomForestRegressor(random_state=42);, score=(train=0.864, test=-0.113) total time=  18.6s\n",
            "[CV 2/3; 6/6] START Feature selection__percentile=80, Regressor=RandomForestRegressor(random_state=42)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/3; 6/6] END Feature selection__percentile=80, Regressor=RandomForestRegressor(random_state=42);, score=(train=0.870, test=0.162) total time=  18.4s\n",
            "[CV 3/3; 6/6] START Feature selection__percentile=80, Regressor=RandomForestRegressor(random_state=42)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 6/6] END Feature selection__percentile=80, Regressor=RandomForestRegressor(random_state=42);, score=(train=0.892, test=0.019) total time=  20.3s\n",
            "----------\n",
            "iter: 1\n",
            "n_candidates: 2\n",
            "n_resources: 5514\n",
            "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
            "[CV 1/3; 1/2] START Feature selection__percentile=60, Regressor=SVR()...........\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning:\n",
            "\n",
            "\n",
            "12 fits failed out of a total of 18.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "6 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\", line 394, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py\", line 190, in fit\n",
            "    X, y = self._validate_data(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/base.py\", line 581, in _validate_data\n",
            "    X, y = check_X_y(X, y, **check_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py\", line 964, in check_X_y\n",
            "    X = check_array(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py\", line 814, in check_array\n",
            "    raise ValueError(\n",
            "ValueError: Found array with 0 feature(s) (shape=(1225, 0)) while a minimum of 1 is required.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "6 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\", line 394, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py\", line 327, in fit\n",
            "    X, y = self._validate_data(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/base.py\", line 581, in _validate_data\n",
            "    X, y = check_X_y(X, y, **check_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py\", line 964, in check_X_y\n",
            "    X = check_array(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py\", line 814, in check_array\n",
            "    raise ValueError(\n",
            "ValueError: Found array with 0 feature(s) (shape=(1225, 0)) while a minimum of 1 is required.\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py:969: UserWarning:\n",
            "\n",
            "One or more of the test scores are non-finite: [        nan         nan         nan         nan -0.02070131  0.02261739]\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py:969: UserWarning:\n",
            "\n",
            "One or more of the train scores are non-finite: [        nan         nan         nan         nan -0.01665023  0.87518904]\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3; 1/2] END Feature selection__percentile=60, Regressor=SVR();, score=(train=-0.012, test=-0.034) total time=  12.2s\n",
            "[CV 2/3; 1/2] START Feature selection__percentile=60, Regressor=SVR()...........\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/3; 1/2] END Feature selection__percentile=60, Regressor=SVR();, score=(train=-0.011, test=-0.031) total time=  12.3s\n",
            "[CV 3/3; 1/2] START Feature selection__percentile=60, Regressor=SVR()...........\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 1/2] END Feature selection__percentile=60, Regressor=SVR();, score=(train=-0.033, test=-0.010) total time=  12.0s\n",
            "[CV 1/3; 2/2] START Feature selection__percentile=60, Regressor=RandomForestRegressor(random_state=42)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3; 2/2] END Feature selection__percentile=60, Regressor=RandomForestRegressor(random_state=42);, score=(train=0.873, test=-0.409) total time= 1.7min\n",
            "[CV 2/3; 2/2] START Feature selection__percentile=60, Regressor=RandomForestRegressor(random_state=42)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/3; 2/2] END Feature selection__percentile=60, Regressor=RandomForestRegressor(random_state=42);, score=(train=0.878, test=-0.401) total time= 1.4min\n",
            "[CV 3/3; 2/2] START Feature selection__percentile=60, Regressor=RandomForestRegressor(random_state=42)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3; 2/2] END Feature selection__percentile=60, Regressor=RandomForestRegressor(random_state=42);, score=(train=0.880, test=0.056) total time= 1.4min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py:969: UserWarning:\n",
            "\n",
            "One or more of the test scores are non-finite: [        nan         nan         nan         nan -0.02070131  0.02261739\n",
            " -0.02485879 -0.25137517]\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py:969: UserWarning:\n",
            "\n",
            "One or more of the train scores are non-finite: [        nan         nan         nan         nan -0.01665023  0.87518904\n",
            " -0.01845471  0.87683114]\n",
            "\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in true_divide\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params_clf = [\n",
        "    {\n",
        "    'Feature selection__percentile': [40, 60, 80],\n",
        "    'Regressor': [SVC(), RandomForestClassifier(random_state=42)],\n",
        "    }\n",
        "]\n",
        "\n",
        "search_clf = HalvingGridSearchCV(\n",
        "    regressor_pipe,\n",
        "    params_clf,\n",
        "    cv=3,\n",
        "    random_state=42,\n",
        "    verbose=10).fit(X_train_clf, y_train_clf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtepQuwhqHSn",
        "outputId": "bda9a3a1-9d41-4b0d-a0cf-08154e73857d"
      },
      "id": "DtepQuwhqHSn",
      "execution_count": 325,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_iterations: 2\n",
            "n_required_iterations: 2\n",
            "n_possible_iterations: 2\n",
            "min_resources_: 1838\n",
            "max_resources_: 5516\n",
            "aggressive_elimination: False\n",
            "factor: 3\n",
            "----------\n",
            "iter: 0\n",
            "n_candidates: 6\n",
            "n_resources: 1838\n",
            "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
            "[CV 1/3; 1/6] START Feature selection__percentile=40, Regressor=SVC()...........\n",
            "[CV 1/3; 1/6] END Feature selection__percentile=40, Regressor=SVC();, score=(train=0.674, test=0.312) total time=   2.6s\n",
            "[CV 2/3; 1/6] START Feature selection__percentile=40, Regressor=SVC()...........\n",
            "[CV 2/3; 1/6] END Feature selection__percentile=40, Regressor=SVC();, score=(train=0.676, test=0.319) total time=   2.5s\n",
            "[CV 3/3; 1/6] START Feature selection__percentile=40, Regressor=SVC()...........\n",
            "[CV 3/3; 1/6] END Feature selection__percentile=40, Regressor=SVC();, score=(train=0.652, test=0.268) total time=   2.6s\n",
            "[CV 1/3; 2/6] START Feature selection__percentile=40, Regressor=RandomForestClassifier(random_state=42)\n",
            "[CV 1/3; 2/6] END Feature selection__percentile=40, Regressor=RandomForestClassifier(random_state=42);, score=(train=1.000, test=0.325) total time=   2.7s\n",
            "[CV 2/3; 2/6] START Feature selection__percentile=40, Regressor=RandomForestClassifier(random_state=42)\n",
            "[CV 2/3; 2/6] END Feature selection__percentile=40, Regressor=RandomForestClassifier(random_state=42);, score=(train=1.000, test=0.286) total time=   2.7s\n",
            "[CV 3/3; 2/6] START Feature selection__percentile=40, Regressor=RandomForestClassifier(random_state=42)\n",
            "[CV 3/3; 2/6] END Feature selection__percentile=40, Regressor=RandomForestClassifier(random_state=42);, score=(train=1.000, test=0.283) total time=   2.6s\n",
            "[CV 1/3; 3/6] START Feature selection__percentile=60, Regressor=SVC()...........\n",
            "[CV 1/3; 3/6] END Feature selection__percentile=60, Regressor=SVC();, score=(train=0.718, test=0.324) total time=   2.6s\n",
            "[CV 2/3; 3/6] START Feature selection__percentile=60, Regressor=SVC()...........\n",
            "[CV 2/3; 3/6] END Feature selection__percentile=60, Regressor=SVC();, score=(train=0.727, test=0.314) total time=   2.5s\n",
            "[CV 3/3; 3/6] START Feature selection__percentile=60, Regressor=SVC()...........\n",
            "[CV 3/3; 3/6] END Feature selection__percentile=60, Regressor=SVC();, score=(train=0.700, test=0.276) total time=   2.5s\n",
            "[CV 1/3; 4/6] START Feature selection__percentile=60, Regressor=RandomForestClassifier(random_state=42)\n",
            "[CV 1/3; 4/6] END Feature selection__percentile=60, Regressor=RandomForestClassifier(random_state=42);, score=(train=1.000, test=0.335) total time=   2.7s\n",
            "[CV 2/3; 4/6] START Feature selection__percentile=60, Regressor=RandomForestClassifier(random_state=42)\n",
            "[CV 2/3; 4/6] END Feature selection__percentile=60, Regressor=RandomForestClassifier(random_state=42);, score=(train=1.000, test=0.306) total time=   2.7s\n",
            "[CV 3/3; 4/6] START Feature selection__percentile=60, Regressor=RandomForestClassifier(random_state=42)\n",
            "[CV 3/3; 4/6] END Feature selection__percentile=60, Regressor=RandomForestClassifier(random_state=42);, score=(train=1.000, test=0.320) total time=   2.7s\n",
            "[CV 1/3; 5/6] START Feature selection__percentile=80, Regressor=SVC()...........\n",
            "[CV 1/3; 5/6] END Feature selection__percentile=80, Regressor=SVC();, score=(train=0.700, test=0.340) total time=   2.7s\n",
            "[CV 2/3; 5/6] START Feature selection__percentile=80, Regressor=SVC()...........\n",
            "[CV 2/3; 5/6] END Feature selection__percentile=80, Regressor=SVC();, score=(train=0.671, test=0.317) total time=   2.7s\n",
            "[CV 3/3; 5/6] START Feature selection__percentile=80, Regressor=SVC()...........\n",
            "[CV 3/3; 5/6] END Feature selection__percentile=80, Regressor=SVC();, score=(train=0.666, test=0.296) total time=   2.7s\n",
            "[CV 1/3; 6/6] START Feature selection__percentile=80, Regressor=RandomForestClassifier(random_state=42)\n",
            "[CV 1/3; 6/6] END Feature selection__percentile=80, Regressor=RandomForestClassifier(random_state=42);, score=(train=1.000, test=0.337) total time=   2.7s\n",
            "[CV 2/3; 6/6] START Feature selection__percentile=80, Regressor=RandomForestClassifier(random_state=42)\n",
            "[CV 2/3; 6/6] END Feature selection__percentile=80, Regressor=RandomForestClassifier(random_state=42);, score=(train=1.000, test=0.324) total time=   4.1s\n",
            "[CV 3/3; 6/6] START Feature selection__percentile=80, Regressor=RandomForestClassifier(random_state=42)\n",
            "[CV 3/3; 6/6] END Feature selection__percentile=80, Regressor=RandomForestClassifier(random_state=42);, score=(train=1.000, test=0.304) total time=   3.5s\n",
            "----------\n",
            "iter: 1\n",
            "n_candidates: 2\n",
            "n_resources: 5514\n",
            "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
            "[CV 1/3; 1/2] START Feature selection__percentile=60, Regressor=RandomForestClassifier(random_state=42)\n",
            "[CV 1/3; 1/2] END Feature selection__percentile=60, Regressor=RandomForestClassifier(random_state=42);, score=(train=0.999, test=0.334) total time=   9.7s\n",
            "[CV 2/3; 1/2] START Feature selection__percentile=60, Regressor=RandomForestClassifier(random_state=42)\n",
            "[CV 2/3; 1/2] END Feature selection__percentile=60, Regressor=RandomForestClassifier(random_state=42);, score=(train=0.998, test=0.307) total time=  13.9s\n",
            "[CV 3/3; 1/2] START Feature selection__percentile=60, Regressor=RandomForestClassifier(random_state=42)\n",
            "[CV 3/3; 1/2] END Feature selection__percentile=60, Regressor=RandomForestClassifier(random_state=42);, score=(train=1.000, test=0.315) total time=  10.5s\n",
            "[CV 1/3; 2/2] START Feature selection__percentile=80, Regressor=RandomForestClassifier(random_state=42)\n",
            "[CV 1/3; 2/2] END Feature selection__percentile=80, Regressor=RandomForestClassifier(random_state=42);, score=(train=0.999, test=0.326) total time=   9.9s\n",
            "[CV 2/3; 2/2] START Feature selection__percentile=80, Regressor=RandomForestClassifier(random_state=42)\n",
            "[CV 2/3; 2/2] END Feature selection__percentile=80, Regressor=RandomForestClassifier(random_state=42);, score=(train=0.998, test=0.322) total time=  14.6s\n",
            "[CV 3/3; 2/2] START Feature selection__percentile=80, Regressor=RandomForestClassifier(random_state=42)\n",
            "[CV 3/3; 2/2] END Feature selection__percentile=80, Regressor=RandomForestClassifier(random_state=42);, score=(train=1.000, test=0.320) total time=  11.4s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_search_reg = search_reg.predict(X_test_reg)\n",
        "evaluate(y_test_reg, y_search_reg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sN-AK20clko6",
        "outputId": "ba2773f5-8fe8-4876-be9c-5cb22778285e"
      },
      "id": "sN-AK20clko6",
      "execution_count": 307,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 1681365069334.453 \n",
            "\n",
            "RMSE: 1296674.6196846967\n",
            "MAE: 211596.22982794192\n",
            "MedAE: 14488.033281318541 \n",
            "\n",
            "R²: -0.024647614659153882\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_search_clf = search_clf.predict(X_test_clf)\n",
        "print(classification_report(y_test_clf, y_search_clf))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krJ6mpWErN-Z",
        "outputId": "2baf46e8-b10b-4648-f338-57f6380a23b5"
      },
      "id": "krJ6mpWErN-Z",
      "execution_count": 326,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 precision    recall  f1-score   support\n",
            "\n",
            "          Mixed       0.32      0.26      0.29       497\n",
            "Mostly Positive       0.24      0.19      0.21       521\n",
            "       Negative       0.46      0.35      0.39       389\n",
            "       Positive       0.31      0.57      0.40       588\n",
            "  Very Positive       0.46      0.23      0.31       370\n",
            "\n",
            "       accuracy                           0.33      2365\n",
            "      macro avg       0.36      0.32      0.32      2365\n",
            "   weighted avg       0.35      0.33      0.32      2365\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_final_reg = search_reg.predict(df_test)\n",
        "y_final_clf = search_clf.predict(df_test)"
      ],
      "metadata": {
        "id": "tJCrqm_OVxRk"
      },
      "id": "tJCrqm_OVxRk",
      "execution_count": 344,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pudimos ver que el modelo mejora con respecto al baseline en clasificación pero empeora en regresión."
      ],
      "metadata": {
        "cell_id": "00026-033fd9c9-519f-4f04-9a92-18c61e7ad868",
        "deepnote_cell_type": "markdown",
        "id": "9AnXQBR4Aj8A"
      },
      "id": "9AnXQBR4Aj8A"
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## 6. Conclusiones"
      ],
      "metadata": {
        "cell_id": "00028-0df286d4-2014-4748-afd7-a47f04952db1",
        "deepnote_cell_type": "markdown",
        "id": "8LxwsT2f3pv3"
      },
      "id": "8LxwsT2f3pv3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "En base a los resultados obtenidos se puede concluir que el problema fue exitosamente resuelto, ya que los resultados obtenidos en la competencia superan ambos el baseline establecido.\n",
        "Por esto mismo, se consiera que los resultados obtenidos son aceptables en el contexto del problema.\n",
        "\n",
        "El rendimiento del baseline considera un valor de 0.23 de `f1-score weighted` con `r_2` de 0.23.\n",
        "En el baseline se realizó un enfoque distinto utilizando `bag of words`, dando un `f1-score weighted` de 0.32 y un `r_2` de -0.024.\n",
        "Con esto se puede ver que el resultado de la clasificación mejora, mientras que el de la regresión empeora.\n",
        "\n",
        "Los resultados obtenidos nos edjan conformes, ya que consideramos que se cumplieron las metas del curso, entendiendo y aplicando diversos conceptos para obtener obtener buenos resultados.\n",
        "También consideramos que enfoques más produndos de `NLP` y de análisis de variables pueden dar mejores resultados.\n",
        "En cuanto a la competencia establecida, si bien genera un estrés de cumplir cierta base, una vez alcanzado dicho nivel aporta a mejorar y ver el contexto de rendimiento de otras personas que están resolviendo el mismo problema.\n",
        "Los aprendizajes del proyecto fueron variados, partiendo aprender a analizar desde una perspectiva más global los datos, y pensando en el rendimiento del modelo en cada decisión tomada, lo cual permitió integrar muchos de los contenidos vistos en el curso.\n",
        "Entre los aprendizajes no obtenidos fueron análsis más profundos de NLP que permitieran un mejor rendimiento.\n",
        "\n",
        "\n",
        "<!-- Algunas respuestas que podrían plantearse pueden ser:\n",
        "\n",
        "- ¿Pudieron resolver exitosamente el problema?\n",
        "- ¿Son aceptables los resultados obtenidos?\n",
        "\n",
        "\n",
        "- ¿Como fue el rendimiento del baseline?\n",
        "- ¿Pudieron optimizar el baseline?\n",
        "- ¿Que tanto mejoro el baseline con respecto a sus optimizaciones?\n",
        "\n",
        "\n",
        "- ¿Estuvieron conformes con sus resultados?\n",
        "- ¿Creen que hayan mejores formas de modelar el problema?\n",
        "- ¿Creen que fue buena idea usar una competencia de por medio?\n",
        "- ¿En general, qué aprendieron en el pryecto?¿Qué no aprendieron y les gustaría haber aprendido?\n",
        "- Etc...\n",
        "\n",
        "**OJO** si usted decide responder parte de estas preguntas, debe redactarlas en un formato de informe y no responderlas directamente. -->"
      ],
      "metadata": {
        "cell_id": "00029-3e9c2b3c-3f41-4117-a85c-075e76c9697a",
        "deepnote_cell_type": "markdown",
        "id": "HnXM1nT83pv3"
      },
      "id": "HnXM1nT83pv3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "### Anexo: Generación de Archivo Submit de la Competencia"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00032-eccf6cec-1f5a-487c-94c0-f231fe261f8b",
        "deepnote_cell_type": "markdown",
        "id": "fT4HetBy3pv3"
      },
      "id": "fT4HetBy3pv3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para subir los resultados obtenidos a la pagina de CodaLab utilice la función `generateFiles` entregada mas abajo. Esto es debido a que usted deberá generar archivos que respeten extrictamente el formato de CodaLab, de lo contario los resultados no se veran reflejados en la pagina de la competencia.\n",
        "\n",
        "Para los resultados obtenidos en su modelo de clasificación y regresión, estos serán guardados en un archivo zip que contenga los archivos `predicctions_clf.txt` para la clasificación y `predicctions_rgr.clf` para la regresión. Los resultados, como se comento antes, deberan ser obtenidos en base al dataset `test.pickle` y en cada una de las lineas deberan presentar las predicciones realizadas.\n",
        "\n",
        "Ejemplos de archivos:\n",
        "\n",
        "- [ ] `predicctions_clf.txt`\n",
        "\n",
        "        Mostly Positive\n",
        "        Mostly Positive\n",
        "        Negative\n",
        "        Positive\n",
        "        Negative\n",
        "        Positive\n",
        "        ...\n",
        "\n",
        "- [ ] `predicctions_rgr.txt`\n",
        "\n",
        "        16103.58\n",
        "        16103.58\n",
        "        16041.89\n",
        "        9328.62\n",
        "        107976.03\n",
        "        194374.08\n",
        "        ...\n",
        "\n"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00032-86dd47d4-3847-4273-9ffd-596c9f8a130e",
        "deepnote_cell_type": "markdown",
        "id": "RzGwbHzr3pv3"
      },
      "id": "RzGwbHzr3pv3"
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "import os\n",
        "\n",
        "def generateFiles(predict_data, clf_pipe, rgr_pipe):\n",
        "    \"\"\"Genera los archivos a subir en CodaLab\n",
        "\n",
        "    Input\n",
        "    predict_data: Dataframe con los datos de entrada a predecir\n",
        "    clf_pipe: pipeline del clf\n",
        "    rgr_pipe: pipeline del rgr\n",
        "\n",
        "    Ouput\n",
        "    archivo de txt\n",
        "    \"\"\"\n",
        "    y_pred_clf = clf_pipe.predict(predict_data)\n",
        "    y_pred_rgr = rgr_pipe.predict(predict_data)\n",
        "    \n",
        "    with open('./predictions_clf.txt', 'w') as f:\n",
        "        for item in y_pred_clf:\n",
        "            f.write(\"%s\\n\" % item)\n",
        "\n",
        "    with open('./predictions_rgr.txt', 'w') as f:\n",
        "        for item in y_pred_rgr:\n",
        "            f.write(\"%s\\n\" % item)\n",
        "\n",
        "    with ZipFile('predictions.zip', 'w') as zipObj2:\n",
        "       zipObj2.write('predictions_rgr.txt')\n",
        "       zipObj2.write('predictions_clf.txt')\n",
        "\n",
        "    os.remove(\"predictions_rgr.txt\")\n",
        "    os.remove(\"predictions_clf.txt\")"
      ],
      "metadata": {
        "tags": [],
        "cell_id": "00029-0111b615-ba72-461a-aa17-1fe6ceb0ebd0",
        "deepnote_cell_type": "code",
        "id": "QknCpO5V3pv3"
      },
      "outputs": [],
      "execution_count": 349,
      "id": "QknCpO5V3pv3"
    },
    {
      "cell_type": "code",
      "source": [
        "generateFiles(df_test, search_clf, search_reg)"
      ],
      "metadata": {
        "id": "osk_J5FWs69z"
      },
      "id": "osk_J5FWs69z",
      "execution_count": 350,
      "outputs": []
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "deepnote_notebook_id": "cd4ffb8b-90a0-4648-9d80-2b8c0eef5325",
    "deepnote": {},
    "deepnote_execution_queue": [],
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "dHT7oe6E3pv1"
      ]
    }
  }
}